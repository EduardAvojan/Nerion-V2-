# Duplicate Prevention System

## Overview

The curriculum database now has **2-layer duplicate prevention** to ensure every lesson is truly unique:

1. **Name Uniqueness** - Database constraint
2. **Content Uniqueness** - Hash-based deduplication

## How It Works

### Layer 1: Name Uniqueness

- Database schema has `UNIQUE` constraint on `name` field
- Prevents two lessons from having the same name
- Example: Can't create both `a1_variable_scope_001` and `a1_variable_scope_001`

### Layer 2: Content Uniqueness

**Problem Solved**: 46 lessons had identical code but different names!

**Solution**: SHA256 hash-based content deduplication

#### Process:

1. **Code Normalization**: Before hashing, Python code is normalized:
   - Parse into Abstract Syntax Tree (AST)
   - Remove comments and docstrings
   - Normalize whitespace and indentation
   - Unparse back to canonical form

2. **Hash Calculation**: SHA256 hash of normalized `before_code + after_code + test_code`

3. **Duplicate Detection**: Before inserting, check if hash exists in database

4. **Rejection**: If content exists, reject the new lesson (even with different name)

#### Example:

```python
# These would be detected as duplicates:

# Lesson 1: "a1_greeting_001"
before_code = "def greet():\n    print('Hello')"
after_code = "def greet():\n    print('Hello!')"

# Lesson 2: "different_name_greeting"
before_code = "def greet():\n    print('Hello')"  # Same code!
after_code = "def greet():\n    print('Hello!')"  # Same code!
# ‚ùå REJECTED - Content hash matches Lesson 1
```

## Implementation

### Database Schema

```sql
CREATE TABLE lessons (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,              -- Layer 1: Name uniqueness
    description TEXT NOT NULL,
    focus_area TEXT,
    before_code TEXT NOT NULL,
    after_code TEXT NOT NULL,
    test_code TEXT NOT NULL,
    content_hash TEXT,                      -- Layer 2: Content uniqueness
    timestamp TEXT NOT NULL
);

CREATE INDEX idx_lessons_content_hash ON lessons(content_hash);
```

### SafeCurriculumDB API

```python
from nerion_digital_physicist.db.safe_curriculum import SafeCurriculumDB

with SafeCurriculumDB() as db:
    # Check if name exists
    if db.lesson_exists("a1_example_001"):
        print("Name already taken")

    # Check if content exists
    exists, existing_name = db.content_exists(
        before_code="...",
        after_code="...",
        test_code="..."
    )
    if exists:
        print(f"Content already exists as: {existing_name}")

    # Add lesson (automatically checks both)
    success = db.add_lesson(
        name="a1_example_001",
        description="...",
        focus_area="a1",
        before_code="...",
        after_code="...",
        test_code="..."
    )

    if not success:
        print("Lesson rejected (duplicate name or content)")
```

## Migration History

### October 9, 2025: Initial Implementation

**Before**:
- 523 lessons in database
- Only name uniqueness enforced
- 46 duplicate lessons with identical code

**Actions**:
1. Added `content_hash` column to lessons table
2. Calculated SHA256 hash for all 523 lessons
3. Identified 1 duplicate group with 47 identical lessons
4. Removed 46 duplicates, kept oldest
5. Created index on `content_hash` for fast lookups

**After**:
- 477 unique lessons
- Both name and content uniqueness enforced
- Zero duplicates

### Duplicate Group Found

All 47 lessons below had **identical code** (empty placeholder):

- `offline_security_hardening` (KEPT - oldest, 2025-09-28)
- `asynchronous_processing_with_status_polling_and_webhooks` (removed)
- `cqrs_pattern` (removed)
- `instrumenting_with_high_cardinality_context` (removed)
- ... (43 more removed)

## Scripts

### Migration
```bash
python scripts/migrate_add_content_hash.py
```
- Adds `content_hash` column
- Calculates hashes for existing lessons
- Reports duplicate groups

### Cleanup
```bash
python scripts/remove_duplicate_lessons.py
```
- Removes duplicate content
- Keeps oldest lesson in each duplicate group
- Creates backup before deletion

## Validation

### Test Results

```bash
$ python test_duplicate_prevention.py

1Ô∏è‚É£ Adding original lesson... ‚úÖ Added
2Ô∏è‚É£ Testing duplicate NAME... ‚ùå Rejected (EXPECTED)
3Ô∏è‚É£ Testing duplicate CONTENT... ‚ùå Rejected (EXPECTED)
4Ô∏è‚É£ Content exists check... ‚úÖ Found existing
5Ô∏è‚É£ Adding unique lesson... ‚úÖ Added (EXPECTED)
```

### Current Status

```bash
$ sqlite3 out/learning/curriculum.sqlite "
  SELECT COUNT(*) as total,
         COUNT(DISTINCT content_hash) as unique_content
  FROM lessons"

477|477  # All lessons have unique content!
```

## Benefits

### For Developers
- **No wasted effort**: Can't accidentally create duplicate lessons
- **Instant feedback**: Immediate rejection with existing lesson name
- **Clear warnings**: Logs show exactly why lesson was rejected

### For Database
- **Data quality**: 100% unique lessons
- **No bloat**: No duplicate content wasting space
- **Fast queries**: Index on content_hash for O(1) lookups

### For Training
- **Better diversity**: GNN model trains on truly unique examples
- **Accurate metrics**: Lesson count reflects actual variety
- **No redundancy**: Every lesson teaches something different

## CERF Agent Integration

All 6 CERF agents now have duplicate prevention warnings:

```markdown
## Critical Rules
- **‚ö†Ô∏è DUPLICATE PREVENTION**: The database prevents BOTH:
  - Duplicate names (UNIQUE constraint)
  - Duplicate content (SHA256 hash of code) - **Even with different names!**
```

When agents attempt duplicates:
1. SafeCurriculumDB checks name uniqueness
2. SafeCurriculumDB checks content hash
3. Returns `False` if duplicate detected
4. Logs warning with reason for rejection

## Technical Details

### Hash Algorithm

**SHA256** chosen because:
- Cryptographically secure (collision-resistant)
- Fast computation (< 1ms per lesson)
- 64-character hex string (compact storage)
- Industry standard

### Normalization Strategy

Uses Python's `ast.parse()` and `ast.unparse()`:
- **Handles**: Comments, whitespace, docstrings, formatting
- **Preserves**: Logic, semantics, structure
- **Catches**: Identical lessons with different formatting

Example:
```python
# These normalize to the same hash:

# Version 1 (with comments)
def greet():
    # Say hello
    print("Hello")

# Version 2 (different formatting)
def greet():
    print("Hello")

# ‚úÖ Both produce same content_hash
```

### Edge Cases Handled

1. **AST parse failure**: Falls back to whitespace normalization
2. **Null content_hash**: Old lessons without hash are migrated
3. **Index performance**: O(1) hash lookup via database index
4. **Backup before cleanup**: Duplicate removal creates backup first

## Future Enhancements

Potential improvements:

1. **Semantic similarity**: Use embeddings to detect "similar but not identical" lessons
2. **Fuzzy matching**: Catch lessons with minor variations (e.g., variable renames)
3. **Similarity scoring**: Report lessons that are 90%+ similar
4. **Cross-table dedup**: Check for duplicates across bug_fixes, features, etc.

## Monitoring

Check for duplicates at any time:

```bash
# Find any duplicate content (should return empty)
sqlite3 out/learning/curriculum.sqlite "
  SELECT content_hash, COUNT(*) as cnt, GROUP_CONCAT(name) as lessons
  FROM lessons
  GROUP BY content_hash
  HAVING cnt > 1"

# Verify all lessons have hashes
sqlite3 out/learning/curriculum.sqlite "
  SELECT COUNT(*) FROM lessons WHERE content_hash IS NULL"
# Should return: 0
```

## Summary

‚úÖ **477 unique lessons** (down from 523)
‚úÖ **46 duplicates removed** (all had identical code)
‚úÖ **2-layer protection** (name + content)
‚úÖ **100% tested** (all tests pass)
‚úÖ **All agents updated** (6 CERF agents aware)
‚úÖ **Fully documented** (this guide + DATABASE_PROTECTION.md)

**The curriculum database now guarantees every lesson is truly unique!** üéâ
