{
  "mined_at": "2025-11-25T21:27:33.789293",
  "total_bugs": 87,
  "bugs": [
    {
      "bug_id": "a357384087aa",
      "repo": "flask",
      "commit_hash": "fb54159",
      "commit_message": "secret key rotation: fix key list ordering",
      "file_path": "src/flask/sessions.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport collections.abc as c\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\nclass SessionMixin(MutableMapping[str, t.Any]):\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\nclass SecureCookieSession(CallbackDict[str, t.Any], SessionMixin):\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(\n        self,\n        initial: c.Mapping[str, t.Any] | c.Iterable[tuple[str, t.Any]] | None = None,\n    ) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # type: ignore # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n    The session object returned by the :meth:`open_session` method has to\n    provide a dictionary like interface plus the properties and methods\n    from the :class:`SessionMixin`.  We recommend just subclassing a dict\n    and adding that mixin::\n\n        class Session(dict, SessionMixin):\n            pass\n\n    If :meth:`open_session` returns ``None`` Flask will call into\n    :meth:`make_null_session` to create a session that acts as replacement\n    if the session support cannot work because some requirement is not\n    fulfilled.  The default :class:`NullSession` class that is created\n    will complain that the secret key was not set.\n\n    To replace the session interface on an application all you have to do\n    is to assign :attr:`flask.Flask.session_interface`::\n\n        app = Flask(__name__)\n        app.session_interface = MySessionInterface()\n\n    Multiple requests with the same session may be sent and handled\n    concurrently. When implementing a new session interface, consider\n    whether reads or writes to the backing store must be synchronized.\n    There is no guarantee on the order in which the session for each\n    request is opened or saved, it will occur in the order that requests\n    begin and end processing.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    #: :meth:`make_null_session` will look here for the class that should\n    #: be created when a null session is requested.  Likewise the\n    #: :meth:`is_null_session` method will perform a typecheck against\n    #: this type.\n    null_session_class = NullSession\n\n    #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by Flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n\n    def make_null_session(self, app: Flask) -> NullSession:\n        \"\"\"Creates a null session which acts as a replacement object if the\n        real session support could not be loaded due to a configuration\n        error.  This mainly aids the user experience because the job of the\n        null session is to still support lookup without complaining but\n        modifications are answered with a helpful error message of what\n        failed.\n\n        This creates an instance of :attr:`null_session_class` by default.\n        \"\"\"\n        return self.null_session_class()\n\n    def is_null_session(self, obj: object) -> bool:\n        \"\"\"Checks if a given object is a null session.  Null sessions are\n        not asked to be saved.\n\n        This checks if the object is an instance of :attr:`null_session_class`\n        by default.\n        \"\"\"\n        return isinstance(obj, self.null_session_class)\n\n    def get_cookie_name(self, app: Flask) -> str:\n        \"\"\"The name of the session cookie. Uses``app.config[\"SESSION_COOKIE_NAME\"]``.\"\"\"\n        return app.config[\"SESSION_COOKIE_NAME\"]  # type: ignore[no-any-return]\n\n    def get_cookie_domain(self, app: Flask) -> str | None:\n        \"\"\"The value of the ``Domain`` parameter on the session cookie. If not set,\n        browsers will only send the cookie to the exact domain it was set from.\n        Otherwise, they will send it to any subdomain of the given value as well.\n\n        Uses the :data:`SESSION_COOKIE_DOMAIN` config.\n\n        .. versionchanged:: 2.3\n            Not set by default, does not fall back to ``SERVER_NAME``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_DOMAIN\"]  # type: ignore[no-any-return]\n\n    def get_cookie_path(self, app: Flask) -> str:\n        \"\"\"Returns the path for which the cookie should be valid.  The\n        default implementation uses the value from the ``SESSION_COOKIE_PATH``\n        config var if it's set, and falls back to ``APPLICATION_ROOT`` or\n        uses ``/`` if it's ``None``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PATH\"] or app.config[\"APPLICATION_ROOT\"]  # type: ignore[no-any-return]\n\n    def get_cookie_httponly(self, app: Flask) -> bool:\n        \"\"\"Returns True if the session cookie should be httponly.  This\n        currently just returns the value of the ``SESSION_COOKIE_HTTPONLY``\n        config var.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_HTTPONLY\"]  # type: ignore[no-any-return]\n\n    def get_cookie_secure(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be secure.  This currently\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SECURE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_samesite(self, app: Flask) -> str | None:\n        \"\"\"Return ``'Strict'`` or ``'Lax'`` if the cookie should use the\n        ``SameSite`` attribute. This currently just returns the value of\n        the :data:`SESSION_COOKIE_SAMESITE` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SAMESITE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_partitioned(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be partitioned. By default, uses\n        the value of :data:`SESSION_COOKIE_PARTITIONED`.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PARTITIONED\"]  # type: ignore[no-any-return]\n\n    def get_expiration_time(self, app: Flask, session: SessionMixin) -> datetime | None:\n        \"\"\"A helper method that returns an expiration date for the session\n        or ``None`` if the session is linked to the browser session.  The\n        default implementation returns now + the permanent session\n        lifetime configured on the application.\n        \"\"\"\n        if session.permanent:\n            return datetime.now(timezone.utc) + app.permanent_session_lifetime\n        return None\n\n    def should_set_cookie(self, app: Flask, session: SessionMixin) -> bool:\n        \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n        should be set for this session cookie for this response. If the session\n        has been modified, the cookie is set. If the session is permanent and\n        the ``SESSION_REFRESH_EACH_REQUEST`` config is true, the cookie is\n        always set.\n\n        This check is usually skipped if the session was deleted.\n\n        .. versionadded:: 0.11\n        \"\"\"\n\n        return session.modified or (\n            session.permanent and app.config[\"SESSION_REFRESH_EACH_REQUEST\"]\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SessionMixin | None:\n        \"\"\"This is called at the beginning of each request, after\n        pushing the request context, before matching the URL.\n\n        This must return an object which implements a dictionary-like\n        interface as well as the :class:`SessionMixin` interface.\n\n        This will return ``None`` to indicate that loading failed in\n        some way that is not immediately an error. The request\n        context will fall back to using :meth:`make_null_session`\n        in this case.\n        \"\"\"\n        raise NotImplementedError()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, after generating\n        a response, before removing the request context. It is skipped\n        if :meth:`is_null_session` returns ``True``.\n        \"\"\"\n        raise NotImplementedError()\n\n\nsession_json_serializer = TaggedJSONSerializer()\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass SecureCookieSessionInterface(SessionInterface):\n    \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.\n    salt = \"cookie-session\"\n    #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(_lazy_sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = \"hmac\"\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.\n    serializer = session_json_serializer\n    session_class = SecureCookieSession\n\n    def get_signing_serializer(self, app: Flask) -> URLSafeTimedSerializer | None:\n        if not app.secret_key:\n            return None\n\n        keys: list[str | bytes] = [app.secret_key]\n\n        if fallbacks := app.config[\"SECRET_KEY_FALLBACKS\"]:\n            keys.extend(fallbacks)\n\n        return URLSafeTimedSerializer(\n            keys,  # type: ignore[arg-type]\n            salt=self.salt,\n            serializer=self.serializer,\n            signer_kwargs={\n                \"key_derivation\": self.key_derivation,\n                \"digest_method\": self.digest_method,\n            },\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SecureCookieSession | None:\n        s = self.get_signing_serializer(app)\n        if s is None:\n            return None\n        val = request.cookies.get(self.get_cookie_name(app))\n        if not val:\n            return self.session_class()\n        max_age = int(app.permanent_session_lifetime.total_seconds())\n        try:\n            data = s.loads(val, max_age=max_age)\n            return self.session_class(data)\n        except BadSignature:\n            return self.session_class()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        name = self.get_cookie_name(app)\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        secure = self.get_cookie_secure(app)\n        partitioned = self.get_cookie_partitioned(app)\n        samesite = self.get_cookie_samesite(app)\n        httponly = self.get_cookie_httponly(app)\n\n        # Add a \"Vary: Cookie\" header if the session was accessed at all.\n        if session.accessed:\n            response.vary.add(\"Cookie\")\n\n        # If the session is modified to be empty, remove the cookie.\n        # If the session is empty, return without setting the cookie.\n        if not session:\n            if session.modified:\n                response.delete_cookie(\n                    name,\n                    domain=domain,\n                    path=path,\n                    secure=secure,\n                    partitioned=partitioned,\n                    samesite=samesite,\n                    httponly=httponly,\n                )\n                response.vary.add(\"Cookie\")\n\n            return\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        expires = self.get_expiration_time(app, session)\n        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore[union-attr]\n        response.set_cookie(\n            name,\n            val,\n            expires=expires,\n            httponly=httponly,\n            domain=domain,\n            path=path,\n            secure=secure,\n            partitioned=partitioned,\n            samesite=samesite,\n        )\n        response.vary.add(\"Cookie\")\n",
      "code_after": "from __future__ import annotations\n\nimport collections.abc as c\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\nclass SessionMixin(MutableMapping[str, t.Any]):\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\nclass SecureCookieSession(CallbackDict[str, t.Any], SessionMixin):\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(\n        self,\n        initial: c.Mapping[str, t.Any] | c.Iterable[tuple[str, t.Any]] | None = None,\n    ) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # type: ignore # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n    The session object returned by the :meth:`open_session` method has to\n    provide a dictionary like interface plus the properties and methods\n    from the :class:`SessionMixin`.  We recommend just subclassing a dict\n    and adding that mixin::\n\n        class Session(dict, SessionMixin):\n            pass\n\n    If :meth:`open_session` returns ``None`` Flask will call into\n    :meth:`make_null_session` to create a session that acts as replacement\n    if the session support cannot work because some requirement is not\n    fulfilled.  The default :class:`NullSession` class that is created\n    will complain that the secret key was not set.\n\n    To replace the session interface on an application all you have to do\n    is to assign :attr:`flask.Flask.session_interface`::\n\n        app = Flask(__name__)\n        app.session_interface = MySessionInterface()\n\n    Multiple requests with the same session may be sent and handled\n    concurrently. When implementing a new session interface, consider\n    whether reads or writes to the backing store must be synchronized.\n    There is no guarantee on the order in which the session for each\n    request is opened or saved, it will occur in the order that requests\n    begin and end processing.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    #: :meth:`make_null_session` will look here for the class that should\n    #: be created when a null session is requested.  Likewise the\n    #: :meth:`is_null_session` method will perform a typecheck against\n    #: this type.\n    null_session_class = NullSession\n\n    #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by Flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n\n    def make_null_session(self, app: Flask) -> NullSession:\n        \"\"\"Creates a null session which acts as a replacement object if the\n        real session support could not be loaded due to a configuration\n        error.  This mainly aids the user experience because the job of the\n        null session is to still support lookup without complaining but\n        modifications are answered with a helpful error message of what\n        failed.\n\n        This creates an instance of :attr:`null_session_class` by default.\n        \"\"\"\n        return self.null_session_class()\n\n    def is_null_session(self, obj: object) -> bool:\n        \"\"\"Checks if a given object is a null session.  Null sessions are\n        not asked to be saved.\n\n        This checks if the object is an instance of :attr:`null_session_class`\n        by default.\n        \"\"\"\n        return isinstance(obj, self.null_session_class)\n\n    def get_cookie_name(self, app: Flask) -> str:\n        \"\"\"The name of the session cookie. Uses``app.config[\"SESSION_COOKIE_NAME\"]``.\"\"\"\n        return app.config[\"SESSION_COOKIE_NAME\"]  # type: ignore[no-any-return]\n\n    def get_cookie_domain(self, app: Flask) -> str | None:\n        \"\"\"The value of the ``Domain`` parameter on the session cookie. If not set,\n        browsers will only send the cookie to the exact domain it was set from.\n        Otherwise, they will send it to any subdomain of the given value as well.\n\n        Uses the :data:`SESSION_COOKIE_DOMAIN` config.\n\n        .. versionchanged:: 2.3\n            Not set by default, does not fall back to ``SERVER_NAME``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_DOMAIN\"]  # type: ignore[no-any-return]\n\n    def get_cookie_path(self, app: Flask) -> str:\n        \"\"\"Returns the path for which the cookie should be valid.  The\n        default implementation uses the value from the ``SESSION_COOKIE_PATH``\n        config var if it's set, and falls back to ``APPLICATION_ROOT`` or\n        uses ``/`` if it's ``None``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PATH\"] or app.config[\"APPLICATION_ROOT\"]  # type: ignore[no-any-return]\n\n    def get_cookie_httponly(self, app: Flask) -> bool:\n        \"\"\"Returns True if the session cookie should be httponly.  This\n        currently just returns the value of the ``SESSION_COOKIE_HTTPONLY``\n        config var.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_HTTPONLY\"]  # type: ignore[no-any-return]\n\n    def get_cookie_secure(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be secure.  This currently\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SECURE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_samesite(self, app: Flask) -> str | None:\n        \"\"\"Return ``'Strict'`` or ``'Lax'`` if the cookie should use the\n        ``SameSite`` attribute. This currently just returns the value of\n        the :data:`SESSION_COOKIE_SAMESITE` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SAMESITE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_partitioned(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be partitioned. By default, uses\n        the value of :data:`SESSION_COOKIE_PARTITIONED`.\n\n        .. versionadded:: 3.1\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PARTITIONED\"]  # type: ignore[no-any-return]\n\n    def get_expiration_time(self, app: Flask, session: SessionMixin) -> datetime | None:\n        \"\"\"A helper method that returns an expiration date for the session\n        or ``None`` if the session is linked to the browser session.  The\n        default implementation returns now + the permanent session\n        lifetime configured on the application.\n        \"\"\"\n        if session.permanent:\n            return datetime.now(timezone.utc) + app.permanent_session_lifetime\n        return None\n\n    def should_set_cookie(self, app: Flask, session: SessionMixin) -> bool:\n        \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n        should be set for this session cookie for this response. If the session\n        has been modified, the cookie is set. If the session is permanent and\n        the ``SESSION_REFRESH_EACH_REQUEST`` config is true, the cookie is\n        always set.\n\n        This check is usually skipped if the session was deleted.\n\n        .. versionadded:: 0.11\n        \"\"\"\n\n        return session.modified or (\n            session.permanent and app.config[\"SESSION_REFRESH_EACH_REQUEST\"]\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SessionMixin | None:\n        \"\"\"This is called at the beginning of each request, after\n        pushing the request context, before matching the URL.\n\n        This must return an object which implements a dictionary-like\n        interface as well as the :class:`SessionMixin` interface.\n\n        This will return ``None`` to indicate that loading failed in\n        some way that is not immediately an error. The request\n        context will fall back to using :meth:`make_null_session`\n        in this case.\n        \"\"\"\n        raise NotImplementedError()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, after generating\n        a response, before removing the request context. It is skipped\n        if :meth:`is_null_session` returns ``True``.\n        \"\"\"\n        raise NotImplementedError()\n\n\nsession_json_serializer = TaggedJSONSerializer()\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass SecureCookieSessionInterface(SessionInterface):\n    \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.\n    salt = \"cookie-session\"\n    #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(_lazy_sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = \"hmac\"\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.\n    serializer = session_json_serializer\n    session_class = SecureCookieSession\n\n    def get_signing_serializer(self, app: Flask) -> URLSafeTimedSerializer | None:\n        if not app.secret_key:\n            return None\n\n        keys: list[str | bytes] = []\n\n        if fallbacks := app.config[\"SECRET_KEY_FALLBACKS\"]:\n            keys.extend(fallbacks)\n\n        keys.append(app.secret_key)  # itsdangerous expects current key at top\n        return URLSafeTimedSerializer(\n            keys,  # type: ignore[arg-type]\n            salt=self.salt,\n            serializer=self.serializer,\n            signer_kwargs={\n                \"key_derivation\": self.key_derivation,\n                \"digest_method\": self.digest_method,\n            },\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SecureCookieSession | None:\n        s = self.get_signing_serializer(app)\n        if s is None:\n            return None\n        val = request.cookies.get(self.get_cookie_name(app))\n        if not val:\n            return self.session_class()\n        max_age = int(app.permanent_session_lifetime.total_seconds())\n        try:\n            data = s.loads(val, max_age=max_age)\n            return self.session_class(data)\n        except BadSignature:\n            return self.session_class()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        name = self.get_cookie_name(app)\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        secure = self.get_cookie_secure(app)\n        partitioned = self.get_cookie_partitioned(app)\n        samesite = self.get_cookie_samesite(app)\n        httponly = self.get_cookie_httponly(app)\n\n        # Add a \"Vary: Cookie\" header if the session was accessed at all.\n        if session.accessed:\n            response.vary.add(\"Cookie\")\n\n        # If the session is modified to be empty, remove the cookie.\n        # If the session is empty, return without setting the cookie.\n        if not session:\n            if session.modified:\n                response.delete_cookie(\n                    name,\n                    domain=domain,\n                    path=path,\n                    secure=secure,\n                    partitioned=partitioned,\n                    samesite=samesite,\n                    httponly=httponly,\n                )\n                response.vary.add(\"Cookie\")\n\n            return\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        expires = self.get_expiration_time(app, session)\n        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore[union-attr]\n        response.set_cookie(\n            name,\n            val,\n            expires=expires,\n            httponly=httponly,\n            domain=domain,\n            path=path,\n            secure=secure,\n            partitioned=partitioned,\n            samesite=samesite,\n        )\n        response.vary.add(\"Cookie\")\n",
      "bug_category": "secret",
      "error_type": "secret_management",
      "confidence": 1.0
    },
    {
      "bug_id": "ce3ea4e3d6a9",
      "repo": "flask",
      "commit_hash": "54c3f87",
      "commit_message": "fix type hint for `cli_runner.invoke`",
      "file_path": "src/flask/testing.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport importlib.metadata\nimport typing as t\nfrom contextlib import contextmanager\nfrom contextlib import ExitStack\nfrom copy import copy\nfrom types import TracebackType\nfrom urllib.parse import urlsplit\n\nimport werkzeug.test\nfrom click.testing import CliRunner\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Request as BaseRequest\n\nfrom .cli import ScriptInfo\nfrom .sessions import SessionMixin\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIEnvironment\n    from werkzeug.test import TestResponse\n\n    from .app import Flask\n\n\nclass EnvironBuilder(werkzeug.test.EnvironBuilder):\n    \"\"\"An :class:`~werkzeug.test.EnvironBuilder`, that takes defaults from the\n    application.\n\n    :param app: The Flask application to configure the environment from.\n    :param path: URL path being requested.\n    :param base_url: Base URL where the app is being served, which\n        ``path`` is relative to. If not given, built from\n        :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n        :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n    :param subdomain: Subdomain name to append to :data:`SERVER_NAME`.\n    :param url_scheme: Scheme to use instead of\n        :data:`PREFERRED_URL_SCHEME`.\n    :param json: If given, this is serialized as JSON and passed as\n        ``data``. Also defaults ``content_type`` to\n        ``application/json``.\n    :param args: other positional arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    :param kwargs: other keyword arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: Flask,\n        path: str = \"/\",\n        base_url: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str | None = None,\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> None:\n        assert not (base_url or subdomain or url_scheme) or (\n            base_url is not None\n        ) != bool(\n            subdomain or url_scheme\n        ), 'Cannot pass \"subdomain\" or \"url_scheme\" with \"base_url\".'\n\n        if base_url is None:\n            http_host = app.config.get(\"SERVER_NAME\") or \"localhost\"\n            app_root = app.config[\"APPLICATION_ROOT\"]\n\n            if subdomain:\n                http_host = f\"{subdomain}.{http_host}\"\n\n            if url_scheme is None:\n                url_scheme = app.config[\"PREFERRED_URL_SCHEME\"]\n\n            url = urlsplit(path)\n            base_url = (\n                f\"{url.scheme or url_scheme}://{url.netloc or http_host}\"\n                f\"/{app_root.lstrip('/')}\"\n            )\n            path = url.path\n\n            if url.query:\n                path = f\"{path}?{url.query}\"\n\n        self.app = app\n        super().__init__(path, base_url, *args, **kwargs)\n\n    def json_dumps(self, obj: t.Any, **kwargs: t.Any) -> str:  # type: ignore\n        \"\"\"Serialize ``obj`` to a JSON-formatted string.\n\n        The serialization will be configured according to the config associated\n        with this EnvironBuilder's ``app``.\n        \"\"\"\n        return self.app.json.dumps(obj, **kwargs)\n\n\n_werkzeug_version = \"\"\n\n\ndef _get_werkzeug_version() -> str:\n    global _werkzeug_version\n\n    if not _werkzeug_version:\n        _werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    return _werkzeug_version\n\n\nclass FlaskClient(Client):\n    \"\"\"Works like a regular Werkzeug test client but has knowledge about\n    Flask's contexts to defer the cleanup of the request context until\n    the end of a ``with`` block. For general information about how to\n    use this class refer to :class:`werkzeug.test.Client`.\n\n    .. versionchanged:: 0.12\n       `app.test_client()` includes preset default environment, which can be\n       set after instantiation of the `app.test_client()` object in\n       `client.environ_base`.\n\n    Basic usage is outlined in the :doc:`/testing` chapter.\n    \"\"\"\n\n    application: Flask\n\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        super().__init__(*args, **kwargs)\n        self.preserve_context = False\n        self._new_contexts: list[t.ContextManager[t.Any]] = []\n        self._context_stack = ExitStack()\n        self.environ_base = {\n            \"REMOTE_ADDR\": \"127.0.0.1\",\n            \"HTTP_USER_AGENT\": f\"Werkzeug/{_get_werkzeug_version()}\",\n        }\n\n    @contextmanager\n    def session_transaction(\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Iterator[SessionMixin]:\n        \"\"\"When used in combination with a ``with`` statement this opens a\n        session transaction.  This can be used to modify the session that\n        the test client uses.  Once the ``with`` block is left the session is\n        stored back.\n\n        ::\n\n            with client.session_transaction() as session:\n                session['value'] = 42\n\n        Internally this is implemented by going through a temporary test\n        request context and since session handling could depend on\n        request variables this function accepts the same arguments as\n        :meth:`~flask.Flask.test_request_context` which are directly\n        passed through.\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        app = self.application\n        ctx = app.test_request_context(*args, **kwargs)\n        self._add_cookies_to_wsgi(ctx.request.environ)\n\n        with ctx:\n            sess = app.session_interface.open_session(app, ctx.request)\n\n        if sess is None:\n            raise RuntimeError(\"Session backend did not open a session.\")\n\n        yield sess\n        resp = app.response_class()\n\n        if app.session_interface.is_null_session(sess):\n            return\n\n        with ctx:\n            app.session_interface.save_session(app, sess, resp)\n\n        self._update_cookies_from_response(\n            ctx.request.host.partition(\":\")[0],\n            ctx.request.path,\n            resp.headers.getlist(\"Set-Cookie\"),\n        )\n\n    def _copy_environ(self, other: WSGIEnvironment) -> WSGIEnvironment:\n        out = {**self.environ_base, **other}\n\n        if self.preserve_context:\n            out[\"werkzeug.debug.preserve_context\"] = self._new_contexts.append\n\n        return out\n\n    def _request_from_builder_args(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> BaseRequest:\n        kwargs[\"environ_base\"] = self._copy_environ(kwargs.get(\"environ_base\", {}))\n        builder = EnvironBuilder(self.application, *args, **kwargs)\n\n        try:\n            return builder.get_request()\n        finally:\n            builder.close()\n\n    def open(\n        self,\n        *args: t.Any,\n        buffered: bool = False,\n        follow_redirects: bool = False,\n        **kwargs: t.Any,\n    ) -> TestResponse:\n        if args and isinstance(\n            args[0], (werkzeug.test.EnvironBuilder, dict, BaseRequest)\n        ):\n            if isinstance(args[0], werkzeug.test.EnvironBuilder):\n                builder = copy(args[0])\n                builder.environ_base = self._copy_environ(builder.environ_base or {})  # type: ignore[arg-type]\n                request = builder.get_request()\n            elif isinstance(args[0], dict):\n                request = EnvironBuilder.from_environ(\n                    args[0], app=self.application, environ_base=self._copy_environ({})\n                ).get_request()\n            else:\n                # isinstance(args[0], BaseRequest)\n                request = copy(args[0])\n                request.environ = self._copy_environ(request.environ)\n        else:\n            # request is None\n            request = self._request_from_builder_args(args, kwargs)\n\n        # Pop any previously preserved contexts. This prevents contexts\n        # from being preserved across redirects or multiple requests\n        # within a single block.\n        self._context_stack.close()\n\n        response = super().open(\n            request,\n            buffered=buffered,\n            follow_redirects=follow_redirects,\n        )\n        response.json_module = self.application.json  # type: ignore[assignment]\n\n        # Re-push contexts that were preserved during the request.\n        while self._new_contexts:\n            cm = self._new_contexts.pop()\n            self._context_stack.enter_context(cm)\n\n        return response\n\n    def __enter__(self) -> FlaskClient:\n        if self.preserve_context:\n            raise RuntimeError(\"Cannot nest client invocations\")\n        self.preserve_context = True\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.preserve_context = False\n        self._context_stack.close()\n\n\nclass FlaskCliRunner(CliRunner):\n    \"\"\"A :class:`~click.testing.CliRunner` for testing a Flask app's\n    CLI commands. Typically created using\n    :meth:`~flask.Flask.test_cli_runner`. See :ref:`testing-cli`.\n    \"\"\"\n\n    def __init__(self, app: Flask, **kwargs: t.Any) -> None:\n        self.app = app\n        super().__init__(**kwargs)\n\n    def invoke(  # type: ignore\n        self, cli: t.Any = None, args: t.Any = None, **kwargs: t.Any\n    ) -> t.Any:\n        \"\"\"Invokes a CLI command in an isolated environment. See\n        :meth:`CliRunner.invoke <click.testing.CliRunner.invoke>` for\n        full method documentation. See :ref:`testing-cli` for examples.\n\n        If the ``obj`` argument is not given, passes an instance of\n        :class:`~flask.cli.ScriptInfo` that knows how to load the Flask\n        app being tested.\n\n        :param cli: Command object to invoke. Default is the app's\n            :attr:`~flask.app.Flask.cli` group.\n        :param args: List of strings to invoke the command with.\n\n        :return: a :class:`~click.testing.Result` object.\n        \"\"\"\n        if cli is None:\n            cli = self.app.cli\n\n        if \"obj\" not in kwargs:\n            kwargs[\"obj\"] = ScriptInfo(create_app=lambda: self.app)\n\n        return super().invoke(cli, args, **kwargs)\n",
      "code_after": "from __future__ import annotations\n\nimport importlib.metadata\nimport typing as t\nfrom contextlib import contextmanager\nfrom contextlib import ExitStack\nfrom copy import copy\nfrom types import TracebackType\nfrom urllib.parse import urlsplit\n\nimport werkzeug.test\nfrom click.testing import CliRunner\nfrom click.testing import Result\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Request as BaseRequest\n\nfrom .cli import ScriptInfo\nfrom .sessions import SessionMixin\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIEnvironment\n    from werkzeug.test import TestResponse\n\n    from .app import Flask\n\n\nclass EnvironBuilder(werkzeug.test.EnvironBuilder):\n    \"\"\"An :class:`~werkzeug.test.EnvironBuilder`, that takes defaults from the\n    application.\n\n    :param app: The Flask application to configure the environment from.\n    :param path: URL path being requested.\n    :param base_url: Base URL where the app is being served, which\n        ``path`` is relative to. If not given, built from\n        :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n        :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n    :param subdomain: Subdomain name to append to :data:`SERVER_NAME`.\n    :param url_scheme: Scheme to use instead of\n        :data:`PREFERRED_URL_SCHEME`.\n    :param json: If given, this is serialized as JSON and passed as\n        ``data``. Also defaults ``content_type`` to\n        ``application/json``.\n    :param args: other positional arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    :param kwargs: other keyword arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: Flask,\n        path: str = \"/\",\n        base_url: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str | None = None,\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> None:\n        assert not (base_url or subdomain or url_scheme) or (\n            base_url is not None\n        ) != bool(\n            subdomain or url_scheme\n        ), 'Cannot pass \"subdomain\" or \"url_scheme\" with \"base_url\".'\n\n        if base_url is None:\n            http_host = app.config.get(\"SERVER_NAME\") or \"localhost\"\n            app_root = app.config[\"APPLICATION_ROOT\"]\n\n            if subdomain:\n                http_host = f\"{subdomain}.{http_host}\"\n\n            if url_scheme is None:\n                url_scheme = app.config[\"PREFERRED_URL_SCHEME\"]\n\n            url = urlsplit(path)\n            base_url = (\n                f\"{url.scheme or url_scheme}://{url.netloc or http_host}\"\n                f\"/{app_root.lstrip('/')}\"\n            )\n            path = url.path\n\n            if url.query:\n                path = f\"{path}?{url.query}\"\n\n        self.app = app\n        super().__init__(path, base_url, *args, **kwargs)\n\n    def json_dumps(self, obj: t.Any, **kwargs: t.Any) -> str:  # type: ignore\n        \"\"\"Serialize ``obj`` to a JSON-formatted string.\n\n        The serialization will be configured according to the config associated\n        with this EnvironBuilder's ``app``.\n        \"\"\"\n        return self.app.json.dumps(obj, **kwargs)\n\n\n_werkzeug_version = \"\"\n\n\ndef _get_werkzeug_version() -> str:\n    global _werkzeug_version\n\n    if not _werkzeug_version:\n        _werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    return _werkzeug_version\n\n\nclass FlaskClient(Client):\n    \"\"\"Works like a regular Werkzeug test client but has knowledge about\n    Flask's contexts to defer the cleanup of the request context until\n    the end of a ``with`` block. For general information about how to\n    use this class refer to :class:`werkzeug.test.Client`.\n\n    .. versionchanged:: 0.12\n       `app.test_client()` includes preset default environment, which can be\n       set after instantiation of the `app.test_client()` object in\n       `client.environ_base`.\n\n    Basic usage is outlined in the :doc:`/testing` chapter.\n    \"\"\"\n\n    application: Flask\n\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        super().__init__(*args, **kwargs)\n        self.preserve_context = False\n        self._new_contexts: list[t.ContextManager[t.Any]] = []\n        self._context_stack = ExitStack()\n        self.environ_base = {\n            \"REMOTE_ADDR\": \"127.0.0.1\",\n            \"HTTP_USER_AGENT\": f\"Werkzeug/{_get_werkzeug_version()}\",\n        }\n\n    @contextmanager\n    def session_transaction(\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Iterator[SessionMixin]:\n        \"\"\"When used in combination with a ``with`` statement this opens a\n        session transaction.  This can be used to modify the session that\n        the test client uses.  Once the ``with`` block is left the session is\n        stored back.\n\n        ::\n\n            with client.session_transaction() as session:\n                session['value'] = 42\n\n        Internally this is implemented by going through a temporary test\n        request context and since session handling could depend on\n        request variables this function accepts the same arguments as\n        :meth:`~flask.Flask.test_request_context` which are directly\n        passed through.\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        app = self.application\n        ctx = app.test_request_context(*args, **kwargs)\n        self._add_cookies_to_wsgi(ctx.request.environ)\n\n        with ctx:\n            sess = app.session_interface.open_session(app, ctx.request)\n\n        if sess is None:\n            raise RuntimeError(\"Session backend did not open a session.\")\n\n        yield sess\n        resp = app.response_class()\n\n        if app.session_interface.is_null_session(sess):\n            return\n\n        with ctx:\n            app.session_interface.save_session(app, sess, resp)\n\n        self._update_cookies_from_response(\n            ctx.request.host.partition(\":\")[0],\n            ctx.request.path,\n            resp.headers.getlist(\"Set-Cookie\"),\n        )\n\n    def _copy_environ(self, other: WSGIEnvironment) -> WSGIEnvironment:\n        out = {**self.environ_base, **other}\n\n        if self.preserve_context:\n            out[\"werkzeug.debug.preserve_context\"] = self._new_contexts.append\n\n        return out\n\n    def _request_from_builder_args(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> BaseRequest:\n        kwargs[\"environ_base\"] = self._copy_environ(kwargs.get(\"environ_base\", {}))\n        builder = EnvironBuilder(self.application, *args, **kwargs)\n\n        try:\n            return builder.get_request()\n        finally:\n            builder.close()\n\n    def open(\n        self,\n        *args: t.Any,\n        buffered: bool = False,\n        follow_redirects: bool = False,\n        **kwargs: t.Any,\n    ) -> TestResponse:\n        if args and isinstance(\n            args[0], (werkzeug.test.EnvironBuilder, dict, BaseRequest)\n        ):\n            if isinstance(args[0], werkzeug.test.EnvironBuilder):\n                builder = copy(args[0])\n                builder.environ_base = self._copy_environ(builder.environ_base or {})  # type: ignore[arg-type]\n                request = builder.get_request()\n            elif isinstance(args[0], dict):\n                request = EnvironBuilder.from_environ(\n                    args[0], app=self.application, environ_base=self._copy_environ({})\n                ).get_request()\n            else:\n                # isinstance(args[0], BaseRequest)\n                request = copy(args[0])\n                request.environ = self._copy_environ(request.environ)\n        else:\n            # request is None\n            request = self._request_from_builder_args(args, kwargs)\n\n        # Pop any previously preserved contexts. This prevents contexts\n        # from being preserved across redirects or multiple requests\n        # within a single block.\n        self._context_stack.close()\n\n        response = super().open(\n            request,\n            buffered=buffered,\n            follow_redirects=follow_redirects,\n        )\n        response.json_module = self.application.json  # type: ignore[assignment]\n\n        # Re-push contexts that were preserved during the request.\n        while self._new_contexts:\n            cm = self._new_contexts.pop()\n            self._context_stack.enter_context(cm)\n\n        return response\n\n    def __enter__(self) -> FlaskClient:\n        if self.preserve_context:\n            raise RuntimeError(\"Cannot nest client invocations\")\n        self.preserve_context = True\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.preserve_context = False\n        self._context_stack.close()\n\n\nclass FlaskCliRunner(CliRunner):\n    \"\"\"A :class:`~click.testing.CliRunner` for testing a Flask app's\n    CLI commands. Typically created using\n    :meth:`~flask.Flask.test_cli_runner`. See :ref:`testing-cli`.\n    \"\"\"\n\n    def __init__(self, app: Flask, **kwargs: t.Any) -> None:\n        self.app = app\n        super().__init__(**kwargs)\n\n    def invoke(  # type: ignore\n        self, cli: t.Any = None, args: t.Any = None, **kwargs: t.Any\n    ) -> Result:\n        \"\"\"Invokes a CLI command in an isolated environment. See\n        :meth:`CliRunner.invoke <click.testing.CliRunner.invoke>` for\n        full method documentation. See :ref:`testing-cli` for examples.\n\n        If the ``obj`` argument is not given, passes an instance of\n        :class:`~flask.cli.ScriptInfo` that knows how to load the Flask\n        app being tested.\n\n        :param cli: Command object to invoke. Default is the app's\n            :attr:`~flask.app.Flask.cli` group.\n        :param args: List of strings to invoke the command with.\n\n        :return: a :class:`~click.testing.Result` object.\n        \"\"\"\n        if cli is None:\n            cli = self.app.cli\n\n        if \"obj\" not in kwargs:\n            kwargs[\"obj\"] = ScriptInfo(create_app=lambda: self.app)\n\n        return super().invoke(cli, args, **kwargs)\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "5ea8f3429c4d",
      "repo": "flask",
      "commit_hash": "4995a77",
      "commit_message": "fix subdomain_matching=False behavior",
      "file_path": "tests/test_blueprints.py",
      "language": "python",
      "code_before": "import pytest\nfrom jinja2 import TemplateNotFound\nfrom werkzeug.http import parse_cache_control_header\n\nimport flask\n\n\ndef test_blueprint_specific_error_handling(app, client):\n    frontend = flask.Blueprint(\"frontend\", __name__)\n    backend = flask.Blueprint(\"backend\", __name__)\n    sideend = flask.Blueprint(\"sideend\", __name__)\n\n    @frontend.errorhandler(403)\n    def frontend_forbidden(e):\n        return \"frontend says no\", 403\n\n    @frontend.route(\"/frontend-no\")\n    def frontend_no():\n        flask.abort(403)\n\n    @backend.errorhandler(403)\n    def backend_forbidden(e):\n        return \"backend says no\", 403\n\n    @backend.route(\"/backend-no\")\n    def backend_no():\n        flask.abort(403)\n\n    @sideend.route(\"/what-is-a-sideend\")\n    def sideend_no():\n        flask.abort(403)\n\n    app.register_blueprint(frontend)\n    app.register_blueprint(backend)\n    app.register_blueprint(sideend)\n\n    @app.errorhandler(403)\n    def app_forbidden(e):\n        return \"application itself says no\", 403\n\n    assert client.get(\"/frontend-no\").data == b\"frontend says no\"\n    assert client.get(\"/backend-no\").data == b\"backend says no\"\n    assert client.get(\"/what-is-a-sideend\").data == b\"application itself says no\"\n\n\ndef test_blueprint_specific_user_error_handling(app, client):\n    class MyDecoratorException(Exception):\n        pass\n\n    class MyFunctionException(Exception):\n        pass\n\n    blue = flask.Blueprint(\"blue\", __name__)\n\n    @blue.errorhandler(MyDecoratorException)\n    def my_decorator_exception_handler(e):\n        assert isinstance(e, MyDecoratorException)\n        return \"boom\"\n\n    def my_function_exception_handler(e):\n        assert isinstance(e, MyFunctionException)\n        return \"bam\"\n\n    blue.register_error_handler(MyFunctionException, my_function_exception_handler)\n\n    @blue.route(\"/decorator\")\n    def blue_deco_test():\n        raise MyDecoratorException()\n\n    @blue.route(\"/function\")\n    def blue_func_test():\n        raise MyFunctionException()\n\n    app.register_blueprint(blue)\n\n    assert client.get(\"/decorator\").data == b\"boom\"\n    assert client.get(\"/function\").data == b\"bam\"\n\n\ndef test_blueprint_app_error_handling(app, client):\n    errors = flask.Blueprint(\"errors\", __name__)\n\n    @errors.app_errorhandler(403)\n    def forbidden_handler(e):\n        return \"you shall not pass\", 403\n\n    @app.route(\"/forbidden\")\n    def app_forbidden():\n        flask.abort(403)\n\n    forbidden_bp = flask.Blueprint(\"forbidden_bp\", __name__)\n\n    @forbidden_bp.route(\"/nope\")\n    def bp_forbidden():\n        flask.abort(403)\n\n    app.register_blueprint(errors)\n    app.register_blueprint(forbidden_bp)\n\n    assert client.get(\"/forbidden\").data == b\"you shall not pass\"\n    assert client.get(\"/nope\").data == b\"you shall not pass\"\n\n\n@pytest.mark.parametrize(\n    (\"prefix\", \"rule\", \"url\"),\n    (\n        (\"\", \"/\", \"/\"),\n        (\"/\", \"\", \"/\"),\n        (\"/\", \"/\", \"/\"),\n        (\"/foo\", \"\", \"/foo\"),\n        (\"/foo/\", \"\", \"/foo/\"),\n        (\"\", \"/bar\", \"/bar\"),\n        (\"/foo/\", \"/bar\", \"/foo/bar\"),\n        (\"/foo/\", \"bar\", \"/foo/bar\"),\n        (\"/foo\", \"/bar\", \"/foo/bar\"),\n        (\"/foo/\", \"//bar\", \"/foo/bar\"),\n        (\"/foo//\", \"/bar\", \"/foo/bar\"),\n    ),\n)\ndef test_blueprint_prefix_slash(app, client, prefix, rule, url):\n    bp = flask.Blueprint(\"test\", __name__, url_prefix=prefix)\n\n    @bp.route(rule)\n    def index():\n        return \"\", 204\n\n    app.register_blueprint(bp)\n    assert client.get(url).status_code == 204\n\n\ndef test_blueprint_url_defaults(app, client):\n    bp = flask.Blueprint(\"test\", __name__)\n\n    @bp.route(\"/foo\", defaults={\"baz\": 42})\n    def foo(bar, baz):\n        return f\"{bar}/{baz:d}\"\n\n    @bp.route(\"/bar\")\n    def bar(bar):\n        return str(bar)\n\n    app.register_blueprint(bp, url_prefix=\"/1\", url_defaults={\"bar\": 23})\n    app.register_blueprint(bp, name=\"test2\", url_prefix=\"/2\", url_defaults={\"bar\": 19})\n\n    assert client.get(\"/1/foo\").data == b\"23/42\"\n    assert client.get(\"/2/foo\").data == b\"19/42\"\n    assert client.get(\"/1/bar\").data == b\"23\"\n    assert client.get(\"/2/bar\").data == b\"19\"\n\n\ndef test_blueprint_url_processors(app, client):\n    bp = flask.Blueprint(\"frontend\", __name__, url_prefix=\"/<lang_code>\")\n\n    @bp.url_defaults\n    def add_language_code(endpoint, values):\n        values.setdefault(\"lang_code\", flask.g.lang_code)\n\n    @bp.url_value_preprocessor\n    def pull_lang_code(endpoint, values):\n        flask.g.lang_code = values.pop(\"lang_code\")\n\n    @bp.route(\"/\")\n    def index():\n        return flask.url_for(\".about\")\n\n    @bp.route(\"/about\")\n    def about():\n        return flask.url_for(\".index\")\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/de/\").data == b\"/de/about\"\n    assert client.get(\"/de/about\").data == b\"/de/\"\n\n\ndef test_templates_and_static(test_apps):\n    from blueprintapp import app\n\n    client = app.test_client()\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"Hello from the Frontend\"\n    rv = client.get(\"/admin/\")\n    assert rv.data == b\"Hello from the Admin\"\n    rv = client.get(\"/admin/index2\")\n    assert rv.data == b\"Hello from the Admin\"\n    rv = client.get(\"/admin/static/test.txt\")\n    assert rv.data.strip() == b\"Admin File\"\n    rv.close()\n    rv = client.get(\"/admin/static/css/test.css\")\n    assert rv.data.strip() == b\"/* nested file */\"\n    rv.close()\n\n    # try/finally, in case other tests use this app for Blueprint tests.\n    max_age_default = app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n    try:\n        expected_max_age = 3600\n        if app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] == expected_max_age:\n            expected_max_age = 7200\n        app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = expected_max_age\n        rv = client.get(\"/admin/static/css/test.css\")\n        cc = parse_cache_control_header(rv.headers[\"Cache-Control\"])\n        assert cc.max_age == expected_max_age\n        rv.close()\n    finally:\n        app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = max_age_default\n\n    with app.test_request_context():\n        assert (\n            flask.url_for(\"admin.static\", filename=\"test.txt\")\n            == \"/admin/static/test.txt\"\n        )\n\n    with app.test_request_context():\n        with pytest.raises(TemplateNotFound) as e:\n            flask.render_template(\"missing.html\")\n        assert e.value.name == \"missing.html\"\n\n    with flask.Flask(__name__).test_request_context():\n        assert flask.render_template(\"nested/nested.txt\") == \"I'm nested\"\n\n\ndef test_default_static_max_age(app):\n    class MyBlueprint(flask.Blueprint):\n        def get_send_file_max_age(self, filename):\n            return 100\n\n    blueprint = MyBlueprint(\"blueprint\", __name__, static_folder=\"static\")\n    app.register_blueprint(blueprint)\n\n    # try/finally, in case other tests use this app for Blueprint tests.\n    max_age_default = app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n    try:\n        with app.test_request_context():\n            unexpected_max_age = 3600\n            if app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] == unexpected_max_age:\n                unexpected_max_age = 7200\n            app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = unexpected_max_age\n            rv = blueprint.send_static_file(\"index.html\")\n            cc = parse_cache_control_header(rv.headers[\"Cache-Control\"])\n            assert cc.max_age == 100\n            rv.close()\n    finally:\n        app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = max_age_default\n\n\ndef test_templates_list(test_apps):\n    from blueprintapp import app\n\n    templates = sorted(app.jinja_env.list_templates())\n    assert templates == [\"admin/index.html\", \"frontend/index.html\"]\n\n\ndef test_dotted_name_not_allowed(app, client):\n    with pytest.raises(ValueError):\n        flask.Blueprint(\"app.ui\", __name__)\n\n\ndef test_empty_name_not_allowed(app, client):\n    with pytest.raises(ValueError):\n        flask.Blueprint(\"\", __name__)\n\n\ndef test_dotted_names_from_app(app, client):\n    test = flask.Blueprint(\"test\", __name__)\n\n    @app.route(\"/\")\n    def app_index():\n        return flask.url_for(\"test.index\")\n\n    @test.route(\"/test/\")\n    def index():\n        return flask.url_for(\"app_index\")\n\n    app.register_blueprint(test)\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"/test/\"\n\n\ndef test_empty_url_defaults(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.route(\"/\", defaults={\"page\": 1})\n    @bp.route(\"/page/<int:page>\")\n    def something(page):\n        return str(page)\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/\").data == b\"1\"\n    assert client.get(\"/page/2\").data == b\"2\"\n\n\ndef test_route_decorator_custom_endpoint(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.route(\"/foo\")\n    def foo():\n        return flask.request.endpoint\n\n    @bp.route(\"/bar\", endpoint=\"bar\")\n    def foo_bar():\n        return flask.request.endpoint\n\n    @bp.route(\"/bar/123\", endpoint=\"123\")\n    def foo_bar_foo():\n        return flask.request.endpoint\n\n    @bp.route(\"/bar/foo\")\n    def bar_foo():\n        return flask.request.endpoint\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.request.endpoint\n\n    assert client.get(\"/\").data == b\"index\"\n    assert client.get(\"/py/foo\").data == b\"bp.foo\"\n    assert client.get(\"/py/bar\").data == b\"bp.bar\"\n    assert client.get(\"/py/bar/123\").data == b\"bp.123\"\n    assert client.get(\"/py/bar/foo\").data == b\"bp.bar_foo\"\n\n\ndef test_route_decorator_custom_endpoint_with_dots(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    with pytest.raises(ValueError):\n        bp.route(\"/\", endpoint=\"a.b\")(lambda: \"\")\n\n    with pytest.raises(ValueError):\n        bp.add_url_rule(\"/\", endpoint=\"a.b\")\n\n    def view():\n        return \"\"\n\n    view.__name__ = \"a.b\"\n\n    with pytest.raises(ValueError):\n        bp.add_url_rule(\"/\", view_func=view)\n\n\ndef test_endpoint_decorator(app, client):\n    from werkzeug.routing import Rule\n\n    app.url_map.add(Rule(\"/foo\", endpoint=\"bar\"))\n\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.endpoint(\"bar\")\n    def foobar():\n        return flask.request.endpoint\n\n    app.register_blueprint(bp, url_prefix=\"/bp_prefix\")\n\n    assert client.get(\"/foo\").data == b\"bar\"\n    assert client.get(\"/bp_prefix/bar\").status_code == 404\n\n\ndef test_template_filter(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter()\n    def my_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"my_reverse\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"my_reverse\"] == my_reverse\n    assert app.jinja_env.filters[\"my_reverse\"](\"abcd\") == \"dcba\"\n\n\ndef test_add_template_filter(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def my_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(my_reverse)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"my_reverse\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"my_reverse\"] == my_reverse\n    assert app.jinja_env.filters[\"my_reverse\"](\"abcd\") == \"dcba\"\n\n\ndef test_template_filter_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter(\"strrev\")\n    def my_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"strrev\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"strrev\"] == my_reverse\n    assert app.jinja_env.filters[\"strrev\"](\"abcd\") == \"dcba\"\n\n\ndef test_add_template_filter_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def my_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(my_reverse, \"strrev\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"strrev\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"strrev\"] == my_reverse\n    assert app.jinja_env.filters[\"strrev\"](\"abcd\") == \"dcba\"\n\n\ndef test_template_filter_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter()\n    def super_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_template_filter_after_route_with_template(app, client):\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter()\n    def super_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_add_template_filter_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def super_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(super_reverse)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_template_filter_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter(\"super_reverse\")\n    def my_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_add_template_filter_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def my_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(my_reverse, \"super_reverse\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_template_test(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test()\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"is_boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"is_boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"is_boolean\"](False)\n\n\ndef test_add_template_test(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(is_boolean)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"is_boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"is_boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"is_boolean\"](False)\n\n\ndef test_template_test_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test(\"boolean\")\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"boolean\"](False)\n\n\ndef test_add_template_test_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(is_boolean, \"boolean\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"boolean\"](False)\n\n\ndef test_template_test_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test()\n    def boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_template_test_after_route_with_template(app, client):\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test()\n    def boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_add_template_test_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(boolean)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_template_test_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test(\"boolean\")\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_add_template_test_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(is_boolean, \"boolean\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_context_processing(app, client):\n    answer_bp = flask.Blueprint(\"answer_bp\", __name__)\n\n    def template_string():\n        return flask.render_template_string(\n            \"{% if notanswer %}{{ notanswer }} is not the answer. {% endif %}\"\n            \"{% if answer %}{{ answer }} is the answer.{% endif %}\"\n        )\n\n    # App global context processor\n    @answer_bp.app_context_processor\n    def not_answer_context_processor():\n        return {\"notanswer\": 43}\n\n    # Blueprint local context processor\n    @answer_bp.context_processor\n    def answer_context_processor():\n        return {\"answer\": 42}\n\n    # Setup endpoints for testing\n    @answer_bp.route(\"/bp\")\n    def bp_page():\n        return template_string()\n\n    @app.route(\"/\")\n    def app_page():\n        return template_string()\n\n    # Register the blueprint\n    app.register_blueprint(answer_bp)\n\n    app_page_bytes = client.get(\"/\").data\n    answer_page_bytes = client.get(\"/bp\").data\n\n    assert b\"43\" in app_page_bytes\n    assert b\"42\" not in app_page_bytes\n\n    assert b\"42\" in answer_page_bytes\n    assert b\"43\" in answer_page_bytes\n\n\ndef test_template_global(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_global()\n    def get_answer():\n        return 42\n\n    # Make sure the function is not in the jinja_env already\n    assert \"get_answer\" not in app.jinja_env.globals.keys()\n    app.register_blueprint(bp)\n\n    # Tests\n    assert \"get_answer\" in app.jinja_env.globals.keys()\n    assert app.jinja_env.globals[\"get_answer\"] is get_answer\n    assert app.jinja_env.globals[\"get_answer\"]() == 42\n\n    with app.app_context():\n        rv = flask.render_template_string(\"{{ get_answer() }}\")\n        assert rv == \"42\"\n\n\ndef test_request_processing(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n    evts = []\n\n    @bp.before_request\n    def before_bp():\n        evts.append(\"before\")\n\n    @bp.after_request\n    def after_bp(response):\n        response.data += b\"|after\"\n        evts.append(\"after\")\n        return response\n\n    @bp.teardown_request\n    def teardown_bp(exc):\n        evts.append(\"teardown\")\n\n    # Setup routes for testing\n    @bp.route(\"/bp\")\n    def bp_endpoint():\n        return \"request\"\n\n    app.register_blueprint(bp)\n\n    assert evts == []\n    rv = client.get(\"/bp\")\n    assert rv.data == b\"request|after\"\n    assert evts == [\"before\", \"after\", \"teardown\"]\n\n\ndef test_app_request_processing(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n    evts = []\n\n    @bp.before_app_request\n    def before_app():\n        evts.append(\"before\")\n\n    @bp.after_app_request\n    def after_app(response):\n        response.data += b\"|after\"\n        evts.append(\"after\")\n        return response\n\n    @bp.teardown_app_request\n    def teardown_app(exc):\n        evts.append(\"teardown\")\n\n    app.register_blueprint(bp)\n\n    # Setup routes for testing\n    @app.route(\"/\")\n    def bp_endpoint():\n        return \"request\"\n\n    # before first request\n    assert evts == []\n\n    # first request\n    resp = client.get(\"/\").data\n    assert resp == b\"request|after\"\n    assert evts == [\"before\", \"after\", \"teardown\"]\n\n    # second request\n    resp = client.get(\"/\").data\n    assert resp == b\"request|after\"\n    assert evts == [\"before\", \"after\", \"teardown\"] * 2\n\n\ndef test_app_url_processors(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    # Register app-wide url defaults and preprocessor on blueprint\n    @bp.app_url_defaults\n    def add_language_code(endpoint, values):\n        values.setdefault(\"lang_code\", flask.g.lang_code)\n\n    @bp.app_url_value_preprocessor\n    def pull_lang_code(endpoint, values):\n        flask.g.lang_code = values.pop(\"lang_code\")\n\n    # Register route rules at the app level\n    @app.route(\"/<lang_code>/\")\n    def index():\n        return flask.url_for(\"about\")\n\n    @app.route(\"/<lang_code>/about\")\n    def about():\n        return flask.url_for(\"index\")\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/de/\").data == b\"/de/about\"\n    assert client.get(\"/de/about\").data == b\"/de/\"\n\n\ndef test_nested_blueprint(app, client):\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__)\n    grandchild = flask.Blueprint(\"grandchild\", __name__)\n\n    @parent.errorhandler(403)\n    def forbidden(e):\n        return \"Parent no\", 403\n\n    @parent.route(\"/\")\n    def parent_index():\n        return \"Parent yes\"\n\n    @parent.route(\"/no\")\n    def parent_no():\n        flask.abort(403)\n\n    @child.route(\"/\")\n    def child_index():\n        return \"Child yes\"\n\n    @child.route(\"/no\")\n    def child_no():\n        flask.abort(403)\n\n    @grandchild.errorhandler(403)\n    def grandchild_forbidden(e):\n        return \"Grandchild no\", 403\n\n    @grandchild.route(\"/\")\n    def grandchild_index():\n        return \"Grandchild yes\"\n\n    @grandchild.route(\"/no\")\n    def grandchild_no():\n        flask.abort(403)\n\n    child.register_blueprint(grandchild, url_prefix=\"/grandchild\")\n    parent.register_blueprint(child, url_prefix=\"/child\")\n    app.register_blueprint(parent, url_prefix=\"/parent\")\n\n    assert client.get(\"/parent/\").data == b\"Parent yes\"\n    assert client.get(\"/parent/child/\").data == b\"Child yes\"\n    assert client.get(\"/parent/child/grandchild/\").data == b\"Grandchild yes\"\n    assert client.get(\"/parent/no\").data == b\"Parent no\"\n    assert client.get(\"/parent/child/no\").data == b\"Parent no\"\n    assert client.get(\"/parent/child/grandchild/no\").data == b\"Grandchild no\"\n\n\ndef test_nested_callback_order(app, client):\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__)\n\n    @app.before_request\n    def app_before1():\n        flask.g.setdefault(\"seen\", []).append(\"app_1\")\n\n    @app.teardown_request\n    def app_teardown1(e=None):\n        assert flask.g.seen.pop() == \"app_1\"\n\n    @app.before_request\n    def app_before2():\n        flask.g.setdefault(\"seen\", []).append(\"app_2\")\n\n    @app.teardown_request\n    def app_teardown2(e=None):\n        assert flask.g.seen.pop() == \"app_2\"\n\n    @app.context_processor\n    def app_ctx():\n        return dict(key=\"app\")\n\n    @parent.before_request\n    def parent_before1():\n        flask.g.setdefault(\"seen\", []).append(\"parent_1\")\n\n    @parent.teardown_request\n    def parent_teardown1(e=None):\n        assert flask.g.seen.pop() == \"parent_1\"\n\n    @parent.before_request\n    def parent_before2():\n        flask.g.setdefault(\"seen\", []).append(\"parent_2\")\n\n    @parent.teardown_request\n    def parent_teardown2(e=None):\n        assert flask.g.seen.pop() == \"parent_2\"\n\n    @parent.context_processor\n    def parent_ctx():\n        return dict(key=\"parent\")\n\n    @child.before_request\n    def child_before1():\n        flask.g.setdefault(\"seen\", []).append(\"child_1\")\n\n    @child.teardown_request\n    def child_teardown1(e=None):\n        assert flask.g.seen.pop() == \"child_1\"\n\n    @child.before_request\n    def child_before2():\n        flask.g.setdefault(\"seen\", []).append(\"child_2\")\n\n    @child.teardown_request\n    def child_teardown2(e=None):\n        assert flask.g.seen.pop() == \"child_2\"\n\n    @child.context_processor\n    def child_ctx():\n        return dict(key=\"child\")\n\n    @child.route(\"/a\")\n    def a():\n        return \", \".join(flask.g.seen)\n\n    @child.route(\"/b\")\n    def b():\n        return flask.render_template_string(\"{{ key }}\")\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent)\n    assert (\n        client.get(\"/a\").data == b\"app_1, app_2, parent_1, parent_2, child_1, child_2\"\n    )\n    assert client.get(\"/b\").data == b\"child\"\n\n\n@pytest.mark.parametrize(\n    \"parent_init, child_init, parent_registration, child_registration\",\n    [\n        (\"/parent\", \"/child\", None, None),\n        (\"/parent\", None, None, \"/child\"),\n        (None, None, \"/parent\", \"/child\"),\n        (\"/other\", \"/something\", \"/parent\", \"/child\"),\n    ],\n)\ndef test_nesting_url_prefixes(\n    parent_init,\n    child_init,\n    parent_registration,\n    child_registration,\n    app,\n    client,\n) -> None:\n    parent = flask.Blueprint(\"parent\", __name__, url_prefix=parent_init)\n    child = flask.Blueprint(\"child\", __name__, url_prefix=child_init)\n\n    @child.route(\"/\")\n    def index():\n        return \"index\"\n\n    parent.register_blueprint(child, url_prefix=child_registration)\n    app.register_blueprint(parent, url_prefix=parent_registration)\n\n    response = client.get(\"/parent/child/\")\n    assert response.status_code == 200\n\n\ndef test_nesting_subdomains(app, client) -> None:\n    subdomain = \"api\"\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__)\n\n    @child.route(\"/child/\")\n    def index():\n        return \"child\"\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent, subdomain=subdomain)\n\n    client.allow_subdomain_redirects = True\n\n    domain_name = \"domain.tld\"\n    app.config[\"SERVER_NAME\"] = domain_name\n    response = client.get(\"/child/\", base_url=\"http://api.\" + domain_name)\n\n    assert response.status_code == 200\n\n\ndef test_child_and_parent_subdomain(app, client) -> None:\n    child_subdomain = \"api\"\n    parent_subdomain = \"parent\"\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__, subdomain=child_subdomain)\n\n    @child.route(\"/\")\n    def index():\n        return \"child\"\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent, subdomain=parent_subdomain)\n\n    client.allow_subdomain_redirects = True\n\n    domain_name = \"domain.tld\"\n    app.config[\"SERVER_NAME\"] = domain_name\n    response = client.get(\n        \"/\", base_url=f\"http://{child_subdomain}.{parent_subdomain}.{domain_name}\"\n    )\n\n    assert response.status_code == 200\n\n    response = client.get(\"/\", base_url=f\"http://{parent_subdomain}.{domain_name}\")\n\n    assert response.status_code == 404\n\n\ndef test_unique_blueprint_names(app, client) -> None:\n    bp = flask.Blueprint(\"bp\", __name__)\n    bp2 = flask.Blueprint(\"bp\", __name__)\n\n    app.register_blueprint(bp)\n\n    with pytest.raises(ValueError):\n        app.register_blueprint(bp)  # same bp, same name, error\n\n    app.register_blueprint(bp, name=\"again\")  # same bp, different name, ok\n\n    with pytest.raises(ValueError):\n        app.register_blueprint(bp2)  # different bp, same name, error\n\n    app.register_blueprint(bp2, name=\"alt\")  # different bp, different name, ok\n\n\ndef test_self_registration(app, client) -> None:\n    bp = flask.Blueprint(\"bp\", __name__)\n    with pytest.raises(ValueError):\n        bp.register_blueprint(bp)\n\n\ndef test_blueprint_renaming(app, client) -> None:\n    bp = flask.Blueprint(\"bp\", __name__)\n    bp2 = flask.Blueprint(\"bp2\", __name__)\n\n    @bp.get(\"/\")\n    def index():\n        return flask.request.endpoint\n\n    @bp.get(\"/error\")\n    def error():\n        flask.abort(403)\n\n    @bp.errorhandler(403)\n    def forbidden(_: Exception):\n        return \"Error\", 403\n\n    @bp2.get(\"/\")\n    def index2():\n        return flask.request.endpoint\n\n    bp.register_blueprint(bp2, url_prefix=\"/a\", name=\"sub\")\n    app.register_blueprint(bp, url_prefix=\"/a\")\n    app.register_blueprint(bp, url_prefix=\"/b\", name=\"alt\")\n\n    assert client.get(\"/a/\").data == b\"bp.index\"\n    assert client.get(\"/b/\").data == b\"alt.index\"\n    assert client.get(\"/a/a/\").data == b\"bp.sub.index2\"\n    assert client.get(\"/b/a/\").data == b\"alt.sub.index2\"\n    assert client.get(\"/a/error\").data == b\"Error\"\n    assert client.get(\"/b/error\").data == b\"Error\"\n",
      "code_after": "import pytest\nfrom jinja2 import TemplateNotFound\nfrom werkzeug.http import parse_cache_control_header\n\nimport flask\n\n\ndef test_blueprint_specific_error_handling(app, client):\n    frontend = flask.Blueprint(\"frontend\", __name__)\n    backend = flask.Blueprint(\"backend\", __name__)\n    sideend = flask.Blueprint(\"sideend\", __name__)\n\n    @frontend.errorhandler(403)\n    def frontend_forbidden(e):\n        return \"frontend says no\", 403\n\n    @frontend.route(\"/frontend-no\")\n    def frontend_no():\n        flask.abort(403)\n\n    @backend.errorhandler(403)\n    def backend_forbidden(e):\n        return \"backend says no\", 403\n\n    @backend.route(\"/backend-no\")\n    def backend_no():\n        flask.abort(403)\n\n    @sideend.route(\"/what-is-a-sideend\")\n    def sideend_no():\n        flask.abort(403)\n\n    app.register_blueprint(frontend)\n    app.register_blueprint(backend)\n    app.register_blueprint(sideend)\n\n    @app.errorhandler(403)\n    def app_forbidden(e):\n        return \"application itself says no\", 403\n\n    assert client.get(\"/frontend-no\").data == b\"frontend says no\"\n    assert client.get(\"/backend-no\").data == b\"backend says no\"\n    assert client.get(\"/what-is-a-sideend\").data == b\"application itself says no\"\n\n\ndef test_blueprint_specific_user_error_handling(app, client):\n    class MyDecoratorException(Exception):\n        pass\n\n    class MyFunctionException(Exception):\n        pass\n\n    blue = flask.Blueprint(\"blue\", __name__)\n\n    @blue.errorhandler(MyDecoratorException)\n    def my_decorator_exception_handler(e):\n        assert isinstance(e, MyDecoratorException)\n        return \"boom\"\n\n    def my_function_exception_handler(e):\n        assert isinstance(e, MyFunctionException)\n        return \"bam\"\n\n    blue.register_error_handler(MyFunctionException, my_function_exception_handler)\n\n    @blue.route(\"/decorator\")\n    def blue_deco_test():\n        raise MyDecoratorException()\n\n    @blue.route(\"/function\")\n    def blue_func_test():\n        raise MyFunctionException()\n\n    app.register_blueprint(blue)\n\n    assert client.get(\"/decorator\").data == b\"boom\"\n    assert client.get(\"/function\").data == b\"bam\"\n\n\ndef test_blueprint_app_error_handling(app, client):\n    errors = flask.Blueprint(\"errors\", __name__)\n\n    @errors.app_errorhandler(403)\n    def forbidden_handler(e):\n        return \"you shall not pass\", 403\n\n    @app.route(\"/forbidden\")\n    def app_forbidden():\n        flask.abort(403)\n\n    forbidden_bp = flask.Blueprint(\"forbidden_bp\", __name__)\n\n    @forbidden_bp.route(\"/nope\")\n    def bp_forbidden():\n        flask.abort(403)\n\n    app.register_blueprint(errors)\n    app.register_blueprint(forbidden_bp)\n\n    assert client.get(\"/forbidden\").data == b\"you shall not pass\"\n    assert client.get(\"/nope\").data == b\"you shall not pass\"\n\n\n@pytest.mark.parametrize(\n    (\"prefix\", \"rule\", \"url\"),\n    (\n        (\"\", \"/\", \"/\"),\n        (\"/\", \"\", \"/\"),\n        (\"/\", \"/\", \"/\"),\n        (\"/foo\", \"\", \"/foo\"),\n        (\"/foo/\", \"\", \"/foo/\"),\n        (\"\", \"/bar\", \"/bar\"),\n        (\"/foo/\", \"/bar\", \"/foo/bar\"),\n        (\"/foo/\", \"bar\", \"/foo/bar\"),\n        (\"/foo\", \"/bar\", \"/foo/bar\"),\n        (\"/foo/\", \"//bar\", \"/foo/bar\"),\n        (\"/foo//\", \"/bar\", \"/foo/bar\"),\n    ),\n)\ndef test_blueprint_prefix_slash(app, client, prefix, rule, url):\n    bp = flask.Blueprint(\"test\", __name__, url_prefix=prefix)\n\n    @bp.route(rule)\n    def index():\n        return \"\", 204\n\n    app.register_blueprint(bp)\n    assert client.get(url).status_code == 204\n\n\ndef test_blueprint_url_defaults(app, client):\n    bp = flask.Blueprint(\"test\", __name__)\n\n    @bp.route(\"/foo\", defaults={\"baz\": 42})\n    def foo(bar, baz):\n        return f\"{bar}/{baz:d}\"\n\n    @bp.route(\"/bar\")\n    def bar(bar):\n        return str(bar)\n\n    app.register_blueprint(bp, url_prefix=\"/1\", url_defaults={\"bar\": 23})\n    app.register_blueprint(bp, name=\"test2\", url_prefix=\"/2\", url_defaults={\"bar\": 19})\n\n    assert client.get(\"/1/foo\").data == b\"23/42\"\n    assert client.get(\"/2/foo\").data == b\"19/42\"\n    assert client.get(\"/1/bar\").data == b\"23\"\n    assert client.get(\"/2/bar\").data == b\"19\"\n\n\ndef test_blueprint_url_processors(app, client):\n    bp = flask.Blueprint(\"frontend\", __name__, url_prefix=\"/<lang_code>\")\n\n    @bp.url_defaults\n    def add_language_code(endpoint, values):\n        values.setdefault(\"lang_code\", flask.g.lang_code)\n\n    @bp.url_value_preprocessor\n    def pull_lang_code(endpoint, values):\n        flask.g.lang_code = values.pop(\"lang_code\")\n\n    @bp.route(\"/\")\n    def index():\n        return flask.url_for(\".about\")\n\n    @bp.route(\"/about\")\n    def about():\n        return flask.url_for(\".index\")\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/de/\").data == b\"/de/about\"\n    assert client.get(\"/de/about\").data == b\"/de/\"\n\n\ndef test_templates_and_static(test_apps):\n    from blueprintapp import app\n\n    client = app.test_client()\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"Hello from the Frontend\"\n    rv = client.get(\"/admin/\")\n    assert rv.data == b\"Hello from the Admin\"\n    rv = client.get(\"/admin/index2\")\n    assert rv.data == b\"Hello from the Admin\"\n    rv = client.get(\"/admin/static/test.txt\")\n    assert rv.data.strip() == b\"Admin File\"\n    rv.close()\n    rv = client.get(\"/admin/static/css/test.css\")\n    assert rv.data.strip() == b\"/* nested file */\"\n    rv.close()\n\n    # try/finally, in case other tests use this app for Blueprint tests.\n    max_age_default = app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n    try:\n        expected_max_age = 3600\n        if app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] == expected_max_age:\n            expected_max_age = 7200\n        app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = expected_max_age\n        rv = client.get(\"/admin/static/css/test.css\")\n        cc = parse_cache_control_header(rv.headers[\"Cache-Control\"])\n        assert cc.max_age == expected_max_age\n        rv.close()\n    finally:\n        app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = max_age_default\n\n    with app.test_request_context():\n        assert (\n            flask.url_for(\"admin.static\", filename=\"test.txt\")\n            == \"/admin/static/test.txt\"\n        )\n\n    with app.test_request_context():\n        with pytest.raises(TemplateNotFound) as e:\n            flask.render_template(\"missing.html\")\n        assert e.value.name == \"missing.html\"\n\n    with flask.Flask(__name__).test_request_context():\n        assert flask.render_template(\"nested/nested.txt\") == \"I'm nested\"\n\n\ndef test_default_static_max_age(app):\n    class MyBlueprint(flask.Blueprint):\n        def get_send_file_max_age(self, filename):\n            return 100\n\n    blueprint = MyBlueprint(\"blueprint\", __name__, static_folder=\"static\")\n    app.register_blueprint(blueprint)\n\n    # try/finally, in case other tests use this app for Blueprint tests.\n    max_age_default = app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n    try:\n        with app.test_request_context():\n            unexpected_max_age = 3600\n            if app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] == unexpected_max_age:\n                unexpected_max_age = 7200\n            app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = unexpected_max_age\n            rv = blueprint.send_static_file(\"index.html\")\n            cc = parse_cache_control_header(rv.headers[\"Cache-Control\"])\n            assert cc.max_age == 100\n            rv.close()\n    finally:\n        app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"] = max_age_default\n\n\ndef test_templates_list(test_apps):\n    from blueprintapp import app\n\n    templates = sorted(app.jinja_env.list_templates())\n    assert templates == [\"admin/index.html\", \"frontend/index.html\"]\n\n\ndef test_dotted_name_not_allowed(app, client):\n    with pytest.raises(ValueError):\n        flask.Blueprint(\"app.ui\", __name__)\n\n\ndef test_empty_name_not_allowed(app, client):\n    with pytest.raises(ValueError):\n        flask.Blueprint(\"\", __name__)\n\n\ndef test_dotted_names_from_app(app, client):\n    test = flask.Blueprint(\"test\", __name__)\n\n    @app.route(\"/\")\n    def app_index():\n        return flask.url_for(\"test.index\")\n\n    @test.route(\"/test/\")\n    def index():\n        return flask.url_for(\"app_index\")\n\n    app.register_blueprint(test)\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"/test/\"\n\n\ndef test_empty_url_defaults(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.route(\"/\", defaults={\"page\": 1})\n    @bp.route(\"/page/<int:page>\")\n    def something(page):\n        return str(page)\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/\").data == b\"1\"\n    assert client.get(\"/page/2\").data == b\"2\"\n\n\ndef test_route_decorator_custom_endpoint(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.route(\"/foo\")\n    def foo():\n        return flask.request.endpoint\n\n    @bp.route(\"/bar\", endpoint=\"bar\")\n    def foo_bar():\n        return flask.request.endpoint\n\n    @bp.route(\"/bar/123\", endpoint=\"123\")\n    def foo_bar_foo():\n        return flask.request.endpoint\n\n    @bp.route(\"/bar/foo\")\n    def bar_foo():\n        return flask.request.endpoint\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.request.endpoint\n\n    assert client.get(\"/\").data == b\"index\"\n    assert client.get(\"/py/foo\").data == b\"bp.foo\"\n    assert client.get(\"/py/bar\").data == b\"bp.bar\"\n    assert client.get(\"/py/bar/123\").data == b\"bp.123\"\n    assert client.get(\"/py/bar/foo\").data == b\"bp.bar_foo\"\n\n\ndef test_route_decorator_custom_endpoint_with_dots(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    with pytest.raises(ValueError):\n        bp.route(\"/\", endpoint=\"a.b\")(lambda: \"\")\n\n    with pytest.raises(ValueError):\n        bp.add_url_rule(\"/\", endpoint=\"a.b\")\n\n    def view():\n        return \"\"\n\n    view.__name__ = \"a.b\"\n\n    with pytest.raises(ValueError):\n        bp.add_url_rule(\"/\", view_func=view)\n\n\ndef test_endpoint_decorator(app, client):\n    from werkzeug.routing import Rule\n\n    app.url_map.add(Rule(\"/foo\", endpoint=\"bar\"))\n\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.endpoint(\"bar\")\n    def foobar():\n        return flask.request.endpoint\n\n    app.register_blueprint(bp, url_prefix=\"/bp_prefix\")\n\n    assert client.get(\"/foo\").data == b\"bar\"\n    assert client.get(\"/bp_prefix/bar\").status_code == 404\n\n\ndef test_template_filter(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter()\n    def my_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"my_reverse\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"my_reverse\"] == my_reverse\n    assert app.jinja_env.filters[\"my_reverse\"](\"abcd\") == \"dcba\"\n\n\ndef test_add_template_filter(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def my_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(my_reverse)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"my_reverse\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"my_reverse\"] == my_reverse\n    assert app.jinja_env.filters[\"my_reverse\"](\"abcd\") == \"dcba\"\n\n\ndef test_template_filter_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter(\"strrev\")\n    def my_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"strrev\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"strrev\"] == my_reverse\n    assert app.jinja_env.filters[\"strrev\"](\"abcd\") == \"dcba\"\n\n\ndef test_add_template_filter_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def my_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(my_reverse, \"strrev\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"strrev\" in app.jinja_env.filters.keys()\n    assert app.jinja_env.filters[\"strrev\"] == my_reverse\n    assert app.jinja_env.filters[\"strrev\"](\"abcd\") == \"dcba\"\n\n\ndef test_template_filter_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter()\n    def super_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_template_filter_after_route_with_template(app, client):\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter()\n    def super_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_add_template_filter_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def super_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(super_reverse)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_template_filter_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_filter(\"super_reverse\")\n    def my_reverse(s):\n        return s[::-1]\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_add_template_filter_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def my_reverse(s):\n        return s[::-1]\n\n    bp.add_app_template_filter(my_reverse, \"super_reverse\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_filter.html\", value=\"abcd\")\n\n    rv = client.get(\"/\")\n    assert rv.data == b\"dcba\"\n\n\ndef test_template_test(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test()\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"is_boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"is_boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"is_boolean\"](False)\n\n\ndef test_add_template_test(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(is_boolean)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"is_boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"is_boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"is_boolean\"](False)\n\n\ndef test_template_test_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test(\"boolean\")\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"boolean\"](False)\n\n\ndef test_add_template_test_with_name(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(is_boolean, \"boolean\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    assert \"boolean\" in app.jinja_env.tests.keys()\n    assert app.jinja_env.tests[\"boolean\"] == is_boolean\n    assert app.jinja_env.tests[\"boolean\"](False)\n\n\ndef test_template_test_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test()\n    def boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_template_test_after_route_with_template(app, client):\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test()\n    def boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_add_template_test_with_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(boolean)\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_template_test_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_test(\"boolean\")\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_add_template_test_with_name_and_template(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    def is_boolean(value):\n        return isinstance(value, bool)\n\n    bp.add_app_template_test(is_boolean, \"boolean\")\n    app.register_blueprint(bp, url_prefix=\"/py\")\n\n    @app.route(\"/\")\n    def index():\n        return flask.render_template(\"template_test.html\", value=False)\n\n    rv = client.get(\"/\")\n    assert b\"Success!\" in rv.data\n\n\ndef test_context_processing(app, client):\n    answer_bp = flask.Blueprint(\"answer_bp\", __name__)\n\n    def template_string():\n        return flask.render_template_string(\n            \"{% if notanswer %}{{ notanswer }} is not the answer. {% endif %}\"\n            \"{% if answer %}{{ answer }} is the answer.{% endif %}\"\n        )\n\n    # App global context processor\n    @answer_bp.app_context_processor\n    def not_answer_context_processor():\n        return {\"notanswer\": 43}\n\n    # Blueprint local context processor\n    @answer_bp.context_processor\n    def answer_context_processor():\n        return {\"answer\": 42}\n\n    # Setup endpoints for testing\n    @answer_bp.route(\"/bp\")\n    def bp_page():\n        return template_string()\n\n    @app.route(\"/\")\n    def app_page():\n        return template_string()\n\n    # Register the blueprint\n    app.register_blueprint(answer_bp)\n\n    app_page_bytes = client.get(\"/\").data\n    answer_page_bytes = client.get(\"/bp\").data\n\n    assert b\"43\" in app_page_bytes\n    assert b\"42\" not in app_page_bytes\n\n    assert b\"42\" in answer_page_bytes\n    assert b\"43\" in answer_page_bytes\n\n\ndef test_template_global(app):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    @bp.app_template_global()\n    def get_answer():\n        return 42\n\n    # Make sure the function is not in the jinja_env already\n    assert \"get_answer\" not in app.jinja_env.globals.keys()\n    app.register_blueprint(bp)\n\n    # Tests\n    assert \"get_answer\" in app.jinja_env.globals.keys()\n    assert app.jinja_env.globals[\"get_answer\"] is get_answer\n    assert app.jinja_env.globals[\"get_answer\"]() == 42\n\n    with app.app_context():\n        rv = flask.render_template_string(\"{{ get_answer() }}\")\n        assert rv == \"42\"\n\n\ndef test_request_processing(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n    evts = []\n\n    @bp.before_request\n    def before_bp():\n        evts.append(\"before\")\n\n    @bp.after_request\n    def after_bp(response):\n        response.data += b\"|after\"\n        evts.append(\"after\")\n        return response\n\n    @bp.teardown_request\n    def teardown_bp(exc):\n        evts.append(\"teardown\")\n\n    # Setup routes for testing\n    @bp.route(\"/bp\")\n    def bp_endpoint():\n        return \"request\"\n\n    app.register_blueprint(bp)\n\n    assert evts == []\n    rv = client.get(\"/bp\")\n    assert rv.data == b\"request|after\"\n    assert evts == [\"before\", \"after\", \"teardown\"]\n\n\ndef test_app_request_processing(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n    evts = []\n\n    @bp.before_app_request\n    def before_app():\n        evts.append(\"before\")\n\n    @bp.after_app_request\n    def after_app(response):\n        response.data += b\"|after\"\n        evts.append(\"after\")\n        return response\n\n    @bp.teardown_app_request\n    def teardown_app(exc):\n        evts.append(\"teardown\")\n\n    app.register_blueprint(bp)\n\n    # Setup routes for testing\n    @app.route(\"/\")\n    def bp_endpoint():\n        return \"request\"\n\n    # before first request\n    assert evts == []\n\n    # first request\n    resp = client.get(\"/\").data\n    assert resp == b\"request|after\"\n    assert evts == [\"before\", \"after\", \"teardown\"]\n\n    # second request\n    resp = client.get(\"/\").data\n    assert resp == b\"request|after\"\n    assert evts == [\"before\", \"after\", \"teardown\"] * 2\n\n\ndef test_app_url_processors(app, client):\n    bp = flask.Blueprint(\"bp\", __name__)\n\n    # Register app-wide url defaults and preprocessor on blueprint\n    @bp.app_url_defaults\n    def add_language_code(endpoint, values):\n        values.setdefault(\"lang_code\", flask.g.lang_code)\n\n    @bp.app_url_value_preprocessor\n    def pull_lang_code(endpoint, values):\n        flask.g.lang_code = values.pop(\"lang_code\")\n\n    # Register route rules at the app level\n    @app.route(\"/<lang_code>/\")\n    def index():\n        return flask.url_for(\"about\")\n\n    @app.route(\"/<lang_code>/about\")\n    def about():\n        return flask.url_for(\"index\")\n\n    app.register_blueprint(bp)\n\n    assert client.get(\"/de/\").data == b\"/de/about\"\n    assert client.get(\"/de/about\").data == b\"/de/\"\n\n\ndef test_nested_blueprint(app, client):\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__)\n    grandchild = flask.Blueprint(\"grandchild\", __name__)\n\n    @parent.errorhandler(403)\n    def forbidden(e):\n        return \"Parent no\", 403\n\n    @parent.route(\"/\")\n    def parent_index():\n        return \"Parent yes\"\n\n    @parent.route(\"/no\")\n    def parent_no():\n        flask.abort(403)\n\n    @child.route(\"/\")\n    def child_index():\n        return \"Child yes\"\n\n    @child.route(\"/no\")\n    def child_no():\n        flask.abort(403)\n\n    @grandchild.errorhandler(403)\n    def grandchild_forbidden(e):\n        return \"Grandchild no\", 403\n\n    @grandchild.route(\"/\")\n    def grandchild_index():\n        return \"Grandchild yes\"\n\n    @grandchild.route(\"/no\")\n    def grandchild_no():\n        flask.abort(403)\n\n    child.register_blueprint(grandchild, url_prefix=\"/grandchild\")\n    parent.register_blueprint(child, url_prefix=\"/child\")\n    app.register_blueprint(parent, url_prefix=\"/parent\")\n\n    assert client.get(\"/parent/\").data == b\"Parent yes\"\n    assert client.get(\"/parent/child/\").data == b\"Child yes\"\n    assert client.get(\"/parent/child/grandchild/\").data == b\"Grandchild yes\"\n    assert client.get(\"/parent/no\").data == b\"Parent no\"\n    assert client.get(\"/parent/child/no\").data == b\"Parent no\"\n    assert client.get(\"/parent/child/grandchild/no\").data == b\"Grandchild no\"\n\n\ndef test_nested_callback_order(app, client):\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__)\n\n    @app.before_request\n    def app_before1():\n        flask.g.setdefault(\"seen\", []).append(\"app_1\")\n\n    @app.teardown_request\n    def app_teardown1(e=None):\n        assert flask.g.seen.pop() == \"app_1\"\n\n    @app.before_request\n    def app_before2():\n        flask.g.setdefault(\"seen\", []).append(\"app_2\")\n\n    @app.teardown_request\n    def app_teardown2(e=None):\n        assert flask.g.seen.pop() == \"app_2\"\n\n    @app.context_processor\n    def app_ctx():\n        return dict(key=\"app\")\n\n    @parent.before_request\n    def parent_before1():\n        flask.g.setdefault(\"seen\", []).append(\"parent_1\")\n\n    @parent.teardown_request\n    def parent_teardown1(e=None):\n        assert flask.g.seen.pop() == \"parent_1\"\n\n    @parent.before_request\n    def parent_before2():\n        flask.g.setdefault(\"seen\", []).append(\"parent_2\")\n\n    @parent.teardown_request\n    def parent_teardown2(e=None):\n        assert flask.g.seen.pop() == \"parent_2\"\n\n    @parent.context_processor\n    def parent_ctx():\n        return dict(key=\"parent\")\n\n    @child.before_request\n    def child_before1():\n        flask.g.setdefault(\"seen\", []).append(\"child_1\")\n\n    @child.teardown_request\n    def child_teardown1(e=None):\n        assert flask.g.seen.pop() == \"child_1\"\n\n    @child.before_request\n    def child_before2():\n        flask.g.setdefault(\"seen\", []).append(\"child_2\")\n\n    @child.teardown_request\n    def child_teardown2(e=None):\n        assert flask.g.seen.pop() == \"child_2\"\n\n    @child.context_processor\n    def child_ctx():\n        return dict(key=\"child\")\n\n    @child.route(\"/a\")\n    def a():\n        return \", \".join(flask.g.seen)\n\n    @child.route(\"/b\")\n    def b():\n        return flask.render_template_string(\"{{ key }}\")\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent)\n    assert (\n        client.get(\"/a\").data == b\"app_1, app_2, parent_1, parent_2, child_1, child_2\"\n    )\n    assert client.get(\"/b\").data == b\"child\"\n\n\n@pytest.mark.parametrize(\n    \"parent_init, child_init, parent_registration, child_registration\",\n    [\n        (\"/parent\", \"/child\", None, None),\n        (\"/parent\", None, None, \"/child\"),\n        (None, None, \"/parent\", \"/child\"),\n        (\"/other\", \"/something\", \"/parent\", \"/child\"),\n    ],\n)\ndef test_nesting_url_prefixes(\n    parent_init,\n    child_init,\n    parent_registration,\n    child_registration,\n    app,\n    client,\n) -> None:\n    parent = flask.Blueprint(\"parent\", __name__, url_prefix=parent_init)\n    child = flask.Blueprint(\"child\", __name__, url_prefix=child_init)\n\n    @child.route(\"/\")\n    def index():\n        return \"index\"\n\n    parent.register_blueprint(child, url_prefix=child_registration)\n    app.register_blueprint(parent, url_prefix=parent_registration)\n\n    response = client.get(\"/parent/child/\")\n    assert response.status_code == 200\n\n\ndef test_nesting_subdomains(app, client) -> None:\n    app.subdomain_matching = True\n    app.config[\"SERVER_NAME\"] = \"example.test\"\n    client.allow_subdomain_redirects = True\n\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__)\n\n    @child.route(\"/child/\")\n    def index():\n        return \"child\"\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent, subdomain=\"api\")\n\n    response = client.get(\"/child/\", base_url=\"http://api.example.test\")\n    assert response.status_code == 200\n\n\ndef test_child_and_parent_subdomain(app, client) -> None:\n    app.subdomain_matching = True\n    app.config[\"SERVER_NAME\"] = \"example.test\"\n    client.allow_subdomain_redirects = True\n\n    parent = flask.Blueprint(\"parent\", __name__)\n    child = flask.Blueprint(\"child\", __name__, subdomain=\"api\")\n\n    @child.route(\"/\")\n    def index():\n        return \"child\"\n\n    parent.register_blueprint(child)\n    app.register_blueprint(parent, subdomain=\"parent\")\n\n    response = client.get(\"/\", base_url=\"http://api.parent.example.test\")\n    assert response.status_code == 200\n\n    response = client.get(\"/\", base_url=\"http://parent.example.test\")\n    assert response.status_code == 404\n\n\ndef test_unique_blueprint_names(app, client) -> None:\n    bp = flask.Blueprint(\"bp\", __name__)\n    bp2 = flask.Blueprint(\"bp\", __name__)\n\n    app.register_blueprint(bp)\n\n    with pytest.raises(ValueError):\n        app.register_blueprint(bp)  # same bp, same name, error\n\n    app.register_blueprint(bp, name=\"again\")  # same bp, different name, ok\n\n    with pytest.raises(ValueError):\n        app.register_blueprint(bp2)  # different bp, same name, error\n\n    app.register_blueprint(bp2, name=\"alt\")  # different bp, different name, ok\n\n\ndef test_self_registration(app, client) -> None:\n    bp = flask.Blueprint(\"bp\", __name__)\n    with pytest.raises(ValueError):\n        bp.register_blueprint(bp)\n\n\ndef test_blueprint_renaming(app, client) -> None:\n    bp = flask.Blueprint(\"bp\", __name__)\n    bp2 = flask.Blueprint(\"bp2\", __name__)\n\n    @bp.get(\"/\")\n    def index():\n        return flask.request.endpoint\n\n    @bp.get(\"/error\")\n    def error():\n        flask.abort(403)\n\n    @bp.errorhandler(403)\n    def forbidden(_: Exception):\n        return \"Error\", 403\n\n    @bp2.get(\"/\")\n    def index2():\n        return flask.request.endpoint\n\n    bp.register_blueprint(bp2, url_prefix=\"/a\", name=\"sub\")\n    app.register_blueprint(bp, url_prefix=\"/a\")\n    app.register_blueprint(bp, url_prefix=\"/b\", name=\"alt\")\n\n    assert client.get(\"/a/\").data == b\"bp.index\"\n    assert client.get(\"/b/\").data == b\"alt.index\"\n    assert client.get(\"/a/a/\").data == b\"bp.sub.index2\"\n    assert client.get(\"/b/a/\").data == b\"alt.sub.index2\"\n    assert client.get(\"/a/error\").data == b\"Error\"\n    assert client.get(\"/b/error\").data == b\"Error\"\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "073cf52f85cb",
      "repo": "flask",
      "commit_hash": "df201ed",
      "commit_message": "fix js example test",
      "file_path": "examples/javascript/tests/test_js_example.py",
      "language": "python",
      "code_before": "import pytest\nfrom flask import template_rendered\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"template_name\"),\n    (\n        (\"/\", \"xhr.html\"),\n        (\"/plain\", \"xhr.html\"),\n        (\"/fetch\", \"fetch.html\"),\n        (\"/jquery\", \"jquery.html\"),\n    ),\n)\ndef test_index(app, client, path, template_name):\n    def check(sender, template, context):\n        assert template.name == template_name\n\n    with template_rendered.connected_to(check, app):\n        client.get(path)\n\n\n@pytest.mark.parametrize(\n    (\"a\", \"b\", \"result\"), ((2, 3, 5), (2.5, 3, 5.5), (2, None, 2), (2, \"b\", 2))\n)\ndef test_add(client, a, b, result):\n    response = client.post(\"/add\", data={\"a\": a, \"b\": b})\n    assert response.get_json()[\"result\"] == result\n",
      "code_after": "import pytest\nfrom flask import template_rendered\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"template_name\"),\n    (\n        (\"/\", \"fetch.html\"),\n        (\"/plain\", \"xhr.html\"),\n        (\"/fetch\", \"fetch.html\"),\n        (\"/jquery\", \"jquery.html\"),\n    ),\n)\ndef test_index(app, client, path, template_name):\n    def check(sender, template, context):\n        assert template.name == template_name\n\n    with template_rendered.connected_to(check, app):\n        client.get(path)\n\n\n@pytest.mark.parametrize(\n    (\"a\", \"b\", \"result\"), ((2, 3, 5), (2.5, 3, 5.5), (2, None, 2), (2, \"b\", 2))\n)\ndef test_add(client, a, b, result):\n    response = client.post(\"/add\", data={\"a\": a, \"b\": b})\n    assert response.get_json()[\"result\"] == result\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "64f5a99b5ad4",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/blueprints.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport os\nimport typing as t\nfrom datetime import timedelta\n\nfrom .cli import AppGroup\nfrom .globals import current_app\nfrom .helpers import send_from_directory\nfrom .sansio.blueprints import Blueprint as SansioBlueprint\nfrom .sansio.blueprints import BlueprintSetupState as BlueprintSetupState  # noqa\nfrom .sansio.scaffold import _sentinel\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\nclass Blueprint(SansioBlueprint):\n    def __init__(\n        self,\n        name: str,\n        import_name: str,\n        static_folder: str | os.PathLike[str] | None = None,\n        static_url_path: str | None = None,\n        template_folder: str | os.PathLike[str] | None = None,\n        url_prefix: str | None = None,\n        subdomain: str | None = None,\n        url_defaults: dict[str, t.Any] | None = None,\n        root_path: str | None = None,\n        cli_group: str | None = _sentinel,  # type: ignore\n    ) -> None:\n        super().__init__(\n            name,\n            import_name,\n            static_folder,\n            static_url_path,\n            template_folder,\n            url_prefix,\n            subdomain,\n            url_defaults,\n            root_path,\n            cli_group,\n        )\n\n        #: The Click command group for registering CLI commands for this\n        #: object. The commands are available from the ``flask`` command\n        #: once the application has been discovered and blueprints have\n        #: been registered.\n        self.cli = AppGroup()\n\n        # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name\n\n    def get_send_file_max_age(self, filename: str | None) -> int | None:\n        \"\"\"Used by :func:`send_file` to determine the ``max_age`` cache\n        value for a given file path if it wasn't passed.\n\n        By default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\n        the configuration of :data:`~flask.current_app`. This defaults\n        to ``None``, which tells the browser to use conditional requests\n        instead of a timed cache, which is usually preferable.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionchanged:: 2.0\n            The default configuration is ``None`` instead of 12 hours.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        value = current_app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n\n        if value is None:\n            return None\n\n        if isinstance(value, timedelta):\n            return int(value.total_seconds())\n\n        return value  # type: ignore[no-any-return]\n\n    def send_static_file(self, filename: str) -> Response:\n        \"\"\"The view function used to serve files from\n        :attr:`static_folder`. A route is automatically registered for\n        this view at :attr:`static_url_path` if :attr:`static_folder` is\n        set.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionadded:: 0.5\n\n        \"\"\"\n        if not self.has_static_folder:\n            raise RuntimeError(\"'static_folder' must be set to serve static_files.\")\n\n        # send_file only knows to call get_send_file_max_age on the app,\n        # call it here so it works for blueprints too.\n        max_age = self.get_send_file_max_age(filename)\n        return send_from_directory(\n            t.cast(str, self.static_folder), filename, max_age=max_age\n        )\n\n    def open_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = \"utf-8\"\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to :attr:`root_path` for reading. The\n        blueprint-relative equivalent of the app's :meth:`~.Flask.open_resource`\n        method.\n\n        :param resource: Path to the resource relative to :attr:`root_path`.\n        :param mode: Open the file in this mode. Only reading is supported,\n            valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        if mode not in {\"r\", \"rt\", \"rb\"}:\n            raise ValueError(\"Resources can only be opened for reading.\")\n\n        path = os.path.join(self.root_path, resource)\n\n        if mode == \"rb\":\n            return open(path, mode)\n\n        return open(path, mode, encoding=encoding)\n",
      "code_after": "from __future__ import annotations\n\nimport os\nimport typing as t\nfrom datetime import timedelta\n\nfrom .cli import AppGroup\nfrom .globals import current_app\nfrom .helpers import send_from_directory\nfrom .sansio.blueprints import Blueprint as SansioBlueprint\nfrom .sansio.blueprints import BlueprintSetupState as BlueprintSetupState  # noqa\nfrom .sansio.scaffold import _sentinel\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\nclass Blueprint(SansioBlueprint):\n    def __init__(\n        self,\n        name: str,\n        import_name: str,\n        static_folder: str | os.PathLike[str] | None = None,\n        static_url_path: str | None = None,\n        template_folder: str | os.PathLike[str] | None = None,\n        url_prefix: str | None = None,\n        subdomain: str | None = None,\n        url_defaults: dict[str, t.Any] | None = None,\n        root_path: str | None = None,\n        cli_group: str | None = _sentinel,  # type: ignore\n    ) -> None:\n        super().__init__(\n            name,\n            import_name,\n            static_folder,\n            static_url_path,\n            template_folder,\n            url_prefix,\n            subdomain,\n            url_defaults,\n            root_path,\n            cli_group,\n        )\n\n        #: The Click command group for registering CLI commands for this\n        #: object. The commands are available from the ``flask`` command\n        #: once the application has been discovered and blueprints have\n        #: been registered.\n        self.cli = AppGroup()\n\n        # Set the name of the Click group in case someone wants to add\n        # the app's commands to another CLI tool.\n        self.cli.name = self.name\n\n    def get_send_file_max_age(self, filename: str | None) -> int | None:\n        \"\"\"Used by :func:`send_file` to determine the ``max_age`` cache\n        value for a given file path if it wasn't passed.\n\n        By default, this returns :data:`SEND_FILE_MAX_AGE_DEFAULT` from\n        the configuration of :data:`~flask.current_app`. This defaults\n        to ``None``, which tells the browser to use conditional requests\n        instead of a timed cache, which is usually preferable.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionchanged:: 2.0\n            The default configuration is ``None`` instead of 12 hours.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        value = current_app.config[\"SEND_FILE_MAX_AGE_DEFAULT\"]\n\n        if value is None:\n            return None\n\n        if isinstance(value, timedelta):\n            return int(value.total_seconds())\n\n        return value  # type: ignore[no-any-return]\n\n    def send_static_file(self, filename: str) -> Response:\n        \"\"\"The view function used to serve files from\n        :attr:`static_folder`. A route is automatically registered for\n        this view at :attr:`static_url_path` if :attr:`static_folder` is\n        set.\n\n        Note this is a duplicate of the same method in the Flask\n        class.\n\n        .. versionadded:: 0.5\n\n        \"\"\"\n        if not self.has_static_folder:\n            raise RuntimeError(\"'static_folder' must be set to serve static_files.\")\n\n        # send_file only knows to call get_send_file_max_age on the app,\n        # call it here so it works for blueprints too.\n        max_age = self.get_send_file_max_age(filename)\n        return send_from_directory(\n            t.cast(str, self.static_folder), filename, max_age=max_age\n        )\n\n    def open_resource(\n        self, resource: str, mode: str = \"rb\", encoding: str | None = \"utf-8\"\n    ) -> t.IO[t.AnyStr]:\n        \"\"\"Open a resource file relative to :attr:`root_path` for reading. The\n        blueprint-relative equivalent of the app's :meth:`~.Flask.open_resource`\n        method.\n\n        :param resource: Path to the resource relative to :attr:`root_path`.\n        :param mode: Open the file in this mode. Only reading is supported,\n            valid values are ``\"r\"`` (or ``\"rt\"``) and ``\"rb\"``.\n        :param encoding: Open the file with this encoding when opening in text\n            mode. This is ignored when opening in binary mode.\n\n        .. versionchanged:: 3.1\n            Added the ``encoding`` parameter.\n        \"\"\"\n        if mode not in {\"r\", \"rt\", \"rb\"}:\n            raise ValueError(\"Resources can only be opened for reading.\")\n\n        path = os.path.join(self.root_path, resource)\n\n        if mode == \"rb\":\n            return open(path, mode)  # pyright: ignore\n\n        return open(path, mode, encoding=encoding)\n",
      "bug_category": "type",
      "error_type": "type_error",
      "confidence": 0.4
    },
    {
      "bug_id": "952636bb7641",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/cli.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport ast\nimport collections.abc as cabc\nimport importlib.metadata\nimport inspect\nimport os\nimport platform\nimport re\nimport sys\nimport traceback\nimport typing as t\nfrom functools import update_wrapper\nfrom operator import itemgetter\nfrom types import ModuleType\n\nimport click\nfrom click.core import ParameterSource\nfrom werkzeug import run_simple\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.utils import import_string\n\nfrom .globals import current_app\nfrom .helpers import get_debug_flag\nfrom .helpers import get_load_dotenv\n\nif t.TYPE_CHECKING:\n    import ssl\n\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n\n\nclass NoAppException(click.UsageError):\n    \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n\n\ndef find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )\n\n\ndef _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb\n\n\ndef find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n    \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.\n    \"\"\"\n    from . import Flask\n\n    # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) from None\n\n    if isinstance(expr, ast.Name):\n        name = expr.id\n        args = []\n        kwargs = {}\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {\n                kw.arg: ast.literal_eval(kw.value)\n                for kw in expr.keywords\n                if kw.arg is not None\n            }\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            ) from None\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        )\n\n    try:\n        attr = getattr(module, name)\n    except AttributeError as e:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) from e\n\n    # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.\n    if inspect.isfunction(attr):\n        try:\n            app = attr(*args, **kwargs)\n        except TypeError as e:\n            if not _called_with_wrong_args(attr):\n                raise\n\n            raise NoAppException(\n                f\"The factory {app_name!r} in module\"\n                f\" {module.__name__!r} could not be called with the\"\n                \" specified arguments.\"\n            ) from e\n    else:\n        app = attr\n\n    if isinstance(app, Flask):\n        return app\n\n    raise NoAppException(\n        \"A valid Flask application was not obtained from\"\n        f\" '{module.__name__}:{app_name}'.\"\n    )\n\n\ndef prepare_import(path: str) -> str:\n    \"\"\"Given a filename this will try to calculate the python path, add it\n    to the search path and return the actual module name that is expected.\n    \"\"\"\n    path = os.path.realpath(path)\n\n    fname, ext = os.path.splitext(path)\n    if ext == \".py\":\n        path = fname\n\n    if os.path.basename(path) == \"__init__\":\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, \"__init__.py\")):\n            break\n\n    if sys.path[0] != path:\n        sys.path.insert(0, path)\n\n    return \".\".join(module_name[::-1])\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[True] = True\n) -> Flask: ...\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[False] = ...\n) -> Flask | None: ...\n\n\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: bool = True\n) -> Flask | None:\n    try:\n        __import__(module_name)\n    except ImportError:\n        # Reraise the ImportError if it occurred within the imported module.\n        # Determine this by checking whether the trace has a depth > 1.\n        if sys.exc_info()[2].tb_next:  # type: ignore[union-attr]\n            raise NoAppException(\n                f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None\n        elif raise_if_not_found:\n            raise NoAppException(f\"Could not import {module_name!r}.\") from None\n        else:\n            return None\n\n    module = sys.modules[module_name]\n\n    if app_name is None:\n        return find_best_app(module)\n    else:\n        return find_app_by_string(module, app_name)\n\n\ndef get_version(ctx: click.Context, param: click.Parameter, value: t.Any) -> None:\n    if not value or ctx.resilient_parsing:\n        return\n\n    flask_version = importlib.metadata.version(\"flask\")\n    werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    click.echo(\n        f\"Python {platform.python_version()}\\n\"\n        f\"Flask {flask_version}\\n\"\n        f\"Werkzeug {werkzeug_version}\",\n        color=ctx.color,\n    )\n    ctx.exit()\n\n\nversion_option = click.Option(\n    [\"--version\"],\n    help=\"Show the Flask version.\",\n    expose_value=False,\n    callback=get_version,\n    is_flag=True,\n    is_eager=True,\n)\n\n\nclass ScriptInfo:\n    \"\"\"Helper object to deal with Flask applications.  This is usually not\n    necessary to interface with as it's used internally in the dispatching\n    to click.  In future versions of Flask this object will most likely play\n    a bigger role.  Typically it's created automatically by the\n    :class:`FlaskGroup` but you can also manually create it and pass it\n    onwards as click object.\n    \"\"\"\n\n    def __init__(\n        self,\n        app_import_path: str | None = None,\n        create_app: t.Callable[..., Flask] | None = None,\n        set_debug_flag: bool = True,\n    ) -> None:\n        #: Optionally the import path for the Flask application.\n        self.app_import_path = app_import_path\n        #: Optionally a function that is passed the script info to create\n        #: the instance of the application.\n        self.create_app = create_app\n        #: A dictionary with arbitrary data that can be associated with\n        #: this script info.\n        self.data: dict[t.Any, t.Any] = {}\n        self.set_debug_flag = set_debug_flag\n        self._loaded_app: Flask | None = None\n\n    def load_app(self) -> Flask:\n        \"\"\"Loads the Flask app (if not yet loaded) and returns it.  Calling\n        this multiple times will just result in the already loaded app to\n        be returned.\n        \"\"\"\n        if self._loaded_app is not None:\n            return self._loaded_app\n\n        if self.create_app is not None:\n            app: Flask | None = self.create_app()\n        else:\n            if self.app_import_path:\n                path, name = (\n                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                )[:2]\n                import_name = prepare_import(path)\n                app = locate_app(import_name, name)\n            else:\n                for path in (\"wsgi.py\", \"app.py\"):\n                    import_name = prepare_import(path)\n                    app = locate_app(import_name, None, raise_if_not_found=False)\n\n                    if app is not None:\n                        break\n\n        if app is None:\n            raise NoAppException(\n                \"Could not locate a Flask application. Use the\"\n                \" 'flask --app' option, 'FLASK_APP' environment\"\n                \" variable, or a 'wsgi.py' or 'app.py' file in the\"\n                \" current directory.\"\n            )\n\n        if self.set_debug_flag:\n            # Update the app's debug flag through the descriptor so that\n            # other values repopulate as well.\n            app.debug = get_debug_flag()\n\n        self._loaded_app = app\n        return app\n\n\npass_script_info = click.make_pass_decorator(ScriptInfo, ensure=True)\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef with_appcontext(f: F) -> F:\n    \"\"\"Wraps a callback so that it's guaranteed to be executed with the\n    script's application context.\n\n    Custom commands (and their options) registered under ``app.cli`` or\n    ``blueprint.cli`` will always have an app context available, this\n    decorator is not required in that case.\n\n    .. versionchanged:: 2.2\n        The app context is active for subcommands as well as the\n        decorated callback. The app context is always available to\n        ``app.cli`` command and parameter callbacks.\n    \"\"\"\n\n    @click.pass_context\n    def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not current_app:\n            app = ctx.ensure_object(ScriptInfo).load_app()\n            ctx.with_resource(app.app_context())\n\n        return ctx.invoke(f, *args, **kwargs)\n\n    return update_wrapper(decorator, f)  # type: ignore[return-value]\n\n\nclass AppGroup(click.Group):\n    \"\"\"This works similar to a regular click :class:`~click.Group` but it\n    changes the behavior of the :meth:`command` decorator so that it\n    automatically wraps the functions in :func:`with_appcontext`.\n\n    Not to be confused with :class:`FlaskGroup`.\n    \"\"\"\n\n    def command(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Command]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\n        unless it's disabled by passing ``with_appcontext=False``.\n        \"\"\"\n        wrap_for_ctx = kwargs.pop(\"with_appcontext\", True)\n\n        def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n            if wrap_for_ctx:\n                f = with_appcontext(f)\n            return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n\n        return decorator\n\n    def group(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Group]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it defaults the group class to\n        :class:`AppGroup`.\n        \"\"\"\n        kwargs.setdefault(\"cls\", AppGroup)\n        return super().group(*args, **kwargs)  # type: ignore[no-any-return]\n\n\ndef _set_app(ctx: click.Context, param: click.Option, value: str | None) -> str | None:\n    if value is None:\n        return None\n\n    info = ctx.ensure_object(ScriptInfo)\n    info.app_import_path = value\n    return value\n\n\n# This option is eager so the app will be available if --help is given.\n# --help is also eager, so --app must be before it in the param list.\n# no_args_is_help bypasses eager processing, so this option must be\n# processed manually in that case to ensure FLASK_APP gets picked up.\n_app_option = click.Option(\n    [\"-A\", \"--app\"],\n    metavar=\"IMPORT\",\n    help=(\n        \"The Flask application or factory function to load, in the form 'module:name'.\"\n        \" Module can be a dotted import or file path. Name is not required if it is\"\n        \" 'app', 'application', 'create_app', or 'make_app', and can be 'name(args)' to\"\n        \" pass arguments.\"\n    ),\n    is_eager=True,\n    expose_value=False,\n    callback=_set_app,\n)\n\n\ndef _set_debug(ctx: click.Context, param: click.Option, value: bool) -> bool | None:\n    # If the flag isn't provided, it will default to False. Don't use\n    # that, let debug be set by env in that case.\n    source = ctx.get_parameter_source(param.name)  # type: ignore[arg-type]\n\n    if source is not None and source in (\n        ParameterSource.DEFAULT,\n        ParameterSource.DEFAULT_MAP,\n    ):\n        return None\n\n    # Set with env var instead of ScriptInfo.load so that it can be\n    # accessed early during a factory function.\n    os.environ[\"FLASK_DEBUG\"] = \"1\" if value else \"0\"\n    return value\n\n\n_debug_option = click.Option(\n    [\"--debug/--no-debug\"],\n    help=\"Set debug mode.\",\n    expose_value=False,\n    callback=_set_debug,\n)\n\n\ndef _env_file_callback(\n    ctx: click.Context, param: click.Option, value: str | None\n) -> str | None:\n    if value is None:\n        return None\n\n    import importlib\n\n    try:\n        importlib.import_module(\"dotenv\")\n    except ImportError:\n        raise click.BadParameter(\n            \"python-dotenv must be installed to load an env file.\",\n            ctx=ctx,\n            param=param,\n        ) from None\n\n    # Don't check FLASK_SKIP_DOTENV, that only disables automatically\n    # loading .env and .flaskenv files.\n    load_dotenv(value)\n    return value\n\n\n# This option is eager so env vars are loaded as early as possible to be\n# used by other options.\n_env_file_option = click.Option(\n    [\"-e\", \"--env-file\"],\n    type=click.Path(exists=True, dir_okay=False),\n    help=\"Load environment variables from this file. python-dotenv must be installed.\",\n    is_eager=True,\n    expose_value=False,\n    callback=_env_file_callback,\n)\n\n\nclass FlaskGroup(AppGroup):\n    \"\"\"Special subclass of the :class:`AppGroup` group that supports\n    loading more commands from the configured Flask app.  Normally a\n    developer does not have to interface with this class but there are\n    some very advanced use cases for which it makes sense to create an\n    instance of this. see :ref:`custom-scripts`.\n\n    :param add_default_commands: if this is True then the default run and\n        shell commands will be added.\n    :param add_version_option: adds the ``--version`` option.\n    :param create_app: an optional callback that is passed the script info and\n        returns the loaded app.\n    :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n        files to set environment variables. Will also change the working\n        directory to the directory containing the first file found.\n    :param set_debug_flag: Set the app's debug flag.\n\n    .. versionchanged:: 2.2\n        Added the ``-A/--app``, ``--debug/--no-debug``, ``-e/--env-file`` options.\n\n    .. versionchanged:: 2.2\n        An app context is pushed when running ``app.cli`` commands, so\n        ``@with_appcontext`` is no longer required for those commands.\n\n    .. versionchanged:: 1.0\n        If installed, python-dotenv will be used to load environment variables\n        from :file:`.env` and :file:`.flaskenv` files.\n    \"\"\"\n\n    def __init__(\n        self,\n        add_default_commands: bool = True,\n        create_app: t.Callable[..., Flask] | None = None,\n        add_version_option: bool = True,\n        load_dotenv: bool = True,\n        set_debug_flag: bool = True,\n        **extra: t.Any,\n    ) -> None:\n        params = list(extra.pop(\"params\", None) or ())\n        # Processing is done with option callbacks instead of a group\n        # callback. This allows users to make a custom group callback\n        # without losing the behavior. --env-file must come first so\n        # that it is eagerly evaluated before --app.\n        params.extend((_env_file_option, _app_option, _debug_option))\n\n        if add_version_option:\n            params.append(version_option)\n\n        if \"context_settings\" not in extra:\n            extra[\"context_settings\"] = {}\n\n        extra[\"context_settings\"].setdefault(\"auto_envvar_prefix\", \"FLASK\")\n\n        super().__init__(params=params, **extra)\n\n        self.create_app = create_app\n        self.load_dotenv = load_dotenv\n        self.set_debug_flag = set_debug_flag\n\n        if add_default_commands:\n            self.add_command(run_command)\n            self.add_command(shell_command)\n            self.add_command(routes_command)\n\n        self._loaded_plugin_commands = False\n\n    def _load_plugin_commands(self) -> None:\n        if self._loaded_plugin_commands:\n            return\n\n        if sys.version_info >= (3, 10):\n            from importlib import metadata\n        else:\n            # Use a backport on Python < 3.10. We technically have\n            # importlib.metadata on 3.8+, but the API changed in 3.10,\n            # so use the backport for consistency.\n            import importlib_metadata as metadata\n\n        for ep in metadata.entry_points(group=\"flask.commands\"):\n            self.add_command(ep.load(), ep.name)\n\n        self._loaded_plugin_commands = True\n\n    def get_command(self, ctx: click.Context, name: str) -> click.Command | None:\n        self._load_plugin_commands()\n        # Look up built-in and plugin commands, which should be\n        # available even if the app fails to load.\n        rv = super().get_command(ctx, name)\n\n        if rv is not None:\n            return rv\n\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Look up commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            app = info.load_app()\n        except NoAppException as e:\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n            return None\n\n        # Push an app context for the loaded app unless it is already\n        # active somehow. This makes the context available to parameter\n        # and command callbacks without needing @with_appcontext.\n        if not current_app or current_app._get_current_object() is not app:  # type: ignore[attr-defined]\n            ctx.with_resource(app.app_context())\n\n        return app.cli.get_command(ctx, name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        self._load_plugin_commands()\n        # Start with the built-in and plugin commands.\n        rv = set(super().list_commands(ctx))\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Add commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            rv.update(info.load_app().cli.list_commands(ctx))\n        except NoAppException as e:\n            # When an app couldn't be loaded, show the error message\n            # without the traceback.\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n        except Exception:\n            # When any other errors occurred during loading, show the\n            # full traceback.\n            click.secho(f\"{traceback.format_exc()}\\n\", err=True, fg=\"red\")\n\n        return sorted(rv)\n\n    def make_context(\n        self,\n        info_name: str | None,\n        args: list[str],\n        parent: click.Context | None = None,\n        **extra: t.Any,\n    ) -> click.Context:\n        # Set a flag to tell app.run to become a no-op. If app.run was\n        # not in a __name__ == __main__ guard, it would start the server\n        # when importing, blocking whatever command is being called.\n        os.environ[\"FLASK_RUN_FROM_CLI\"] = \"true\"\n\n        # Attempt to load .env and .flask env files. The --env-file\n        # option can cause another file to be loaded.\n        if get_load_dotenv(self.load_dotenv):\n            load_dotenv()\n\n        if \"obj\" not in extra and \"obj\" not in self.context_settings:\n            extra[\"obj\"] = ScriptInfo(\n                create_app=self.create_app, set_debug_flag=self.set_debug_flag\n            )\n\n        return super().make_context(info_name, args, parent=parent, **extra)\n\n    def parse_args(self, ctx: click.Context, args: list[str]) -> list[str]:\n        if not args and self.no_args_is_help:\n            # Attempt to load --env-file and --app early in case they\n            # were given as env vars. Otherwise no_args_is_help will not\n            # see commands from app.cli.\n            _env_file_option.handle_parse_result(ctx, {}, [])\n            _app_option.handle_parse_result(ctx, {}, [])\n\n        return super().parse_args(ctx, args)\n\n\ndef _path_is_ancestor(path: str, other: str) -> bool:\n    \"\"\"Take ``other`` and remove the length of ``path`` from it. Then join it\n    to ``path``. If it is the original value, ``path`` is an ancestor of\n    ``other``.\"\"\"\n    return os.path.join(path, other[len(path) :].lstrip(os.sep)) == other\n\n\ndef load_dotenv(path: str | os.PathLike[str] | None = None) -> bool:\n    \"\"\"Load \"dotenv\" files in order of precedence to set environment variables.\n\n    If an env var is already set it is not overwritten, so earlier files in the\n    list are preferred over later files.\n\n    This is a no-op if `python-dotenv`_ is not installed.\n\n    .. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n    :param path: Load the file at this location instead of searching.\n    :return: ``True`` if a file was loaded.\n\n    .. versionchanged:: 2.0\n        The current directory is not changed to the location of the\n        loaded file.\n\n    .. versionchanged:: 2.0\n        When loading the env files, set the default encoding to UTF-8.\n\n    .. versionchanged:: 1.1.0\n        Returns ``False`` when python-dotenv is not installed, or when\n        the given path isn't a file.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    try:\n        import dotenv\n    except ImportError:\n        if path or os.path.isfile(\".env\") or os.path.isfile(\".flaskenv\"):\n            click.secho(\n                \" * Tip: There are .env or .flaskenv files present.\"\n                ' Do \"pip install python-dotenv\" to use them.',\n                fg=\"yellow\",\n                err=True,\n            )\n\n        return False\n\n    # Always return after attempting to load a given path, don't load\n    # the default files.\n    if path is not None:\n        if os.path.isfile(path):\n            return dotenv.load_dotenv(path, encoding=\"utf-8\")\n\n        return False\n\n    loaded = False\n\n    for name in (\".env\", \".flaskenv\"):\n        path = dotenv.find_dotenv(name, usecwd=True)\n\n        if not path:\n            continue\n\n        dotenv.load_dotenv(path, encoding=\"utf-8\")\n        loaded = True\n\n    return loaded  # True if at least one file was located and loaded.\n\n\ndef show_server_banner(debug: bool, app_import_path: str | None) -> None:\n    \"\"\"Show extra startup messages the first time the server is run,\n    ignoring the reloader.\n    \"\"\"\n    if is_running_from_reloader():\n        return\n\n    if app_import_path is not None:\n        click.echo(f\" * Serving Flask app '{app_import_path}'\")\n\n    if debug is not None:\n        click.echo(f\" * Debug mode: {'on' if debug else 'off'}\")\n\n\nclass CertParamType(click.ParamType):\n    \"\"\"Click option type for the ``--cert`` option. Allows either an\n    existing file, the string ``'adhoc'``, or an import for a\n    :class:`~ssl.SSLContext` object.\n    \"\"\"\n\n    name = \"path\"\n\n    def __init__(self) -> None:\n        self.path_type = click.Path(exists=True, dir_okay=False, resolve_path=True)\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        try:\n            import ssl\n        except ImportError:\n            raise click.BadParameter(\n                'Using \"--cert\" requires Python to be compiled with SSL support.',\n                ctx,\n                param,\n            ) from None\n\n        try:\n            return self.path_type(value, param, ctx)\n        except click.BadParameter:\n            value = click.STRING(value, param, ctx).lower()\n\n            if value == \"adhoc\":\n                try:\n                    import cryptography  # noqa: F401\n                except ImportError:\n                    raise click.BadParameter(\n                        \"Using ad-hoc certificates requires the cryptography library.\",\n                        ctx,\n                        param,\n                    ) from None\n\n                return value\n\n            obj = import_string(value, silent=True)\n\n            if isinstance(obj, ssl.SSLContext):\n                return obj\n\n            raise\n\n\ndef _validate_key(ctx: click.Context, param: click.Parameter, value: t.Any) -> t.Any:\n    \"\"\"The ``--key`` option must be specified when ``--cert`` is a file.\n    Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.\n    \"\"\"\n    cert = ctx.params.get(\"cert\")\n    is_adhoc = cert == \"adhoc\"\n\n    try:\n        import ssl\n    except ImportError:\n        is_context = False\n    else:\n        is_context = isinstance(cert, ssl.SSLContext)\n\n    if value is not None:\n        if is_adhoc:\n            raise click.BadParameter(\n                'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n            )\n\n        if is_context:\n            raise click.BadParameter(\n                'When \"--cert\" is an SSLContext object, \"--key\" is not used.',\n                ctx,\n                param,\n            )\n\n        if not cert:\n            raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        ctx.params[\"cert\"] = cert, value\n\n    else:\n        if cert and not (is_adhoc or is_context):\n            raise click.BadParameter('Required when using \"--cert\".', ctx, param)\n\n    return value\n\n\nclass SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        items = self.split_envvar_value(value)\n        # can't call no-arg super() inside list comprehension until Python 3.12\n        super_convert = super().convert\n        return [super_convert(item, param, ctx) for item in items]\n\n\n@click.command(\"run\", short_help=\"Run a development server.\")\n@click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n@click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n@click.option(\n    \"--cert\",\n    type=CertParamType(),\n    help=\"Specify a certificate file to use HTTPS.\",\n    is_eager=True,\n)\n@click.option(\n    \"--key\",\n    type=click.Path(exists=True, dir_okay=False, resolve_path=True),\n    callback=_validate_key,\n    expose_value=False,\n    help=\"The key file to use when specifying a certificate.\",\n)\n@click.option(\n    \"--reload/--no-reload\",\n    default=None,\n    help=\"Enable or disable the reloader. By default the reloader \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--debugger/--no-debugger\",\n    default=None,\n    help=\"Enable or disable the debugger. By default the debugger \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--with-threads/--without-threads\",\n    default=True,\n    help=\"Enable or disable multithreading.\",\n)\n@click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        f\" are separated by {os.path.pathsep!r}.\"\n    ),\n)\n@click.option(\n    \"--exclude-patterns\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Files matching these fnmatch patterns will not trigger a reload\"\n        \" on change. Multiple patterns are separated by\"\n        f\" {os.path.pathsep!r}.\"\n    ),\n)\n@pass_script_info\ndef run_command(\n    info: ScriptInfo,\n    host: str,\n    port: int,\n    reload: bool,\n    debugger: bool,\n    with_threads: bool,\n    cert: ssl.SSLContext | tuple[str, str | None] | t.Literal[\"adhoc\"] | None,\n    extra_files: list[str] | None,\n    exclude_patterns: list[str] | None,\n) -> None:\n    \"\"\"Run a local development server.\n\n    This server is for development purposes only. It does not provide\n    the stability, security, or performance of production WSGI servers.\n\n    The reloader and debugger are enabled by default with the '--debug'\n    option.\n    \"\"\"\n    try:\n        app: WSGIApplication = info.load_app()\n    except Exception as e:\n        if is_running_from_reloader():\n            # When reloading, print out the error immediately, but raise\n            # it later so the debugger or server can handle it.\n            traceback.print_exc()\n            err = e\n\n            def app(\n                environ: WSGIEnvironment, start_response: StartResponse\n            ) -> cabc.Iterable[bytes]:\n                raise err from None\n\n        else:\n            # When not reloading, raise the error immediately so the\n            # command fails.\n            raise e from None\n\n    debug = get_debug_flag()\n\n    if reload is None:\n        reload = debug\n\n    if debugger is None:\n        debugger = debug\n\n    show_server_banner(debug, info.app_import_path)\n\n    run_simple(\n        host,\n        port,\n        app,\n        use_reloader=reload,\n        use_debugger=debugger,\n        threaded=with_threads,\n        ssl_context=cert,\n        extra_files=extra_files,\n        exclude_patterns=exclude_patterns,\n    )\n\n\nrun_command.params.insert(0, _debug_option)\n\n\n@click.command(\"shell\", short_help=\"Run a shell in the app context.\")\n@with_appcontext\ndef shell_command() -> None:\n    \"\"\"Run an interactive Python shell in the context of a given\n    Flask application.  The application will populate the default\n    namespace of this shell according to its configuration.\n\n    This is useful for executing small snippets of management code\n    without having to manually configure the application.\n    \"\"\"\n    import code\n\n    banner = (\n        f\"Python {sys.version} on {sys.platform}\\n\"\n        f\"App: {current_app.import_name}\\n\"\n        f\"Instance: {current_app.instance_path}\"\n    )\n    ctx: dict[str, t.Any] = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get(\"PYTHONSTARTUP\")\n    if startup and os.path.isfile(startup):\n        with open(startup) as f:\n            eval(compile(f.read(), startup, \"exec\"), ctx)\n\n    ctx.update(current_app.make_shell_context())\n\n    # Site, customize, or startup script can set a hook to call when\n    # entering interactive mode. The default one sets up readline with\n    # tab and history completion.\n    interactive_hook = getattr(sys, \"__interactivehook__\", None)\n\n    if interactive_hook is not None:\n        try:\n            import readline\n            from rlcompleter import Completer\n        except ImportError:\n            pass\n        else:\n            # rlcompleter uses __main__.__dict__ by default, which is\n            # flask.__main__. Use the shell context instead.\n            readline.set_completer(Completer(ctx).complete)\n\n        interactive_hook()\n\n    code.interact(banner=banner, local=ctx)\n\n\n@click.command(\"routes\", short_help=\"Show the routes for the app.\")\n@click.option(\n    \"--sort\",\n    \"-s\",\n    type=click.Choice((\"endpoint\", \"methods\", \"domain\", \"rule\", \"match\")),\n    default=\"endpoint\",\n    help=(\n        \"Method to sort routes by. 'match' is the order that Flask will match routes\"\n        \" when dispatching a request.\"\n    ),\n)\n@click.option(\"--all-methods\", is_flag=True, help=\"Show HEAD and OPTIONS methods.\")\n@with_appcontext\ndef routes_command(sort: str, all_methods: bool) -> None:\n    \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n    rules = list(current_app.url_map.iter_rules())\n\n    if not rules:\n        click.echo(\"No routes were registered.\")\n        return\n\n    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n    host_matching = current_app.url_map.host_matching\n    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n    rows = []\n\n    for rule in rules:\n        row = [\n            rule.endpoint,\n            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n        ]\n\n        if has_domain:\n            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n\n        row.append(rule.rule)\n        rows.append(row)\n\n    headers = [\"Endpoint\", \"Methods\"]\n    sorts = [\"endpoint\", \"methods\"]\n\n    if has_domain:\n        headers.append(\"Host\" if host_matching else \"Subdomain\")\n        sorts.append(\"domain\")\n\n    headers.append(\"Rule\")\n    sorts.append(\"rule\")\n\n    try:\n        rows.sort(key=itemgetter(sorts.index(sort)))\n    except ValueError:\n        pass\n\n    rows.insert(0, headers)\n    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n    rows.insert(1, [\"-\" * w for w in widths])\n    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n\n    for row in rows:\n        click.echo(template.format(*row))\n\n\ncli = FlaskGroup(\n    name=\"flask\",\n    help=\"\"\"\\\nA general utility script for Flask applications.\n\nAn application to load must be given with the '--app' option,\n'FLASK_APP' environment variable, or with a 'wsgi.py' or 'app.py' file\nin the current directory.\n\"\"\",\n)\n\n\ndef main() -> None:\n    cli.main()\n\n\nif __name__ == \"__main__\":\n    main()\n",
      "code_after": "from __future__ import annotations\n\nimport ast\nimport collections.abc as cabc\nimport importlib.metadata\nimport inspect\nimport os\nimport platform\nimport re\nimport sys\nimport traceback\nimport typing as t\nfrom functools import update_wrapper\nfrom operator import itemgetter\nfrom types import ModuleType\n\nimport click\nfrom click.core import ParameterSource\nfrom werkzeug import run_simple\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.utils import import_string\n\nfrom .globals import current_app\nfrom .helpers import get_debug_flag\nfrom .helpers import get_load_dotenv\n\nif t.TYPE_CHECKING:\n    import ssl\n\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n\n\nclass NoAppException(click.UsageError):\n    \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n\n\ndef find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )\n\n\ndef _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb\n\n\ndef find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n    \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.\n    \"\"\"\n    from . import Flask\n\n    # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) from None\n\n    if isinstance(expr, ast.Name):\n        name = expr.id\n        args = []\n        kwargs = {}\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {\n                kw.arg: ast.literal_eval(kw.value)\n                for kw in expr.keywords\n                if kw.arg is not None\n            }\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            ) from None\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        )\n\n    try:\n        attr = getattr(module, name)\n    except AttributeError as e:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) from e\n\n    # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.\n    if inspect.isfunction(attr):\n        try:\n            app = attr(*args, **kwargs)\n        except TypeError as e:\n            if not _called_with_wrong_args(attr):\n                raise\n\n            raise NoAppException(\n                f\"The factory {app_name!r} in module\"\n                f\" {module.__name__!r} could not be called with the\"\n                \" specified arguments.\"\n            ) from e\n    else:\n        app = attr\n\n    if isinstance(app, Flask):\n        return app\n\n    raise NoAppException(\n        \"A valid Flask application was not obtained from\"\n        f\" '{module.__name__}:{app_name}'.\"\n    )\n\n\ndef prepare_import(path: str) -> str:\n    \"\"\"Given a filename this will try to calculate the python path, add it\n    to the search path and return the actual module name that is expected.\n    \"\"\"\n    path = os.path.realpath(path)\n\n    fname, ext = os.path.splitext(path)\n    if ext == \".py\":\n        path = fname\n\n    if os.path.basename(path) == \"__init__\":\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, \"__init__.py\")):\n            break\n\n    if sys.path[0] != path:\n        sys.path.insert(0, path)\n\n    return \".\".join(module_name[::-1])\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[True] = True\n) -> Flask: ...\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[False] = ...\n) -> Flask | None: ...\n\n\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: bool = True\n) -> Flask | None:\n    try:\n        __import__(module_name)\n    except ImportError:\n        # Reraise the ImportError if it occurred within the imported module.\n        # Determine this by checking whether the trace has a depth > 1.\n        if sys.exc_info()[2].tb_next:  # type: ignore[union-attr]\n            raise NoAppException(\n                f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None\n        elif raise_if_not_found:\n            raise NoAppException(f\"Could not import {module_name!r}.\") from None\n        else:\n            return None\n\n    module = sys.modules[module_name]\n\n    if app_name is None:\n        return find_best_app(module)\n    else:\n        return find_app_by_string(module, app_name)\n\n\ndef get_version(ctx: click.Context, param: click.Parameter, value: t.Any) -> None:\n    if not value or ctx.resilient_parsing:\n        return\n\n    flask_version = importlib.metadata.version(\"flask\")\n    werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    click.echo(\n        f\"Python {platform.python_version()}\\n\"\n        f\"Flask {flask_version}\\n\"\n        f\"Werkzeug {werkzeug_version}\",\n        color=ctx.color,\n    )\n    ctx.exit()\n\n\nversion_option = click.Option(\n    [\"--version\"],\n    help=\"Show the Flask version.\",\n    expose_value=False,\n    callback=get_version,\n    is_flag=True,\n    is_eager=True,\n)\n\n\nclass ScriptInfo:\n    \"\"\"Helper object to deal with Flask applications.  This is usually not\n    necessary to interface with as it's used internally in the dispatching\n    to click.  In future versions of Flask this object will most likely play\n    a bigger role.  Typically it's created automatically by the\n    :class:`FlaskGroup` but you can also manually create it and pass it\n    onwards as click object.\n    \"\"\"\n\n    def __init__(\n        self,\n        app_import_path: str | None = None,\n        create_app: t.Callable[..., Flask] | None = None,\n        set_debug_flag: bool = True,\n    ) -> None:\n        #: Optionally the import path for the Flask application.\n        self.app_import_path = app_import_path\n        #: Optionally a function that is passed the script info to create\n        #: the instance of the application.\n        self.create_app = create_app\n        #: A dictionary with arbitrary data that can be associated with\n        #: this script info.\n        self.data: dict[t.Any, t.Any] = {}\n        self.set_debug_flag = set_debug_flag\n        self._loaded_app: Flask | None = None\n\n    def load_app(self) -> Flask:\n        \"\"\"Loads the Flask app (if not yet loaded) and returns it.  Calling\n        this multiple times will just result in the already loaded app to\n        be returned.\n        \"\"\"\n        if self._loaded_app is not None:\n            return self._loaded_app\n        app: Flask | None = None\n        if self.create_app is not None:\n            app = self.create_app()\n        else:\n            if self.app_import_path:\n                path, name = (\n                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                )[:2]\n                import_name = prepare_import(path)\n                app = locate_app(import_name, name)\n            else:\n                for path in (\"wsgi.py\", \"app.py\"):\n                    import_name = prepare_import(path)\n                    app = locate_app(import_name, None, raise_if_not_found=False)\n\n                    if app is not None:\n                        break\n\n        if app is None:\n            raise NoAppException(\n                \"Could not locate a Flask application. Use the\"\n                \" 'flask --app' option, 'FLASK_APP' environment\"\n                \" variable, or a 'wsgi.py' or 'app.py' file in the\"\n                \" current directory.\"\n            )\n\n        if self.set_debug_flag:\n            # Update the app's debug flag through the descriptor so that\n            # other values repopulate as well.\n            app.debug = get_debug_flag()\n\n        self._loaded_app = app\n        return app\n\n\npass_script_info = click.make_pass_decorator(ScriptInfo, ensure=True)\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef with_appcontext(f: F) -> F:\n    \"\"\"Wraps a callback so that it's guaranteed to be executed with the\n    script's application context.\n\n    Custom commands (and their options) registered under ``app.cli`` or\n    ``blueprint.cli`` will always have an app context available, this\n    decorator is not required in that case.\n\n    .. versionchanged:: 2.2\n        The app context is active for subcommands as well as the\n        decorated callback. The app context is always available to\n        ``app.cli`` command and parameter callbacks.\n    \"\"\"\n\n    @click.pass_context\n    def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not current_app:\n            app = ctx.ensure_object(ScriptInfo).load_app()\n            ctx.with_resource(app.app_context())\n\n        return ctx.invoke(f, *args, **kwargs)\n\n    return update_wrapper(decorator, f)  # type: ignore[return-value]\n\n\nclass AppGroup(click.Group):\n    \"\"\"This works similar to a regular click :class:`~click.Group` but it\n    changes the behavior of the :meth:`command` decorator so that it\n    automatically wraps the functions in :func:`with_appcontext`.\n\n    Not to be confused with :class:`FlaskGroup`.\n    \"\"\"\n\n    def command(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Command]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\n        unless it's disabled by passing ``with_appcontext=False``.\n        \"\"\"\n        wrap_for_ctx = kwargs.pop(\"with_appcontext\", True)\n\n        def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n            if wrap_for_ctx:\n                f = with_appcontext(f)\n            return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n\n        return decorator\n\n    def group(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Group]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it defaults the group class to\n        :class:`AppGroup`.\n        \"\"\"\n        kwargs.setdefault(\"cls\", AppGroup)\n        return super().group(*args, **kwargs)  # type: ignore[no-any-return]\n\n\ndef _set_app(ctx: click.Context, param: click.Option, value: str | None) -> str | None:\n    if value is None:\n        return None\n\n    info = ctx.ensure_object(ScriptInfo)\n    info.app_import_path = value\n    return value\n\n\n# This option is eager so the app will be available if --help is given.\n# --help is also eager, so --app must be before it in the param list.\n# no_args_is_help bypasses eager processing, so this option must be\n# processed manually in that case to ensure FLASK_APP gets picked up.\n_app_option = click.Option(\n    [\"-A\", \"--app\"],\n    metavar=\"IMPORT\",\n    help=(\n        \"The Flask application or factory function to load, in the form 'module:name'.\"\n        \" Module can be a dotted import or file path. Name is not required if it is\"\n        \" 'app', 'application', 'create_app', or 'make_app', and can be 'name(args)' to\"\n        \" pass arguments.\"\n    ),\n    is_eager=True,\n    expose_value=False,\n    callback=_set_app,\n)\n\n\ndef _set_debug(ctx: click.Context, param: click.Option, value: bool) -> bool | None:\n    # If the flag isn't provided, it will default to False. Don't use\n    # that, let debug be set by env in that case.\n    source = ctx.get_parameter_source(param.name)  # type: ignore[arg-type]\n\n    if source is not None and source in (\n        ParameterSource.DEFAULT,\n        ParameterSource.DEFAULT_MAP,\n    ):\n        return None\n\n    # Set with env var instead of ScriptInfo.load so that it can be\n    # accessed early during a factory function.\n    os.environ[\"FLASK_DEBUG\"] = \"1\" if value else \"0\"\n    return value\n\n\n_debug_option = click.Option(\n    [\"--debug/--no-debug\"],\n    help=\"Set debug mode.\",\n    expose_value=False,\n    callback=_set_debug,\n)\n\n\ndef _env_file_callback(\n    ctx: click.Context, param: click.Option, value: str | None\n) -> str | None:\n    if value is None:\n        return None\n\n    import importlib\n\n    try:\n        importlib.import_module(\"dotenv\")\n    except ImportError:\n        raise click.BadParameter(\n            \"python-dotenv must be installed to load an env file.\",\n            ctx=ctx,\n            param=param,\n        ) from None\n\n    # Don't check FLASK_SKIP_DOTENV, that only disables automatically\n    # loading .env and .flaskenv files.\n    load_dotenv(value)\n    return value\n\n\n# This option is eager so env vars are loaded as early as possible to be\n# used by other options.\n_env_file_option = click.Option(\n    [\"-e\", \"--env-file\"],\n    type=click.Path(exists=True, dir_okay=False),\n    help=\"Load environment variables from this file. python-dotenv must be installed.\",\n    is_eager=True,\n    expose_value=False,\n    callback=_env_file_callback,\n)\n\n\nclass FlaskGroup(AppGroup):\n    \"\"\"Special subclass of the :class:`AppGroup` group that supports\n    loading more commands from the configured Flask app.  Normally a\n    developer does not have to interface with this class but there are\n    some very advanced use cases for which it makes sense to create an\n    instance of this. see :ref:`custom-scripts`.\n\n    :param add_default_commands: if this is True then the default run and\n        shell commands will be added.\n    :param add_version_option: adds the ``--version`` option.\n    :param create_app: an optional callback that is passed the script info and\n        returns the loaded app.\n    :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n        files to set environment variables. Will also change the working\n        directory to the directory containing the first file found.\n    :param set_debug_flag: Set the app's debug flag.\n\n    .. versionchanged:: 2.2\n        Added the ``-A/--app``, ``--debug/--no-debug``, ``-e/--env-file`` options.\n\n    .. versionchanged:: 2.2\n        An app context is pushed when running ``app.cli`` commands, so\n        ``@with_appcontext`` is no longer required for those commands.\n\n    .. versionchanged:: 1.0\n        If installed, python-dotenv will be used to load environment variables\n        from :file:`.env` and :file:`.flaskenv` files.\n    \"\"\"\n\n    def __init__(\n        self,\n        add_default_commands: bool = True,\n        create_app: t.Callable[..., Flask] | None = None,\n        add_version_option: bool = True,\n        load_dotenv: bool = True,\n        set_debug_flag: bool = True,\n        **extra: t.Any,\n    ) -> None:\n        params: list[click.Parameter] = list(extra.pop(\"params\", None) or ())\n        # Processing is done with option callbacks instead of a group\n        # callback. This allows users to make a custom group callback\n        # without losing the behavior. --env-file must come first so\n        # that it is eagerly evaluated before --app.\n        params.extend((_env_file_option, _app_option, _debug_option))\n\n        if add_version_option:\n            params.append(version_option)\n\n        if \"context_settings\" not in extra:\n            extra[\"context_settings\"] = {}\n\n        extra[\"context_settings\"].setdefault(\"auto_envvar_prefix\", \"FLASK\")\n\n        super().__init__(params=params, **extra)\n\n        self.create_app = create_app\n        self.load_dotenv = load_dotenv\n        self.set_debug_flag = set_debug_flag\n\n        if add_default_commands:\n            self.add_command(run_command)\n            self.add_command(shell_command)\n            self.add_command(routes_command)\n\n        self._loaded_plugin_commands = False\n\n    def _load_plugin_commands(self) -> None:\n        if self._loaded_plugin_commands:\n            return\n\n        if sys.version_info >= (3, 10):\n            from importlib import metadata\n        else:\n            # Use a backport on Python < 3.10. We technically have\n            # importlib.metadata on 3.8+, but the API changed in 3.10,\n            # so use the backport for consistency.\n            import importlib_metadata as metadata  # pyright: ignore\n\n        for ep in metadata.entry_points(group=\"flask.commands\"):\n            self.add_command(ep.load(), ep.name)\n\n        self._loaded_plugin_commands = True\n\n    def get_command(self, ctx: click.Context, name: str) -> click.Command | None:\n        self._load_plugin_commands()\n        # Look up built-in and plugin commands, which should be\n        # available even if the app fails to load.\n        rv = super().get_command(ctx, name)\n\n        if rv is not None:\n            return rv\n\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Look up commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            app = info.load_app()\n        except NoAppException as e:\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n            return None\n\n        # Push an app context for the loaded app unless it is already\n        # active somehow. This makes the context available to parameter\n        # and command callbacks without needing @with_appcontext.\n        if not current_app or current_app._get_current_object() is not app:  # type: ignore[attr-defined]\n            ctx.with_resource(app.app_context())\n\n        return app.cli.get_command(ctx, name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        self._load_plugin_commands()\n        # Start with the built-in and plugin commands.\n        rv = set(super().list_commands(ctx))\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Add commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            rv.update(info.load_app().cli.list_commands(ctx))\n        except NoAppException as e:\n            # When an app couldn't be loaded, show the error message\n            # without the traceback.\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n        except Exception:\n            # When any other errors occurred during loading, show the\n            # full traceback.\n            click.secho(f\"{traceback.format_exc()}\\n\", err=True, fg=\"red\")\n\n        return sorted(rv)\n\n    def make_context(\n        self,\n        info_name: str | None,\n        args: list[str],\n        parent: click.Context | None = None,\n        **extra: t.Any,\n    ) -> click.Context:\n        # Set a flag to tell app.run to become a no-op. If app.run was\n        # not in a __name__ == __main__ guard, it would start the server\n        # when importing, blocking whatever command is being called.\n        os.environ[\"FLASK_RUN_FROM_CLI\"] = \"true\"\n\n        # Attempt to load .env and .flask env files. The --env-file\n        # option can cause another file to be loaded.\n        if get_load_dotenv(self.load_dotenv):\n            load_dotenv()\n\n        if \"obj\" not in extra and \"obj\" not in self.context_settings:\n            extra[\"obj\"] = ScriptInfo(\n                create_app=self.create_app, set_debug_flag=self.set_debug_flag\n            )\n\n        return super().make_context(info_name, args, parent=parent, **extra)\n\n    def parse_args(self, ctx: click.Context, args: list[str]) -> list[str]:\n        if not args and self.no_args_is_help:\n            # Attempt to load --env-file and --app early in case they\n            # were given as env vars. Otherwise no_args_is_help will not\n            # see commands from app.cli.\n            _env_file_option.handle_parse_result(ctx, {}, [])\n            _app_option.handle_parse_result(ctx, {}, [])\n\n        return super().parse_args(ctx, args)\n\n\ndef _path_is_ancestor(path: str, other: str) -> bool:\n    \"\"\"Take ``other`` and remove the length of ``path`` from it. Then join it\n    to ``path``. If it is the original value, ``path`` is an ancestor of\n    ``other``.\"\"\"\n    return os.path.join(path, other[len(path) :].lstrip(os.sep)) == other\n\n\ndef load_dotenv(path: str | os.PathLike[str] | None = None) -> bool:\n    \"\"\"Load \"dotenv\" files in order of precedence to set environment variables.\n\n    If an env var is already set it is not overwritten, so earlier files in the\n    list are preferred over later files.\n\n    This is a no-op if `python-dotenv`_ is not installed.\n\n    .. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n    :param path: Load the file at this location instead of searching.\n    :return: ``True`` if a file was loaded.\n\n    .. versionchanged:: 2.0\n        The current directory is not changed to the location of the\n        loaded file.\n\n    .. versionchanged:: 2.0\n        When loading the env files, set the default encoding to UTF-8.\n\n    .. versionchanged:: 1.1.0\n        Returns ``False`` when python-dotenv is not installed, or when\n        the given path isn't a file.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    try:\n        import dotenv\n    except ImportError:\n        if path or os.path.isfile(\".env\") or os.path.isfile(\".flaskenv\"):\n            click.secho(\n                \" * Tip: There are .env or .flaskenv files present.\"\n                ' Do \"pip install python-dotenv\" to use them.',\n                fg=\"yellow\",\n                err=True,\n            )\n\n        return False\n\n    # Always return after attempting to load a given path, don't load\n    # the default files.\n    if path is not None:\n        if os.path.isfile(path):\n            return dotenv.load_dotenv(path, encoding=\"utf-8\")\n\n        return False\n\n    loaded = False\n\n    for name in (\".env\", \".flaskenv\"):\n        path = dotenv.find_dotenv(name, usecwd=True)\n\n        if not path:\n            continue\n\n        dotenv.load_dotenv(path, encoding=\"utf-8\")\n        loaded = True\n\n    return loaded  # True if at least one file was located and loaded.\n\n\ndef show_server_banner(debug: bool, app_import_path: str | None) -> None:\n    \"\"\"Show extra startup messages the first time the server is run,\n    ignoring the reloader.\n    \"\"\"\n    if is_running_from_reloader():\n        return\n\n    if app_import_path is not None:\n        click.echo(f\" * Serving Flask app '{app_import_path}'\")\n\n    if debug is not None:\n        click.echo(f\" * Debug mode: {'on' if debug else 'off'}\")\n\n\nclass CertParamType(click.ParamType):\n    \"\"\"Click option type for the ``--cert`` option. Allows either an\n    existing file, the string ``'adhoc'``, or an import for a\n    :class:`~ssl.SSLContext` object.\n    \"\"\"\n\n    name = \"path\"\n\n    def __init__(self) -> None:\n        self.path_type = click.Path(exists=True, dir_okay=False, resolve_path=True)\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        try:\n            import ssl\n        except ImportError:\n            raise click.BadParameter(\n                'Using \"--cert\" requires Python to be compiled with SSL support.',\n                ctx,\n                param,\n            ) from None\n\n        try:\n            return self.path_type(value, param, ctx)\n        except click.BadParameter:\n            value = click.STRING(value, param, ctx).lower()\n\n            if value == \"adhoc\":\n                try:\n                    import cryptography  # noqa: F401\n                except ImportError:\n                    raise click.BadParameter(\n                        \"Using ad-hoc certificates requires the cryptography library.\",\n                        ctx,\n                        param,\n                    ) from None\n\n                return value\n\n            obj = import_string(value, silent=True)\n\n            if isinstance(obj, ssl.SSLContext):\n                return obj\n\n            raise\n\n\ndef _validate_key(ctx: click.Context, param: click.Parameter, value: t.Any) -> t.Any:\n    \"\"\"The ``--key`` option must be specified when ``--cert`` is a file.\n    Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.\n    \"\"\"\n    cert = ctx.params.get(\"cert\")\n    is_adhoc = cert == \"adhoc\"\n\n    try:\n        import ssl\n    except ImportError:\n        is_context = False\n    else:\n        is_context = isinstance(cert, ssl.SSLContext)\n\n    if value is not None:\n        if is_adhoc:\n            raise click.BadParameter(\n                'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n            )\n\n        if is_context:\n            raise click.BadParameter(\n                'When \"--cert\" is an SSLContext object, \"--key\" is not used.',\n                ctx,\n                param,\n            )\n\n        if not cert:\n            raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        ctx.params[\"cert\"] = cert, value\n\n    else:\n        if cert and not (is_adhoc or is_context):\n            raise click.BadParameter('Required when using \"--cert\".', ctx, param)\n\n    return value\n\n\nclass SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        items = self.split_envvar_value(value)\n        # can't call no-arg super() inside list comprehension until Python 3.12\n        super_convert = super().convert\n        return [super_convert(item, param, ctx) for item in items]\n\n\n@click.command(\"run\", short_help=\"Run a development server.\")\n@click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n@click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n@click.option(\n    \"--cert\",\n    type=CertParamType(),\n    help=\"Specify a certificate file to use HTTPS.\",\n    is_eager=True,\n)\n@click.option(\n    \"--key\",\n    type=click.Path(exists=True, dir_okay=False, resolve_path=True),\n    callback=_validate_key,\n    expose_value=False,\n    help=\"The key file to use when specifying a certificate.\",\n)\n@click.option(\n    \"--reload/--no-reload\",\n    default=None,\n    help=\"Enable or disable the reloader. By default the reloader \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--debugger/--no-debugger\",\n    default=None,\n    help=\"Enable or disable the debugger. By default the debugger \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--with-threads/--without-threads\",\n    default=True,\n    help=\"Enable or disable multithreading.\",\n)\n@click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        f\" are separated by {os.path.pathsep!r}.\"\n    ),\n)\n@click.option(\n    \"--exclude-patterns\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Files matching these fnmatch patterns will not trigger a reload\"\n        \" on change. Multiple patterns are separated by\"\n        f\" {os.path.pathsep!r}.\"\n    ),\n)\n@pass_script_info\ndef run_command(\n    info: ScriptInfo,\n    host: str,\n    port: int,\n    reload: bool,\n    debugger: bool,\n    with_threads: bool,\n    cert: ssl.SSLContext | tuple[str, str | None] | t.Literal[\"adhoc\"] | None,\n    extra_files: list[str] | None,\n    exclude_patterns: list[str] | None,\n) -> None:\n    \"\"\"Run a local development server.\n\n    This server is for development purposes only. It does not provide\n    the stability, security, or performance of production WSGI servers.\n\n    The reloader and debugger are enabled by default with the '--debug'\n    option.\n    \"\"\"\n    try:\n        app: WSGIApplication = info.load_app()  # pyright: ignore\n    except Exception as e:\n        if is_running_from_reloader():\n            # When reloading, print out the error immediately, but raise\n            # it later so the debugger or server can handle it.\n            traceback.print_exc()\n            err = e\n\n            def app(\n                environ: WSGIEnvironment, start_response: StartResponse\n            ) -> cabc.Iterable[bytes]:\n                raise err from None\n\n        else:\n            # When not reloading, raise the error immediately so the\n            # command fails.\n            raise e from None\n\n    debug = get_debug_flag()\n\n    if reload is None:\n        reload = debug\n\n    if debugger is None:\n        debugger = debug\n\n    show_server_banner(debug, info.app_import_path)\n\n    run_simple(\n        host,\n        port,\n        app,\n        use_reloader=reload,\n        use_debugger=debugger,\n        threaded=with_threads,\n        ssl_context=cert,\n        extra_files=extra_files,\n        exclude_patterns=exclude_patterns,\n    )\n\n\nrun_command.params.insert(0, _debug_option)\n\n\n@click.command(\"shell\", short_help=\"Run a shell in the app context.\")\n@with_appcontext\ndef shell_command() -> None:\n    \"\"\"Run an interactive Python shell in the context of a given\n    Flask application.  The application will populate the default\n    namespace of this shell according to its configuration.\n\n    This is useful for executing small snippets of management code\n    without having to manually configure the application.\n    \"\"\"\n    import code\n\n    banner = (\n        f\"Python {sys.version} on {sys.platform}\\n\"\n        f\"App: {current_app.import_name}\\n\"\n        f\"Instance: {current_app.instance_path}\"\n    )\n    ctx: dict[str, t.Any] = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get(\"PYTHONSTARTUP\")\n    if startup and os.path.isfile(startup):\n        with open(startup) as f:\n            eval(compile(f.read(), startup, \"exec\"), ctx)\n\n    ctx.update(current_app.make_shell_context())\n\n    # Site, customize, or startup script can set a hook to call when\n    # entering interactive mode. The default one sets up readline with\n    # tab and history completion.\n    interactive_hook = getattr(sys, \"__interactivehook__\", None)\n\n    if interactive_hook is not None:\n        try:\n            import readline\n            from rlcompleter import Completer\n        except ImportError:\n            pass\n        else:\n            # rlcompleter uses __main__.__dict__ by default, which is\n            # flask.__main__. Use the shell context instead.\n            readline.set_completer(Completer(ctx).complete)\n\n        interactive_hook()\n\n    code.interact(banner=banner, local=ctx)\n\n\n@click.command(\"routes\", short_help=\"Show the routes for the app.\")\n@click.option(\n    \"--sort\",\n    \"-s\",\n    type=click.Choice((\"endpoint\", \"methods\", \"domain\", \"rule\", \"match\")),\n    default=\"endpoint\",\n    help=(\n        \"Method to sort routes by. 'match' is the order that Flask will match routes\"\n        \" when dispatching a request.\"\n    ),\n)\n@click.option(\"--all-methods\", is_flag=True, help=\"Show HEAD and OPTIONS methods.\")\n@with_appcontext\ndef routes_command(sort: str, all_methods: bool) -> None:\n    \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n    rules = list(current_app.url_map.iter_rules())\n\n    if not rules:\n        click.echo(\"No routes were registered.\")\n        return\n\n    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n    host_matching = current_app.url_map.host_matching\n    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n    rows = []\n\n    for rule in rules:\n        row = [\n            rule.endpoint,\n            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n        ]\n\n        if has_domain:\n            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n\n        row.append(rule.rule)\n        rows.append(row)\n\n    headers = [\"Endpoint\", \"Methods\"]\n    sorts = [\"endpoint\", \"methods\"]\n\n    if has_domain:\n        headers.append(\"Host\" if host_matching else \"Subdomain\")\n        sorts.append(\"domain\")\n\n    headers.append(\"Rule\")\n    sorts.append(\"rule\")\n\n    try:\n        rows.sort(key=itemgetter(sorts.index(sort)))\n    except ValueError:\n        pass\n\n    rows.insert(0, headers)\n    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n    rows.insert(1, [\"-\" * w for w in widths])\n    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n\n    for row in rows:\n        click.echo(template.format(*row))\n\n\ncli = FlaskGroup(\n    name=\"flask\",\n    help=\"\"\"\\\nA general utility script for Flask applications.\n\nAn application to load must be given with the '--app' option,\n'FLASK_APP' environment variable, or with a 'wsgi.py' or 'app.py' file\nin the current directory.\n\"\"\",\n)\n\n\ndef main() -> None:\n    cli.main()\n\n\nif __name__ == \"__main__\":\n    main()\n",
      "bug_category": "type",
      "error_type": "type_error",
      "confidence": 0.4
    },
    {
      "bug_id": "cee8202bda55",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/helpers.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "code_after": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)  # pyright: ignore\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "bug_category": "type",
      "error_type": "type_error",
      "confidence": 0.4
    },
    {
      "bug_id": "de699efa1892",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/sansio/app.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nimport typing as t\nfrom datetime import timedelta\nfrom itertools import chain\n\nfrom werkzeug.exceptions import Aborter\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.sansio.response import Response\nfrom werkzeug.utils import cached_property\nfrom werkzeug.utils import redirect as _wz_redirect\n\nfrom .. import typing as ft\nfrom ..config import Config\nfrom ..config import ConfigAttribute\nfrom ..ctx import _AppCtxGlobals\nfrom ..helpers import _split_blueprint_path\nfrom ..helpers import get_debug_flag\nfrom ..json.provider import DefaultJSONProvider\nfrom ..json.provider import JSONProvider\nfrom ..logging import create_logger\nfrom ..templating import DispatchingJinjaLoader\nfrom ..templating import Environment\nfrom .scaffold import _endpoint_from_view_func\nfrom .scaffold import find_package\nfrom .scaffold import Scaffold\nfrom .scaffold import setupmethod\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.wrappers import Response as BaseResponse\n\n    from ..testing import FlaskClient\n    from ..testing import FlaskCliRunner\n    from .blueprints import Blueprint\n\nT_shell_context_processor = t.TypeVar(\n    \"T_shell_context_processor\", bound=ft.ShellContextProcessorCallable\n)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\n\n\ndef _make_timedelta(value: timedelta | int | None) -> timedelta | None:\n    if value is None or isinstance(value, timedelta):\n        return value\n\n    return timedelta(seconds=value)\n\n\nclass App(Scaffold):\n    \"\"\"The flask object implements a WSGI application and acts as the central\n    object.  It is passed the name of the module or package of the\n    application.  Once it is created it will act as a central registry for\n    the view functions, the URL rules, template configuration and much more.\n\n    The name of the package is used to resolve resources from inside the\n    package or the folder the module is contained in depending on if the\n    package parameter resolves to an actual python package (a folder with\n    an :file:`__init__.py` file inside) or a standard module (just a ``.py`` file).\n\n    For more information about resource loading, see :func:`open_resource`.\n\n    Usually you create a :class:`Flask` instance in your main module or\n    in the :file:`__init__.py` file of your package like this::\n\n        from flask import Flask\n        app = Flask(__name__)\n\n    .. admonition:: About the First Parameter\n\n        The idea of the first parameter is to give Flask an idea of what\n        belongs to your application.  This name is used to find resources\n        on the filesystem, can be used by extensions to improve debugging\n        information and a lot more.\n\n        So it's important what you provide there.  If you are using a single\n        module, `__name__` is always the correct value.  If you however are\n        using a package, it's usually recommended to hardcode the name of\n        your package there.\n\n        For example if your application is defined in :file:`yourapplication/app.py`\n        you should create it with one of the two versions below::\n\n            app = Flask('yourapplication')\n            app = Flask(__name__.split('.')[0])\n\n        Why is that?  The application will work even with `__name__`, thanks\n        to how resources are looked up.  However it will make debugging more\n        painful.  Certain extensions can make assumptions based on the\n        import name of your application.  For example the Flask-SQLAlchemy\n        extension will look for the code in your application that triggered\n        an SQL query in debug mode.  If the import name is not properly set\n        up, that debugging information is lost.  (For example it would only\n        pick up SQL queries in `yourapplication.app` and not\n        `yourapplication.views.frontend`)\n\n    .. versionadded:: 0.7\n       The `static_url_path`, `static_folder`, and `template_folder`\n       parameters were added.\n\n    .. versionadded:: 0.8\n       The `instance_path` and `instance_relative_config` parameters were\n       added.\n\n    .. versionadded:: 0.11\n       The `root_path` parameter was added.\n\n    .. versionadded:: 1.0\n       The ``host_matching`` and ``static_host`` parameters were added.\n\n    .. versionadded:: 1.0\n       The ``subdomain_matching`` parameter was added. Subdomain\n       matching needs to be enabled manually now. Setting\n       :data:`SERVER_NAME` does not implicitly enable it.\n\n    :param import_name: the name of the application package\n    :param static_url_path: can be used to specify a different path for the\n                            static files on the web.  Defaults to the name\n                            of the `static_folder` folder.\n    :param static_folder: The folder with static files that is served at\n        ``static_url_path``. Relative to the application ``root_path``\n        or an absolute path. Defaults to ``'static'``.\n    :param static_host: the host to use when adding the static route.\n        Defaults to None. Required when using ``host_matching=True``\n        with a ``static_folder`` configured.\n    :param host_matching: set ``url_map.host_matching`` attribute.\n        Defaults to False.\n    :param subdomain_matching: consider the subdomain relative to\n        :data:`SERVER_NAME` when matching routes. Defaults to False.\n    :param template_folder: the folder that contains the templates that should\n                            be used by the application.  Defaults to\n                            ``'templates'`` folder in the root path of the\n                            application.\n    :param instance_path: An alternative instance path for the application.\n                          By default the folder ``'instance'`` next to the\n                          package or module is assumed to be the instance\n                          path.\n    :param instance_relative_config: if set to ``True`` relative filenames\n                                     for loading the config are assumed to\n                                     be relative to the instance path instead\n                                     of the application root.\n    :param root_path: The path to the root of the application files.\n        This should only be set manually when it can't be detected\n        automatically, such as for namespace packages.\n    \"\"\"\n\n    #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n\n    #: The class that is used for the Jinja environment.\n    #:\n    #: .. versionadded:: 0.11\n    jinja_environment = Environment\n\n    #: The class that is used for the :data:`~flask.g` instance.\n    #:\n    #: Example use cases for a custom class:\n    #:\n    #: 1. Store arbitrary attributes on flask.g.\n    #: 2. Add a property for lazy per-request database connectors.\n    #: 3. Return None instead of AttributeError on unexpected attributes.\n    #: 4. Raise exception if an unexpected attr is set, a \"controlled\" flask.g.\n    #:\n    #: In Flask 0.9 this property was called `request_globals_class` but it\n    #: was changed in 0.10 to :attr:`app_ctx_globals_class` because the\n    #: flask.g object is now application context scoped.\n    #:\n    #: .. versionadded:: 0.10\n    app_ctx_globals_class = _AppCtxGlobals\n\n    #: The class that is used for the ``config`` attribute of this app.\n    #: Defaults to :class:`~flask.Config`.\n    #:\n    #: Example use cases for a custom class:\n    #:\n    #: 1. Default values for certain config options.\n    #: 2. Access to config values through attributes in addition to keys.\n    #:\n    #: .. versionadded:: 0.11\n    config_class = Config\n\n    #: The testing flag.  Set this to ``True`` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate test helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: If this is enabled and PROPAGATE_EXCEPTIONS is not changed from the\n    #: default it's implicitly enabled.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: ``TESTING`` configuration key.  Defaults to ``False``.\n    testing = ConfigAttribute[bool](\"TESTING\")\n\n    #: If a secret key is set, cryptographic components can use this to\n    #: sign cookies and other things. Set this to a complex random value\n    #: when you want to use the secure cookie for instance.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: :data:`SECRET_KEY` configuration key. Defaults to ``None``.\n    secret_key = ConfigAttribute[t.Union[str, bytes, None]](\"SECRET_KEY\")\n\n    #: A :class:`~datetime.timedelta` which is used to set the expiration\n    #: date of a permanent session.  The default is 31 days which makes a\n    #: permanent session survive for roughly one month.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: ``PERMANENT_SESSION_LIFETIME`` configuration key.  Defaults to\n    #: ``timedelta(days=31)``\n    permanent_session_lifetime = ConfigAttribute[timedelta](\n        \"PERMANENT_SESSION_LIFETIME\",\n        get_converter=_make_timedelta,  # type: ignore[arg-type]\n    )\n\n    json_provider_class: type[JSONProvider] = DefaultJSONProvider\n    \"\"\"A subclass of :class:`~flask.json.provider.JSONProvider`. An\n    instance is created and assigned to :attr:`app.json` when creating\n    the app.\n\n    The default, :class:`~flask.json.provider.DefaultJSONProvider`, uses\n    Python's built-in :mod:`json` library. A different provider can use\n    a different JSON library.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    #: Options that are passed to the Jinja environment in\n    #: :meth:`create_jinja_environment`. Changing these options after\n    #: the environment is created (accessing :attr:`jinja_env`) will\n    #: have no effect.\n    #:\n    #: .. versionchanged:: 1.1.0\n    #:     This is a ``dict`` instead of an ``ImmutableDict`` to allow\n    #:     easier configuration.\n    #:\n    jinja_options: dict[str, t.Any] = {}\n\n    #: The rule object to use for URL rules created.  This is used by\n    #: :meth:`add_url_rule`.  Defaults to :class:`werkzeug.routing.Rule`.\n    #:\n    #: .. versionadded:: 0.7\n    url_rule_class = Rule\n\n    #: The map object to use for storing the URL rules and routing\n    #: configuration parameters. Defaults to :class:`werkzeug.routing.Map`.\n    #:\n    #: .. versionadded:: 1.1.0\n    url_map_class = Map\n\n    #: The :meth:`test_client` method creates an instance of this test\n    #: client class. Defaults to :class:`~flask.testing.FlaskClient`.\n    #:\n    #: .. versionadded:: 0.7\n    test_client_class: type[FlaskClient] | None = None\n\n    #: The :class:`~click.testing.CliRunner` subclass, by default\n    #: :class:`~flask.testing.FlaskCliRunner` that is used by\n    #: :meth:`test_cli_runner`. Its ``__init__`` method should take a\n    #: Flask app object as the first argument.\n    #:\n    #: .. versionadded:: 1.0\n    test_cli_runner_class: type[FlaskCliRunner] | None = None\n\n    default_config: dict[str, t.Any]\n    response_class: type[Response]\n\n    def __init__(\n        self,\n        import_name: str,\n        static_url_path: str | None = None,\n        static_folder: str | os.PathLike[str] | None = \"static\",\n        static_host: str | None = None,\n        host_matching: bool = False,\n        subdomain_matching: bool = False,\n        template_folder: str | os.PathLike[str] | None = \"templates\",\n        instance_path: str | None = None,\n        instance_relative_config: bool = False,\n        root_path: str | None = None,\n    ) -> None:\n        super().__init__(\n            import_name=import_name,\n            static_folder=static_folder,\n            static_url_path=static_url_path,\n            template_folder=template_folder,\n            root_path=root_path,\n        )\n\n        if instance_path is None:\n            instance_path = self.auto_find_instance_path()\n        elif not os.path.isabs(instance_path):\n            raise ValueError(\n                \"If an instance path is provided it must be absolute.\"\n                \" A relative path was given instead.\"\n            )\n\n        #: Holds the path to the instance folder.\n        #:\n        #: .. versionadded:: 0.8\n        self.instance_path = instance_path\n\n        #: The configuration dictionary as :class:`Config`.  This behaves\n        #: exactly like a regular dictionary but supports additional methods\n        #: to load a config from files.\n        self.config = self.make_config(instance_relative_config)\n\n        #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        #:     Moved from ``flask.abort``, which calls this object.\n        self.aborter = self.make_aborter()\n\n        self.json: JSONProvider = self.json_provider_class(self)\n        \"\"\"Provides access to JSON methods. Functions in ``flask.json``\n        will call methods on this provider when the application context\n        is active. Used for handling JSON requests and responses.\n\n        An instance of :attr:`json_provider_class`. Can be customized by\n        changing that attribute on a subclass, or by assigning to this\n        attribute afterwards.\n\n        The default, :class:`~flask.json.provider.DefaultJSONProvider`,\n        uses Python's built-in :mod:`json` library. A different provider\n        can use a different JSON library.\n\n        .. versionadded:: 2.2\n        \"\"\"\n\n        #: A list of functions that are called by\n        #: :meth:`handle_url_build_error` when :meth:`.url_for` raises a\n        #: :exc:`~werkzeug.routing.BuildError`. Each function is called\n        #: with ``error``, ``endpoint`` and ``values``. If a function\n        #: returns ``None`` or raises a ``BuildError``, it is skipped.\n        #: Otherwise, its return value is returned by ``url_for``.\n        #:\n        #: .. versionadded:: 0.9\n        self.url_build_error_handlers: list[\n            t.Callable[[Exception, str, dict[str, t.Any]], str]\n        ] = []\n\n        #: A list of functions that are called when the application context\n        #: is destroyed.  Since the application context is also torn down\n        #: if the request ends this is the place to store code that disconnects\n        #: from databases.\n        #:\n        #: .. versionadded:: 0.9\n        self.teardown_appcontext_funcs: list[ft.TeardownCallable] = []\n\n        #: A list of shell context processor functions that should be run\n        #: when a shell context is created.\n        #:\n        #: .. versionadded:: 0.11\n        self.shell_context_processors: list[ft.ShellContextProcessorCallable] = []\n\n        #: Maps registered blueprint names to blueprint objects. The\n        #: dict retains the order the blueprints were registered in.\n        #: Blueprints can be registered multiple times, this dict does\n        #: not track how often they were attached.\n        #:\n        #: .. versionadded:: 0.7\n        self.blueprints: dict[str, Blueprint] = {}\n\n        #: a place where extensions can store application specific state.  For\n        #: example this is where an extension could store database engines and\n        #: similar things.\n        #:\n        #: The key must match the name of the extension module. For example in\n        #: case of a \"Flask-Foo\" extension in `flask_foo`, the key would be\n        #: ``'foo'``.\n        #:\n        #: .. versionadded:: 0.7\n        self.extensions: dict[str, t.Any] = {}\n\n        #: The :class:`~werkzeug.routing.Map` for this instance.  You can use\n        #: this to change the routing converters after the class was created\n        #: but before any routes are connected.  Example::\n        #:\n        #:    from werkzeug.routing import BaseConverter\n        #:\n        #:    class ListConverter(BaseConverter):\n        #:        def to_python(self, value):\n        #:            return value.split(',')\n        #:        def to_url(self, values):\n        #:            return ','.join(super(ListConverter, self).to_url(value)\n        #:                            for value in values)\n        #:\n        #:    app = Flask(__name__)\n        #:    app.url_map.converters['list'] = ListConverter\n        self.url_map = self.url_map_class(host_matching=host_matching)\n\n        self.subdomain_matching = subdomain_matching\n\n        # tracks internally if the application already handled at least one\n        # request.\n        self._got_first_request = False\n\n    def _check_setup_finished(self, f_name: str) -> None:\n        if self._got_first_request:\n            raise AssertionError(\n                f\"The setup method '{f_name}' can no longer be called\"\n                \" on the application. It has already handled its first\"\n                \" request, any changes will not be applied\"\n                \" consistently.\\n\"\n                \"Make sure all imports, decorators, functions, etc.\"\n                \" needed to set up the application are done before\"\n                \" running it.\"\n            )\n\n    @cached_property\n    def name(self) -> str:  # type: ignore\n        \"\"\"The name of the application.  This is usually the import name\n        with the difference that it's guessed from the run file if the\n        import name is main.  This name is used as a display name when\n        Flask needs the name of the application.  It can be set and overridden\n        to change the value.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.import_name == \"__main__\":\n            fn: str | None = getattr(sys.modules[\"__main__\"], \"__file__\", None)\n            if fn is None:\n                return \"__main__\"\n            return os.path.splitext(os.path.basename(fn))[0]\n        return self.import_name\n\n    @cached_property\n    def logger(self) -> logging.Logger:\n        \"\"\"A standard Python :class:`~logging.Logger` for the app, with\n        the same name as :attr:`name`.\n\n        In debug mode, the logger's :attr:`~logging.Logger.level` will\n        be set to :data:`~logging.DEBUG`.\n\n        If there are no handlers configured, a default handler will be\n        added. See :doc:`/logging` for more information.\n\n        .. versionchanged:: 1.1.0\n            The logger takes the same name as :attr:`name` rather than\n            hard-coding ``\"flask.app\"``.\n\n        .. versionchanged:: 1.0.0\n            Behavior was simplified. The logger is always named\n            ``\"flask.app\"``. The level is only set during configuration,\n            it doesn't check ``app.debug`` each time. Only one format is\n            used, not different ones depending on ``app.debug``. No\n            handlers are removed, and a handler is only added if no\n            handlers are already configured.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        return create_logger(self)\n\n    @cached_property\n    def jinja_env(self) -> Environment:\n        \"\"\"The Jinja environment used to load templates.\n\n        The environment is created the first time this property is\n        accessed. Changing :attr:`jinja_options` after that will have no\n        effect.\n        \"\"\"\n        return self.create_jinja_environment()\n\n    def create_jinja_environment(self) -> Environment:\n        raise NotImplementedError()\n\n    def make_config(self, instance_relative: bool = False) -> Config:\n        \"\"\"Used to create the config attribute by the Flask constructor.\n        The `instance_relative` parameter is passed in from the constructor\n        of Flask (there named `instance_relative_config`) and indicates if\n        the config should be relative to the instance path or the root path\n        of the application.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        root_path = self.root_path\n        if instance_relative:\n            root_path = self.instance_path\n        defaults = dict(self.default_config)\n        defaults[\"DEBUG\"] = get_debug_flag()\n        return self.config_class(root_path, defaults)\n\n    def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n\n    def auto_find_instance_path(self) -> str:\n        \"\"\"Tries to locate the instance path if it was not provided to the\n        constructor of the application class.  It will basically calculate\n        the path to a folder named ``instance`` next to your main file or\n        the package.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        prefix, package_path = find_package(self.import_name)\n        if prefix is None:\n            return os.path.join(package_path, \"instance\")\n        return os.path.join(prefix, \"var\", f\"{self.name}-instance\")\n\n    def create_global_jinja_loader(self) -> DispatchingJinjaLoader:\n        \"\"\"Creates the loader for the Jinja2 environment.  Can be used to\n        override just the loader and keeping the rest unchanged.  It's\n        discouraged to override this function.  Instead one should override\n        the :meth:`jinja_loader` function instead.\n\n        The global loader dispatches between the loaders of the application\n        and the individual blueprints.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        return DispatchingJinjaLoader(self)\n\n    def select_jinja_autoescape(self, filename: str) -> bool:\n        \"\"\"Returns ``True`` if autoescaping should be active for the given\n        template name. If no template name is given, returns `True`.\n\n        .. versionchanged:: 2.2\n            Autoescaping is now enabled by default for ``.svg`` files.\n\n        .. versionadded:: 0.5\n        \"\"\"\n        if filename is None:\n            return True\n        return filename.endswith((\".html\", \".htm\", \".xml\", \".xhtml\", \".svg\"))\n\n    @property\n    def debug(self) -> bool:\n        \"\"\"Whether debug mode is enabled. When using ``flask run`` to start the\n        development server, an interactive debugger will be shown for unhandled\n        exceptions, and the server will be reloaded when code changes. This maps to the\n        :data:`DEBUG` config key. It may not behave as expected if set late.\n\n        **Do not enable debug mode when deploying in production.**\n\n        Default: ``False``\n        \"\"\"\n        return self.config[\"DEBUG\"]  # type: ignore[no-any-return]\n\n    @debug.setter\n    def debug(self, value: bool) -> None:\n        self.config[\"DEBUG\"] = value\n\n        if self.config[\"TEMPLATES_AUTO_RELOAD\"] is None:\n            self.jinja_env.auto_reload = value\n\n    @setupmethod\n    def register_blueprint(self, blueprint: Blueprint, **options: t.Any) -> None:\n        \"\"\"Register a :class:`~flask.Blueprint` on the application. Keyword\n        arguments passed to this method will override the defaults set on the\n        blueprint.\n\n        Calls the blueprint's :meth:`~flask.Blueprint.register` method after\n        recording the blueprint in the application's :attr:`blueprints`.\n\n        :param blueprint: The blueprint to register.\n        :param url_prefix: Blueprint routes will be prefixed with this.\n        :param subdomain: Blueprint routes will match on this subdomain.\n        :param url_defaults: Blueprint routes will use these default values for\n            view arguments.\n        :param options: Additional keyword arguments are passed to\n            :class:`~flask.blueprints.BlueprintSetupState`. They can be\n            accessed in :meth:`~flask.Blueprint.record` callbacks.\n\n        .. versionchanged:: 2.0.1\n            The ``name`` option can be used to change the (pre-dotted)\n            name the blueprint is registered with. This allows the same\n            blueprint to be registered multiple times with unique names\n            for ``url_for``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        blueprint.register(self, options)\n\n    def iter_blueprints(self) -> t.ValuesView[Blueprint]:\n        \"\"\"Iterates over all blueprints by the order they were registered.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        return self.blueprints.values()\n\n    @setupmethod\n    def add_url_rule(\n        self,\n        rule: str,\n        endpoint: str | None = None,\n        view_func: ft.RouteCallable | None = None,\n        provide_automatic_options: bool | None = None,\n        **options: t.Any,\n    ) -> None:\n        if endpoint is None:\n            endpoint = _endpoint_from_view_func(view_func)  # type: ignore\n        options[\"endpoint\"] = endpoint\n        methods = options.pop(\"methods\", None)\n\n        # if the methods are not given and the view_func object knows its\n        # methods we can use that instead.  If neither exists, we go with\n        # a tuple of only ``GET`` as default.\n        if methods is None:\n            methods = getattr(view_func, \"methods\", None) or (\"GET\",)\n        if isinstance(methods, str):\n            raise TypeError(\n                \"Allowed methods must be a list of strings, for\"\n                ' example: @app.route(..., methods=[\"POST\"])'\n            )\n        methods = {item.upper() for item in methods}\n\n        # Methods that should always be added\n        required_methods = set(getattr(view_func, \"required_methods\", ()))\n\n        # starting with Flask 0.8 the view_func object can disable and\n        # force-enable the automatic options handling.\n        if provide_automatic_options is None:\n            provide_automatic_options = getattr(\n                view_func, \"provide_automatic_options\", None\n            )\n\n        if provide_automatic_options is None:\n            if \"OPTIONS\" not in methods and self.config[\"PROVIDE_AUTOMATIC_OPTIONS\"]:\n                provide_automatic_options = True\n                required_methods.add(\"OPTIONS\")\n            else:\n                provide_automatic_options = False\n\n        # Add the required methods now.\n        methods |= required_methods\n\n        rule_obj = self.url_rule_class(rule, methods=methods, **options)\n        rule_obj.provide_automatic_options = provide_automatic_options  # type: ignore[attr-defined]\n\n        self.url_map.add(rule_obj)\n        if view_func is not None:\n            old_func = self.view_functions.get(endpoint)\n            if old_func is not None and old_func != view_func:\n                raise AssertionError(\n                    \"View function mapping is overwriting an existing\"\n                    f\" endpoint function: {endpoint}\"\n                )\n            self.view_functions[endpoint] = view_func\n\n    @setupmethod\n    def template_filter(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_filter], T_template_filter]:\n        \"\"\"A decorator that is used to register custom template filter.\n        You can specify a name for the filter, otherwise the function\n        name will be used. Example::\n\n          @app.template_filter()\n          def reverse(s):\n              return s[::-1]\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_filter) -> T_template_filter:\n            self.add_template_filter(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_filter(\n        self, f: ft.TemplateFilterCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template filter.  Works exactly like the\n        :meth:`template_filter` decorator.\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.filters[name or f.__name__] = f\n\n    @setupmethod\n    def template_test(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_test], T_template_test]:\n        \"\"\"A decorator that is used to register custom template test.\n        You can specify a name for the test, otherwise the function\n        name will be used. Example::\n\n          @app.template_test()\n          def is_prime(n):\n              if n == 2:\n                  return True\n              for i in range(2, int(math.ceil(math.sqrt(n))) + 1):\n                  if n % i == 0:\n                      return False\n              return True\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the test, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_test) -> T_template_test:\n            self.add_template_test(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_test(\n        self, f: ft.TemplateTestCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template test.  Works exactly like the\n        :meth:`template_test` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the test, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.tests[name or f.__name__] = f\n\n    @setupmethod\n    def template_global(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_global], T_template_global]:\n        \"\"\"A decorator that is used to register a custom template global function.\n        You can specify a name for the global function, otherwise the function\n        name will be used. Example::\n\n            @app.template_global()\n            def double(n):\n                return 2 * n\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_global) -> T_template_global:\n            self.add_template_global(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_global(\n        self, f: ft.TemplateGlobalCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template global function. Works exactly like the\n        :meth:`template_global` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.globals[name or f.__name__] = f\n\n    @setupmethod\n    def teardown_appcontext(self, f: T_teardown) -> T_teardown:\n        \"\"\"Registers a function to be called when the application\n        context is popped. The application context is typically popped\n        after the request context for each request, at the end of CLI\n        commands, or after a manually pushed context ends.\n\n        .. code-block:: python\n\n            with app.app_context():\n                ...\n\n        When the ``with`` block exits (or ``ctx.pop()`` is called), the\n        teardown functions are called just before the app context is\n        made inactive. Since a request context typically also manages an\n        application context it would also be called when you pop a\n        request context.\n\n        When a teardown function was called because of an unhandled\n        exception it will be passed an error object. If an\n        :meth:`errorhandler` is registered, it will handle the exception\n        and the teardown will not receive it.\n\n        Teardown functions must avoid raising exceptions. If they\n        execute code that might fail they must surround that code with a\n        ``try``/``except`` block and log any errors.\n\n        The return values of teardown functions are ignored.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        self.teardown_appcontext_funcs.append(f)\n        return f\n\n    @setupmethod\n    def shell_context_processor(\n        self, f: T_shell_context_processor\n    ) -> T_shell_context_processor:\n        \"\"\"Registers a shell context processor function.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        self.shell_context_processors.append(f)\n        return f\n\n    def _find_error_handler(\n        self, e: Exception, blueprints: list[str]\n    ) -> ft.ErrorHandlerCallable | None:\n        \"\"\"Return a registered error handler for an exception in this order:\n        blueprint handler for a specific code, app handler for a specific code,\n        blueprint handler for an exception class, app handler for an exception\n        class, or ``None`` if a suitable handler is not found.\n        \"\"\"\n        exc_class, code = self._get_exc_class_and_code(type(e))\n        names = (*blueprints, None)\n\n        for c in (code, None) if code is not None else (None,):\n            for name in names:\n                handler_map = self.error_handler_spec[name][c]\n\n                if not handler_map:\n                    continue\n\n                for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls)\n\n                    if handler is not None:\n                        return handler\n        return None\n\n    def trap_http_exception(self, e: Exception) -> bool:\n        \"\"\"Checks if an HTTP exception should be trapped or not.  By default\n        this will return ``False`` for all exceptions except for a bad request\n        key error if ``TRAP_BAD_REQUEST_ERRORS`` is set to ``True``.  It\n        also returns ``True`` if ``TRAP_HTTP_EXCEPTIONS`` is set to ``True``.\n\n        This is called for all HTTP exceptions raised by a view function.\n        If it returns ``True`` for any exception the error handler for this\n        exception is not called and it shows up as regular exception in the\n        traceback.  This is helpful for debugging implicitly raised HTTP\n        exceptions.\n\n        .. versionchanged:: 1.0\n            Bad request errors are not trapped by default in debug mode.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.config[\"TRAP_HTTP_EXCEPTIONS\"]:\n            return True\n\n        trap_bad_request = self.config[\"TRAP_BAD_REQUEST_ERRORS\"]\n\n        # if unset, trap key errors in debug mode\n        if (\n            trap_bad_request is None\n            and self.debug\n            and isinstance(e, BadRequestKeyError)\n        ):\n            return True\n\n        if trap_bad_request:\n            return isinstance(e, BadRequest)\n\n        return False\n\n    def should_ignore_error(self, error: BaseException | None) -> bool:\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns ``True`` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False\n\n    def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        This is called by :func:`flask.redirect`, and can be called\n        directly as well.\n\n        :param location: The URL to redirect to.\n        :param code: The status code for the redirect.\n\n        .. versionadded:: 2.2\n            Moved from ``flask.redirect``, which calls this method.\n        \"\"\"\n        return _wz_redirect(\n            location,\n            code=code,\n            Response=self.response_class,  # type: ignore[arg-type]\n        )\n\n    def inject_url_defaults(self, endpoint: str, values: dict[str, t.Any]) -> None:\n        \"\"\"Injects the URL defaults for the given endpoint directly into\n        the values dictionary passed.  This is used internally and\n        automatically called on URL building.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        names: t.Iterable[str | None] = (None,)\n\n        # url_for may be called outside a request context, parse the\n        # passed endpoint instead of using request.blueprints.\n        if \".\" in endpoint:\n            names = chain(\n                names, reversed(_split_blueprint_path(endpoint.rpartition(\".\")[0]))\n            )\n\n        for name in names:\n            if name in self.url_default_functions:\n                for func in self.url_default_functions[name]:\n                    func(endpoint, values)\n\n    def handle_url_build_error(\n        self, error: BuildError, endpoint: str, values: dict[str, t.Any]\n    ) -> str:\n        \"\"\"Called by :meth:`.url_for` if a\n        :exc:`~werkzeug.routing.BuildError` was raised. If this returns\n        a value, it will be returned by ``url_for``, otherwise the error\n        will be re-raised.\n\n        Each function in :attr:`url_build_error_handlers` is called with\n        ``error``, ``endpoint`` and ``values``. If a function returns\n        ``None`` or raises a ``BuildError``, it is skipped. Otherwise,\n        its return value is returned by ``url_for``.\n\n        :param error: The active ``BuildError`` being handled.\n        :param endpoint: The endpoint being built.\n        :param values: The keyword arguments passed to ``url_for``.\n        \"\"\"\n        for handler in self.url_build_error_handlers:\n            try:\n                rv = handler(error, endpoint, values)\n            except BuildError as e:\n                # make error available outside except block\n                error = e\n            else:\n                if rv is not None:\n                    return rv\n\n        # Re-raise if called with an active exception, otherwise raise\n        # the passed in exception.\n        if error is sys.exc_info()[1]:\n            raise\n\n        raise error\n",
      "code_after": "from __future__ import annotations\n\nimport logging\nimport os\nimport sys\nimport typing as t\nfrom datetime import timedelta\nfrom itertools import chain\n\nfrom werkzeug.exceptions import Aborter\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import BadRequestKeyError\nfrom werkzeug.routing import BuildError\nfrom werkzeug.routing import Map\nfrom werkzeug.routing import Rule\nfrom werkzeug.sansio.response import Response\nfrom werkzeug.utils import cached_property\nfrom werkzeug.utils import redirect as _wz_redirect\n\nfrom .. import typing as ft\nfrom ..config import Config\nfrom ..config import ConfigAttribute\nfrom ..ctx import _AppCtxGlobals\nfrom ..helpers import _split_blueprint_path\nfrom ..helpers import get_debug_flag\nfrom ..json.provider import DefaultJSONProvider\nfrom ..json.provider import JSONProvider\nfrom ..logging import create_logger\nfrom ..templating import DispatchingJinjaLoader\nfrom ..templating import Environment\nfrom .scaffold import _endpoint_from_view_func\nfrom .scaffold import find_package\nfrom .scaffold import Scaffold\nfrom .scaffold import setupmethod\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.wrappers import Response as BaseResponse\n\n    from ..testing import FlaskClient\n    from ..testing import FlaskCliRunner\n    from .blueprints import Blueprint\n\nT_shell_context_processor = t.TypeVar(\n    \"T_shell_context_processor\", bound=ft.ShellContextProcessorCallable\n)\nT_teardown = t.TypeVar(\"T_teardown\", bound=ft.TeardownCallable)\nT_template_filter = t.TypeVar(\"T_template_filter\", bound=ft.TemplateFilterCallable)\nT_template_global = t.TypeVar(\"T_template_global\", bound=ft.TemplateGlobalCallable)\nT_template_test = t.TypeVar(\"T_template_test\", bound=ft.TemplateTestCallable)\n\n\ndef _make_timedelta(value: timedelta | int | None) -> timedelta | None:\n    if value is None or isinstance(value, timedelta):\n        return value\n\n    return timedelta(seconds=value)\n\n\nclass App(Scaffold):\n    \"\"\"The flask object implements a WSGI application and acts as the central\n    object.  It is passed the name of the module or package of the\n    application.  Once it is created it will act as a central registry for\n    the view functions, the URL rules, template configuration and much more.\n\n    The name of the package is used to resolve resources from inside the\n    package or the folder the module is contained in depending on if the\n    package parameter resolves to an actual python package (a folder with\n    an :file:`__init__.py` file inside) or a standard module (just a ``.py`` file).\n\n    For more information about resource loading, see :func:`open_resource`.\n\n    Usually you create a :class:`Flask` instance in your main module or\n    in the :file:`__init__.py` file of your package like this::\n\n        from flask import Flask\n        app = Flask(__name__)\n\n    .. admonition:: About the First Parameter\n\n        The idea of the first parameter is to give Flask an idea of what\n        belongs to your application.  This name is used to find resources\n        on the filesystem, can be used by extensions to improve debugging\n        information and a lot more.\n\n        So it's important what you provide there.  If you are using a single\n        module, `__name__` is always the correct value.  If you however are\n        using a package, it's usually recommended to hardcode the name of\n        your package there.\n\n        For example if your application is defined in :file:`yourapplication/app.py`\n        you should create it with one of the two versions below::\n\n            app = Flask('yourapplication')\n            app = Flask(__name__.split('.')[0])\n\n        Why is that?  The application will work even with `__name__`, thanks\n        to how resources are looked up.  However it will make debugging more\n        painful.  Certain extensions can make assumptions based on the\n        import name of your application.  For example the Flask-SQLAlchemy\n        extension will look for the code in your application that triggered\n        an SQL query in debug mode.  If the import name is not properly set\n        up, that debugging information is lost.  (For example it would only\n        pick up SQL queries in `yourapplication.app` and not\n        `yourapplication.views.frontend`)\n\n    .. versionadded:: 0.7\n       The `static_url_path`, `static_folder`, and `template_folder`\n       parameters were added.\n\n    .. versionadded:: 0.8\n       The `instance_path` and `instance_relative_config` parameters were\n       added.\n\n    .. versionadded:: 0.11\n       The `root_path` parameter was added.\n\n    .. versionadded:: 1.0\n       The ``host_matching`` and ``static_host`` parameters were added.\n\n    .. versionadded:: 1.0\n       The ``subdomain_matching`` parameter was added. Subdomain\n       matching needs to be enabled manually now. Setting\n       :data:`SERVER_NAME` does not implicitly enable it.\n\n    :param import_name: the name of the application package\n    :param static_url_path: can be used to specify a different path for the\n                            static files on the web.  Defaults to the name\n                            of the `static_folder` folder.\n    :param static_folder: The folder with static files that is served at\n        ``static_url_path``. Relative to the application ``root_path``\n        or an absolute path. Defaults to ``'static'``.\n    :param static_host: the host to use when adding the static route.\n        Defaults to None. Required when using ``host_matching=True``\n        with a ``static_folder`` configured.\n    :param host_matching: set ``url_map.host_matching`` attribute.\n        Defaults to False.\n    :param subdomain_matching: consider the subdomain relative to\n        :data:`SERVER_NAME` when matching routes. Defaults to False.\n    :param template_folder: the folder that contains the templates that should\n                            be used by the application.  Defaults to\n                            ``'templates'`` folder in the root path of the\n                            application.\n    :param instance_path: An alternative instance path for the application.\n                          By default the folder ``'instance'`` next to the\n                          package or module is assumed to be the instance\n                          path.\n    :param instance_relative_config: if set to ``True`` relative filenames\n                                     for loading the config are assumed to\n                                     be relative to the instance path instead\n                                     of the application root.\n    :param root_path: The path to the root of the application files.\n        This should only be set manually when it can't be detected\n        automatically, such as for namespace packages.\n    \"\"\"\n\n    #: The class of the object assigned to :attr:`aborter`, created by\n    #: :meth:`create_aborter`. That object is called by\n    #: :func:`flask.abort` to raise HTTP errors, and can be\n    #: called directly as well.\n    #:\n    #: Defaults to :class:`werkzeug.exceptions.Aborter`.\n    #:\n    #: .. versionadded:: 2.2\n    aborter_class = Aborter\n\n    #: The class that is used for the Jinja environment.\n    #:\n    #: .. versionadded:: 0.11\n    jinja_environment = Environment\n\n    #: The class that is used for the :data:`~flask.g` instance.\n    #:\n    #: Example use cases for a custom class:\n    #:\n    #: 1. Store arbitrary attributes on flask.g.\n    #: 2. Add a property for lazy per-request database connectors.\n    #: 3. Return None instead of AttributeError on unexpected attributes.\n    #: 4. Raise exception if an unexpected attr is set, a \"controlled\" flask.g.\n    #:\n    #: In Flask 0.9 this property was called `request_globals_class` but it\n    #: was changed in 0.10 to :attr:`app_ctx_globals_class` because the\n    #: flask.g object is now application context scoped.\n    #:\n    #: .. versionadded:: 0.10\n    app_ctx_globals_class = _AppCtxGlobals\n\n    #: The class that is used for the ``config`` attribute of this app.\n    #: Defaults to :class:`~flask.Config`.\n    #:\n    #: Example use cases for a custom class:\n    #:\n    #: 1. Default values for certain config options.\n    #: 2. Access to config values through attributes in addition to keys.\n    #:\n    #: .. versionadded:: 0.11\n    config_class = Config\n\n    #: The testing flag.  Set this to ``True`` to enable the test mode of\n    #: Flask extensions (and in the future probably also Flask itself).\n    #: For example this might activate test helpers that have an\n    #: additional runtime cost which should not be enabled by default.\n    #:\n    #: If this is enabled and PROPAGATE_EXCEPTIONS is not changed from the\n    #: default it's implicitly enabled.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: ``TESTING`` configuration key.  Defaults to ``False``.\n    testing = ConfigAttribute[bool](\"TESTING\")\n\n    #: If a secret key is set, cryptographic components can use this to\n    #: sign cookies and other things. Set this to a complex random value\n    #: when you want to use the secure cookie for instance.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: :data:`SECRET_KEY` configuration key. Defaults to ``None``.\n    secret_key = ConfigAttribute[t.Union[str, bytes, None]](\"SECRET_KEY\")\n\n    #: A :class:`~datetime.timedelta` which is used to set the expiration\n    #: date of a permanent session.  The default is 31 days which makes a\n    #: permanent session survive for roughly one month.\n    #:\n    #: This attribute can also be configured from the config with the\n    #: ``PERMANENT_SESSION_LIFETIME`` configuration key.  Defaults to\n    #: ``timedelta(days=31)``\n    permanent_session_lifetime = ConfigAttribute[timedelta](\n        \"PERMANENT_SESSION_LIFETIME\",\n        get_converter=_make_timedelta,  # type: ignore[arg-type]\n    )\n\n    json_provider_class: type[JSONProvider] = DefaultJSONProvider\n    \"\"\"A subclass of :class:`~flask.json.provider.JSONProvider`. An\n    instance is created and assigned to :attr:`app.json` when creating\n    the app.\n\n    The default, :class:`~flask.json.provider.DefaultJSONProvider`, uses\n    Python's built-in :mod:`json` library. A different provider can use\n    a different JSON library.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    #: Options that are passed to the Jinja environment in\n    #: :meth:`create_jinja_environment`. Changing these options after\n    #: the environment is created (accessing :attr:`jinja_env`) will\n    #: have no effect.\n    #:\n    #: .. versionchanged:: 1.1.0\n    #:     This is a ``dict`` instead of an ``ImmutableDict`` to allow\n    #:     easier configuration.\n    #:\n    jinja_options: dict[str, t.Any] = {}\n\n    #: The rule object to use for URL rules created.  This is used by\n    #: :meth:`add_url_rule`.  Defaults to :class:`werkzeug.routing.Rule`.\n    #:\n    #: .. versionadded:: 0.7\n    url_rule_class = Rule\n\n    #: The map object to use for storing the URL rules and routing\n    #: configuration parameters. Defaults to :class:`werkzeug.routing.Map`.\n    #:\n    #: .. versionadded:: 1.1.0\n    url_map_class = Map\n\n    #: The :meth:`test_client` method creates an instance of this test\n    #: client class. Defaults to :class:`~flask.testing.FlaskClient`.\n    #:\n    #: .. versionadded:: 0.7\n    test_client_class: type[FlaskClient] | None = None\n\n    #: The :class:`~click.testing.CliRunner` subclass, by default\n    #: :class:`~flask.testing.FlaskCliRunner` that is used by\n    #: :meth:`test_cli_runner`. Its ``__init__`` method should take a\n    #: Flask app object as the first argument.\n    #:\n    #: .. versionadded:: 1.0\n    test_cli_runner_class: type[FlaskCliRunner] | None = None\n\n    default_config: dict[str, t.Any]\n    response_class: type[Response]\n\n    def __init__(\n        self,\n        import_name: str,\n        static_url_path: str | None = None,\n        static_folder: str | os.PathLike[str] | None = \"static\",\n        static_host: str | None = None,\n        host_matching: bool = False,\n        subdomain_matching: bool = False,\n        template_folder: str | os.PathLike[str] | None = \"templates\",\n        instance_path: str | None = None,\n        instance_relative_config: bool = False,\n        root_path: str | None = None,\n    ) -> None:\n        super().__init__(\n            import_name=import_name,\n            static_folder=static_folder,\n            static_url_path=static_url_path,\n            template_folder=template_folder,\n            root_path=root_path,\n        )\n\n        if instance_path is None:\n            instance_path = self.auto_find_instance_path()\n        elif not os.path.isabs(instance_path):\n            raise ValueError(\n                \"If an instance path is provided it must be absolute.\"\n                \" A relative path was given instead.\"\n            )\n\n        #: Holds the path to the instance folder.\n        #:\n        #: .. versionadded:: 0.8\n        self.instance_path = instance_path\n\n        #: The configuration dictionary as :class:`Config`.  This behaves\n        #: exactly like a regular dictionary but supports additional methods\n        #: to load a config from files.\n        self.config = self.make_config(instance_relative_config)\n\n        #: An instance of :attr:`aborter_class` created by\n        #: :meth:`make_aborter`. This is called by :func:`flask.abort`\n        #: to raise HTTP errors, and can be called directly as well.\n        #:\n        #: .. versionadded:: 2.2\n        #:     Moved from ``flask.abort``, which calls this object.\n        self.aborter = self.make_aborter()\n\n        self.json: JSONProvider = self.json_provider_class(self)\n        \"\"\"Provides access to JSON methods. Functions in ``flask.json``\n        will call methods on this provider when the application context\n        is active. Used for handling JSON requests and responses.\n\n        An instance of :attr:`json_provider_class`. Can be customized by\n        changing that attribute on a subclass, or by assigning to this\n        attribute afterwards.\n\n        The default, :class:`~flask.json.provider.DefaultJSONProvider`,\n        uses Python's built-in :mod:`json` library. A different provider\n        can use a different JSON library.\n\n        .. versionadded:: 2.2\n        \"\"\"\n\n        #: A list of functions that are called by\n        #: :meth:`handle_url_build_error` when :meth:`.url_for` raises a\n        #: :exc:`~werkzeug.routing.BuildError`. Each function is called\n        #: with ``error``, ``endpoint`` and ``values``. If a function\n        #: returns ``None`` or raises a ``BuildError``, it is skipped.\n        #: Otherwise, its return value is returned by ``url_for``.\n        #:\n        #: .. versionadded:: 0.9\n        self.url_build_error_handlers: list[\n            t.Callable[[Exception, str, dict[str, t.Any]], str]\n        ] = []\n\n        #: A list of functions that are called when the application context\n        #: is destroyed.  Since the application context is also torn down\n        #: if the request ends this is the place to store code that disconnects\n        #: from databases.\n        #:\n        #: .. versionadded:: 0.9\n        self.teardown_appcontext_funcs: list[ft.TeardownCallable] = []\n\n        #: A list of shell context processor functions that should be run\n        #: when a shell context is created.\n        #:\n        #: .. versionadded:: 0.11\n        self.shell_context_processors: list[ft.ShellContextProcessorCallable] = []\n\n        #: Maps registered blueprint names to blueprint objects. The\n        #: dict retains the order the blueprints were registered in.\n        #: Blueprints can be registered multiple times, this dict does\n        #: not track how often they were attached.\n        #:\n        #: .. versionadded:: 0.7\n        self.blueprints: dict[str, Blueprint] = {}\n\n        #: a place where extensions can store application specific state.  For\n        #: example this is where an extension could store database engines and\n        #: similar things.\n        #:\n        #: The key must match the name of the extension module. For example in\n        #: case of a \"Flask-Foo\" extension in `flask_foo`, the key would be\n        #: ``'foo'``.\n        #:\n        #: .. versionadded:: 0.7\n        self.extensions: dict[str, t.Any] = {}\n\n        #: The :class:`~werkzeug.routing.Map` for this instance.  You can use\n        #: this to change the routing converters after the class was created\n        #: but before any routes are connected.  Example::\n        #:\n        #:    from werkzeug.routing import BaseConverter\n        #:\n        #:    class ListConverter(BaseConverter):\n        #:        def to_python(self, value):\n        #:            return value.split(',')\n        #:        def to_url(self, values):\n        #:            return ','.join(super(ListConverter, self).to_url(value)\n        #:                            for value in values)\n        #:\n        #:    app = Flask(__name__)\n        #:    app.url_map.converters['list'] = ListConverter\n        self.url_map = self.url_map_class(host_matching=host_matching)\n\n        self.subdomain_matching = subdomain_matching\n\n        # tracks internally if the application already handled at least one\n        # request.\n        self._got_first_request = False\n\n    def _check_setup_finished(self, f_name: str) -> None:\n        if self._got_first_request:\n            raise AssertionError(\n                f\"The setup method '{f_name}' can no longer be called\"\n                \" on the application. It has already handled its first\"\n                \" request, any changes will not be applied\"\n                \" consistently.\\n\"\n                \"Make sure all imports, decorators, functions, etc.\"\n                \" needed to set up the application are done before\"\n                \" running it.\"\n            )\n\n    @cached_property\n    def name(self) -> str:  # type: ignore\n        \"\"\"The name of the application.  This is usually the import name\n        with the difference that it's guessed from the run file if the\n        import name is main.  This name is used as a display name when\n        Flask needs the name of the application.  It can be set and overridden\n        to change the value.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.import_name == \"__main__\":\n            fn: str | None = getattr(sys.modules[\"__main__\"], \"__file__\", None)\n            if fn is None:\n                return \"__main__\"\n            return os.path.splitext(os.path.basename(fn))[0]\n        return self.import_name\n\n    @cached_property\n    def logger(self) -> logging.Logger:\n        \"\"\"A standard Python :class:`~logging.Logger` for the app, with\n        the same name as :attr:`name`.\n\n        In debug mode, the logger's :attr:`~logging.Logger.level` will\n        be set to :data:`~logging.DEBUG`.\n\n        If there are no handlers configured, a default handler will be\n        added. See :doc:`/logging` for more information.\n\n        .. versionchanged:: 1.1.0\n            The logger takes the same name as :attr:`name` rather than\n            hard-coding ``\"flask.app\"``.\n\n        .. versionchanged:: 1.0.0\n            Behavior was simplified. The logger is always named\n            ``\"flask.app\"``. The level is only set during configuration,\n            it doesn't check ``app.debug`` each time. Only one format is\n            used, not different ones depending on ``app.debug``. No\n            handlers are removed, and a handler is only added if no\n            handlers are already configured.\n\n        .. versionadded:: 0.3\n        \"\"\"\n        return create_logger(self)\n\n    @cached_property\n    def jinja_env(self) -> Environment:\n        \"\"\"The Jinja environment used to load templates.\n\n        The environment is created the first time this property is\n        accessed. Changing :attr:`jinja_options` after that will have no\n        effect.\n        \"\"\"\n        return self.create_jinja_environment()\n\n    def create_jinja_environment(self) -> Environment:\n        raise NotImplementedError()\n\n    def make_config(self, instance_relative: bool = False) -> Config:\n        \"\"\"Used to create the config attribute by the Flask constructor.\n        The `instance_relative` parameter is passed in from the constructor\n        of Flask (there named `instance_relative_config`) and indicates if\n        the config should be relative to the instance path or the root path\n        of the application.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        root_path = self.root_path\n        if instance_relative:\n            root_path = self.instance_path\n        defaults = dict(self.default_config)\n        defaults[\"DEBUG\"] = get_debug_flag()\n        return self.config_class(root_path, defaults)\n\n    def make_aborter(self) -> Aborter:\n        \"\"\"Create the object to assign to :attr:`aborter`. That object\n        is called by :func:`flask.abort` to raise HTTP errors, and can\n        be called directly as well.\n\n        By default, this creates an instance of :attr:`aborter_class`,\n        which defaults to :class:`werkzeug.exceptions.Aborter`.\n\n        .. versionadded:: 2.2\n        \"\"\"\n        return self.aborter_class()\n\n    def auto_find_instance_path(self) -> str:\n        \"\"\"Tries to locate the instance path if it was not provided to the\n        constructor of the application class.  It will basically calculate\n        the path to a folder named ``instance`` next to your main file or\n        the package.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        prefix, package_path = find_package(self.import_name)\n        if prefix is None:\n            return os.path.join(package_path, \"instance\")\n        return os.path.join(prefix, \"var\", f\"{self.name}-instance\")\n\n    def create_global_jinja_loader(self) -> DispatchingJinjaLoader:\n        \"\"\"Creates the loader for the Jinja2 environment.  Can be used to\n        override just the loader and keeping the rest unchanged.  It's\n        discouraged to override this function.  Instead one should override\n        the :meth:`jinja_loader` function instead.\n\n        The global loader dispatches between the loaders of the application\n        and the individual blueprints.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        return DispatchingJinjaLoader(self)\n\n    def select_jinja_autoescape(self, filename: str) -> bool:\n        \"\"\"Returns ``True`` if autoescaping should be active for the given\n        template name. If no template name is given, returns `True`.\n\n        .. versionchanged:: 2.2\n            Autoescaping is now enabled by default for ``.svg`` files.\n\n        .. versionadded:: 0.5\n        \"\"\"\n        if filename is None:\n            return True\n        return filename.endswith((\".html\", \".htm\", \".xml\", \".xhtml\", \".svg\"))\n\n    @property\n    def debug(self) -> bool:\n        \"\"\"Whether debug mode is enabled. When using ``flask run`` to start the\n        development server, an interactive debugger will be shown for unhandled\n        exceptions, and the server will be reloaded when code changes. This maps to the\n        :data:`DEBUG` config key. It may not behave as expected if set late.\n\n        **Do not enable debug mode when deploying in production.**\n\n        Default: ``False``\n        \"\"\"\n        return self.config[\"DEBUG\"]  # type: ignore[no-any-return]\n\n    @debug.setter\n    def debug(self, value: bool) -> None:\n        self.config[\"DEBUG\"] = value\n\n        if self.config[\"TEMPLATES_AUTO_RELOAD\"] is None:\n            self.jinja_env.auto_reload = value\n\n    @setupmethod\n    def register_blueprint(self, blueprint: Blueprint, **options: t.Any) -> None:\n        \"\"\"Register a :class:`~flask.Blueprint` on the application. Keyword\n        arguments passed to this method will override the defaults set on the\n        blueprint.\n\n        Calls the blueprint's :meth:`~flask.Blueprint.register` method after\n        recording the blueprint in the application's :attr:`blueprints`.\n\n        :param blueprint: The blueprint to register.\n        :param url_prefix: Blueprint routes will be prefixed with this.\n        :param subdomain: Blueprint routes will match on this subdomain.\n        :param url_defaults: Blueprint routes will use these default values for\n            view arguments.\n        :param options: Additional keyword arguments are passed to\n            :class:`~flask.blueprints.BlueprintSetupState`. They can be\n            accessed in :meth:`~flask.Blueprint.record` callbacks.\n\n        .. versionchanged:: 2.0.1\n            The ``name`` option can be used to change the (pre-dotted)\n            name the blueprint is registered with. This allows the same\n            blueprint to be registered multiple times with unique names\n            for ``url_for``.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        blueprint.register(self, options)\n\n    def iter_blueprints(self) -> t.ValuesView[Blueprint]:\n        \"\"\"Iterates over all blueprints by the order they were registered.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        return self.blueprints.values()\n\n    @setupmethod\n    def add_url_rule(\n        self,\n        rule: str,\n        endpoint: str | None = None,\n        view_func: ft.RouteCallable | None = None,\n        provide_automatic_options: bool | None = None,\n        **options: t.Any,\n    ) -> None:\n        if endpoint is None:\n            endpoint = _endpoint_from_view_func(view_func)  # type: ignore\n        options[\"endpoint\"] = endpoint\n        methods = options.pop(\"methods\", None)\n\n        # if the methods are not given and the view_func object knows its\n        # methods we can use that instead.  If neither exists, we go with\n        # a tuple of only ``GET`` as default.\n        if methods is None:\n            methods = getattr(view_func, \"methods\", None) or (\"GET\",)\n        if isinstance(methods, str):\n            raise TypeError(\n                \"Allowed methods must be a list of strings, for\"\n                ' example: @app.route(..., methods=[\"POST\"])'\n            )\n        methods = {item.upper() for item in methods}\n\n        # Methods that should always be added\n        required_methods: set[str] = set(getattr(view_func, \"required_methods\", ()))\n\n        # starting with Flask 0.8 the view_func object can disable and\n        # force-enable the automatic options handling.\n        if provide_automatic_options is None:\n            provide_automatic_options = getattr(\n                view_func, \"provide_automatic_options\", None\n            )\n\n        if provide_automatic_options is None:\n            if \"OPTIONS\" not in methods and self.config[\"PROVIDE_AUTOMATIC_OPTIONS\"]:\n                provide_automatic_options = True\n                required_methods.add(\"OPTIONS\")\n            else:\n                provide_automatic_options = False\n\n        # Add the required methods now.\n        methods |= required_methods\n\n        rule_obj = self.url_rule_class(rule, methods=methods, **options)\n        rule_obj.provide_automatic_options = provide_automatic_options  # type: ignore[attr-defined]\n\n        self.url_map.add(rule_obj)\n        if view_func is not None:\n            old_func = self.view_functions.get(endpoint)\n            if old_func is not None and old_func != view_func:\n                raise AssertionError(\n                    \"View function mapping is overwriting an existing\"\n                    f\" endpoint function: {endpoint}\"\n                )\n            self.view_functions[endpoint] = view_func\n\n    @setupmethod\n    def template_filter(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_filter], T_template_filter]:\n        \"\"\"A decorator that is used to register custom template filter.\n        You can specify a name for the filter, otherwise the function\n        name will be used. Example::\n\n          @app.template_filter()\n          def reverse(s):\n              return s[::-1]\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_filter) -> T_template_filter:\n            self.add_template_filter(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_filter(\n        self, f: ft.TemplateFilterCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template filter.  Works exactly like the\n        :meth:`template_filter` decorator.\n\n        :param name: the optional name of the filter, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.filters[name or f.__name__] = f\n\n    @setupmethod\n    def template_test(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_test], T_template_test]:\n        \"\"\"A decorator that is used to register custom template test.\n        You can specify a name for the test, otherwise the function\n        name will be used. Example::\n\n          @app.template_test()\n          def is_prime(n):\n              if n == 2:\n                  return True\n              for i in range(2, int(math.ceil(math.sqrt(n))) + 1):\n                  if n % i == 0:\n                      return False\n              return True\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the test, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_test) -> T_template_test:\n            self.add_template_test(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_test(\n        self, f: ft.TemplateTestCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template test.  Works exactly like the\n        :meth:`template_test` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the test, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.tests[name or f.__name__] = f\n\n    @setupmethod\n    def template_global(\n        self, name: str | None = None\n    ) -> t.Callable[[T_template_global], T_template_global]:\n        \"\"\"A decorator that is used to register a custom template global function.\n        You can specify a name for the global function, otherwise the function\n        name will be used. Example::\n\n            @app.template_global()\n            def double(n):\n                return 2 * n\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n\n        def decorator(f: T_template_global) -> T_template_global:\n            self.add_template_global(f, name=name)\n            return f\n\n        return decorator\n\n    @setupmethod\n    def add_template_global(\n        self, f: ft.TemplateGlobalCallable, name: str | None = None\n    ) -> None:\n        \"\"\"Register a custom template global function. Works exactly like the\n        :meth:`template_global` decorator.\n\n        .. versionadded:: 0.10\n\n        :param name: the optional name of the global function, otherwise the\n                     function name will be used.\n        \"\"\"\n        self.jinja_env.globals[name or f.__name__] = f\n\n    @setupmethod\n    def teardown_appcontext(self, f: T_teardown) -> T_teardown:\n        \"\"\"Registers a function to be called when the application\n        context is popped. The application context is typically popped\n        after the request context for each request, at the end of CLI\n        commands, or after a manually pushed context ends.\n\n        .. code-block:: python\n\n            with app.app_context():\n                ...\n\n        When the ``with`` block exits (or ``ctx.pop()`` is called), the\n        teardown functions are called just before the app context is\n        made inactive. Since a request context typically also manages an\n        application context it would also be called when you pop a\n        request context.\n\n        When a teardown function was called because of an unhandled\n        exception it will be passed an error object. If an\n        :meth:`errorhandler` is registered, it will handle the exception\n        and the teardown will not receive it.\n\n        Teardown functions must avoid raising exceptions. If they\n        execute code that might fail they must surround that code with a\n        ``try``/``except`` block and log any errors.\n\n        The return values of teardown functions are ignored.\n\n        .. versionadded:: 0.9\n        \"\"\"\n        self.teardown_appcontext_funcs.append(f)\n        return f\n\n    @setupmethod\n    def shell_context_processor(\n        self, f: T_shell_context_processor\n    ) -> T_shell_context_processor:\n        \"\"\"Registers a shell context processor function.\n\n        .. versionadded:: 0.11\n        \"\"\"\n        self.shell_context_processors.append(f)\n        return f\n\n    def _find_error_handler(\n        self, e: Exception, blueprints: list[str]\n    ) -> ft.ErrorHandlerCallable | None:\n        \"\"\"Return a registered error handler for an exception in this order:\n        blueprint handler for a specific code, app handler for a specific code,\n        blueprint handler for an exception class, app handler for an exception\n        class, or ``None`` if a suitable handler is not found.\n        \"\"\"\n        exc_class, code = self._get_exc_class_and_code(type(e))\n        names = (*blueprints, None)\n\n        for c in (code, None) if code is not None else (None,):\n            for name in names:\n                handler_map = self.error_handler_spec[name][c]\n\n                if not handler_map:\n                    continue\n\n                for cls in exc_class.__mro__:\n                    handler = handler_map.get(cls)\n\n                    if handler is not None:\n                        return handler\n        return None\n\n    def trap_http_exception(self, e: Exception) -> bool:\n        \"\"\"Checks if an HTTP exception should be trapped or not.  By default\n        this will return ``False`` for all exceptions except for a bad request\n        key error if ``TRAP_BAD_REQUEST_ERRORS`` is set to ``True``.  It\n        also returns ``True`` if ``TRAP_HTTP_EXCEPTIONS`` is set to ``True``.\n\n        This is called for all HTTP exceptions raised by a view function.\n        If it returns ``True`` for any exception the error handler for this\n        exception is not called and it shows up as regular exception in the\n        traceback.  This is helpful for debugging implicitly raised HTTP\n        exceptions.\n\n        .. versionchanged:: 1.0\n            Bad request errors are not trapped by default in debug mode.\n\n        .. versionadded:: 0.8\n        \"\"\"\n        if self.config[\"TRAP_HTTP_EXCEPTIONS\"]:\n            return True\n\n        trap_bad_request = self.config[\"TRAP_BAD_REQUEST_ERRORS\"]\n\n        # if unset, trap key errors in debug mode\n        if (\n            trap_bad_request is None\n            and self.debug\n            and isinstance(e, BadRequestKeyError)\n        ):\n            return True\n\n        if trap_bad_request:\n            return isinstance(e, BadRequest)\n\n        return False\n\n    def should_ignore_error(self, error: BaseException | None) -> bool:\n        \"\"\"This is called to figure out if an error should be ignored\n        or not as far as the teardown system is concerned.  If this\n        function returns ``True`` then the teardown handlers will not be\n        passed the error.\n\n        .. versionadded:: 0.10\n        \"\"\"\n        return False\n\n    def redirect(self, location: str, code: int = 302) -> BaseResponse:\n        \"\"\"Create a redirect response object.\n\n        This is called by :func:`flask.redirect`, and can be called\n        directly as well.\n\n        :param location: The URL to redirect to.\n        :param code: The status code for the redirect.\n\n        .. versionadded:: 2.2\n            Moved from ``flask.redirect``, which calls this method.\n        \"\"\"\n        return _wz_redirect(\n            location,\n            code=code,\n            Response=self.response_class,  # type: ignore[arg-type]\n        )\n\n    def inject_url_defaults(self, endpoint: str, values: dict[str, t.Any]) -> None:\n        \"\"\"Injects the URL defaults for the given endpoint directly into\n        the values dictionary passed.  This is used internally and\n        automatically called on URL building.\n\n        .. versionadded:: 0.7\n        \"\"\"\n        names: t.Iterable[str | None] = (None,)\n\n        # url_for may be called outside a request context, parse the\n        # passed endpoint instead of using request.blueprints.\n        if \".\" in endpoint:\n            names = chain(\n                names, reversed(_split_blueprint_path(endpoint.rpartition(\".\")[0]))\n            )\n\n        for name in names:\n            if name in self.url_default_functions:\n                for func in self.url_default_functions[name]:\n                    func(endpoint, values)\n\n    def handle_url_build_error(\n        self, error: BuildError, endpoint: str, values: dict[str, t.Any]\n    ) -> str:\n        \"\"\"Called by :meth:`.url_for` if a\n        :exc:`~werkzeug.routing.BuildError` was raised. If this returns\n        a value, it will be returned by ``url_for``, otherwise the error\n        will be re-raised.\n\n        Each function in :attr:`url_build_error_handlers` is called with\n        ``error``, ``endpoint`` and ``values``. If a function returns\n        ``None`` or raises a ``BuildError``, it is skipped. Otherwise,\n        its return value is returned by ``url_for``.\n\n        :param error: The active ``BuildError`` being handled.\n        :param endpoint: The endpoint being built.\n        :param values: The keyword arguments passed to ``url_for``.\n        \"\"\"\n        for handler in self.url_build_error_handlers:\n            try:\n                rv = handler(error, endpoint, values)\n            except BuildError as e:\n                # make error available outside except block\n                error = e\n            else:\n                if rv is not None:\n                    return rv\n\n        # Re-raise if called with an active exception, otherwise raise\n        # the passed in exception.\n        if error is sys.exc_info()[1]:\n            raise\n\n        raise error\n",
      "bug_category": "type",
      "error_type": "type_error",
      "confidence": 0.4
    },
    {
      "bug_id": "5ae096597146",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/testing.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport importlib.metadata\nimport typing as t\nfrom contextlib import contextmanager\nfrom contextlib import ExitStack\nfrom copy import copy\nfrom types import TracebackType\nfrom urllib.parse import urlsplit\n\nimport werkzeug.test\nfrom click.testing import CliRunner\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Request as BaseRequest\n\nfrom .cli import ScriptInfo\nfrom .sessions import SessionMixin\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIEnvironment\n    from werkzeug.test import TestResponse\n\n    from .app import Flask\n\n\nclass EnvironBuilder(werkzeug.test.EnvironBuilder):\n    \"\"\"An :class:`~werkzeug.test.EnvironBuilder`, that takes defaults from the\n    application.\n\n    :param app: The Flask application to configure the environment from.\n    :param path: URL path being requested.\n    :param base_url: Base URL where the app is being served, which\n        ``path`` is relative to. If not given, built from\n        :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n        :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n    :param subdomain: Subdomain name to append to :data:`SERVER_NAME`.\n    :param url_scheme: Scheme to use instead of\n        :data:`PREFERRED_URL_SCHEME`.\n    :param json: If given, this is serialized as JSON and passed as\n        ``data``. Also defaults ``content_type`` to\n        ``application/json``.\n    :param args: other positional arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    :param kwargs: other keyword arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: Flask,\n        path: str = \"/\",\n        base_url: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str | None = None,\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> None:\n        assert not (base_url or subdomain or url_scheme) or (\n            base_url is not None\n        ) != bool(\n            subdomain or url_scheme\n        ), 'Cannot pass \"subdomain\" or \"url_scheme\" with \"base_url\".'\n\n        if base_url is None:\n            http_host = app.config.get(\"SERVER_NAME\") or \"localhost\"\n            app_root = app.config[\"APPLICATION_ROOT\"]\n\n            if subdomain:\n                http_host = f\"{subdomain}.{http_host}\"\n\n            if url_scheme is None:\n                url_scheme = app.config[\"PREFERRED_URL_SCHEME\"]\n\n            url = urlsplit(path)\n            base_url = (\n                f\"{url.scheme or url_scheme}://{url.netloc or http_host}\"\n                f\"/{app_root.lstrip('/')}\"\n            )\n            path = url.path\n\n            if url.query:\n                sep = b\"?\" if isinstance(url.query, bytes) else \"?\"\n                path += sep + url.query\n\n        self.app = app\n        super().__init__(path, base_url, *args, **kwargs)\n\n    def json_dumps(self, obj: t.Any, **kwargs: t.Any) -> str:  # type: ignore\n        \"\"\"Serialize ``obj`` to a JSON-formatted string.\n\n        The serialization will be configured according to the config associated\n        with this EnvironBuilder's ``app``.\n        \"\"\"\n        return self.app.json.dumps(obj, **kwargs)\n\n\n_werkzeug_version = \"\"\n\n\ndef _get_werkzeug_version() -> str:\n    global _werkzeug_version\n\n    if not _werkzeug_version:\n        _werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    return _werkzeug_version\n\n\nclass FlaskClient(Client):\n    \"\"\"Works like a regular Werkzeug test client but has knowledge about\n    Flask's contexts to defer the cleanup of the request context until\n    the end of a ``with`` block. For general information about how to\n    use this class refer to :class:`werkzeug.test.Client`.\n\n    .. versionchanged:: 0.12\n       `app.test_client()` includes preset default environment, which can be\n       set after instantiation of the `app.test_client()` object in\n       `client.environ_base`.\n\n    Basic usage is outlined in the :doc:`/testing` chapter.\n    \"\"\"\n\n    application: Flask\n\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        super().__init__(*args, **kwargs)\n        self.preserve_context = False\n        self._new_contexts: list[t.ContextManager[t.Any]] = []\n        self._context_stack = ExitStack()\n        self.environ_base = {\n            \"REMOTE_ADDR\": \"127.0.0.1\",\n            \"HTTP_USER_AGENT\": f\"Werkzeug/{_get_werkzeug_version()}\",\n        }\n\n    @contextmanager\n    def session_transaction(\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Iterator[SessionMixin]:\n        \"\"\"When used in combination with a ``with`` statement this opens a\n        session transaction.  This can be used to modify the session that\n        the test client uses.  Once the ``with`` block is left the session is\n        stored back.\n\n        ::\n\n            with client.session_transaction() as session:\n                session['value'] = 42\n\n        Internally this is implemented by going through a temporary test\n        request context and since session handling could depend on\n        request variables this function accepts the same arguments as\n        :meth:`~flask.Flask.test_request_context` which are directly\n        passed through.\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        app = self.application\n        ctx = app.test_request_context(*args, **kwargs)\n        self._add_cookies_to_wsgi(ctx.request.environ)\n\n        with ctx:\n            sess = app.session_interface.open_session(app, ctx.request)\n\n        if sess is None:\n            raise RuntimeError(\"Session backend did not open a session.\")\n\n        yield sess\n        resp = app.response_class()\n\n        if app.session_interface.is_null_session(sess):\n            return\n\n        with ctx:\n            app.session_interface.save_session(app, sess, resp)\n\n        self._update_cookies_from_response(\n            ctx.request.host.partition(\":\")[0],\n            ctx.request.path,\n            resp.headers.getlist(\"Set-Cookie\"),\n        )\n\n    def _copy_environ(self, other: WSGIEnvironment) -> WSGIEnvironment:\n        out = {**self.environ_base, **other}\n\n        if self.preserve_context:\n            out[\"werkzeug.debug.preserve_context\"] = self._new_contexts.append\n\n        return out\n\n    def _request_from_builder_args(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> BaseRequest:\n        kwargs[\"environ_base\"] = self._copy_environ(kwargs.get(\"environ_base\", {}))\n        builder = EnvironBuilder(self.application, *args, **kwargs)\n\n        try:\n            return builder.get_request()\n        finally:\n            builder.close()\n\n    def open(\n        self,\n        *args: t.Any,\n        buffered: bool = False,\n        follow_redirects: bool = False,\n        **kwargs: t.Any,\n    ) -> TestResponse:\n        if args and isinstance(\n            args[0], (werkzeug.test.EnvironBuilder, dict, BaseRequest)\n        ):\n            if isinstance(args[0], werkzeug.test.EnvironBuilder):\n                builder = copy(args[0])\n                builder.environ_base = self._copy_environ(builder.environ_base or {})  # type: ignore[arg-type]\n                request = builder.get_request()\n            elif isinstance(args[0], dict):\n                request = EnvironBuilder.from_environ(\n                    args[0], app=self.application, environ_base=self._copy_environ({})\n                ).get_request()\n            else:\n                # isinstance(args[0], BaseRequest)\n                request = copy(args[0])\n                request.environ = self._copy_environ(request.environ)\n        else:\n            # request is None\n            request = self._request_from_builder_args(args, kwargs)\n\n        # Pop any previously preserved contexts. This prevents contexts\n        # from being preserved across redirects or multiple requests\n        # within a single block.\n        self._context_stack.close()\n\n        response = super().open(\n            request,\n            buffered=buffered,\n            follow_redirects=follow_redirects,\n        )\n        response.json_module = self.application.json  # type: ignore[assignment]\n\n        # Re-push contexts that were preserved during the request.\n        while self._new_contexts:\n            cm = self._new_contexts.pop()\n            self._context_stack.enter_context(cm)\n\n        return response\n\n    def __enter__(self) -> FlaskClient:\n        if self.preserve_context:\n            raise RuntimeError(\"Cannot nest client invocations\")\n        self.preserve_context = True\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.preserve_context = False\n        self._context_stack.close()\n\n\nclass FlaskCliRunner(CliRunner):\n    \"\"\"A :class:`~click.testing.CliRunner` for testing a Flask app's\n    CLI commands. Typically created using\n    :meth:`~flask.Flask.test_cli_runner`. See :ref:`testing-cli`.\n    \"\"\"\n\n    def __init__(self, app: Flask, **kwargs: t.Any) -> None:\n        self.app = app\n        super().__init__(**kwargs)\n\n    def invoke(  # type: ignore\n        self, cli: t.Any = None, args: t.Any = None, **kwargs: t.Any\n    ) -> t.Any:\n        \"\"\"Invokes a CLI command in an isolated environment. See\n        :meth:`CliRunner.invoke <click.testing.CliRunner.invoke>` for\n        full method documentation. See :ref:`testing-cli` for examples.\n\n        If the ``obj`` argument is not given, passes an instance of\n        :class:`~flask.cli.ScriptInfo` that knows how to load the Flask\n        app being tested.\n\n        :param cli: Command object to invoke. Default is the app's\n            :attr:`~flask.app.Flask.cli` group.\n        :param args: List of strings to invoke the command with.\n\n        :return: a :class:`~click.testing.Result` object.\n        \"\"\"\n        if cli is None:\n            cli = self.app.cli\n\n        if \"obj\" not in kwargs:\n            kwargs[\"obj\"] = ScriptInfo(create_app=lambda: self.app)\n\n        return super().invoke(cli, args, **kwargs)\n",
      "code_after": "from __future__ import annotations\n\nimport importlib.metadata\nimport typing as t\nfrom contextlib import contextmanager\nfrom contextlib import ExitStack\nfrom copy import copy\nfrom types import TracebackType\nfrom urllib.parse import urlsplit\n\nimport werkzeug.test\nfrom click.testing import CliRunner\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import Request as BaseRequest\n\nfrom .cli import ScriptInfo\nfrom .sessions import SessionMixin\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from _typeshed.wsgi import WSGIEnvironment\n    from werkzeug.test import TestResponse\n\n    from .app import Flask\n\n\nclass EnvironBuilder(werkzeug.test.EnvironBuilder):\n    \"\"\"An :class:`~werkzeug.test.EnvironBuilder`, that takes defaults from the\n    application.\n\n    :param app: The Flask application to configure the environment from.\n    :param path: URL path being requested.\n    :param base_url: Base URL where the app is being served, which\n        ``path`` is relative to. If not given, built from\n        :data:`PREFERRED_URL_SCHEME`, ``subdomain``,\n        :data:`SERVER_NAME`, and :data:`APPLICATION_ROOT`.\n    :param subdomain: Subdomain name to append to :data:`SERVER_NAME`.\n    :param url_scheme: Scheme to use instead of\n        :data:`PREFERRED_URL_SCHEME`.\n    :param json: If given, this is serialized as JSON and passed as\n        ``data``. Also defaults ``content_type`` to\n        ``application/json``.\n    :param args: other positional arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    :param kwargs: other keyword arguments passed to\n        :class:`~werkzeug.test.EnvironBuilder`.\n    \"\"\"\n\n    def __init__(\n        self,\n        app: Flask,\n        path: str = \"/\",\n        base_url: str | None = None,\n        subdomain: str | None = None,\n        url_scheme: str | None = None,\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -> None:\n        assert not (base_url or subdomain or url_scheme) or (\n            base_url is not None\n        ) != bool(\n            subdomain or url_scheme\n        ), 'Cannot pass \"subdomain\" or \"url_scheme\" with \"base_url\".'\n\n        if base_url is None:\n            http_host = app.config.get(\"SERVER_NAME\") or \"localhost\"\n            app_root = app.config[\"APPLICATION_ROOT\"]\n\n            if subdomain:\n                http_host = f\"{subdomain}.{http_host}\"\n\n            if url_scheme is None:\n                url_scheme = app.config[\"PREFERRED_URL_SCHEME\"]\n\n            url = urlsplit(path)\n            base_url = (\n                f\"{url.scheme or url_scheme}://{url.netloc or http_host}\"\n                f\"/{app_root.lstrip('/')}\"\n            )\n            path = url.path\n\n            if url.query:\n                path = f\"{path}?{url.query}\"\n\n        self.app = app\n        super().__init__(path, base_url, *args, **kwargs)\n\n    def json_dumps(self, obj: t.Any, **kwargs: t.Any) -> str:  # type: ignore\n        \"\"\"Serialize ``obj`` to a JSON-formatted string.\n\n        The serialization will be configured according to the config associated\n        with this EnvironBuilder's ``app``.\n        \"\"\"\n        return self.app.json.dumps(obj, **kwargs)\n\n\n_werkzeug_version = \"\"\n\n\ndef _get_werkzeug_version() -> str:\n    global _werkzeug_version\n\n    if not _werkzeug_version:\n        _werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    return _werkzeug_version\n\n\nclass FlaskClient(Client):\n    \"\"\"Works like a regular Werkzeug test client but has knowledge about\n    Flask's contexts to defer the cleanup of the request context until\n    the end of a ``with`` block. For general information about how to\n    use this class refer to :class:`werkzeug.test.Client`.\n\n    .. versionchanged:: 0.12\n       `app.test_client()` includes preset default environment, which can be\n       set after instantiation of the `app.test_client()` object in\n       `client.environ_base`.\n\n    Basic usage is outlined in the :doc:`/testing` chapter.\n    \"\"\"\n\n    application: Flask\n\n    def __init__(self, *args: t.Any, **kwargs: t.Any) -> None:\n        super().__init__(*args, **kwargs)\n        self.preserve_context = False\n        self._new_contexts: list[t.ContextManager[t.Any]] = []\n        self._context_stack = ExitStack()\n        self.environ_base = {\n            \"REMOTE_ADDR\": \"127.0.0.1\",\n            \"HTTP_USER_AGENT\": f\"Werkzeug/{_get_werkzeug_version()}\",\n        }\n\n    @contextmanager\n    def session_transaction(\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Iterator[SessionMixin]:\n        \"\"\"When used in combination with a ``with`` statement this opens a\n        session transaction.  This can be used to modify the session that\n        the test client uses.  Once the ``with`` block is left the session is\n        stored back.\n\n        ::\n\n            with client.session_transaction() as session:\n                session['value'] = 42\n\n        Internally this is implemented by going through a temporary test\n        request context and since session handling could depend on\n        request variables this function accepts the same arguments as\n        :meth:`~flask.Flask.test_request_context` which are directly\n        passed through.\n        \"\"\"\n        if self._cookies is None:\n            raise TypeError(\n                \"Cookies are disabled. Create a client with 'use_cookies=True'.\"\n            )\n\n        app = self.application\n        ctx = app.test_request_context(*args, **kwargs)\n        self._add_cookies_to_wsgi(ctx.request.environ)\n\n        with ctx:\n            sess = app.session_interface.open_session(app, ctx.request)\n\n        if sess is None:\n            raise RuntimeError(\"Session backend did not open a session.\")\n\n        yield sess\n        resp = app.response_class()\n\n        if app.session_interface.is_null_session(sess):\n            return\n\n        with ctx:\n            app.session_interface.save_session(app, sess, resp)\n\n        self._update_cookies_from_response(\n            ctx.request.host.partition(\":\")[0],\n            ctx.request.path,\n            resp.headers.getlist(\"Set-Cookie\"),\n        )\n\n    def _copy_environ(self, other: WSGIEnvironment) -> WSGIEnvironment:\n        out = {**self.environ_base, **other}\n\n        if self.preserve_context:\n            out[\"werkzeug.debug.preserve_context\"] = self._new_contexts.append\n\n        return out\n\n    def _request_from_builder_args(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> BaseRequest:\n        kwargs[\"environ_base\"] = self._copy_environ(kwargs.get(\"environ_base\", {}))\n        builder = EnvironBuilder(self.application, *args, **kwargs)\n\n        try:\n            return builder.get_request()\n        finally:\n            builder.close()\n\n    def open(\n        self,\n        *args: t.Any,\n        buffered: bool = False,\n        follow_redirects: bool = False,\n        **kwargs: t.Any,\n    ) -> TestResponse:\n        if args and isinstance(\n            args[0], (werkzeug.test.EnvironBuilder, dict, BaseRequest)\n        ):\n            if isinstance(args[0], werkzeug.test.EnvironBuilder):\n                builder = copy(args[0])\n                builder.environ_base = self._copy_environ(builder.environ_base or {})  # type: ignore[arg-type]\n                request = builder.get_request()\n            elif isinstance(args[0], dict):\n                request = EnvironBuilder.from_environ(\n                    args[0], app=self.application, environ_base=self._copy_environ({})\n                ).get_request()\n            else:\n                # isinstance(args[0], BaseRequest)\n                request = copy(args[0])\n                request.environ = self._copy_environ(request.environ)\n        else:\n            # request is None\n            request = self._request_from_builder_args(args, kwargs)\n\n        # Pop any previously preserved contexts. This prevents contexts\n        # from being preserved across redirects or multiple requests\n        # within a single block.\n        self._context_stack.close()\n\n        response = super().open(\n            request,\n            buffered=buffered,\n            follow_redirects=follow_redirects,\n        )\n        response.json_module = self.application.json  # type: ignore[assignment]\n\n        # Re-push contexts that were preserved during the request.\n        while self._new_contexts:\n            cm = self._new_contexts.pop()\n            self._context_stack.enter_context(cm)\n\n        return response\n\n    def __enter__(self) -> FlaskClient:\n        if self.preserve_context:\n            raise RuntimeError(\"Cannot nest client invocations\")\n        self.preserve_context = True\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.preserve_context = False\n        self._context_stack.close()\n\n\nclass FlaskCliRunner(CliRunner):\n    \"\"\"A :class:`~click.testing.CliRunner` for testing a Flask app's\n    CLI commands. Typically created using\n    :meth:`~flask.Flask.test_cli_runner`. See :ref:`testing-cli`.\n    \"\"\"\n\n    def __init__(self, app: Flask, **kwargs: t.Any) -> None:\n        self.app = app\n        super().__init__(**kwargs)\n\n    def invoke(  # type: ignore\n        self, cli: t.Any = None, args: t.Any = None, **kwargs: t.Any\n    ) -> t.Any:\n        \"\"\"Invokes a CLI command in an isolated environment. See\n        :meth:`CliRunner.invoke <click.testing.CliRunner.invoke>` for\n        full method documentation. See :ref:`testing-cli` for examples.\n\n        If the ``obj`` argument is not given, passes an instance of\n        :class:`~flask.cli.ScriptInfo` that knows how to load the Flask\n        app being tested.\n\n        :param cli: Command object to invoke. Default is the app's\n            :attr:`~flask.app.Flask.cli` group.\n        :param args: List of strings to invoke the command with.\n\n        :return: a :class:`~click.testing.Result` object.\n        \"\"\"\n        if cli is None:\n            cli = self.app.cli\n\n        if \"obj\" not in kwargs:\n            kwargs[\"obj\"] = ScriptInfo(create_app=lambda: self.app)\n\n        return super().invoke(cli, args, **kwargs)\n",
      "bug_category": "type",
      "error_type": "type_error",
      "confidence": 0.4
    },
    {
      "bug_id": "9d9764ec2574",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/views.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport typing as t\n\nfrom . import typing as ft\nfrom .globals import current_app\nfrom .globals import request\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\nhttp_method_funcs = frozenset(\n    [\"get\", \"post\", \"head\", \"options\", \"delete\", \"put\", \"trace\", \"patch\"]\n)\n\n\nclass View:\n    \"\"\"Subclass this class and override :meth:`dispatch_request` to\n    create a generic class-based view. Call :meth:`as_view` to create a\n    view function that creates an instance of the class with the given\n    arguments and calls its ``dispatch_request`` method with any URL\n    variables.\n\n    See :doc:`views` for a detailed guide.\n\n    .. code-block:: python\n\n        class Hello(View):\n            init_every_request = False\n\n            def dispatch_request(self, name):\n                return f\"Hello, {name}!\"\n\n        app.add_url_rule(\n            \"/hello/<name>\", view_func=Hello.as_view(\"hello\")\n        )\n\n    Set :attr:`methods` on the class to change what methods the view\n    accepts.\n\n    Set :attr:`decorators` on the class to apply a list of decorators to\n    the generated view function. Decorators applied to the class itself\n    will not be applied to the generated view function!\n\n    Set :attr:`init_every_request` to ``False`` for efficiency, unless\n    you need to store request-global data on ``self``.\n    \"\"\"\n\n    #: The methods this view is registered for. Uses the same default\n    #: (``[\"GET\", \"HEAD\", \"OPTIONS\"]``) as ``route`` and\n    #: ``add_url_rule`` by default.\n    methods: t.ClassVar[t.Collection[str] | None] = None\n\n    #: Control whether the ``OPTIONS`` method is handled automatically.\n    #: Uses the same default (``True``) as ``route`` and\n    #: ``add_url_rule`` by default.\n    provide_automatic_options: t.ClassVar[bool | None] = None\n\n    #: A list of decorators to apply, in order, to the generated view\n    #: function. Remember that ``@decorator`` syntax is applied bottom\n    #: to top, so the first decorator in the list would be the bottom\n    #: decorator.\n    #:\n    #: .. versionadded:: 0.8\n    decorators: t.ClassVar[list[t.Callable[[F], F]]] = []\n\n    #: Create a new instance of this view class for every request by\n    #: default. If a view subclass sets this to ``False``, the same\n    #: instance is used for every request.\n    #:\n    #: A single instance is more efficient, especially if complex setup\n    #: is done during init. However, storing data on ``self`` is no\n    #: longer safe across requests, and :data:`~flask.g` should be used\n    #: instead.\n    #:\n    #: .. versionadded:: 2.2\n    init_every_request: t.ClassVar[bool] = True\n\n    def dispatch_request(self) -> ft.ResponseReturnValue:\n        \"\"\"The actual view function behavior. Subclasses must override\n        this and return a valid response. Any variables from the URL\n        rule are passed as keyword arguments.\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def as_view(\n        cls, name: str, *class_args: t.Any, **class_kwargs: t.Any\n    ) -> ft.RouteCallable:\n        \"\"\"Convert the class into a view function that can be registered\n        for a route.\n\n        By default, the generated view will create a new instance of the\n        view class for every request and call its\n        :meth:`dispatch_request` method. If the view class sets\n        :attr:`init_every_request` to ``False``, the same instance will\n        be used for every request.\n\n        Except for ``name``, all other arguments passed to this method\n        are forwarded to the view class ``__init__`` method.\n\n        .. versionchanged:: 2.2\n            Added the ``init_every_request`` class attribute.\n        \"\"\"\n        if cls.init_every_request:\n\n            def view(**kwargs: t.Any) -> ft.ResponseReturnValue:\n                self = view.view_class(  # type: ignore[attr-defined]\n                    *class_args, **class_kwargs\n                )\n                return current_app.ensure_sync(self.dispatch_request)(**kwargs)  # type: ignore[no-any-return]\n\n        else:\n            self = cls(*class_args, **class_kwargs)\n\n            def view(**kwargs: t.Any) -> ft.ResponseReturnValue:\n                return current_app.ensure_sync(self.dispatch_request)(**kwargs)  # type: ignore[no-any-return]\n\n        if cls.decorators:\n            view.__name__ = name\n            view.__module__ = cls.__module__\n            for decorator in cls.decorators:\n                view = decorator(view)\n\n        # We attach the view class to the view function for two reasons:\n        # first of all it allows us to easily figure out what class-based\n        # view this thing came from, secondly it's also used for instantiating\n        # the view class so you can actually replace it with something else\n        # for testing purposes and debugging.\n        view.view_class = cls  # type: ignore\n        view.__name__ = name\n        view.__doc__ = cls.__doc__\n        view.__module__ = cls.__module__\n        view.methods = cls.methods  # type: ignore\n        view.provide_automatic_options = cls.provide_automatic_options  # type: ignore\n        return view\n\n\nclass MethodView(View):\n    \"\"\"Dispatches request methods to the corresponding instance methods.\n    For example, if you implement a ``get`` method, it will be used to\n    handle ``GET`` requests.\n\n    This can be useful for defining a REST API.\n\n    :attr:`methods` is automatically set based on the methods defined on\n    the class.\n\n    See :doc:`views` for a detailed guide.\n\n    .. code-block:: python\n\n        class CounterAPI(MethodView):\n            def get(self):\n                return str(session.get(\"counter\", 0))\n\n            def post(self):\n                session[\"counter\"] = session.get(\"counter\", 0) + 1\n                return redirect(url_for(\"counter\"))\n\n        app.add_url_rule(\n            \"/counter\", view_func=CounterAPI.as_view(\"counter\")\n        )\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs: t.Any) -> None:\n        super().__init_subclass__(**kwargs)\n\n        if \"methods\" not in cls.__dict__:\n            methods = set()\n\n            for base in cls.__bases__:\n                if getattr(base, \"methods\", None):\n                    methods.update(base.methods)  # type: ignore[attr-defined]\n\n            for key in http_method_funcs:\n                if hasattr(cls, key):\n                    methods.add(key.upper())\n\n            if methods:\n                cls.methods = methods\n\n    def dispatch_request(self, **kwargs: t.Any) -> ft.ResponseReturnValue:\n        meth = getattr(self, request.method.lower(), None)\n\n        # If the request method is HEAD and we don't have a handler for it\n        # retry with GET.\n        if meth is None and request.method == \"HEAD\":\n            meth = getattr(self, \"get\", None)\n\n        assert meth is not None, f\"Unimplemented method {request.method!r}\"\n        return current_app.ensure_sync(meth)(**kwargs)  # type: ignore[no-any-return]\n",
      "code_after": "from __future__ import annotations\n\nimport typing as t\n\nfrom . import typing as ft\nfrom .globals import current_app\nfrom .globals import request\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\nhttp_method_funcs = frozenset(\n    [\"get\", \"post\", \"head\", \"options\", \"delete\", \"put\", \"trace\", \"patch\"]\n)\n\n\nclass View:\n    \"\"\"Subclass this class and override :meth:`dispatch_request` to\n    create a generic class-based view. Call :meth:`as_view` to create a\n    view function that creates an instance of the class with the given\n    arguments and calls its ``dispatch_request`` method with any URL\n    variables.\n\n    See :doc:`views` for a detailed guide.\n\n    .. code-block:: python\n\n        class Hello(View):\n            init_every_request = False\n\n            def dispatch_request(self, name):\n                return f\"Hello, {name}!\"\n\n        app.add_url_rule(\n            \"/hello/<name>\", view_func=Hello.as_view(\"hello\")\n        )\n\n    Set :attr:`methods` on the class to change what methods the view\n    accepts.\n\n    Set :attr:`decorators` on the class to apply a list of decorators to\n    the generated view function. Decorators applied to the class itself\n    will not be applied to the generated view function!\n\n    Set :attr:`init_every_request` to ``False`` for efficiency, unless\n    you need to store request-global data on ``self``.\n    \"\"\"\n\n    #: The methods this view is registered for. Uses the same default\n    #: (``[\"GET\", \"HEAD\", \"OPTIONS\"]``) as ``route`` and\n    #: ``add_url_rule`` by default.\n    methods: t.ClassVar[t.Collection[str] | None] = None\n\n    #: Control whether the ``OPTIONS`` method is handled automatically.\n    #: Uses the same default (``True``) as ``route`` and\n    #: ``add_url_rule`` by default.\n    provide_automatic_options: t.ClassVar[bool | None] = None\n\n    #: A list of decorators to apply, in order, to the generated view\n    #: function. Remember that ``@decorator`` syntax is applied bottom\n    #: to top, so the first decorator in the list would be the bottom\n    #: decorator.\n    #:\n    #: .. versionadded:: 0.8\n    decorators: t.ClassVar[list[t.Callable[..., t.Any]]] = []\n\n    #: Create a new instance of this view class for every request by\n    #: default. If a view subclass sets this to ``False``, the same\n    #: instance is used for every request.\n    #:\n    #: A single instance is more efficient, especially if complex setup\n    #: is done during init. However, storing data on ``self`` is no\n    #: longer safe across requests, and :data:`~flask.g` should be used\n    #: instead.\n    #:\n    #: .. versionadded:: 2.2\n    init_every_request: t.ClassVar[bool] = True\n\n    def dispatch_request(self) -> ft.ResponseReturnValue:\n        \"\"\"The actual view function behavior. Subclasses must override\n        this and return a valid response. Any variables from the URL\n        rule are passed as keyword arguments.\n        \"\"\"\n        raise NotImplementedError()\n\n    @classmethod\n    def as_view(\n        cls, name: str, *class_args: t.Any, **class_kwargs: t.Any\n    ) -> ft.RouteCallable:\n        \"\"\"Convert the class into a view function that can be registered\n        for a route.\n\n        By default, the generated view will create a new instance of the\n        view class for every request and call its\n        :meth:`dispatch_request` method. If the view class sets\n        :attr:`init_every_request` to ``False``, the same instance will\n        be used for every request.\n\n        Except for ``name``, all other arguments passed to this method\n        are forwarded to the view class ``__init__`` method.\n\n        .. versionchanged:: 2.2\n            Added the ``init_every_request`` class attribute.\n        \"\"\"\n        if cls.init_every_request:\n\n            def view(**kwargs: t.Any) -> ft.ResponseReturnValue:\n                self = view.view_class(  # type: ignore[attr-defined]\n                    *class_args, **class_kwargs\n                )\n                return current_app.ensure_sync(self.dispatch_request)(**kwargs)  # type: ignore[no-any-return]\n\n        else:\n            self = cls(*class_args, **class_kwargs)  # pyright: ignore\n\n            def view(**kwargs: t.Any) -> ft.ResponseReturnValue:\n                return current_app.ensure_sync(self.dispatch_request)(**kwargs)  # type: ignore[no-any-return]\n\n        if cls.decorators:\n            view.__name__ = name\n            view.__module__ = cls.__module__\n            for decorator in cls.decorators:\n                view = decorator(view)\n\n        # We attach the view class to the view function for two reasons:\n        # first of all it allows us to easily figure out what class-based\n        # view this thing came from, secondly it's also used for instantiating\n        # the view class so you can actually replace it with something else\n        # for testing purposes and debugging.\n        view.view_class = cls  # type: ignore\n        view.__name__ = name\n        view.__doc__ = cls.__doc__\n        view.__module__ = cls.__module__\n        view.methods = cls.methods  # type: ignore\n        view.provide_automatic_options = cls.provide_automatic_options  # type: ignore\n        return view\n\n\nclass MethodView(View):\n    \"\"\"Dispatches request methods to the corresponding instance methods.\n    For example, if you implement a ``get`` method, it will be used to\n    handle ``GET`` requests.\n\n    This can be useful for defining a REST API.\n\n    :attr:`methods` is automatically set based on the methods defined on\n    the class.\n\n    See :doc:`views` for a detailed guide.\n\n    .. code-block:: python\n\n        class CounterAPI(MethodView):\n            def get(self):\n                return str(session.get(\"counter\", 0))\n\n            def post(self):\n                session[\"counter\"] = session.get(\"counter\", 0) + 1\n                return redirect(url_for(\"counter\"))\n\n        app.add_url_rule(\n            \"/counter\", view_func=CounterAPI.as_view(\"counter\")\n        )\n    \"\"\"\n\n    def __init_subclass__(cls, **kwargs: t.Any) -> None:\n        super().__init_subclass__(**kwargs)\n\n        if \"methods\" not in cls.__dict__:\n            methods = set()\n\n            for base in cls.__bases__:\n                if getattr(base, \"methods\", None):\n                    methods.update(base.methods)  # type: ignore[attr-defined]\n\n            for key in http_method_funcs:\n                if hasattr(cls, key):\n                    methods.add(key.upper())\n\n            if methods:\n                cls.methods = methods\n\n    def dispatch_request(self, **kwargs: t.Any) -> ft.ResponseReturnValue:\n        meth = getattr(self, request.method.lower(), None)\n\n        # If the request method is HEAD and we don't have a handler for it\n        # retry with GET.\n        if meth is None and request.method == \"HEAD\":\n            meth = getattr(self, \"get\", None)\n\n        assert meth is not None, f\"Unimplemented method {request.method!r}\"\n        return current_app.ensure_sync(meth)(**kwargs)  # type: ignore[no-any-return]\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 0.6
    },
    {
      "bug_id": "330c92eb779c",
      "repo": "flask",
      "commit_hash": "9e831e9",
      "commit_message": "fix pyright type errors",
      "file_path": "src/flask/wrappers.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport typing as t\n\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.wrappers import Request as RequestBase\nfrom werkzeug.wrappers import Response as ResponseBase\n\nfrom . import json\nfrom .globals import current_app\nfrom .helpers import _split_blueprint_path\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.routing import Rule\n\n\nclass Request(RequestBase):\n    \"\"\"The request object used by default in Flask.  Remembers the\n    matched endpoint and view arguments.\n\n    It is what ends up as :class:`~flask.request`.  If you want to replace\n    the request object used you can subclass this and set\n    :attr:`~flask.Flask.request_class` to your subclass.\n\n    The request object is a :class:`~werkzeug.wrappers.Request` subclass and\n    provides all of the attributes Werkzeug defines plus a few Flask\n    specific ones.\n    \"\"\"\n\n    json_module: t.Any = json\n\n    #: The internal URL rule that matched the request.  This can be\n    #: useful to inspect which methods are allowed for the URL from\n    #: a before/after handler (``request.url_rule.methods``) etc.\n    #: Though if the request's method was invalid for the URL rule,\n    #: the valid list is available in ``routing_exception.valid_methods``\n    #: instead (an attribute of the Werkzeug exception\n    #: :exc:`~werkzeug.exceptions.MethodNotAllowed`)\n    #: because the request was never internally bound.\n    #:\n    #: .. versionadded:: 0.6\n    url_rule: Rule | None = None\n\n    #: A dict of view arguments that matched the request.  If an exception\n    #: happened when matching, this will be ``None``.\n    view_args: dict[str, t.Any] | None = None\n\n    #: If matching the URL failed, this is the exception that will be\n    #: raised / was raised as part of the request handling.  This is\n    #: usually a :exc:`~werkzeug.exceptions.NotFound` exception or\n    #: something similar.\n    routing_exception: HTTPException | None = None\n\n    @property\n    def max_content_length(self) -> int | None:  # type: ignore[override]\n        \"\"\"Read-only view of the ``MAX_CONTENT_LENGTH`` config key.\"\"\"\n        if current_app:\n            return current_app.config[\"MAX_CONTENT_LENGTH\"]  # type: ignore[no-any-return]\n        else:\n            return None\n\n    @property\n    def endpoint(self) -> str | None:\n        \"\"\"The endpoint that matched the request URL.\n\n        This will be ``None`` if matching failed or has not been\n        performed yet.\n\n        This in combination with :attr:`view_args` can be used to\n        reconstruct the same URL or a modified URL.\n        \"\"\"\n        if self.url_rule is not None:\n            return self.url_rule.endpoint  # type: ignore[no-any-return]\n\n        return None\n\n    @property\n    def blueprint(self) -> str | None:\n        \"\"\"The registered name of the current blueprint.\n\n        This will be ``None`` if the endpoint is not part of a\n        blueprint, or if URL matching failed or has not been performed\n        yet.\n\n        This does not necessarily match the name the blueprint was\n        created with. It may have been nested, or registered with a\n        different name.\n        \"\"\"\n        endpoint = self.endpoint\n\n        if endpoint is not None and \".\" in endpoint:\n            return endpoint.rpartition(\".\")[0]\n\n        return None\n\n    @property\n    def blueprints(self) -> list[str]:\n        \"\"\"The registered names of the current blueprint upwards through\n        parent blueprints.\n\n        This will be an empty list if there is no current blueprint, or\n        if URL matching failed.\n\n        .. versionadded:: 2.0.1\n        \"\"\"\n        name = self.blueprint\n\n        if name is None:\n            return []\n\n        return _split_blueprint_path(name)\n\n    def _load_form_data(self) -> None:\n        super()._load_form_data()\n\n        # In debug mode we're replacing the files multidict with an ad-hoc\n        # subclass that raises a different error for key errors.\n        if (\n            current_app\n            and current_app.debug\n            and self.mimetype != \"multipart/form-data\"\n            and not self.files\n        ):\n            from .debughelpers import attach_enctype_error_multidict\n\n            attach_enctype_error_multidict(self)\n\n    def on_json_loading_failed(self, e: ValueError | None) -> t.Any:\n        try:\n            return super().on_json_loading_failed(e)\n        except BadRequest as e:\n            if current_app and current_app.debug:\n                raise\n\n            raise BadRequest() from e\n\n\nclass Response(ResponseBase):\n    \"\"\"The response object that is used by default in Flask.  Works like the\n    response object from Werkzeug but is set to have an HTML mimetype by\n    default.  Quite often you don't have to create this object yourself because\n    :meth:`~flask.Flask.make_response` will take care of that for you.\n\n    If you want to replace the response object used you can subclass this and\n    set :attr:`~flask.Flask.response_class` to your subclass.\n\n    .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON.\n\n    .. versionchanged:: 1.0\n\n        Added :attr:`max_cookie_size`.\n    \"\"\"\n\n    default_mimetype: str | None = \"text/html\"\n\n    json_module = json\n\n    autocorrect_location_header = False\n\n    @property\n    def max_cookie_size(self) -> int:  # type: ignore\n        \"\"\"Read-only view of the :data:`MAX_COOKIE_SIZE` config key.\n\n        See :attr:`~werkzeug.wrappers.Response.max_cookie_size` in\n        Werkzeug's docs.\n        \"\"\"\n        if current_app:\n            return current_app.config[\"MAX_COOKIE_SIZE\"]  # type: ignore[no-any-return]\n\n        # return Werkzeug's default when not in an app context\n        return super().max_cookie_size\n",
      "code_after": "from __future__ import annotations\n\nimport typing as t\n\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.wrappers import Request as RequestBase\nfrom werkzeug.wrappers import Response as ResponseBase\n\nfrom . import json\nfrom .globals import current_app\nfrom .helpers import _split_blueprint_path\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.routing import Rule\n\n\nclass Request(RequestBase):\n    \"\"\"The request object used by default in Flask.  Remembers the\n    matched endpoint and view arguments.\n\n    It is what ends up as :class:`~flask.request`.  If you want to replace\n    the request object used you can subclass this and set\n    :attr:`~flask.Flask.request_class` to your subclass.\n\n    The request object is a :class:`~werkzeug.wrappers.Request` subclass and\n    provides all of the attributes Werkzeug defines plus a few Flask\n    specific ones.\n    \"\"\"\n\n    json_module: t.Any = json\n\n    #: The internal URL rule that matched the request.  This can be\n    #: useful to inspect which methods are allowed for the URL from\n    #: a before/after handler (``request.url_rule.methods``) etc.\n    #: Though if the request's method was invalid for the URL rule,\n    #: the valid list is available in ``routing_exception.valid_methods``\n    #: instead (an attribute of the Werkzeug exception\n    #: :exc:`~werkzeug.exceptions.MethodNotAllowed`)\n    #: because the request was never internally bound.\n    #:\n    #: .. versionadded:: 0.6\n    url_rule: Rule | None = None\n\n    #: A dict of view arguments that matched the request.  If an exception\n    #: happened when matching, this will be ``None``.\n    view_args: dict[str, t.Any] | None = None\n\n    #: If matching the URL failed, this is the exception that will be\n    #: raised / was raised as part of the request handling.  This is\n    #: usually a :exc:`~werkzeug.exceptions.NotFound` exception or\n    #: something similar.\n    routing_exception: HTTPException | None = None\n\n    @property\n    def max_content_length(self) -> int | None:  # type: ignore[override]\n        \"\"\"Read-only view of the ``MAX_CONTENT_LENGTH`` config key.\"\"\"\n        if current_app:\n            return current_app.config[\"MAX_CONTENT_LENGTH\"]  # type: ignore[no-any-return]\n        else:\n            return None\n\n    @property\n    def endpoint(self) -> str | None:\n        \"\"\"The endpoint that matched the request URL.\n\n        This will be ``None`` if matching failed or has not been\n        performed yet.\n\n        This in combination with :attr:`view_args` can be used to\n        reconstruct the same URL or a modified URL.\n        \"\"\"\n        if self.url_rule is not None:\n            return self.url_rule.endpoint  # type: ignore[no-any-return]\n\n        return None\n\n    @property\n    def blueprint(self) -> str | None:\n        \"\"\"The registered name of the current blueprint.\n\n        This will be ``None`` if the endpoint is not part of a\n        blueprint, or if URL matching failed or has not been performed\n        yet.\n\n        This does not necessarily match the name the blueprint was\n        created with. It may have been nested, or registered with a\n        different name.\n        \"\"\"\n        endpoint = self.endpoint\n\n        if endpoint is not None and \".\" in endpoint:\n            return endpoint.rpartition(\".\")[0]\n\n        return None\n\n    @property\n    def blueprints(self) -> list[str]:\n        \"\"\"The registered names of the current blueprint upwards through\n        parent blueprints.\n\n        This will be an empty list if there is no current blueprint, or\n        if URL matching failed.\n\n        .. versionadded:: 2.0.1\n        \"\"\"\n        name = self.blueprint\n\n        if name is None:\n            return []\n\n        return _split_blueprint_path(name)\n\n    def _load_form_data(self) -> None:\n        super()._load_form_data()\n\n        # In debug mode we're replacing the files multidict with an ad-hoc\n        # subclass that raises a different error for key errors.\n        if (\n            current_app\n            and current_app.debug\n            and self.mimetype != \"multipart/form-data\"\n            and not self.files\n        ):\n            from .debughelpers import attach_enctype_error_multidict\n\n            attach_enctype_error_multidict(self)\n\n    def on_json_loading_failed(self, e: ValueError | None) -> t.Any:\n        try:\n            return super().on_json_loading_failed(e)\n        except BadRequest as ebr:\n            if current_app and current_app.debug:\n                raise\n\n            raise BadRequest() from ebr\n\n\nclass Response(ResponseBase):\n    \"\"\"The response object that is used by default in Flask.  Works like the\n    response object from Werkzeug but is set to have an HTML mimetype by\n    default.  Quite often you don't have to create this object yourself because\n    :meth:`~flask.Flask.make_response` will take care of that for you.\n\n    If you want to replace the response object used you can subclass this and\n    set :attr:`~flask.Flask.response_class` to your subclass.\n\n    .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON.\n\n    .. versionchanged:: 1.0\n\n        Added :attr:`max_cookie_size`.\n    \"\"\"\n\n    default_mimetype: str | None = \"text/html\"\n\n    json_module = json\n\n    autocorrect_location_header = False\n\n    @property\n    def max_cookie_size(self) -> int:  # type: ignore\n        \"\"\"Read-only view of the :data:`MAX_COOKIE_SIZE` config key.\n\n        See :attr:`~werkzeug.wrappers.Response.max_cookie_size` in\n        Werkzeug's docs.\n        \"\"\"\n        if current_app:\n            return current_app.config[\"MAX_COOKIE_SIZE\"]  # type: ignore[no-any-return]\n\n        # return Werkzeug's default when not in an app context\n        return super().max_cookie_size\n",
      "bug_category": "type",
      "error_type": "type_error",
      "confidence": 0.4
    },
    {
      "bug_id": "202f17a901e5",
      "repo": "flask",
      "commit_hash": "dffe303",
      "commit_message": "fix mypy findings",
      "file_path": "src/flask/helpers.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type, return-value]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "code_after": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 0.4
    },
    {
      "bug_id": "68b567d246fe",
      "repo": "flask",
      "commit_hash": "176fdfa",
      "commit_message": "fix mypy findings",
      "file_path": "src/flask/helpers.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "code_after": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr],\n) -> t.Iterator[t.AnyStr]: ...\n\n\n@t.overload\ndef stream_with_context(\n    generator_or_function: t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]: ...\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr] | t.Callable[[t.Iterator[t.AnyStr]], t.Iterator[t.AnyStr]]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "9b98f14d16e3",
      "repo": "flask",
      "commit_hash": "176fdfa",
      "commit_message": "fix mypy findings",
      "file_path": "src/flask/json/provider.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport dataclasses\nimport decimal\nimport json\nimport typing as t\nimport uuid\nimport weakref\nfrom datetime import date\n\nfrom werkzeug.http import http_date\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.sansio.response import Response\n\n    from ..sansio.app import App\n\n\nclass JSONProvider:\n    \"\"\"A standard set of JSON operations for an application. Subclasses\n    of this can be used to customize JSON behavior or use different\n    JSON libraries.\n\n    To implement a provider for a specific library, subclass this base\n    class and implement at least :meth:`dumps` and :meth:`loads`. All\n    other methods have default implementations.\n\n    To use a different provider, either subclass ``Flask`` and set\n    :attr:`~flask.Flask.json_provider_class` to a provider class, or set\n    :attr:`app.json <flask.Flask.json>` to an instance of the class.\n\n    :param app: An application instance. This will be stored as a\n        :class:`weakref.proxy` on the :attr:`_app` attribute.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    def __init__(self, app: App) -> None:\n        self._app: App = weakref.proxy(app)\n\n    def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON.\n\n        :param obj: The data to serialize.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError\n\n    def dump(self, obj: t.Any, fp: t.IO[str], **kwargs: t.Any) -> None:\n        \"\"\"Serialize data as JSON and write to a file.\n\n        :param obj: The data to serialize.\n        :param fp: A file opened for writing text. Should use the UTF-8\n            encoding to be valid JSON.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        fp.write(self.dumps(obj, **kwargs))\n\n    def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError\n\n    def load(self, fp: t.IO[t.AnyStr], **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON read from a file.\n\n        :param fp: A file opened for reading text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        return self.loads(fp.read(), **kwargs)\n\n    def _prepare_response_obj(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> t.Any:\n        if args and kwargs:\n            raise TypeError(\"app.json.response() takes either args or kwargs, not both\")\n\n        if not args and not kwargs:\n            return None\n\n        if len(args) == 1:\n            return args[0]\n\n        return args or kwargs\n\n    def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with the ``application/json``\n        mimetype.\n\n        The :func:`~flask.json.jsonify` function calls this method for\n        the current application.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        return self._app.response_class(self.dumps(obj), mimetype=\"application/json\")\n\n\ndef _default(o: t.Any) -> t.Any:\n    if isinstance(o, date):\n        return http_date(o)\n\n    if isinstance(o, (decimal.Decimal, uuid.UUID)):\n        return str(o)\n\n    if dataclasses and dataclasses.is_dataclass(o):\n        return dataclasses.asdict(o)\n\n    if hasattr(o, \"__html__\"):\n        return str(o.__html__())\n\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\n\n\nclass DefaultJSONProvider(JSONProvider):\n    \"\"\"Provide JSON operations using Python's built-in :mod:`json`\n    library. Serializes the following additional data types:\n\n    -   :class:`datetime.datetime` and :class:`datetime.date` are\n        serialized to :rfc:`822` strings. This is the same as the HTTP\n        date format.\n    -   :class:`uuid.UUID` is serialized to a string.\n    -   :class:`dataclasses.dataclass` is passed to\n        :func:`dataclasses.asdict`.\n    -   :class:`~markupsafe.Markup` (or any object with a ``__html__``\n        method) will call the ``__html__`` method to get a string.\n    \"\"\"\n\n    default: t.Callable[[t.Any], t.Any] = staticmethod(_default)  # type: ignore[assignment]\n    \"\"\"Apply this function to any object that :meth:`json.dumps` does\n    not know how to serialize. It should return a valid JSON type or\n    raise a ``TypeError``.\n    \"\"\"\n\n    ensure_ascii = True\n    \"\"\"Replace non-ASCII characters with escape sequences. This may be\n    more compatible with some clients, but can be disabled for better\n    performance and size.\n    \"\"\"\n\n    sort_keys = True\n    \"\"\"Sort the keys in any serialized dicts. This may be useful for\n    some caching situations, but can be disabled for better performance.\n    When enabled, keys must all be strings, they are not converted\n    before sorting.\n    \"\"\"\n\n    compact: bool | None = None\n    \"\"\"If ``True``, or ``None`` out of debug mode, the :meth:`response`\n    output will not add indentation, newlines, or spaces. If ``False``,\n    or ``None`` in debug mode, it will use a non-compact representation.\n    \"\"\"\n\n    mimetype = \"application/json\"\n    \"\"\"The mimetype set in :meth:`response`.\"\"\"\n\n    def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON to a string.\n\n        Keyword arguments are passed to :func:`json.dumps`. Sets some\n        parameter defaults from the :attr:`default`,\n        :attr:`ensure_ascii`, and :attr:`sort_keys` attributes.\n\n        :param obj: The data to serialize.\n        :param kwargs: Passed to :func:`json.dumps`.\n        \"\"\"\n        kwargs.setdefault(\"default\", self.default)\n        kwargs.setdefault(\"ensure_ascii\", self.ensure_ascii)\n        kwargs.setdefault(\"sort_keys\", self.sort_keys)\n        return json.dumps(obj, **kwargs)\n\n    def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON from a string or bytes.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: Passed to :func:`json.loads`.\n        \"\"\"\n        return json.loads(s, **kwargs)\n\n    def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with it. The response mimetype\n        will be \"application/json\" and can be changed with\n        :attr:`mimetype`.\n\n        If :attr:`compact` is ``False`` or debug mode is enabled, the\n        output will be formatted to be easier to read.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        dump_args: dict[str, t.Any] = {}\n\n        if (self.compact is None and self._app.debug) or self.compact is False:\n            dump_args.setdefault(\"indent\", 2)\n        else:\n            dump_args.setdefault(\"separators\", (\",\", \":\"))\n\n        return self._app.response_class(\n            f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n        )\n",
      "code_after": "from __future__ import annotations\n\nimport dataclasses\nimport decimal\nimport json\nimport typing as t\nimport uuid\nimport weakref\nfrom datetime import date\n\nfrom werkzeug.http import http_date\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.sansio.response import Response\n\n    from ..sansio.app import App\n\n\nclass JSONProvider:\n    \"\"\"A standard set of JSON operations for an application. Subclasses\n    of this can be used to customize JSON behavior or use different\n    JSON libraries.\n\n    To implement a provider for a specific library, subclass this base\n    class and implement at least :meth:`dumps` and :meth:`loads`. All\n    other methods have default implementations.\n\n    To use a different provider, either subclass ``Flask`` and set\n    :attr:`~flask.Flask.json_provider_class` to a provider class, or set\n    :attr:`app.json <flask.Flask.json>` to an instance of the class.\n\n    :param app: An application instance. This will be stored as a\n        :class:`weakref.proxy` on the :attr:`_app` attribute.\n\n    .. versionadded:: 2.2\n    \"\"\"\n\n    def __init__(self, app: App) -> None:\n        self._app: App = weakref.proxy(app)\n\n    def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON.\n\n        :param obj: The data to serialize.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError\n\n    def dump(self, obj: t.Any, fp: t.IO[str], **kwargs: t.Any) -> None:\n        \"\"\"Serialize data as JSON and write to a file.\n\n        :param obj: The data to serialize.\n        :param fp: A file opened for writing text. Should use the UTF-8\n            encoding to be valid JSON.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        fp.write(self.dumps(obj, **kwargs))\n\n    def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        raise NotImplementedError\n\n    def load(self, fp: t.IO[t.AnyStr], **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON read from a file.\n\n        :param fp: A file opened for reading text or UTF-8 bytes.\n        :param kwargs: May be passed to the underlying JSON library.\n        \"\"\"\n        return self.loads(fp.read(), **kwargs)\n\n    def _prepare_response_obj(\n        self, args: tuple[t.Any, ...], kwargs: dict[str, t.Any]\n    ) -> t.Any:\n        if args and kwargs:\n            raise TypeError(\"app.json.response() takes either args or kwargs, not both\")\n\n        if not args and not kwargs:\n            return None\n\n        if len(args) == 1:\n            return args[0]\n\n        return args or kwargs\n\n    def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with the ``application/json``\n        mimetype.\n\n        The :func:`~flask.json.jsonify` function calls this method for\n        the current application.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        return self._app.response_class(self.dumps(obj), mimetype=\"application/json\")\n\n\ndef _default(o: t.Any) -> t.Any:\n    if isinstance(o, date):\n        return http_date(o)\n\n    if isinstance(o, (decimal.Decimal, uuid.UUID)):\n        return str(o)\n\n    if dataclasses and dataclasses.is_dataclass(o):\n        return dataclasses.asdict(o)  # type: ignore[call-overload]\n\n    if hasattr(o, \"__html__\"):\n        return str(o.__html__())\n\n    raise TypeError(f\"Object of type {type(o).__name__} is not JSON serializable\")\n\n\nclass DefaultJSONProvider(JSONProvider):\n    \"\"\"Provide JSON operations using Python's built-in :mod:`json`\n    library. Serializes the following additional data types:\n\n    -   :class:`datetime.datetime` and :class:`datetime.date` are\n        serialized to :rfc:`822` strings. This is the same as the HTTP\n        date format.\n    -   :class:`uuid.UUID` is serialized to a string.\n    -   :class:`dataclasses.dataclass` is passed to\n        :func:`dataclasses.asdict`.\n    -   :class:`~markupsafe.Markup` (or any object with a ``__html__``\n        method) will call the ``__html__`` method to get a string.\n    \"\"\"\n\n    default: t.Callable[[t.Any], t.Any] = staticmethod(_default)  # type: ignore[assignment]\n    \"\"\"Apply this function to any object that :meth:`json.dumps` does\n    not know how to serialize. It should return a valid JSON type or\n    raise a ``TypeError``.\n    \"\"\"\n\n    ensure_ascii = True\n    \"\"\"Replace non-ASCII characters with escape sequences. This may be\n    more compatible with some clients, but can be disabled for better\n    performance and size.\n    \"\"\"\n\n    sort_keys = True\n    \"\"\"Sort the keys in any serialized dicts. This may be useful for\n    some caching situations, but can be disabled for better performance.\n    When enabled, keys must all be strings, they are not converted\n    before sorting.\n    \"\"\"\n\n    compact: bool | None = None\n    \"\"\"If ``True``, or ``None`` out of debug mode, the :meth:`response`\n    output will not add indentation, newlines, or spaces. If ``False``,\n    or ``None`` in debug mode, it will use a non-compact representation.\n    \"\"\"\n\n    mimetype = \"application/json\"\n    \"\"\"The mimetype set in :meth:`response`.\"\"\"\n\n    def dumps(self, obj: t.Any, **kwargs: t.Any) -> str:\n        \"\"\"Serialize data as JSON to a string.\n\n        Keyword arguments are passed to :func:`json.dumps`. Sets some\n        parameter defaults from the :attr:`default`,\n        :attr:`ensure_ascii`, and :attr:`sort_keys` attributes.\n\n        :param obj: The data to serialize.\n        :param kwargs: Passed to :func:`json.dumps`.\n        \"\"\"\n        kwargs.setdefault(\"default\", self.default)\n        kwargs.setdefault(\"ensure_ascii\", self.ensure_ascii)\n        kwargs.setdefault(\"sort_keys\", self.sort_keys)\n        return json.dumps(obj, **kwargs)\n\n    def loads(self, s: str | bytes, **kwargs: t.Any) -> t.Any:\n        \"\"\"Deserialize data as JSON from a string or bytes.\n\n        :param s: Text or UTF-8 bytes.\n        :param kwargs: Passed to :func:`json.loads`.\n        \"\"\"\n        return json.loads(s, **kwargs)\n\n    def response(self, *args: t.Any, **kwargs: t.Any) -> Response:\n        \"\"\"Serialize the given arguments as JSON, and return a\n        :class:`~flask.Response` object with it. The response mimetype\n        will be \"application/json\" and can be changed with\n        :attr:`mimetype`.\n\n        If :attr:`compact` is ``False`` or debug mode is enabled, the\n        output will be formatted to be easier to read.\n\n        Either positional or keyword arguments can be given, not both.\n        If no arguments are given, ``None`` is serialized.\n\n        :param args: A single value to serialize, or multiple values to\n            treat as a list to serialize.\n        :param kwargs: Treat as a dict to serialize.\n        \"\"\"\n        obj = self._prepare_response_obj(args, kwargs)\n        dump_args: dict[str, t.Any] = {}\n\n        if (self.compact is None and self._app.debug) or self.compact is False:\n            dump_args.setdefault(\"indent\", 2)\n        else:\n            dump_args.setdefault(\"separators\", (\",\", \":\"))\n\n        return self._app.response_class(\n            f\"{self.dumps(obj, **dump_args)}\\n\", mimetype=self.mimetype\n        )\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "9d6afd36a9c2",
      "repo": "flask",
      "commit_hash": "860a25c",
      "commit_message": "fix mypy finding",
      "file_path": "src/flask/helpers.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "code_after": "from __future__ import annotations\n\nimport importlib.util\nimport os\nimport sys\nimport typing as t\nfrom datetime import datetime\nfrom functools import lru_cache\nfrom functools import update_wrapper\n\nimport werkzeug.utils\nfrom werkzeug.exceptions import abort as _wz_abort\nfrom werkzeug.utils import redirect as _wz_redirect\nfrom werkzeug.wrappers import Response as BaseResponse\n\nfrom .globals import _cv_request\nfrom .globals import current_app\nfrom .globals import request\nfrom .globals import request_ctx\nfrom .globals import session\nfrom .signals import message_flashed\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from .wrappers import Response\n\n\ndef get_debug_flag() -> bool:\n    \"\"\"Get whether debug mode should be enabled for the app, indicated by the\n    :envvar:`FLASK_DEBUG` environment variable. The default is ``False``.\n    \"\"\"\n    val = os.environ.get(\"FLASK_DEBUG\")\n    return bool(val and val.lower() not in {\"0\", \"false\", \"no\"})\n\n\ndef get_load_dotenv(default: bool = True) -> bool:\n    \"\"\"Get whether the user has disabled loading default dotenv files by\n    setting :envvar:`FLASK_SKIP_DOTENV`. The default is ``True``, load\n    the files.\n\n    :param default: What to return if the env var isn't set.\n    \"\"\"\n    val = os.environ.get(\"FLASK_SKIP_DOTENV\")\n\n    if not val:\n        return default\n\n    return val.lower() in (\"0\", \"false\", \"no\")\n\n\ndef stream_with_context(\n    generator_or_function: t.Iterator[t.AnyStr] | t.Callable[..., t.Iterator[t.AnyStr]],\n) -> t.Iterator[t.AnyStr]:\n    \"\"\"Request contexts disappear when the response is started on the server.\n    This is done for efficiency reasons and to make it less likely to encounter\n    memory leaks with badly written WSGI middlewares.  The downside is that if\n    you are using streamed responses, the generator cannot access request bound\n    information any more.\n\n    This function however can help you keep the context around for longer::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            @stream_with_context\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(generate())\n\n    Alternatively it can also be used around a specific generator::\n\n        from flask import stream_with_context, request, Response\n\n        @app.route('/stream')\n        def streamed_response():\n            def generate():\n                yield 'Hello '\n                yield request.args['name']\n                yield '!'\n            return Response(stream_with_context(generate()))\n\n    .. versionadded:: 0.9\n    \"\"\"\n    try:\n        gen = iter(generator_or_function)  # type: ignore[arg-type]\n    except TypeError:\n\n        def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n            gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n            return stream_with_context(gen)\n\n        return update_wrapper(decorator, generator_or_function)  # type: ignore[arg-type, return-value]\n\n    def generator() -> t.Iterator[t.AnyStr | None]:\n        ctx = _cv_request.get(None)\n        if ctx is None:\n            raise RuntimeError(\n                \"'stream_with_context' can only be used when a request\"\n                \" context is active, such as in a view function.\"\n            )\n        with ctx:\n            # Dummy sentinel.  Has to be inside the context block or we're\n            # not actually keeping the context around.\n            yield None\n\n            # The try/finally is here so that if someone passes a WSGI level\n            # iterator in we're still running the cleanup logic.  Generators\n            # don't need that because they are closed on their destruction\n            # automatically.\n            try:\n                yield from gen\n            finally:\n                if hasattr(gen, \"close\"):\n                    gen.close()\n\n    # The trick is to start the generator.  Then the code execution runs until\n    # the first dummy None is yielded at which point the context was already\n    # pushed.  This item is discarded.  Then when the iteration continues the\n    # real generator is executed.\n    wrapped_g = generator()\n    next(wrapped_g)\n    return wrapped_g  # type: ignore[return-value]\n\n\ndef make_response(*args: t.Any) -> Response:\n    \"\"\"Sometimes it is necessary to set additional headers in a view.  Because\n    views do not have to return response objects but can return a value that\n    is converted into a response object by Flask itself, it becomes tricky to\n    add headers to it.  This function can be called instead of using a return\n    and you will get a response object which you can use to attach headers.\n\n    If view looked like this and you want to add a new header::\n\n        def index():\n            return render_template('index.html', foo=42)\n\n    You can now do something like this::\n\n        def index():\n            response = make_response(render_template('index.html', foo=42))\n            response.headers['X-Parachutes'] = 'parachutes are cool'\n            return response\n\n    This function accepts the very same arguments you can return from a\n    view function.  This for example creates a response with a 404 error\n    code::\n\n        response = make_response(render_template('not_found.html'), 404)\n\n    The other use case of this function is to force the return value of a\n    view function into a response which is helpful with view\n    decorators::\n\n        response = make_response(view_function())\n        response.headers['X-Parachutes'] = 'parachutes are cool'\n\n    Internally this function does the following things:\n\n    -   if no arguments are passed, it creates a new response argument\n    -   if one argument is passed, :meth:`flask.Flask.make_response`\n        is invoked with it.\n    -   if more than one argument is passed, the arguments are passed\n        to the :meth:`flask.Flask.make_response` function as tuple.\n\n    .. versionadded:: 0.6\n    \"\"\"\n    if not args:\n        return current_app.response_class()\n    if len(args) == 1:\n        args = args[0]\n    return current_app.make_response(args)\n\n\ndef url_for(\n    endpoint: str,\n    *,\n    _anchor: str | None = None,\n    _method: str | None = None,\n    _scheme: str | None = None,\n    _external: bool | None = None,\n    **values: t.Any,\n) -> str:\n    \"\"\"Generate a URL to the given endpoint with the given values.\n\n    This requires an active request or application context, and calls\n    :meth:`current_app.url_for() <flask.Flask.url_for>`. See that method\n    for full documentation.\n\n    :param endpoint: The endpoint name associated with the URL to\n        generate. If this starts with a ``.``, the current blueprint\n        name (if any) will be used.\n    :param _anchor: If given, append this as ``#anchor`` to the URL.\n    :param _method: If given, generate the URL associated with this\n        method for the endpoint.\n    :param _scheme: If given, the URL will have this scheme if it is\n        external.\n    :param _external: If given, prefer the URL to be internal (False) or\n        require it to be external (True). External URLs include the\n        scheme and domain. When not in an active request, URLs are\n        external by default.\n    :param values: Values to use for the variable parts of the URL rule.\n        Unknown keys are appended as query string arguments, like\n        ``?a=b&c=d``.\n\n    .. versionchanged:: 2.2\n        Calls ``current_app.url_for``, allowing an app to override the\n        behavior.\n\n    .. versionchanged:: 0.10\n       The ``_scheme`` parameter was added.\n\n    .. versionchanged:: 0.9\n       The ``_anchor`` and ``_method`` parameters were added.\n\n    .. versionchanged:: 0.9\n       Calls ``app.handle_url_build_error`` on build errors.\n    \"\"\"\n    return current_app.url_for(\n        endpoint,\n        _anchor=_anchor,\n        _method=_method,\n        _scheme=_scheme,\n        _external=_external,\n        **values,\n    )\n\n\ndef redirect(\n    location: str, code: int = 302, Response: type[BaseResponse] | None = None\n) -> BaseResponse:\n    \"\"\"Create a redirect response object.\n\n    If :data:`~flask.current_app` is available, it will use its\n    :meth:`~flask.Flask.redirect` method, otherwise it will use\n    :func:`werkzeug.utils.redirect`.\n\n    :param location: The URL to redirect to.\n    :param code: The status code for the redirect.\n    :param Response: The response class to use. Not used when\n        ``current_app`` is active, which uses ``app.response_class``.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.redirect`` if available instead of always\n        using Werkzeug's default ``redirect``.\n    \"\"\"\n    if current_app:\n        return current_app.redirect(location, code=code)\n\n    return _wz_redirect(location, code=code, Response=Response)\n\n\ndef abort(code: int | BaseResponse, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n    \"\"\"Raise an :exc:`~werkzeug.exceptions.HTTPException` for the given\n    status code.\n\n    If :data:`~flask.current_app` is available, it will call its\n    :attr:`~flask.Flask.aborter` object, otherwise it will use\n    :func:`werkzeug.exceptions.abort`.\n\n    :param code: The status code for the exception, which must be\n        registered in ``app.aborter``.\n    :param args: Passed to the exception.\n    :param kwargs: Passed to the exception.\n\n    .. versionadded:: 2.2\n        Calls ``current_app.aborter`` if available instead of always\n        using Werkzeug's default ``abort``.\n    \"\"\"\n    if current_app:\n        current_app.aborter(code, *args, **kwargs)\n\n    _wz_abort(code, *args, **kwargs)\n\n\ndef get_template_attribute(template_name: str, attribute: str) -> t.Any:\n    \"\"\"Loads a macro (or variable) a template exports.  This can be used to\n    invoke a macro from within Python code.  If you for example have a\n    template named :file:`_cider.html` with the following contents:\n\n    .. sourcecode:: html+jinja\n\n       {% macro hello(name) %}Hello {{ name }}!{% endmacro %}\n\n    You can access this from Python code like this::\n\n        hello = get_template_attribute('_cider.html', 'hello')\n        return hello('World')\n\n    .. versionadded:: 0.2\n\n    :param template_name: the name of the template\n    :param attribute: the name of the variable of macro to access\n    \"\"\"\n    return getattr(current_app.jinja_env.get_template(template_name).module, attribute)\n\n\ndef flash(message: str, category: str = \"message\") -> None:\n    \"\"\"Flashes a message to the next request.  In order to remove the\n    flashed message from the session and to display it to the user,\n    the template has to call :func:`get_flashed_messages`.\n\n    .. versionchanged:: 0.3\n       `category` parameter added.\n\n    :param message: the message to be flashed.\n    :param category: the category for the message.  The following values\n                     are recommended: ``'message'`` for any kind of message,\n                     ``'error'`` for errors, ``'info'`` for information\n                     messages and ``'warning'`` for warnings.  However any\n                     kind of string can be used as category.\n    \"\"\"\n    # Original implementation:\n    #\n    #     session.setdefault('_flashes', []).append((category, message))\n    #\n    # This assumed that changes made to mutable structures in the session are\n    # always in sync with the session object, which is not true for session\n    # implementations that use external storage for keeping their keys/values.\n    flashes = session.get(\"_flashes\", [])\n    flashes.append((category, message))\n    session[\"_flashes\"] = flashes\n    app = current_app._get_current_object()  # type: ignore\n    message_flashed.send(\n        app,\n        _async_wrapper=app.ensure_sync,\n        message=message,\n        category=category,\n    )\n\n\ndef get_flashed_messages(\n    with_categories: bool = False, category_filter: t.Iterable[str] = ()\n) -> list[str] | list[tuple[str, str]]:\n    \"\"\"Pulls all flashed messages from the session and returns them.\n    Further calls in the same request to the function will return\n    the same messages.  By default just the messages are returned,\n    but when `with_categories` is set to ``True``, the return value will\n    be a list of tuples in the form ``(category, message)`` instead.\n\n    Filter the flashed messages to one or more categories by providing those\n    categories in `category_filter`.  This allows rendering categories in\n    separate html blocks.  The `with_categories` and `category_filter`\n    arguments are distinct:\n\n    * `with_categories` controls whether categories are returned with message\n      text (``True`` gives a tuple, where ``False`` gives just the message text).\n    * `category_filter` filters the messages down to only those matching the\n      provided categories.\n\n    See :doc:`/patterns/flashing` for examples.\n\n    .. versionchanged:: 0.3\n       `with_categories` parameter added.\n\n    .. versionchanged:: 0.9\n        `category_filter` parameter added.\n\n    :param with_categories: set to ``True`` to also receive categories.\n    :param category_filter: filter of categories to limit return values.  Only\n                            categories in the list will be returned.\n    \"\"\"\n    flashes = request_ctx.flashes\n    if flashes is None:\n        flashes = session.pop(\"_flashes\") if \"_flashes\" in session else []\n        request_ctx.flashes = flashes\n    if category_filter:\n        flashes = list(filter(lambda f: f[0] in category_filter, flashes))\n    if not with_categories:\n        return [x[1] for x in flashes]\n    return flashes\n\n\ndef _prepare_send_file_kwargs(**kwargs: t.Any) -> dict[str, t.Any]:\n    if kwargs.get(\"max_age\") is None:\n        kwargs[\"max_age\"] = current_app.get_send_file_max_age\n\n    kwargs.update(\n        environ=request.environ,\n        use_x_sendfile=current_app.config[\"USE_X_SENDFILE\"],\n        response_class=current_app.response_class,\n        _root_path=current_app.root_path,  # type: ignore\n    )\n    return kwargs\n\n\ndef send_file(\n    path_or_file: os.PathLike[t.AnyStr] | str | t.BinaryIO,\n    mimetype: str | None = None,\n    as_attachment: bool = False,\n    download_name: str | None = None,\n    conditional: bool = True,\n    etag: bool | str = True,\n    last_modified: datetime | int | float | None = None,\n    max_age: None | (int | t.Callable[[str | None], int | None]) = None,\n) -> Response:\n    \"\"\"Send the contents of a file to the client.\n\n    The first argument can be a file path or a file-like object. Paths\n    are preferred in most cases because Werkzeug can manage the file and\n    get extra information from the path. Passing a file-like object\n    requires that the file is opened in binary mode, and is mostly\n    useful when building a file in memory with :class:`io.BytesIO`.\n\n    Never pass file paths provided by a user. The path is assumed to be\n    trusted, so a user could craft a path to access a file you didn't\n    intend. Use :func:`send_from_directory` to safely serve\n    user-requested paths from within a directory.\n\n    If the WSGI server sets a ``file_wrapper`` in ``environ``, it is\n    used, otherwise Werkzeug's built-in wrapper is used. Alternatively,\n    if the HTTP server supports ``X-Sendfile``, configuring Flask with\n    ``USE_X_SENDFILE = True`` will tell the server to send the given\n    path, which is much more efficient than reading it in Python.\n\n    :param path_or_file: The path to the file to send, relative to the\n        current working directory if a relative path is given.\n        Alternatively, a file-like object opened in binary mode. Make\n        sure the file pointer is seeked to the start of the data.\n    :param mimetype: The MIME type to send for the file. If not\n        provided, it will try to detect it from the file name.\n    :param as_attachment: Indicate to a browser that it should offer to\n        save the file instead of displaying it.\n    :param download_name: The default name browsers will use when saving\n        the file. Defaults to the passed file name.\n    :param conditional: Enable conditional and range responses based on\n        request headers. Requires passing a file path and ``environ``.\n    :param etag: Calculate an ETag for the file, which requires passing\n        a file path. Can also be a string to use instead.\n    :param last_modified: The last modified time to send for the file,\n        in seconds. If not provided, it will try to detect it from the\n        file path.\n    :param max_age: How long the client should cache the file, in\n        seconds. If set, ``Cache-Control`` will be ``public``, otherwise\n        it will be ``no-cache`` to prefer conditional caching.\n\n    .. versionchanged:: 2.0\n        ``download_name`` replaces the ``attachment_filename``\n        parameter. If ``as_attachment=False``, it is passed with\n        ``Content-Disposition: inline`` instead.\n\n    .. versionchanged:: 2.0\n        ``max_age`` replaces the ``cache_timeout`` parameter.\n        ``conditional`` is enabled and ``max_age`` is not set by\n        default.\n\n    .. versionchanged:: 2.0\n        ``etag`` replaces the ``add_etags`` parameter. It can be a\n        string to use instead of generating one.\n\n    .. versionchanged:: 2.0\n        Passing a file-like object that inherits from\n        :class:`~io.TextIOBase` will raise a :exc:`ValueError` rather\n        than sending an empty file.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionchanged:: 1.1\n        ``filename`` may be a :class:`~os.PathLike` object.\n\n    .. versionchanged:: 1.1\n        Passing a :class:`~io.BytesIO` object supports range requests.\n\n    .. versionchanged:: 1.0.3\n        Filenames are encoded with ASCII instead of Latin-1 for broader\n        compatibility with WSGI servers.\n\n    .. versionchanged:: 1.0\n        UTF-8 filenames as specified in :rfc:`2231` are supported.\n\n    .. versionchanged:: 0.12\n        The filename is no longer automatically inferred from file\n        objects. If you want to use automatic MIME and etag support,\n        pass a filename via ``filename_or_fp`` or\n        ``attachment_filename``.\n\n    .. versionchanged:: 0.12\n        ``attachment_filename`` is preferred over ``filename`` for MIME\n        detection.\n\n    .. versionchanged:: 0.9\n        ``cache_timeout`` defaults to\n        :meth:`Flask.get_send_file_max_age`.\n\n    .. versionchanged:: 0.7\n        MIME guessing and etag support for file-like objects was\n        removed because it was unreliable. Pass a filename if you are\n        able to, otherwise attach an etag yourself.\n\n    .. versionchanged:: 0.5\n        The ``add_etags``, ``cache_timeout`` and ``conditional``\n        parameters were added. The default behavior is to add etags.\n\n    .. versionadded:: 0.2\n    \"\"\"\n    return werkzeug.utils.send_file(  # type: ignore[return-value]\n        **_prepare_send_file_kwargs(\n            path_or_file=path_or_file,\n            environ=request.environ,\n            mimetype=mimetype,\n            as_attachment=as_attachment,\n            download_name=download_name,\n            conditional=conditional,\n            etag=etag,\n            last_modified=last_modified,\n            max_age=max_age,\n        )\n    )\n\n\ndef send_from_directory(\n    directory: os.PathLike[str] | str,\n    path: os.PathLike[str] | str,\n    **kwargs: t.Any,\n) -> Response:\n    \"\"\"Send a file from within a directory using :func:`send_file`.\n\n    .. code-block:: python\n\n        @app.route(\"/uploads/<path:name>\")\n        def download_file(name):\n            return send_from_directory(\n                app.config['UPLOAD_FOLDER'], name, as_attachment=True\n            )\n\n    This is a secure way to serve files from a folder, such as static\n    files or uploads. Uses :func:`~werkzeug.security.safe_join` to\n    ensure the path coming from the client is not maliciously crafted to\n    point outside the specified directory.\n\n    If the final path does not point to an existing regular file,\n    raises a 404 :exc:`~werkzeug.exceptions.NotFound` error.\n\n    :param directory: The directory that ``path`` must be located under,\n        relative to the current application's root path.\n    :param path: The path to the file to send, relative to\n        ``directory``.\n    :param kwargs: Arguments to pass to :func:`send_file`.\n\n    .. versionchanged:: 2.0\n        ``path`` replaces the ``filename`` parameter.\n\n    .. versionadded:: 2.0\n        Moved the implementation to Werkzeug. This is now a wrapper to\n        pass some Flask-specific arguments.\n\n    .. versionadded:: 0.5\n    \"\"\"\n    return werkzeug.utils.send_from_directory(  # type: ignore[return-value]\n        directory, path, **_prepare_send_file_kwargs(**kwargs)\n    )\n\n\ndef get_root_path(import_name: str) -> str:\n    \"\"\"Find the root path of a package, or the path that contains a\n    module. If it cannot be found, returns the current working\n    directory.\n\n    Not to be confused with the value returned by :func:`find_package`.\n\n    :meta private:\n    \"\"\"\n    # Module already imported and has a file attribute. Use that first.\n    mod = sys.modules.get(import_name)\n\n    if mod is not None and hasattr(mod, \"__file__\") and mod.__file__ is not None:\n        return os.path.dirname(os.path.abspath(mod.__file__))\n\n    # Next attempt: check the loader.\n    try:\n        spec = importlib.util.find_spec(import_name)\n\n        if spec is None:\n            raise ValueError\n    except (ImportError, ValueError):\n        loader = None\n    else:\n        loader = spec.loader\n\n    # Loader does not exist or we're referring to an unloaded main\n    # module or a main module without path (interactive sessions), go\n    # with the current working directory.\n    if loader is None:\n        return os.getcwd()\n\n    if hasattr(loader, \"get_filename\"):\n        filepath = loader.get_filename(import_name)\n    else:\n        # Fall back to imports.\n        __import__(import_name)\n        mod = sys.modules[import_name]\n        filepath = getattr(mod, \"__file__\", None)\n\n        # If we don't have a file path it might be because it is a\n        # namespace package. In this case pick the root path from the\n        # first module that is contained in the package.\n        if filepath is None:\n            raise RuntimeError(\n                \"No root path can be found for the provided module\"\n                f\" {import_name!r}. This can happen because the module\"\n                \" came from an import hook that does not provide file\"\n                \" name information or because it's a namespace package.\"\n                \" In this case the root path needs to be explicitly\"\n                \" provided.\"\n            )\n\n    # filepath is import_name.py for a module, or __init__.py for a package.\n    return os.path.dirname(os.path.abspath(filepath))  # type: ignore[no-any-return]\n\n\n@lru_cache(maxsize=None)\ndef _split_blueprint_path(name: str) -> list[str]:\n    out: list[str] = [name]\n\n    if \".\" in name:\n        out.extend(_split_blueprint_path(name.rpartition(\".\")[0]))\n\n    return out\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 0.4
    },
    {
      "bug_id": "563430dfa1cf",
      "repo": "flask",
      "commit_hash": "eb1182a",
      "commit_message": "fix mypy finding",
      "file_path": "src/flask/sessions.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\n# TODO generic when Python > 3.8\nclass SessionMixin(MutableMapping):  # type: ignore[type-arg]\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\n# TODO generic when Python > 3.8\nclass SecureCookieSession(CallbackDict, SessionMixin):  # type: ignore[type-arg]\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(self, initial: t.Any = None) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # type: ignore # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n    The session object returned by the :meth:`open_session` method has to\n    provide a dictionary like interface plus the properties and methods\n    from the :class:`SessionMixin`.  We recommend just subclassing a dict\n    and adding that mixin::\n\n        class Session(dict, SessionMixin):\n            pass\n\n    If :meth:`open_session` returns ``None`` Flask will call into\n    :meth:`make_null_session` to create a session that acts as replacement\n    if the session support cannot work because some requirement is not\n    fulfilled.  The default :class:`NullSession` class that is created\n    will complain that the secret key was not set.\n\n    To replace the session interface on an application all you have to do\n    is to assign :attr:`flask.Flask.session_interface`::\n\n        app = Flask(__name__)\n        app.session_interface = MySessionInterface()\n\n    Multiple requests with the same session may be sent and handled\n    concurrently. When implementing a new session interface, consider\n    whether reads or writes to the backing store must be synchronized.\n    There is no guarantee on the order in which the session for each\n    request is opened or saved, it will occur in the order that requests\n    begin and end processing.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    #: :meth:`make_null_session` will look here for the class that should\n    #: be created when a null session is requested.  Likewise the\n    #: :meth:`is_null_session` method will perform a typecheck against\n    #: this type.\n    null_session_class = NullSession\n\n    #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by Flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n\n    def make_null_session(self, app: Flask) -> NullSession:\n        \"\"\"Creates a null session which acts as a replacement object if the\n        real session support could not be loaded due to a configuration\n        error.  This mainly aids the user experience because the job of the\n        null session is to still support lookup without complaining but\n        modifications are answered with a helpful error message of what\n        failed.\n\n        This creates an instance of :attr:`null_session_class` by default.\n        \"\"\"\n        return self.null_session_class()\n\n    def is_null_session(self, obj: object) -> bool:\n        \"\"\"Checks if a given object is a null session.  Null sessions are\n        not asked to be saved.\n\n        This checks if the object is an instance of :attr:`null_session_class`\n        by default.\n        \"\"\"\n        return isinstance(obj, self.null_session_class)\n\n    def get_cookie_name(self, app: Flask) -> str:\n        \"\"\"The name of the session cookie. Uses``app.config[\"SESSION_COOKIE_NAME\"]``.\"\"\"\n        return app.config[\"SESSION_COOKIE_NAME\"]  # type: ignore[no-any-return]\n\n    def get_cookie_domain(self, app: Flask) -> str | None:\n        \"\"\"The value of the ``Domain`` parameter on the session cookie. If not set,\n        browsers will only send the cookie to the exact domain it was set from.\n        Otherwise, they will send it to any subdomain of the given value as well.\n\n        Uses the :data:`SESSION_COOKIE_DOMAIN` config.\n\n        .. versionchanged:: 2.3\n            Not set by default, does not fall back to ``SERVER_NAME``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_DOMAIN\"]  # type: ignore[no-any-return]\n\n    def get_cookie_path(self, app: Flask) -> str:\n        \"\"\"Returns the path for which the cookie should be valid.  The\n        default implementation uses the value from the ``SESSION_COOKIE_PATH``\n        config var if it's set, and falls back to ``APPLICATION_ROOT`` or\n        uses ``/`` if it's ``None``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PATH\"] or app.config[\"APPLICATION_ROOT\"]  # type: ignore[no-any-return]\n\n    def get_cookie_httponly(self, app: Flask) -> bool:\n        \"\"\"Returns True if the session cookie should be httponly.  This\n        currently just returns the value of the ``SESSION_COOKIE_HTTPONLY``\n        config var.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_HTTPONLY\"]  # type: ignore[no-any-return]\n\n    def get_cookie_secure(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be secure.  This currently\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SECURE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_samesite(self, app: Flask) -> str | None:\n        \"\"\"Return ``'Strict'`` or ``'Lax'`` if the cookie should use the\n        ``SameSite`` attribute. This currently just returns the value of\n        the :data:`SESSION_COOKIE_SAMESITE` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SAMESITE\"]  # type: ignore[no-any-return]\n\n    def get_expiration_time(self, app: Flask, session: SessionMixin) -> datetime | None:\n        \"\"\"A helper method that returns an expiration date for the session\n        or ``None`` if the session is linked to the browser session.  The\n        default implementation returns now + the permanent session\n        lifetime configured on the application.\n        \"\"\"\n        if session.permanent:\n            return datetime.now(timezone.utc) + app.permanent_session_lifetime\n        return None\n\n    def should_set_cookie(self, app: Flask, session: SessionMixin) -> bool:\n        \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n        should be set for this session cookie for this response. If the session\n        has been modified, the cookie is set. If the session is permanent and\n        the ``SESSION_REFRESH_EACH_REQUEST`` config is true, the cookie is\n        always set.\n\n        This check is usually skipped if the session was deleted.\n\n        .. versionadded:: 0.11\n        \"\"\"\n\n        return session.modified or (\n            session.permanent and app.config[\"SESSION_REFRESH_EACH_REQUEST\"]\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SessionMixin | None:\n        \"\"\"This is called at the beginning of each request, after\n        pushing the request context, before matching the URL.\n\n        This must return an object which implements a dictionary-like\n        interface as well as the :class:`SessionMixin` interface.\n\n        This will return ``None`` to indicate that loading failed in\n        some way that is not immediately an error. The request\n        context will fall back to using :meth:`make_null_session`\n        in this case.\n        \"\"\"\n        raise NotImplementedError()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, after generating\n        a response, before removing the request context. It is skipped\n        if :meth:`is_null_session` returns ``True``.\n        \"\"\"\n        raise NotImplementedError()\n\n\nsession_json_serializer = TaggedJSONSerializer()\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass SecureCookieSessionInterface(SessionInterface):\n    \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.\n    salt = \"cookie-session\"\n    #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(_lazy_sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = \"hmac\"\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.\n    serializer = session_json_serializer\n    session_class = SecureCookieSession\n\n    def get_signing_serializer(self, app: Flask) -> URLSafeTimedSerializer | None:\n        if not app.secret_key:\n            return None\n        signer_kwargs = dict(\n            key_derivation=self.key_derivation, digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(\n            app.secret_key,\n            salt=self.salt,\n            serializer=self.serializer,\n            signer_kwargs=signer_kwargs,\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SecureCookieSession | None:\n        s = self.get_signing_serializer(app)\n        if s is None:\n            return None\n        val = request.cookies.get(self.get_cookie_name(app))\n        if not val:\n            return self.session_class()\n        max_age = int(app.permanent_session_lifetime.total_seconds())\n        try:\n            data = s.loads(val, max_age=max_age)\n            return self.session_class(data)\n        except BadSignature:\n            return self.session_class()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        name = self.get_cookie_name(app)\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        secure = self.get_cookie_secure(app)\n        samesite = self.get_cookie_samesite(app)\n        httponly = self.get_cookie_httponly(app)\n\n        # Add a \"Vary: Cookie\" header if the session was accessed at all.\n        if session.accessed:\n            response.vary.add(\"Cookie\")\n\n        # If the session is modified to be empty, remove the cookie.\n        # If the session is empty, return without setting the cookie.\n        if not session:\n            if session.modified:\n                response.delete_cookie(\n                    name,\n                    domain=domain,\n                    path=path,\n                    secure=secure,\n                    samesite=samesite,\n                    httponly=httponly,\n                )\n                response.vary.add(\"Cookie\")\n\n            return\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        expires = self.get_expiration_time(app, session)\n        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n        response.set_cookie(\n            name,\n            val,  # type: ignore\n            expires=expires,\n            httponly=httponly,\n            domain=domain,\n            path=path,\n            secure=secure,\n            samesite=samesite,\n        )\n        response.vary.add(\"Cookie\")\n",
      "code_after": "from __future__ import annotations\n\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\n# TODO generic when Python > 3.8\nclass SessionMixin(MutableMapping):  # type: ignore[type-arg]\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\n# TODO generic when Python > 3.8\nclass SecureCookieSession(CallbackDict, SessionMixin):  # type: ignore[type-arg]\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(self, initial: t.Any = None) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # type: ignore # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n    The session object returned by the :meth:`open_session` method has to\n    provide a dictionary like interface plus the properties and methods\n    from the :class:`SessionMixin`.  We recommend just subclassing a dict\n    and adding that mixin::\n\n        class Session(dict, SessionMixin):\n            pass\n\n    If :meth:`open_session` returns ``None`` Flask will call into\n    :meth:`make_null_session` to create a session that acts as replacement\n    if the session support cannot work because some requirement is not\n    fulfilled.  The default :class:`NullSession` class that is created\n    will complain that the secret key was not set.\n\n    To replace the session interface on an application all you have to do\n    is to assign :attr:`flask.Flask.session_interface`::\n\n        app = Flask(__name__)\n        app.session_interface = MySessionInterface()\n\n    Multiple requests with the same session may be sent and handled\n    concurrently. When implementing a new session interface, consider\n    whether reads or writes to the backing store must be synchronized.\n    There is no guarantee on the order in which the session for each\n    request is opened or saved, it will occur in the order that requests\n    begin and end processing.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    #: :meth:`make_null_session` will look here for the class that should\n    #: be created when a null session is requested.  Likewise the\n    #: :meth:`is_null_session` method will perform a typecheck against\n    #: this type.\n    null_session_class = NullSession\n\n    #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by Flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n\n    def make_null_session(self, app: Flask) -> NullSession:\n        \"\"\"Creates a null session which acts as a replacement object if the\n        real session support could not be loaded due to a configuration\n        error.  This mainly aids the user experience because the job of the\n        null session is to still support lookup without complaining but\n        modifications are answered with a helpful error message of what\n        failed.\n\n        This creates an instance of :attr:`null_session_class` by default.\n        \"\"\"\n        return self.null_session_class()\n\n    def is_null_session(self, obj: object) -> bool:\n        \"\"\"Checks if a given object is a null session.  Null sessions are\n        not asked to be saved.\n\n        This checks if the object is an instance of :attr:`null_session_class`\n        by default.\n        \"\"\"\n        return isinstance(obj, self.null_session_class)\n\n    def get_cookie_name(self, app: Flask) -> str:\n        \"\"\"The name of the session cookie. Uses``app.config[\"SESSION_COOKIE_NAME\"]``.\"\"\"\n        return app.config[\"SESSION_COOKIE_NAME\"]  # type: ignore[no-any-return]\n\n    def get_cookie_domain(self, app: Flask) -> str | None:\n        \"\"\"The value of the ``Domain`` parameter on the session cookie. If not set,\n        browsers will only send the cookie to the exact domain it was set from.\n        Otherwise, they will send it to any subdomain of the given value as well.\n\n        Uses the :data:`SESSION_COOKIE_DOMAIN` config.\n\n        .. versionchanged:: 2.3\n            Not set by default, does not fall back to ``SERVER_NAME``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_DOMAIN\"]  # type: ignore[no-any-return]\n\n    def get_cookie_path(self, app: Flask) -> str:\n        \"\"\"Returns the path for which the cookie should be valid.  The\n        default implementation uses the value from the ``SESSION_COOKIE_PATH``\n        config var if it's set, and falls back to ``APPLICATION_ROOT`` or\n        uses ``/`` if it's ``None``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PATH\"] or app.config[\"APPLICATION_ROOT\"]  # type: ignore[no-any-return]\n\n    def get_cookie_httponly(self, app: Flask) -> bool:\n        \"\"\"Returns True if the session cookie should be httponly.  This\n        currently just returns the value of the ``SESSION_COOKIE_HTTPONLY``\n        config var.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_HTTPONLY\"]  # type: ignore[no-any-return]\n\n    def get_cookie_secure(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be secure.  This currently\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SECURE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_samesite(self, app: Flask) -> str | None:\n        \"\"\"Return ``'Strict'`` or ``'Lax'`` if the cookie should use the\n        ``SameSite`` attribute. This currently just returns the value of\n        the :data:`SESSION_COOKIE_SAMESITE` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SAMESITE\"]  # type: ignore[no-any-return]\n\n    def get_expiration_time(self, app: Flask, session: SessionMixin) -> datetime | None:\n        \"\"\"A helper method that returns an expiration date for the session\n        or ``None`` if the session is linked to the browser session.  The\n        default implementation returns now + the permanent session\n        lifetime configured on the application.\n        \"\"\"\n        if session.permanent:\n            return datetime.now(timezone.utc) + app.permanent_session_lifetime\n        return None\n\n    def should_set_cookie(self, app: Flask, session: SessionMixin) -> bool:\n        \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n        should be set for this session cookie for this response. If the session\n        has been modified, the cookie is set. If the session is permanent and\n        the ``SESSION_REFRESH_EACH_REQUEST`` config is true, the cookie is\n        always set.\n\n        This check is usually skipped if the session was deleted.\n\n        .. versionadded:: 0.11\n        \"\"\"\n\n        return session.modified or (\n            session.permanent and app.config[\"SESSION_REFRESH_EACH_REQUEST\"]\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SessionMixin | None:\n        \"\"\"This is called at the beginning of each request, after\n        pushing the request context, before matching the URL.\n\n        This must return an object which implements a dictionary-like\n        interface as well as the :class:`SessionMixin` interface.\n\n        This will return ``None`` to indicate that loading failed in\n        some way that is not immediately an error. The request\n        context will fall back to using :meth:`make_null_session`\n        in this case.\n        \"\"\"\n        raise NotImplementedError()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, after generating\n        a response, before removing the request context. It is skipped\n        if :meth:`is_null_session` returns ``True``.\n        \"\"\"\n        raise NotImplementedError()\n\n\nsession_json_serializer = TaggedJSONSerializer()\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass SecureCookieSessionInterface(SessionInterface):\n    \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.\n    salt = \"cookie-session\"\n    #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(_lazy_sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = \"hmac\"\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.\n    serializer = session_json_serializer\n    session_class = SecureCookieSession\n\n    def get_signing_serializer(self, app: Flask) -> URLSafeTimedSerializer | None:\n        if not app.secret_key:\n            return None\n        signer_kwargs = dict(\n            key_derivation=self.key_derivation, digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(\n            app.secret_key,\n            salt=self.salt,\n            serializer=self.serializer,\n            signer_kwargs=signer_kwargs,\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SecureCookieSession | None:\n        s = self.get_signing_serializer(app)\n        if s is None:\n            return None\n        val = request.cookies.get(self.get_cookie_name(app))\n        if not val:\n            return self.session_class()\n        max_age = int(app.permanent_session_lifetime.total_seconds())\n        try:\n            data = s.loads(val, max_age=max_age)\n            return self.session_class(data)\n        except BadSignature:\n            return self.session_class()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        name = self.get_cookie_name(app)\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        secure = self.get_cookie_secure(app)\n        samesite = self.get_cookie_samesite(app)\n        httponly = self.get_cookie_httponly(app)\n\n        # Add a \"Vary: Cookie\" header if the session was accessed at all.\n        if session.accessed:\n            response.vary.add(\"Cookie\")\n\n        # If the session is modified to be empty, remove the cookie.\n        # If the session is empty, return without setting the cookie.\n        if not session:\n            if session.modified:\n                response.delete_cookie(\n                    name,\n                    domain=domain,\n                    path=path,\n                    secure=secure,\n                    samesite=samesite,\n                    httponly=httponly,\n                )\n                response.vary.add(\"Cookie\")\n\n            return\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        expires = self.get_expiration_time(app, session)\n        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore[union-attr]\n        response.set_cookie(\n            name,\n            val,\n            expires=expires,\n            httponly=httponly,\n            domain=domain,\n            path=path,\n            secure=secure,\n            samesite=samesite,\n        )\n        response.vary.add(\"Cookie\")\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "d94196772266",
      "repo": "flask",
      "commit_hash": "a363642",
      "commit_message": "fix mypy finding with new werkzeug endpoint type",
      "file_path": "src/flask/wrappers.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport typing as t\n\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.wrappers import Request as RequestBase\nfrom werkzeug.wrappers import Response as ResponseBase\n\nfrom . import json\nfrom .globals import current_app\nfrom .helpers import _split_blueprint_path\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.routing import Rule\n\n\nclass Request(RequestBase):\n    \"\"\"The request object used by default in Flask.  Remembers the\n    matched endpoint and view arguments.\n\n    It is what ends up as :class:`~flask.request`.  If you want to replace\n    the request object used you can subclass this and set\n    :attr:`~flask.Flask.request_class` to your subclass.\n\n    The request object is a :class:`~werkzeug.wrappers.Request` subclass and\n    provides all of the attributes Werkzeug defines plus a few Flask\n    specific ones.\n    \"\"\"\n\n    json_module: t.Any = json\n\n    #: The internal URL rule that matched the request.  This can be\n    #: useful to inspect which methods are allowed for the URL from\n    #: a before/after handler (``request.url_rule.methods``) etc.\n    #: Though if the request's method was invalid for the URL rule,\n    #: the valid list is available in ``routing_exception.valid_methods``\n    #: instead (an attribute of the Werkzeug exception\n    #: :exc:`~werkzeug.exceptions.MethodNotAllowed`)\n    #: because the request was never internally bound.\n    #:\n    #: .. versionadded:: 0.6\n    url_rule: Rule | None = None\n\n    #: A dict of view arguments that matched the request.  If an exception\n    #: happened when matching, this will be ``None``.\n    view_args: dict[str, t.Any] | None = None\n\n    #: If matching the URL failed, this is the exception that will be\n    #: raised / was raised as part of the request handling.  This is\n    #: usually a :exc:`~werkzeug.exceptions.NotFound` exception or\n    #: something similar.\n    routing_exception: HTTPException | None = None\n\n    @property\n    def max_content_length(self) -> int | None:  # type: ignore[override]\n        \"\"\"Read-only view of the ``MAX_CONTENT_LENGTH`` config key.\"\"\"\n        if current_app:\n            return current_app.config[\"MAX_CONTENT_LENGTH\"]  # type: ignore[no-any-return]\n        else:\n            return None\n\n    @property\n    def endpoint(self) -> str | None:\n        \"\"\"The endpoint that matched the request URL.\n\n        This will be ``None`` if matching failed or has not been\n        performed yet.\n\n        This in combination with :attr:`view_args` can be used to\n        reconstruct the same URL or a modified URL.\n        \"\"\"\n        if self.url_rule is not None:\n            return self.url_rule.endpoint\n\n        return None\n\n    @property\n    def blueprint(self) -> str | None:\n        \"\"\"The registered name of the current blueprint.\n\n        This will be ``None`` if the endpoint is not part of a\n        blueprint, or if URL matching failed or has not been performed\n        yet.\n\n        This does not necessarily match the name the blueprint was\n        created with. It may have been nested, or registered with a\n        different name.\n        \"\"\"\n        endpoint = self.endpoint\n\n        if endpoint is not None and \".\" in endpoint:\n            return endpoint.rpartition(\".\")[0]\n\n        return None\n\n    @property\n    def blueprints(self) -> list[str]:\n        \"\"\"The registered names of the current blueprint upwards through\n        parent blueprints.\n\n        This will be an empty list if there is no current blueprint, or\n        if URL matching failed.\n\n        .. versionadded:: 2.0.1\n        \"\"\"\n        name = self.blueprint\n\n        if name is None:\n            return []\n\n        return _split_blueprint_path(name)\n\n    def _load_form_data(self) -> None:\n        super()._load_form_data()\n\n        # In debug mode we're replacing the files multidict with an ad-hoc\n        # subclass that raises a different error for key errors.\n        if (\n            current_app\n            and current_app.debug\n            and self.mimetype != \"multipart/form-data\"\n            and not self.files\n        ):\n            from .debughelpers import attach_enctype_error_multidict\n\n            attach_enctype_error_multidict(self)\n\n    def on_json_loading_failed(self, e: ValueError | None) -> t.Any:\n        try:\n            return super().on_json_loading_failed(e)\n        except BadRequest as e:\n            if current_app and current_app.debug:\n                raise\n\n            raise BadRequest() from e\n\n\nclass Response(ResponseBase):\n    \"\"\"The response object that is used by default in Flask.  Works like the\n    response object from Werkzeug but is set to have an HTML mimetype by\n    default.  Quite often you don't have to create this object yourself because\n    :meth:`~flask.Flask.make_response` will take care of that for you.\n\n    If you want to replace the response object used you can subclass this and\n    set :attr:`~flask.Flask.response_class` to your subclass.\n\n    .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON.\n\n    .. versionchanged:: 1.0\n\n        Added :attr:`max_cookie_size`.\n    \"\"\"\n\n    default_mimetype: str | None = \"text/html\"\n\n    json_module = json\n\n    autocorrect_location_header = False\n\n    @property\n    def max_cookie_size(self) -> int:  # type: ignore\n        \"\"\"Read-only view of the :data:`MAX_COOKIE_SIZE` config key.\n\n        See :attr:`~werkzeug.wrappers.Response.max_cookie_size` in\n        Werkzeug's docs.\n        \"\"\"\n        if current_app:\n            return current_app.config[\"MAX_COOKIE_SIZE\"]  # type: ignore[no-any-return]\n\n        # return Werkzeug's default when not in an app context\n        return super().max_cookie_size\n",
      "code_after": "from __future__ import annotations\n\nimport typing as t\n\nfrom werkzeug.exceptions import BadRequest\nfrom werkzeug.exceptions import HTTPException\nfrom werkzeug.wrappers import Request as RequestBase\nfrom werkzeug.wrappers import Response as ResponseBase\n\nfrom . import json\nfrom .globals import current_app\nfrom .helpers import _split_blueprint_path\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    from werkzeug.routing import Rule\n\n\nclass Request(RequestBase):\n    \"\"\"The request object used by default in Flask.  Remembers the\n    matched endpoint and view arguments.\n\n    It is what ends up as :class:`~flask.request`.  If you want to replace\n    the request object used you can subclass this and set\n    :attr:`~flask.Flask.request_class` to your subclass.\n\n    The request object is a :class:`~werkzeug.wrappers.Request` subclass and\n    provides all of the attributes Werkzeug defines plus a few Flask\n    specific ones.\n    \"\"\"\n\n    json_module: t.Any = json\n\n    #: The internal URL rule that matched the request.  This can be\n    #: useful to inspect which methods are allowed for the URL from\n    #: a before/after handler (``request.url_rule.methods``) etc.\n    #: Though if the request's method was invalid for the URL rule,\n    #: the valid list is available in ``routing_exception.valid_methods``\n    #: instead (an attribute of the Werkzeug exception\n    #: :exc:`~werkzeug.exceptions.MethodNotAllowed`)\n    #: because the request was never internally bound.\n    #:\n    #: .. versionadded:: 0.6\n    url_rule: Rule | None = None\n\n    #: A dict of view arguments that matched the request.  If an exception\n    #: happened when matching, this will be ``None``.\n    view_args: dict[str, t.Any] | None = None\n\n    #: If matching the URL failed, this is the exception that will be\n    #: raised / was raised as part of the request handling.  This is\n    #: usually a :exc:`~werkzeug.exceptions.NotFound` exception or\n    #: something similar.\n    routing_exception: HTTPException | None = None\n\n    @property\n    def max_content_length(self) -> int | None:  # type: ignore[override]\n        \"\"\"Read-only view of the ``MAX_CONTENT_LENGTH`` config key.\"\"\"\n        if current_app:\n            return current_app.config[\"MAX_CONTENT_LENGTH\"]  # type: ignore[no-any-return]\n        else:\n            return None\n\n    @property\n    def endpoint(self) -> str | None:\n        \"\"\"The endpoint that matched the request URL.\n\n        This will be ``None`` if matching failed or has not been\n        performed yet.\n\n        This in combination with :attr:`view_args` can be used to\n        reconstruct the same URL or a modified URL.\n        \"\"\"\n        if self.url_rule is not None:\n            return self.url_rule.endpoint  # type: ignore[no-any-return]\n\n        return None\n\n    @property\n    def blueprint(self) -> str | None:\n        \"\"\"The registered name of the current blueprint.\n\n        This will be ``None`` if the endpoint is not part of a\n        blueprint, or if URL matching failed or has not been performed\n        yet.\n\n        This does not necessarily match the name the blueprint was\n        created with. It may have been nested, or registered with a\n        different name.\n        \"\"\"\n        endpoint = self.endpoint\n\n        if endpoint is not None and \".\" in endpoint:\n            return endpoint.rpartition(\".\")[0]\n\n        return None\n\n    @property\n    def blueprints(self) -> list[str]:\n        \"\"\"The registered names of the current blueprint upwards through\n        parent blueprints.\n\n        This will be an empty list if there is no current blueprint, or\n        if URL matching failed.\n\n        .. versionadded:: 2.0.1\n        \"\"\"\n        name = self.blueprint\n\n        if name is None:\n            return []\n\n        return _split_blueprint_path(name)\n\n    def _load_form_data(self) -> None:\n        super()._load_form_data()\n\n        # In debug mode we're replacing the files multidict with an ad-hoc\n        # subclass that raises a different error for key errors.\n        if (\n            current_app\n            and current_app.debug\n            and self.mimetype != \"multipart/form-data\"\n            and not self.files\n        ):\n            from .debughelpers import attach_enctype_error_multidict\n\n            attach_enctype_error_multidict(self)\n\n    def on_json_loading_failed(self, e: ValueError | None) -> t.Any:\n        try:\n            return super().on_json_loading_failed(e)\n        except BadRequest as e:\n            if current_app and current_app.debug:\n                raise\n\n            raise BadRequest() from e\n\n\nclass Response(ResponseBase):\n    \"\"\"The response object that is used by default in Flask.  Works like the\n    response object from Werkzeug but is set to have an HTML mimetype by\n    default.  Quite often you don't have to create this object yourself because\n    :meth:`~flask.Flask.make_response` will take care of that for you.\n\n    If you want to replace the response object used you can subclass this and\n    set :attr:`~flask.Flask.response_class` to your subclass.\n\n    .. versionchanged:: 1.0\n        JSON support is added to the response, like the request. This is useful\n        when testing to get the test client response data as JSON.\n\n    .. versionchanged:: 1.0\n\n        Added :attr:`max_cookie_size`.\n    \"\"\"\n\n    default_mimetype: str | None = \"text/html\"\n\n    json_module = json\n\n    autocorrect_location_header = False\n\n    @property\n    def max_cookie_size(self) -> int:  # type: ignore\n        \"\"\"Read-only view of the :data:`MAX_COOKIE_SIZE` config key.\n\n        See :attr:`~werkzeug.wrappers.Response.max_cookie_size` in\n        Werkzeug's docs.\n        \"\"\"\n        if current_app:\n            return current_app.config[\"MAX_COOKIE_SIZE\"]  # type: ignore[no-any-return]\n\n        # return Werkzeug's default when not in an app context\n        return super().max_cookie_size\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "173408c6f3a4",
      "repo": "flask",
      "commit_hash": "ccf125b",
      "commit_message": "fix mypy findings",
      "file_path": "src/flask/sessions.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\n# TODO generic when Python > 3.8\nclass SessionMixin(MutableMapping):  # type: ignore[type-arg]\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\n# TODO generic when Python > 3.8\nclass SecureCookieSession(CallbackDict, SessionMixin):  # type: ignore[type-arg]\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(self, initial: t.Any = None) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # type: ignore # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n    The session object returned by the :meth:`open_session` method has to\n    provide a dictionary like interface plus the properties and methods\n    from the :class:`SessionMixin`.  We recommend just subclassing a dict\n    and adding that mixin::\n\n        class Session(dict, SessionMixin):\n            pass\n\n    If :meth:`open_session` returns ``None`` Flask will call into\n    :meth:`make_null_session` to create a session that acts as replacement\n    if the session support cannot work because some requirement is not\n    fulfilled.  The default :class:`NullSession` class that is created\n    will complain that the secret key was not set.\n\n    To replace the session interface on an application all you have to do\n    is to assign :attr:`flask.Flask.session_interface`::\n\n        app = Flask(__name__)\n        app.session_interface = MySessionInterface()\n\n    Multiple requests with the same session may be sent and handled\n    concurrently. When implementing a new session interface, consider\n    whether reads or writes to the backing store must be synchronized.\n    There is no guarantee on the order in which the session for each\n    request is opened or saved, it will occur in the order that requests\n    begin and end processing.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    #: :meth:`make_null_session` will look here for the class that should\n    #: be created when a null session is requested.  Likewise the\n    #: :meth:`is_null_session` method will perform a typecheck against\n    #: this type.\n    null_session_class = NullSession\n\n    #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by Flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n\n    def make_null_session(self, app: Flask) -> NullSession:\n        \"\"\"Creates a null session which acts as a replacement object if the\n        real session support could not be loaded due to a configuration\n        error.  This mainly aids the user experience because the job of the\n        null session is to still support lookup without complaining but\n        modifications are answered with a helpful error message of what\n        failed.\n\n        This creates an instance of :attr:`null_session_class` by default.\n        \"\"\"\n        return self.null_session_class()\n\n    def is_null_session(self, obj: object) -> bool:\n        \"\"\"Checks if a given object is a null session.  Null sessions are\n        not asked to be saved.\n\n        This checks if the object is an instance of :attr:`null_session_class`\n        by default.\n        \"\"\"\n        return isinstance(obj, self.null_session_class)\n\n    def get_cookie_name(self, app: Flask) -> str:\n        \"\"\"The name of the session cookie. Uses``app.config[\"SESSION_COOKIE_NAME\"]``.\"\"\"\n        return app.config[\"SESSION_COOKIE_NAME\"]  # type: ignore[no-any-return]\n\n    def get_cookie_domain(self, app: Flask) -> str | None:\n        \"\"\"The value of the ``Domain`` parameter on the session cookie. If not set,\n        browsers will only send the cookie to the exact domain it was set from.\n        Otherwise, they will send it to any subdomain of the given value as well.\n\n        Uses the :data:`SESSION_COOKIE_DOMAIN` config.\n\n        .. versionchanged:: 2.3\n            Not set by default, does not fall back to ``SERVER_NAME``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_DOMAIN\"]  # type: ignore[no-any-return]\n\n    def get_cookie_path(self, app: Flask) -> str:\n        \"\"\"Returns the path for which the cookie should be valid.  The\n        default implementation uses the value from the ``SESSION_COOKIE_PATH``\n        config var if it's set, and falls back to ``APPLICATION_ROOT`` or\n        uses ``/`` if it's ``None``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PATH\"] or app.config[\"APPLICATION_ROOT\"]  # type: ignore[no-any-return]\n\n    def get_cookie_httponly(self, app: Flask) -> bool:\n        \"\"\"Returns True if the session cookie should be httponly.  This\n        currently just returns the value of the ``SESSION_COOKIE_HTTPONLY``\n        config var.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_HTTPONLY\"]  # type: ignore[no-any-return]\n\n    def get_cookie_secure(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be secure.  This currently\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SECURE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_samesite(self, app: Flask) -> str | None:\n        \"\"\"Return ``'Strict'`` or ``'Lax'`` if the cookie should use the\n        ``SameSite`` attribute. This currently just returns the value of\n        the :data:`SESSION_COOKIE_SAMESITE` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SAMESITE\"]  # type: ignore[no-any-return]\n\n    def get_expiration_time(self, app: Flask, session: SessionMixin) -> datetime | None:\n        \"\"\"A helper method that returns an expiration date for the session\n        or ``None`` if the session is linked to the browser session.  The\n        default implementation returns now + the permanent session\n        lifetime configured on the application.\n        \"\"\"\n        if session.permanent:\n            return datetime.now(timezone.utc) + app.permanent_session_lifetime\n        return None\n\n    def should_set_cookie(self, app: Flask, session: SessionMixin) -> bool:\n        \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n        should be set for this session cookie for this response. If the session\n        has been modified, the cookie is set. If the session is permanent and\n        the ``SESSION_REFRESH_EACH_REQUEST`` config is true, the cookie is\n        always set.\n\n        This check is usually skipped if the session was deleted.\n\n        .. versionadded:: 0.11\n        \"\"\"\n\n        return session.modified or (\n            session.permanent and app.config[\"SESSION_REFRESH_EACH_REQUEST\"]\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SessionMixin | None:\n        \"\"\"This is called at the beginning of each request, after\n        pushing the request context, before matching the URL.\n\n        This must return an object which implements a dictionary-like\n        interface as well as the :class:`SessionMixin` interface.\n\n        This will return ``None`` to indicate that loading failed in\n        some way that is not immediately an error. The request\n        context will fall back to using :meth:`make_null_session`\n        in this case.\n        \"\"\"\n        raise NotImplementedError()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, after generating\n        a response, before removing the request context. It is skipped\n        if :meth:`is_null_session` returns ``True``.\n        \"\"\"\n        raise NotImplementedError()\n\n\nsession_json_serializer = TaggedJSONSerializer()\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass SecureCookieSessionInterface(SessionInterface):\n    \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.\n    salt = \"cookie-session\"\n    #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(_lazy_sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = \"hmac\"\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.\n    serializer = session_json_serializer\n    session_class = SecureCookieSession\n\n    def get_signing_serializer(self, app: Flask) -> URLSafeTimedSerializer | None:\n        if not app.secret_key:\n            return None\n        signer_kwargs = dict(\n            key_derivation=self.key_derivation, digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(\n            app.secret_key,\n            salt=self.salt,\n            serializer=self.serializer,\n            signer_kwargs=signer_kwargs,\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SecureCookieSession | None:\n        s = self.get_signing_serializer(app)\n        if s is None:\n            return None\n        val = request.cookies.get(self.get_cookie_name(app))\n        if not val:\n            return self.session_class()\n        max_age = int(app.permanent_session_lifetime.total_seconds())\n        try:\n            data = s.loads(val, max_age=max_age)\n            return self.session_class(data)\n        except BadSignature:\n            return self.session_class()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        name = self.get_cookie_name(app)\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        secure = self.get_cookie_secure(app)\n        samesite = self.get_cookie_samesite(app)\n        httponly = self.get_cookie_httponly(app)\n\n        # Add a \"Vary: Cookie\" header if the session was accessed at all.\n        if session.accessed:\n            response.vary.add(\"Cookie\")\n\n        # If the session is modified to be empty, remove the cookie.\n        # If the session is empty, return without setting the cookie.\n        if not session:\n            if session.modified:\n                response.delete_cookie(\n                    name,\n                    domain=domain,\n                    path=path,\n                    secure=secure,\n                    samesite=samesite,\n                    httponly=httponly,\n                )\n                response.vary.add(\"Cookie\")\n\n            return\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        expires = self.get_expiration_time(app, session)\n        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n        response.set_cookie(\n            name,\n            val,  # type: ignore\n            expires=expires,\n            httponly=httponly,\n            domain=domain,\n            path=path,\n            secure=secure,\n            samesite=samesite,\n        )\n        response.vary.add(\"Cookie\")\n",
      "code_after": "from __future__ import annotations\n\nimport hashlib\nimport typing as t\nfrom collections.abc import MutableMapping\nfrom datetime import datetime\nfrom datetime import timezone\n\nfrom itsdangerous import BadSignature\nfrom itsdangerous import URLSafeTimedSerializer\nfrom werkzeug.datastructures import CallbackDict\n\nfrom .json.tag import TaggedJSONSerializer\n\nif t.TYPE_CHECKING:  # pragma: no cover\n    import typing_extensions as te\n\n    from .app import Flask\n    from .wrappers import Request\n    from .wrappers import Response\n\n\n# TODO generic when Python > 3.8\nclass SessionMixin(MutableMapping):  # type: ignore[type-arg]\n    \"\"\"Expands a basic dictionary with session attributes.\"\"\"\n\n    @property\n    def permanent(self) -> bool:\n        \"\"\"This reflects the ``'_permanent'`` key in the dict.\"\"\"\n        return self.get(\"_permanent\", False)\n\n    @permanent.setter\n    def permanent(self, value: bool) -> None:\n        self[\"_permanent\"] = bool(value)\n\n    #: Some implementations can detect whether a session is newly\n    #: created, but that is not guaranteed. Use with caution. The mixin\n    # default is hard-coded ``False``.\n    new = False\n\n    #: Some implementations can detect changes to the session and set\n    #: this when that happens. The mixin default is hard coded to\n    #: ``True``.\n    modified = True\n\n    #: Some implementations can detect when session data is read or\n    #: written and set this when that happens. The mixin default is hard\n    #: coded to ``True``.\n    accessed = True\n\n\n# TODO generic when Python > 3.8\nclass SecureCookieSession(CallbackDict, SessionMixin):  # type: ignore[type-arg]\n    \"\"\"Base class for sessions based on signed cookies.\n\n    This session backend will set the :attr:`modified` and\n    :attr:`accessed` attributes. It cannot reliably track whether a\n    session is new (vs. empty), so :attr:`new` remains hard coded to\n    ``False``.\n    \"\"\"\n\n    #: When data is changed, this is set to ``True``. Only the session\n    #: dictionary itself is tracked; if the session contains mutable\n    #: data (for example a nested dict) then this must be set to\n    #: ``True`` manually when modifying that data. The session cookie\n    #: will only be written to the response if this is ``True``.\n    modified = False\n\n    #: When data is read or written, this is set to ``True``. Used by\n    # :class:`.SecureCookieSessionInterface` to add a ``Vary: Cookie``\n    #: header, which allows caching proxies to cache different pages for\n    #: different users.\n    accessed = False\n\n    def __init__(self, initial: t.Any = None) -> None:\n        def on_update(self: te.Self) -> None:\n            self.modified = True\n            self.accessed = True\n\n        super().__init__(initial, on_update)\n\n    def __getitem__(self, key: str) -> t.Any:\n        self.accessed = True\n        return super().__getitem__(key)\n\n    def get(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().get(key, default)\n\n    def setdefault(self, key: str, default: t.Any = None) -> t.Any:\n        self.accessed = True\n        return super().setdefault(key, default)\n\n\nclass NullSession(SecureCookieSession):\n    \"\"\"Class used to generate nicer error messages if sessions are not\n    available.  Will still allow read-only access to the empty session\n    but fail on setting.\n    \"\"\"\n\n    def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n        raise RuntimeError(\n            \"The session is unavailable because no secret \"\n            \"key was set.  Set the secret_key on the \"\n            \"application to something unique and secret.\"\n        )\n\n    __setitem__ = __delitem__ = clear = pop = popitem = update = setdefault = _fail  # type: ignore # noqa: B950\n    del _fail\n\n\nclass SessionInterface:\n    \"\"\"The basic interface you have to implement in order to replace the\n    default session interface which uses werkzeug's securecookie\n    implementation.  The only methods you have to implement are\n    :meth:`open_session` and :meth:`save_session`, the others have\n    useful defaults which you don't need to change.\n\n    The session object returned by the :meth:`open_session` method has to\n    provide a dictionary like interface plus the properties and methods\n    from the :class:`SessionMixin`.  We recommend just subclassing a dict\n    and adding that mixin::\n\n        class Session(dict, SessionMixin):\n            pass\n\n    If :meth:`open_session` returns ``None`` Flask will call into\n    :meth:`make_null_session` to create a session that acts as replacement\n    if the session support cannot work because some requirement is not\n    fulfilled.  The default :class:`NullSession` class that is created\n    will complain that the secret key was not set.\n\n    To replace the session interface on an application all you have to do\n    is to assign :attr:`flask.Flask.session_interface`::\n\n        app = Flask(__name__)\n        app.session_interface = MySessionInterface()\n\n    Multiple requests with the same session may be sent and handled\n    concurrently. When implementing a new session interface, consider\n    whether reads or writes to the backing store must be synchronized.\n    There is no guarantee on the order in which the session for each\n    request is opened or saved, it will occur in the order that requests\n    begin and end processing.\n\n    .. versionadded:: 0.8\n    \"\"\"\n\n    #: :meth:`make_null_session` will look here for the class that should\n    #: be created when a null session is requested.  Likewise the\n    #: :meth:`is_null_session` method will perform a typecheck against\n    #: this type.\n    null_session_class = NullSession\n\n    #: A flag that indicates if the session interface is pickle based.\n    #: This can be used by Flask extensions to make a decision in regards\n    #: to how to deal with the session object.\n    #:\n    #: .. versionadded:: 0.10\n    pickle_based = False\n\n    def make_null_session(self, app: Flask) -> NullSession:\n        \"\"\"Creates a null session which acts as a replacement object if the\n        real session support could not be loaded due to a configuration\n        error.  This mainly aids the user experience because the job of the\n        null session is to still support lookup without complaining but\n        modifications are answered with a helpful error message of what\n        failed.\n\n        This creates an instance of :attr:`null_session_class` by default.\n        \"\"\"\n        return self.null_session_class()\n\n    def is_null_session(self, obj: object) -> bool:\n        \"\"\"Checks if a given object is a null session.  Null sessions are\n        not asked to be saved.\n\n        This checks if the object is an instance of :attr:`null_session_class`\n        by default.\n        \"\"\"\n        return isinstance(obj, self.null_session_class)\n\n    def get_cookie_name(self, app: Flask) -> str:\n        \"\"\"The name of the session cookie. Uses``app.config[\"SESSION_COOKIE_NAME\"]``.\"\"\"\n        return app.config[\"SESSION_COOKIE_NAME\"]  # type: ignore[no-any-return]\n\n    def get_cookie_domain(self, app: Flask) -> str | None:\n        \"\"\"The value of the ``Domain`` parameter on the session cookie. If not set,\n        browsers will only send the cookie to the exact domain it was set from.\n        Otherwise, they will send it to any subdomain of the given value as well.\n\n        Uses the :data:`SESSION_COOKIE_DOMAIN` config.\n\n        .. versionchanged:: 2.3\n            Not set by default, does not fall back to ``SERVER_NAME``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_DOMAIN\"]  # type: ignore[no-any-return]\n\n    def get_cookie_path(self, app: Flask) -> str:\n        \"\"\"Returns the path for which the cookie should be valid.  The\n        default implementation uses the value from the ``SESSION_COOKIE_PATH``\n        config var if it's set, and falls back to ``APPLICATION_ROOT`` or\n        uses ``/`` if it's ``None``.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_PATH\"] or app.config[\"APPLICATION_ROOT\"]  # type: ignore[no-any-return]\n\n    def get_cookie_httponly(self, app: Flask) -> bool:\n        \"\"\"Returns True if the session cookie should be httponly.  This\n        currently just returns the value of the ``SESSION_COOKIE_HTTPONLY``\n        config var.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_HTTPONLY\"]  # type: ignore[no-any-return]\n\n    def get_cookie_secure(self, app: Flask) -> bool:\n        \"\"\"Returns True if the cookie should be secure.  This currently\n        just returns the value of the ``SESSION_COOKIE_SECURE`` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SECURE\"]  # type: ignore[no-any-return]\n\n    def get_cookie_samesite(self, app: Flask) -> str | None:\n        \"\"\"Return ``'Strict'`` or ``'Lax'`` if the cookie should use the\n        ``SameSite`` attribute. This currently just returns the value of\n        the :data:`SESSION_COOKIE_SAMESITE` setting.\n        \"\"\"\n        return app.config[\"SESSION_COOKIE_SAMESITE\"]  # type: ignore[no-any-return]\n\n    def get_expiration_time(self, app: Flask, session: SessionMixin) -> datetime | None:\n        \"\"\"A helper method that returns an expiration date for the session\n        or ``None`` if the session is linked to the browser session.  The\n        default implementation returns now + the permanent session\n        lifetime configured on the application.\n        \"\"\"\n        if session.permanent:\n            return datetime.now(timezone.utc) + app.permanent_session_lifetime\n        return None\n\n    def should_set_cookie(self, app: Flask, session: SessionMixin) -> bool:\n        \"\"\"Used by session backends to determine if a ``Set-Cookie`` header\n        should be set for this session cookie for this response. If the session\n        has been modified, the cookie is set. If the session is permanent and\n        the ``SESSION_REFRESH_EACH_REQUEST`` config is true, the cookie is\n        always set.\n\n        This check is usually skipped if the session was deleted.\n\n        .. versionadded:: 0.11\n        \"\"\"\n\n        return session.modified or (\n            session.permanent and app.config[\"SESSION_REFRESH_EACH_REQUEST\"]\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SessionMixin | None:\n        \"\"\"This is called at the beginning of each request, after\n        pushing the request context, before matching the URL.\n\n        This must return an object which implements a dictionary-like\n        interface as well as the :class:`SessionMixin` interface.\n\n        This will return ``None`` to indicate that loading failed in\n        some way that is not immediately an error. The request\n        context will fall back to using :meth:`make_null_session`\n        in this case.\n        \"\"\"\n        raise NotImplementedError()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, after generating\n        a response, before removing the request context. It is skipped\n        if :meth:`is_null_session` returns ``True``.\n        \"\"\"\n        raise NotImplementedError()\n\n\nsession_json_serializer = TaggedJSONSerializer()\n\n\ndef _lazy_sha1(string: bytes = b\"\") -> t.Any:\n    \"\"\"Don't access ``hashlib.sha1`` until runtime. FIPS builds may not include\n    SHA-1, in which case the import and use as a default would fail before the\n    developer can configure something else.\n    \"\"\"\n    return hashlib.sha1(string)\n\n\nclass SecureCookieSessionInterface(SessionInterface):\n    \"\"\"The default session interface that stores sessions in signed cookies\n    through the :mod:`itsdangerous` module.\n    \"\"\"\n\n    #: the salt that should be applied on top of the secret key for the\n    #: signing of cookie based sessions.\n    salt = \"cookie-session\"\n    #: the hash function to use for the signature.  The default is sha1\n    digest_method = staticmethod(_lazy_sha1)\n    #: the name of the itsdangerous supported key derivation.  The default\n    #: is hmac.\n    key_derivation = \"hmac\"\n    #: A python serializer for the payload.  The default is a compact\n    #: JSON derived serializer with support for some extra Python types\n    #: such as datetime objects or tuples.\n    serializer = session_json_serializer\n    session_class = SecureCookieSession\n\n    def get_signing_serializer(self, app: Flask) -> URLSafeTimedSerializer | None:\n        if not app.secret_key:\n            return None\n        signer_kwargs = dict(\n            key_derivation=self.key_derivation, digest_method=self.digest_method\n        )\n        return URLSafeTimedSerializer(\n            app.secret_key,\n            salt=self.salt,\n            serializer=self.serializer,\n            signer_kwargs=signer_kwargs,\n        )\n\n    def open_session(self, app: Flask, request: Request) -> SecureCookieSession | None:\n        s = self.get_signing_serializer(app)\n        if s is None:\n            return None\n        val = request.cookies.get(self.get_cookie_name(app))\n        if not val:\n            return self.session_class()\n        max_age = int(app.permanent_session_lifetime.total_seconds())\n        try:\n            data = s.loads(val, max_age=max_age)\n            return self.session_class(data)\n        except BadSignature:\n            return self.session_class()\n\n    def save_session(\n        self, app: Flask, session: SessionMixin, response: Response\n    ) -> None:\n        name = self.get_cookie_name(app)\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        secure = self.get_cookie_secure(app)\n        samesite = self.get_cookie_samesite(app)\n        httponly = self.get_cookie_httponly(app)\n\n        # Add a \"Vary: Cookie\" header if the session was accessed at all.\n        if session.accessed:\n            response.vary.add(\"Cookie\")\n\n        # If the session is modified to be empty, remove the cookie.\n        # If the session is empty, return without setting the cookie.\n        if not session:\n            if session.modified:\n                response.delete_cookie(\n                    name,\n                    domain=domain,\n                    path=path,\n                    secure=secure,\n                    samesite=samesite,\n                    httponly=httponly,\n                )\n                response.vary.add(\"Cookie\")\n\n            return\n\n        if not self.should_set_cookie(app, session):\n            return\n\n        expires = self.get_expiration_time(app, session)\n        val = self.get_signing_serializer(app).dumps(dict(session))  # type: ignore\n        response.set_cookie(\n            name,\n            val,\n            expires=expires,\n            httponly=httponly,\n            domain=domain,\n            path=path,\n            secure=secure,\n            samesite=samesite,\n        )\n        response.vary.add(\"Cookie\")\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "670295841d33",
      "repo": "flask",
      "commit_hash": "1af8f95",
      "commit_message": "fix super call in list comprehension",
      "file_path": "src/flask/cli.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport ast\nimport collections.abc as cabc\nimport importlib.metadata\nimport inspect\nimport os\nimport platform\nimport re\nimport sys\nimport traceback\nimport typing as t\nfrom functools import update_wrapper\nfrom operator import itemgetter\nfrom types import ModuleType\n\nimport click\nfrom click.core import ParameterSource\nfrom werkzeug import run_simple\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.utils import import_string\n\nfrom .globals import current_app\nfrom .helpers import get_debug_flag\nfrom .helpers import get_load_dotenv\n\nif t.TYPE_CHECKING:\n    import ssl\n\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n\n\nclass NoAppException(click.UsageError):\n    \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n\n\ndef find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )\n\n\ndef _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb\n\n\ndef find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n    \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.\n    \"\"\"\n    from . import Flask\n\n    # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) from None\n\n    if isinstance(expr, ast.Name):\n        name = expr.id\n        args = []\n        kwargs = {}\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {\n                kw.arg: ast.literal_eval(kw.value)\n                for kw in expr.keywords\n                if kw.arg is not None\n            }\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            ) from None\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        )\n\n    try:\n        attr = getattr(module, name)\n    except AttributeError as e:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) from e\n\n    # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.\n    if inspect.isfunction(attr):\n        try:\n            app = attr(*args, **kwargs)\n        except TypeError as e:\n            if not _called_with_wrong_args(attr):\n                raise\n\n            raise NoAppException(\n                f\"The factory {app_name!r} in module\"\n                f\" {module.__name__!r} could not be called with the\"\n                \" specified arguments.\"\n            ) from e\n    else:\n        app = attr\n\n    if isinstance(app, Flask):\n        return app\n\n    raise NoAppException(\n        \"A valid Flask application was not obtained from\"\n        f\" '{module.__name__}:{app_name}'.\"\n    )\n\n\ndef prepare_import(path: str) -> str:\n    \"\"\"Given a filename this will try to calculate the python path, add it\n    to the search path and return the actual module name that is expected.\n    \"\"\"\n    path = os.path.realpath(path)\n\n    fname, ext = os.path.splitext(path)\n    if ext == \".py\":\n        path = fname\n\n    if os.path.basename(path) == \"__init__\":\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, \"__init__.py\")):\n            break\n\n    if sys.path[0] != path:\n        sys.path.insert(0, path)\n\n    return \".\".join(module_name[::-1])\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[True] = True\n) -> Flask:\n    ...\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[False] = ...\n) -> Flask | None:\n    ...\n\n\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: bool = True\n) -> Flask | None:\n    try:\n        __import__(module_name)\n    except ImportError:\n        # Reraise the ImportError if it occurred within the imported module.\n        # Determine this by checking whether the trace has a depth > 1.\n        if sys.exc_info()[2].tb_next:  # type: ignore[union-attr]\n            raise NoAppException(\n                f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None\n        elif raise_if_not_found:\n            raise NoAppException(f\"Could not import {module_name!r}.\") from None\n        else:\n            return None\n\n    module = sys.modules[module_name]\n\n    if app_name is None:\n        return find_best_app(module)\n    else:\n        return find_app_by_string(module, app_name)\n\n\ndef get_version(ctx: click.Context, param: click.Parameter, value: t.Any) -> None:\n    if not value or ctx.resilient_parsing:\n        return\n\n    flask_version = importlib.metadata.version(\"flask\")\n    werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    click.echo(\n        f\"Python {platform.python_version()}\\n\"\n        f\"Flask {flask_version}\\n\"\n        f\"Werkzeug {werkzeug_version}\",\n        color=ctx.color,\n    )\n    ctx.exit()\n\n\nversion_option = click.Option(\n    [\"--version\"],\n    help=\"Show the Flask version.\",\n    expose_value=False,\n    callback=get_version,\n    is_flag=True,\n    is_eager=True,\n)\n\n\nclass ScriptInfo:\n    \"\"\"Helper object to deal with Flask applications.  This is usually not\n    necessary to interface with as it's used internally in the dispatching\n    to click.  In future versions of Flask this object will most likely play\n    a bigger role.  Typically it's created automatically by the\n    :class:`FlaskGroup` but you can also manually create it and pass it\n    onwards as click object.\n    \"\"\"\n\n    def __init__(\n        self,\n        app_import_path: str | None = None,\n        create_app: t.Callable[..., Flask] | None = None,\n        set_debug_flag: bool = True,\n    ) -> None:\n        #: Optionally the import path for the Flask application.\n        self.app_import_path = app_import_path\n        #: Optionally a function that is passed the script info to create\n        #: the instance of the application.\n        self.create_app = create_app\n        #: A dictionary with arbitrary data that can be associated with\n        #: this script info.\n        self.data: dict[t.Any, t.Any] = {}\n        self.set_debug_flag = set_debug_flag\n        self._loaded_app: Flask | None = None\n\n    def load_app(self) -> Flask:\n        \"\"\"Loads the Flask app (if not yet loaded) and returns it.  Calling\n        this multiple times will just result in the already loaded app to\n        be returned.\n        \"\"\"\n        if self._loaded_app is not None:\n            return self._loaded_app\n\n        if self.create_app is not None:\n            app: Flask | None = self.create_app()\n        else:\n            if self.app_import_path:\n                path, name = (\n                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                )[:2]\n                import_name = prepare_import(path)\n                app = locate_app(import_name, name)\n            else:\n                for path in (\"wsgi.py\", \"app.py\"):\n                    import_name = prepare_import(path)\n                    app = locate_app(import_name, None, raise_if_not_found=False)\n\n                    if app is not None:\n                        break\n\n        if app is None:\n            raise NoAppException(\n                \"Could not locate a Flask application. Use the\"\n                \" 'flask --app' option, 'FLASK_APP' environment\"\n                \" variable, or a 'wsgi.py' or 'app.py' file in the\"\n                \" current directory.\"\n            )\n\n        if self.set_debug_flag:\n            # Update the app's debug flag through the descriptor so that\n            # other values repopulate as well.\n            app.debug = get_debug_flag()\n\n        self._loaded_app = app\n        return app\n\n\npass_script_info = click.make_pass_decorator(ScriptInfo, ensure=True)\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef with_appcontext(f: F) -> F:\n    \"\"\"Wraps a callback so that it's guaranteed to be executed with the\n    script's application context.\n\n    Custom commands (and their options) registered under ``app.cli`` or\n    ``blueprint.cli`` will always have an app context available, this\n    decorator is not required in that case.\n\n    .. versionchanged:: 2.2\n        The app context is active for subcommands as well as the\n        decorated callback. The app context is always available to\n        ``app.cli`` command and parameter callbacks.\n    \"\"\"\n\n    @click.pass_context\n    def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not current_app:\n            app = ctx.ensure_object(ScriptInfo).load_app()\n            ctx.with_resource(app.app_context())\n\n        return ctx.invoke(f, *args, **kwargs)\n\n    return update_wrapper(decorator, f)  # type: ignore[return-value]\n\n\nclass AppGroup(click.Group):\n    \"\"\"This works similar to a regular click :class:`~click.Group` but it\n    changes the behavior of the :meth:`command` decorator so that it\n    automatically wraps the functions in :func:`with_appcontext`.\n\n    Not to be confused with :class:`FlaskGroup`.\n    \"\"\"\n\n    def command(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Command]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\n        unless it's disabled by passing ``with_appcontext=False``.\n        \"\"\"\n        wrap_for_ctx = kwargs.pop(\"with_appcontext\", True)\n\n        def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n            if wrap_for_ctx:\n                f = with_appcontext(f)\n            return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n\n        return decorator\n\n    def group(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Group]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it defaults the group class to\n        :class:`AppGroup`.\n        \"\"\"\n        kwargs.setdefault(\"cls\", AppGroup)\n        return super().group(*args, **kwargs)  # type: ignore[no-any-return]\n\n\ndef _set_app(ctx: click.Context, param: click.Option, value: str | None) -> str | None:\n    if value is None:\n        return None\n\n    info = ctx.ensure_object(ScriptInfo)\n    info.app_import_path = value\n    return value\n\n\n# This option is eager so the app will be available if --help is given.\n# --help is also eager, so --app must be before it in the param list.\n# no_args_is_help bypasses eager processing, so this option must be\n# processed manually in that case to ensure FLASK_APP gets picked up.\n_app_option = click.Option(\n    [\"-A\", \"--app\"],\n    metavar=\"IMPORT\",\n    help=(\n        \"The Flask application or factory function to load, in the form 'module:name'.\"\n        \" Module can be a dotted import or file path. Name is not required if it is\"\n        \" 'app', 'application', 'create_app', or 'make_app', and can be 'name(args)' to\"\n        \" pass arguments.\"\n    ),\n    is_eager=True,\n    expose_value=False,\n    callback=_set_app,\n)\n\n\ndef _set_debug(ctx: click.Context, param: click.Option, value: bool) -> bool | None:\n    # If the flag isn't provided, it will default to False. Don't use\n    # that, let debug be set by env in that case.\n    source = ctx.get_parameter_source(param.name)  # type: ignore[arg-type]\n\n    if source is not None and source in (\n        ParameterSource.DEFAULT,\n        ParameterSource.DEFAULT_MAP,\n    ):\n        return None\n\n    # Set with env var instead of ScriptInfo.load so that it can be\n    # accessed early during a factory function.\n    os.environ[\"FLASK_DEBUG\"] = \"1\" if value else \"0\"\n    return value\n\n\n_debug_option = click.Option(\n    [\"--debug/--no-debug\"],\n    help=\"Set debug mode.\",\n    expose_value=False,\n    callback=_set_debug,\n)\n\n\ndef _env_file_callback(\n    ctx: click.Context, param: click.Option, value: str | None\n) -> str | None:\n    if value is None:\n        return None\n\n    import importlib\n\n    try:\n        importlib.import_module(\"dotenv\")\n    except ImportError:\n        raise click.BadParameter(\n            \"python-dotenv must be installed to load an env file.\",\n            ctx=ctx,\n            param=param,\n        ) from None\n\n    # Don't check FLASK_SKIP_DOTENV, that only disables automatically\n    # loading .env and .flaskenv files.\n    load_dotenv(value)\n    return value\n\n\n# This option is eager so env vars are loaded as early as possible to be\n# used by other options.\n_env_file_option = click.Option(\n    [\"-e\", \"--env-file\"],\n    type=click.Path(exists=True, dir_okay=False),\n    help=\"Load environment variables from this file. python-dotenv must be installed.\",\n    is_eager=True,\n    expose_value=False,\n    callback=_env_file_callback,\n)\n\n\nclass FlaskGroup(AppGroup):\n    \"\"\"Special subclass of the :class:`AppGroup` group that supports\n    loading more commands from the configured Flask app.  Normally a\n    developer does not have to interface with this class but there are\n    some very advanced use cases for which it makes sense to create an\n    instance of this. see :ref:`custom-scripts`.\n\n    :param add_default_commands: if this is True then the default run and\n        shell commands will be added.\n    :param add_version_option: adds the ``--version`` option.\n    :param create_app: an optional callback that is passed the script info and\n        returns the loaded app.\n    :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n        files to set environment variables. Will also change the working\n        directory to the directory containing the first file found.\n    :param set_debug_flag: Set the app's debug flag.\n\n    .. versionchanged:: 2.2\n        Added the ``-A/--app``, ``--debug/--no-debug``, ``-e/--env-file`` options.\n\n    .. versionchanged:: 2.2\n        An app context is pushed when running ``app.cli`` commands, so\n        ``@with_appcontext`` is no longer required for those commands.\n\n    .. versionchanged:: 1.0\n        If installed, python-dotenv will be used to load environment variables\n        from :file:`.env` and :file:`.flaskenv` files.\n    \"\"\"\n\n    def __init__(\n        self,\n        add_default_commands: bool = True,\n        create_app: t.Callable[..., Flask] | None = None,\n        add_version_option: bool = True,\n        load_dotenv: bool = True,\n        set_debug_flag: bool = True,\n        **extra: t.Any,\n    ) -> None:\n        params = list(extra.pop(\"params\", None) or ())\n        # Processing is done with option callbacks instead of a group\n        # callback. This allows users to make a custom group callback\n        # without losing the behavior. --env-file must come first so\n        # that it is eagerly evaluated before --app.\n        params.extend((_env_file_option, _app_option, _debug_option))\n\n        if add_version_option:\n            params.append(version_option)\n\n        if \"context_settings\" not in extra:\n            extra[\"context_settings\"] = {}\n\n        extra[\"context_settings\"].setdefault(\"auto_envvar_prefix\", \"FLASK\")\n\n        super().__init__(params=params, **extra)\n\n        self.create_app = create_app\n        self.load_dotenv = load_dotenv\n        self.set_debug_flag = set_debug_flag\n\n        if add_default_commands:\n            self.add_command(run_command)\n            self.add_command(shell_command)\n            self.add_command(routes_command)\n\n        self._loaded_plugin_commands = False\n\n    def _load_plugin_commands(self) -> None:\n        if self._loaded_plugin_commands:\n            return\n\n        if sys.version_info >= (3, 10):\n            from importlib import metadata\n        else:\n            # Use a backport on Python < 3.10. We technically have\n            # importlib.metadata on 3.8+, but the API changed in 3.10,\n            # so use the backport for consistency.\n            import importlib_metadata as metadata\n\n        for ep in metadata.entry_points(group=\"flask.commands\"):\n            self.add_command(ep.load(), ep.name)\n\n        self._loaded_plugin_commands = True\n\n    def get_command(self, ctx: click.Context, name: str) -> click.Command | None:\n        self._load_plugin_commands()\n        # Look up built-in and plugin commands, which should be\n        # available even if the app fails to load.\n        rv = super().get_command(ctx, name)\n\n        if rv is not None:\n            return rv\n\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Look up commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            app = info.load_app()\n        except NoAppException as e:\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n            return None\n\n        # Push an app context for the loaded app unless it is already\n        # active somehow. This makes the context available to parameter\n        # and command callbacks without needing @with_appcontext.\n        if not current_app or current_app._get_current_object() is not app:  # type: ignore[attr-defined]\n            ctx.with_resource(app.app_context())\n\n        return app.cli.get_command(ctx, name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        self._load_plugin_commands()\n        # Start with the built-in and plugin commands.\n        rv = set(super().list_commands(ctx))\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Add commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            rv.update(info.load_app().cli.list_commands(ctx))\n        except NoAppException as e:\n            # When an app couldn't be loaded, show the error message\n            # without the traceback.\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n        except Exception:\n            # When any other errors occurred during loading, show the\n            # full traceback.\n            click.secho(f\"{traceback.format_exc()}\\n\", err=True, fg=\"red\")\n\n        return sorted(rv)\n\n    def make_context(\n        self,\n        info_name: str | None,\n        args: list[str],\n        parent: click.Context | None = None,\n        **extra: t.Any,\n    ) -> click.Context:\n        # Set a flag to tell app.run to become a no-op. If app.run was\n        # not in a __name__ == __main__ guard, it would start the server\n        # when importing, blocking whatever command is being called.\n        os.environ[\"FLASK_RUN_FROM_CLI\"] = \"true\"\n\n        # Attempt to load .env and .flask env files. The --env-file\n        # option can cause another file to be loaded.\n        if get_load_dotenv(self.load_dotenv):\n            load_dotenv()\n\n        if \"obj\" not in extra and \"obj\" not in self.context_settings:\n            extra[\"obj\"] = ScriptInfo(\n                create_app=self.create_app, set_debug_flag=self.set_debug_flag\n            )\n\n        return super().make_context(info_name, args, parent=parent, **extra)\n\n    def parse_args(self, ctx: click.Context, args: list[str]) -> list[str]:\n        if not args and self.no_args_is_help:\n            # Attempt to load --env-file and --app early in case they\n            # were given as env vars. Otherwise no_args_is_help will not\n            # see commands from app.cli.\n            _env_file_option.handle_parse_result(ctx, {}, [])\n            _app_option.handle_parse_result(ctx, {}, [])\n\n        return super().parse_args(ctx, args)\n\n\ndef _path_is_ancestor(path: str, other: str) -> bool:\n    \"\"\"Take ``other`` and remove the length of ``path`` from it. Then join it\n    to ``path``. If it is the original value, ``path`` is an ancestor of\n    ``other``.\"\"\"\n    return os.path.join(path, other[len(path) :].lstrip(os.sep)) == other\n\n\ndef load_dotenv(path: str | os.PathLike[str] | None = None) -> bool:\n    \"\"\"Load \"dotenv\" files in order of precedence to set environment variables.\n\n    If an env var is already set it is not overwritten, so earlier files in the\n    list are preferred over later files.\n\n    This is a no-op if `python-dotenv`_ is not installed.\n\n    .. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n    :param path: Load the file at this location instead of searching.\n    :return: ``True`` if a file was loaded.\n\n    .. versionchanged:: 2.0\n        The current directory is not changed to the location of the\n        loaded file.\n\n    .. versionchanged:: 2.0\n        When loading the env files, set the default encoding to UTF-8.\n\n    .. versionchanged:: 1.1.0\n        Returns ``False`` when python-dotenv is not installed, or when\n        the given path isn't a file.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    try:\n        import dotenv\n    except ImportError:\n        if path or os.path.isfile(\".env\") or os.path.isfile(\".flaskenv\"):\n            click.secho(\n                \" * Tip: There are .env or .flaskenv files present.\"\n                ' Do \"pip install python-dotenv\" to use them.',\n                fg=\"yellow\",\n                err=True,\n            )\n\n        return False\n\n    # Always return after attempting to load a given path, don't load\n    # the default files.\n    if path is not None:\n        if os.path.isfile(path):\n            return dotenv.load_dotenv(path, encoding=\"utf-8\")\n\n        return False\n\n    loaded = False\n\n    for name in (\".env\", \".flaskenv\"):\n        path = dotenv.find_dotenv(name, usecwd=True)\n\n        if not path:\n            continue\n\n        dotenv.load_dotenv(path, encoding=\"utf-8\")\n        loaded = True\n\n    return loaded  # True if at least one file was located and loaded.\n\n\ndef show_server_banner(debug: bool, app_import_path: str | None) -> None:\n    \"\"\"Show extra startup messages the first time the server is run,\n    ignoring the reloader.\n    \"\"\"\n    if is_running_from_reloader():\n        return\n\n    if app_import_path is not None:\n        click.echo(f\" * Serving Flask app '{app_import_path}'\")\n\n    if debug is not None:\n        click.echo(f\" * Debug mode: {'on' if debug else 'off'}\")\n\n\nclass CertParamType(click.ParamType):\n    \"\"\"Click option type for the ``--cert`` option. Allows either an\n    existing file, the string ``'adhoc'``, or an import for a\n    :class:`~ssl.SSLContext` object.\n    \"\"\"\n\n    name = \"path\"\n\n    def __init__(self) -> None:\n        self.path_type = click.Path(exists=True, dir_okay=False, resolve_path=True)\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        try:\n            import ssl\n        except ImportError:\n            raise click.BadParameter(\n                'Using \"--cert\" requires Python to be compiled with SSL support.',\n                ctx,\n                param,\n            ) from None\n\n        try:\n            return self.path_type(value, param, ctx)\n        except click.BadParameter:\n            value = click.STRING(value, param, ctx).lower()\n\n            if value == \"adhoc\":\n                try:\n                    import cryptography  # noqa: F401\n                except ImportError:\n                    raise click.BadParameter(\n                        \"Using ad-hoc certificates requires the cryptography library.\",\n                        ctx,\n                        param,\n                    ) from None\n\n                return value\n\n            obj = import_string(value, silent=True)\n\n            if isinstance(obj, ssl.SSLContext):\n                return obj\n\n            raise\n\n\ndef _validate_key(ctx: click.Context, param: click.Parameter, value: t.Any) -> t.Any:\n    \"\"\"The ``--key`` option must be specified when ``--cert`` is a file.\n    Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.\n    \"\"\"\n    cert = ctx.params.get(\"cert\")\n    is_adhoc = cert == \"adhoc\"\n\n    try:\n        import ssl\n    except ImportError:\n        is_context = False\n    else:\n        is_context = isinstance(cert, ssl.SSLContext)\n\n    if value is not None:\n        if is_adhoc:\n            raise click.BadParameter(\n                'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n            )\n\n        if is_context:\n            raise click.BadParameter(\n                'When \"--cert\" is an SSLContext object, \"--key\" is not used.',\n                ctx,\n                param,\n            )\n\n        if not cert:\n            raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        ctx.params[\"cert\"] = cert, value\n\n    else:\n        if cert and not (is_adhoc or is_context):\n            raise click.BadParameter('Required when using \"--cert\".', ctx, param)\n\n    return value\n\n\nclass SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        items = self.split_envvar_value(value)\n        return [super().convert(item, param, ctx) for item in items]\n\n\n@click.command(\"run\", short_help=\"Run a development server.\")\n@click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n@click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n@click.option(\n    \"--cert\",\n    type=CertParamType(),\n    help=\"Specify a certificate file to use HTTPS.\",\n    is_eager=True,\n)\n@click.option(\n    \"--key\",\n    type=click.Path(exists=True, dir_okay=False, resolve_path=True),\n    callback=_validate_key,\n    expose_value=False,\n    help=\"The key file to use when specifying a certificate.\",\n)\n@click.option(\n    \"--reload/--no-reload\",\n    default=None,\n    help=\"Enable or disable the reloader. By default the reloader \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--debugger/--no-debugger\",\n    default=None,\n    help=\"Enable or disable the debugger. By default the debugger \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--with-threads/--without-threads\",\n    default=True,\n    help=\"Enable or disable multithreading.\",\n)\n@click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        f\" are separated by {os.path.pathsep!r}.\"\n    ),\n)\n@click.option(\n    \"--exclude-patterns\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Files matching these fnmatch patterns will not trigger a reload\"\n        \" on change. Multiple patterns are separated by\"\n        f\" {os.path.pathsep!r}.\"\n    ),\n)\n@pass_script_info\ndef run_command(\n    info: ScriptInfo,\n    host: str,\n    port: int,\n    reload: bool,\n    debugger: bool,\n    with_threads: bool,\n    cert: ssl.SSLContext | tuple[str, str | None] | t.Literal[\"adhoc\"] | None,\n    extra_files: list[str] | None,\n    exclude_patterns: list[str] | None,\n) -> None:\n    \"\"\"Run a local development server.\n\n    This server is for development purposes only. It does not provide\n    the stability, security, or performance of production WSGI servers.\n\n    The reloader and debugger are enabled by default with the '--debug'\n    option.\n    \"\"\"\n    try:\n        app: WSGIApplication = info.load_app()\n    except Exception as e:\n        if is_running_from_reloader():\n            # When reloading, print out the error immediately, but raise\n            # it later so the debugger or server can handle it.\n            traceback.print_exc()\n            err = e\n\n            def app(\n                environ: WSGIEnvironment, start_response: StartResponse\n            ) -> cabc.Iterable[bytes]:\n                raise err from None\n\n        else:\n            # When not reloading, raise the error immediately so the\n            # command fails.\n            raise e from None\n\n    debug = get_debug_flag()\n\n    if reload is None:\n        reload = debug\n\n    if debugger is None:\n        debugger = debug\n\n    show_server_banner(debug, info.app_import_path)\n\n    run_simple(\n        host,\n        port,\n        app,\n        use_reloader=reload,\n        use_debugger=debugger,\n        threaded=with_threads,\n        ssl_context=cert,\n        extra_files=extra_files,\n        exclude_patterns=exclude_patterns,\n    )\n\n\nrun_command.params.insert(0, _debug_option)\n\n\n@click.command(\"shell\", short_help=\"Run a shell in the app context.\")\n@with_appcontext\ndef shell_command() -> None:\n    \"\"\"Run an interactive Python shell in the context of a given\n    Flask application.  The application will populate the default\n    namespace of this shell according to its configuration.\n\n    This is useful for executing small snippets of management code\n    without having to manually configure the application.\n    \"\"\"\n    import code\n\n    banner = (\n        f\"Python {sys.version} on {sys.platform}\\n\"\n        f\"App: {current_app.import_name}\\n\"\n        f\"Instance: {current_app.instance_path}\"\n    )\n    ctx: dict[str, t.Any] = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get(\"PYTHONSTARTUP\")\n    if startup and os.path.isfile(startup):\n        with open(startup) as f:\n            eval(compile(f.read(), startup, \"exec\"), ctx)\n\n    ctx.update(current_app.make_shell_context())\n\n    # Site, customize, or startup script can set a hook to call when\n    # entering interactive mode. The default one sets up readline with\n    # tab and history completion.\n    interactive_hook = getattr(sys, \"__interactivehook__\", None)\n\n    if interactive_hook is not None:\n        try:\n            import readline\n            from rlcompleter import Completer\n        except ImportError:\n            pass\n        else:\n            # rlcompleter uses __main__.__dict__ by default, which is\n            # flask.__main__. Use the shell context instead.\n            readline.set_completer(Completer(ctx).complete)\n\n        interactive_hook()\n\n    code.interact(banner=banner, local=ctx)\n\n\n@click.command(\"routes\", short_help=\"Show the routes for the app.\")\n@click.option(\n    \"--sort\",\n    \"-s\",\n    type=click.Choice((\"endpoint\", \"methods\", \"domain\", \"rule\", \"match\")),\n    default=\"endpoint\",\n    help=(\n        \"Method to sort routes by. 'match' is the order that Flask will match routes\"\n        \" when dispatching a request.\"\n    ),\n)\n@click.option(\"--all-methods\", is_flag=True, help=\"Show HEAD and OPTIONS methods.\")\n@with_appcontext\ndef routes_command(sort: str, all_methods: bool) -> None:\n    \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n    rules = list(current_app.url_map.iter_rules())\n\n    if not rules:\n        click.echo(\"No routes were registered.\")\n        return\n\n    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n    host_matching = current_app.url_map.host_matching\n    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n    rows = []\n\n    for rule in rules:\n        row = [\n            rule.endpoint,\n            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n        ]\n\n        if has_domain:\n            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n\n        row.append(rule.rule)\n        rows.append(row)\n\n    headers = [\"Endpoint\", \"Methods\"]\n    sorts = [\"endpoint\", \"methods\"]\n\n    if has_domain:\n        headers.append(\"Host\" if host_matching else \"Subdomain\")\n        sorts.append(\"domain\")\n\n    headers.append(\"Rule\")\n    sorts.append(\"rule\")\n\n    try:\n        rows.sort(key=itemgetter(sorts.index(sort)))\n    except ValueError:\n        pass\n\n    rows.insert(0, headers)\n    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n    rows.insert(1, [\"-\" * w for w in widths])\n    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n\n    for row in rows:\n        click.echo(template.format(*row))\n\n\ncli = FlaskGroup(\n    name=\"flask\",\n    help=\"\"\"\\\nA general utility script for Flask applications.\n\nAn application to load must be given with the '--app' option,\n'FLASK_APP' environment variable, or with a 'wsgi.py' or 'app.py' file\nin the current directory.\n\"\"\",\n)\n\n\ndef main() -> None:\n    cli.main()\n\n\nif __name__ == \"__main__\":\n    main()\n",
      "code_after": "from __future__ import annotations\n\nimport ast\nimport collections.abc as cabc\nimport importlib.metadata\nimport inspect\nimport os\nimport platform\nimport re\nimport sys\nimport traceback\nimport typing as t\nfrom functools import update_wrapper\nfrom operator import itemgetter\nfrom types import ModuleType\n\nimport click\nfrom click.core import ParameterSource\nfrom werkzeug import run_simple\nfrom werkzeug.serving import is_running_from_reloader\nfrom werkzeug.utils import import_string\n\nfrom .globals import current_app\nfrom .helpers import get_debug_flag\nfrom .helpers import get_load_dotenv\n\nif t.TYPE_CHECKING:\n    import ssl\n\n    from _typeshed.wsgi import StartResponse\n    from _typeshed.wsgi import WSGIApplication\n    from _typeshed.wsgi import WSGIEnvironment\n\n    from .app import Flask\n\n\nclass NoAppException(click.UsageError):\n    \"\"\"Raised if an application cannot be found or loaded.\"\"\"\n\n\ndef find_best_app(module: ModuleType) -> Flask:\n    \"\"\"Given a module instance this tries to find the best possible\n    application in the module or raises an exception.\n    \"\"\"\n    from . import Flask\n\n    # Search for the most common names first.\n    for attr_name in (\"app\", \"application\"):\n        app = getattr(module, attr_name, None)\n\n        if isinstance(app, Flask):\n            return app\n\n    # Otherwise find the only object that is a Flask instance.\n    matches = [v for v in module.__dict__.values() if isinstance(v, Flask)]\n\n    if len(matches) == 1:\n        return matches[0]\n    elif len(matches) > 1:\n        raise NoAppException(\n            \"Detected multiple Flask applications in module\"\n            f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n            \" to specify the correct one.\"\n        )\n\n    # Search for app factory functions.\n    for attr_name in (\"create_app\", \"make_app\"):\n        app_factory = getattr(module, attr_name, None)\n\n        if inspect.isfunction(app_factory):\n            try:\n                app = app_factory()\n\n                if isinstance(app, Flask):\n                    return app\n            except TypeError as e:\n                if not _called_with_wrong_args(app_factory):\n                    raise\n\n                raise NoAppException(\n                    f\"Detected factory '{attr_name}' in module '{module.__name__}',\"\n                    \" but could not call it without arguments. Use\"\n                    f\" '{module.__name__}:{attr_name}(args)'\"\n                    \" to specify arguments.\"\n                ) from e\n\n    raise NoAppException(\n        \"Failed to find Flask application or factory in module\"\n        f\" '{module.__name__}'. Use '{module.__name__}:name'\"\n        \" to specify one.\"\n    )\n\n\ndef _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n    \"\"\"Check whether calling a function raised a ``TypeError`` because\n    the call failed or because something in the factory raised the\n    error.\n\n    :param f: The function that was called.\n    :return: ``True`` if the call failed.\n    \"\"\"\n    tb = sys.exc_info()[2]\n\n    try:\n        while tb is not None:\n            if tb.tb_frame.f_code is f.__code__:\n                # In the function, it was called successfully.\n                return False\n\n            tb = tb.tb_next\n\n        # Didn't reach the function.\n        return True\n    finally:\n        # Delete tb to break a circular reference.\n        # https://docs.python.org/2/library/sys.html#sys.exc_info\n        del tb\n\n\ndef find_app_by_string(module: ModuleType, app_name: str) -> Flask:\n    \"\"\"Check if the given string is a variable name or a function. Call\n    a function to get the app instance, or return the variable directly.\n    \"\"\"\n    from . import Flask\n\n    # Parse app_name as a single expression to determine if it's a valid\n    # attribute name or function call.\n    try:\n        expr = ast.parse(app_name.strip(), mode=\"eval\").body\n    except SyntaxError:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        ) from None\n\n    if isinstance(expr, ast.Name):\n        name = expr.id\n        args = []\n        kwargs = {}\n    elif isinstance(expr, ast.Call):\n        # Ensure the function name is an attribute name only.\n        if not isinstance(expr.func, ast.Name):\n            raise NoAppException(\n                f\"Function reference must be a simple name: {app_name!r}.\"\n            )\n\n        name = expr.func.id\n\n        # Parse the positional and keyword arguments as literals.\n        try:\n            args = [ast.literal_eval(arg) for arg in expr.args]\n            kwargs = {\n                kw.arg: ast.literal_eval(kw.value)\n                for kw in expr.keywords\n                if kw.arg is not None\n            }\n        except ValueError:\n            # literal_eval gives cryptic error messages, show a generic\n            # message with the full expression instead.\n            raise NoAppException(\n                f\"Failed to parse arguments as literal values: {app_name!r}.\"\n            ) from None\n    else:\n        raise NoAppException(\n            f\"Failed to parse {app_name!r} as an attribute name or function call.\"\n        )\n\n    try:\n        attr = getattr(module, name)\n    except AttributeError as e:\n        raise NoAppException(\n            f\"Failed to find attribute {name!r} in {module.__name__!r}.\"\n        ) from e\n\n    # If the attribute is a function, call it with any args and kwargs\n    # to get the real application.\n    if inspect.isfunction(attr):\n        try:\n            app = attr(*args, **kwargs)\n        except TypeError as e:\n            if not _called_with_wrong_args(attr):\n                raise\n\n            raise NoAppException(\n                f\"The factory {app_name!r} in module\"\n                f\" {module.__name__!r} could not be called with the\"\n                \" specified arguments.\"\n            ) from e\n    else:\n        app = attr\n\n    if isinstance(app, Flask):\n        return app\n\n    raise NoAppException(\n        \"A valid Flask application was not obtained from\"\n        f\" '{module.__name__}:{app_name}'.\"\n    )\n\n\ndef prepare_import(path: str) -> str:\n    \"\"\"Given a filename this will try to calculate the python path, add it\n    to the search path and return the actual module name that is expected.\n    \"\"\"\n    path = os.path.realpath(path)\n\n    fname, ext = os.path.splitext(path)\n    if ext == \".py\":\n        path = fname\n\n    if os.path.basename(path) == \"__init__\":\n        path = os.path.dirname(path)\n\n    module_name = []\n\n    # move up until outside package structure (no __init__.py)\n    while True:\n        path, name = os.path.split(path)\n        module_name.append(name)\n\n        if not os.path.exists(os.path.join(path, \"__init__.py\")):\n            break\n\n    if sys.path[0] != path:\n        sys.path.insert(0, path)\n\n    return \".\".join(module_name[::-1])\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[True] = True\n) -> Flask:\n    ...\n\n\n@t.overload\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: t.Literal[False] = ...\n) -> Flask | None:\n    ...\n\n\ndef locate_app(\n    module_name: str, app_name: str | None, raise_if_not_found: bool = True\n) -> Flask | None:\n    try:\n        __import__(module_name)\n    except ImportError:\n        # Reraise the ImportError if it occurred within the imported module.\n        # Determine this by checking whether the trace has a depth > 1.\n        if sys.exc_info()[2].tb_next:  # type: ignore[union-attr]\n            raise NoAppException(\n                f\"While importing {module_name!r}, an ImportError was\"\n                f\" raised:\\n\\n{traceback.format_exc()}\"\n            ) from None\n        elif raise_if_not_found:\n            raise NoAppException(f\"Could not import {module_name!r}.\") from None\n        else:\n            return None\n\n    module = sys.modules[module_name]\n\n    if app_name is None:\n        return find_best_app(module)\n    else:\n        return find_app_by_string(module, app_name)\n\n\ndef get_version(ctx: click.Context, param: click.Parameter, value: t.Any) -> None:\n    if not value or ctx.resilient_parsing:\n        return\n\n    flask_version = importlib.metadata.version(\"flask\")\n    werkzeug_version = importlib.metadata.version(\"werkzeug\")\n\n    click.echo(\n        f\"Python {platform.python_version()}\\n\"\n        f\"Flask {flask_version}\\n\"\n        f\"Werkzeug {werkzeug_version}\",\n        color=ctx.color,\n    )\n    ctx.exit()\n\n\nversion_option = click.Option(\n    [\"--version\"],\n    help=\"Show the Flask version.\",\n    expose_value=False,\n    callback=get_version,\n    is_flag=True,\n    is_eager=True,\n)\n\n\nclass ScriptInfo:\n    \"\"\"Helper object to deal with Flask applications.  This is usually not\n    necessary to interface with as it's used internally in the dispatching\n    to click.  In future versions of Flask this object will most likely play\n    a bigger role.  Typically it's created automatically by the\n    :class:`FlaskGroup` but you can also manually create it and pass it\n    onwards as click object.\n    \"\"\"\n\n    def __init__(\n        self,\n        app_import_path: str | None = None,\n        create_app: t.Callable[..., Flask] | None = None,\n        set_debug_flag: bool = True,\n    ) -> None:\n        #: Optionally the import path for the Flask application.\n        self.app_import_path = app_import_path\n        #: Optionally a function that is passed the script info to create\n        #: the instance of the application.\n        self.create_app = create_app\n        #: A dictionary with arbitrary data that can be associated with\n        #: this script info.\n        self.data: dict[t.Any, t.Any] = {}\n        self.set_debug_flag = set_debug_flag\n        self._loaded_app: Flask | None = None\n\n    def load_app(self) -> Flask:\n        \"\"\"Loads the Flask app (if not yet loaded) and returns it.  Calling\n        this multiple times will just result in the already loaded app to\n        be returned.\n        \"\"\"\n        if self._loaded_app is not None:\n            return self._loaded_app\n\n        if self.create_app is not None:\n            app: Flask | None = self.create_app()\n        else:\n            if self.app_import_path:\n                path, name = (\n                    re.split(r\":(?![\\\\/])\", self.app_import_path, maxsplit=1) + [None]\n                )[:2]\n                import_name = prepare_import(path)\n                app = locate_app(import_name, name)\n            else:\n                for path in (\"wsgi.py\", \"app.py\"):\n                    import_name = prepare_import(path)\n                    app = locate_app(import_name, None, raise_if_not_found=False)\n\n                    if app is not None:\n                        break\n\n        if app is None:\n            raise NoAppException(\n                \"Could not locate a Flask application. Use the\"\n                \" 'flask --app' option, 'FLASK_APP' environment\"\n                \" variable, or a 'wsgi.py' or 'app.py' file in the\"\n                \" current directory.\"\n            )\n\n        if self.set_debug_flag:\n            # Update the app's debug flag through the descriptor so that\n            # other values repopulate as well.\n            app.debug = get_debug_flag()\n\n        self._loaded_app = app\n        return app\n\n\npass_script_info = click.make_pass_decorator(ScriptInfo, ensure=True)\n\nF = t.TypeVar(\"F\", bound=t.Callable[..., t.Any])\n\n\ndef with_appcontext(f: F) -> F:\n    \"\"\"Wraps a callback so that it's guaranteed to be executed with the\n    script's application context.\n\n    Custom commands (and their options) registered under ``app.cli`` or\n    ``blueprint.cli`` will always have an app context available, this\n    decorator is not required in that case.\n\n    .. versionchanged:: 2.2\n        The app context is active for subcommands as well as the\n        decorated callback. The app context is always available to\n        ``app.cli`` command and parameter callbacks.\n    \"\"\"\n\n    @click.pass_context\n    def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n        if not current_app:\n            app = ctx.ensure_object(ScriptInfo).load_app()\n            ctx.with_resource(app.app_context())\n\n        return ctx.invoke(f, *args, **kwargs)\n\n    return update_wrapper(decorator, f)  # type: ignore[return-value]\n\n\nclass AppGroup(click.Group):\n    \"\"\"This works similar to a regular click :class:`~click.Group` but it\n    changes the behavior of the :meth:`command` decorator so that it\n    automatically wraps the functions in :func:`with_appcontext`.\n\n    Not to be confused with :class:`FlaskGroup`.\n    \"\"\"\n\n    def command(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Command]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it wraps callbacks in :func:`with_appcontext`\n        unless it's disabled by passing ``with_appcontext=False``.\n        \"\"\"\n        wrap_for_ctx = kwargs.pop(\"with_appcontext\", True)\n\n        def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n            if wrap_for_ctx:\n                f = with_appcontext(f)\n            return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n\n        return decorator\n\n    def group(  # type: ignore[override]\n        self, *args: t.Any, **kwargs: t.Any\n    ) -> t.Callable[[t.Callable[..., t.Any]], click.Group]:\n        \"\"\"This works exactly like the method of the same name on a regular\n        :class:`click.Group` but it defaults the group class to\n        :class:`AppGroup`.\n        \"\"\"\n        kwargs.setdefault(\"cls\", AppGroup)\n        return super().group(*args, **kwargs)  # type: ignore[no-any-return]\n\n\ndef _set_app(ctx: click.Context, param: click.Option, value: str | None) -> str | None:\n    if value is None:\n        return None\n\n    info = ctx.ensure_object(ScriptInfo)\n    info.app_import_path = value\n    return value\n\n\n# This option is eager so the app will be available if --help is given.\n# --help is also eager, so --app must be before it in the param list.\n# no_args_is_help bypasses eager processing, so this option must be\n# processed manually in that case to ensure FLASK_APP gets picked up.\n_app_option = click.Option(\n    [\"-A\", \"--app\"],\n    metavar=\"IMPORT\",\n    help=(\n        \"The Flask application or factory function to load, in the form 'module:name'.\"\n        \" Module can be a dotted import or file path. Name is not required if it is\"\n        \" 'app', 'application', 'create_app', or 'make_app', and can be 'name(args)' to\"\n        \" pass arguments.\"\n    ),\n    is_eager=True,\n    expose_value=False,\n    callback=_set_app,\n)\n\n\ndef _set_debug(ctx: click.Context, param: click.Option, value: bool) -> bool | None:\n    # If the flag isn't provided, it will default to False. Don't use\n    # that, let debug be set by env in that case.\n    source = ctx.get_parameter_source(param.name)  # type: ignore[arg-type]\n\n    if source is not None and source in (\n        ParameterSource.DEFAULT,\n        ParameterSource.DEFAULT_MAP,\n    ):\n        return None\n\n    # Set with env var instead of ScriptInfo.load so that it can be\n    # accessed early during a factory function.\n    os.environ[\"FLASK_DEBUG\"] = \"1\" if value else \"0\"\n    return value\n\n\n_debug_option = click.Option(\n    [\"--debug/--no-debug\"],\n    help=\"Set debug mode.\",\n    expose_value=False,\n    callback=_set_debug,\n)\n\n\ndef _env_file_callback(\n    ctx: click.Context, param: click.Option, value: str | None\n) -> str | None:\n    if value is None:\n        return None\n\n    import importlib\n\n    try:\n        importlib.import_module(\"dotenv\")\n    except ImportError:\n        raise click.BadParameter(\n            \"python-dotenv must be installed to load an env file.\",\n            ctx=ctx,\n            param=param,\n        ) from None\n\n    # Don't check FLASK_SKIP_DOTENV, that only disables automatically\n    # loading .env and .flaskenv files.\n    load_dotenv(value)\n    return value\n\n\n# This option is eager so env vars are loaded as early as possible to be\n# used by other options.\n_env_file_option = click.Option(\n    [\"-e\", \"--env-file\"],\n    type=click.Path(exists=True, dir_okay=False),\n    help=\"Load environment variables from this file. python-dotenv must be installed.\",\n    is_eager=True,\n    expose_value=False,\n    callback=_env_file_callback,\n)\n\n\nclass FlaskGroup(AppGroup):\n    \"\"\"Special subclass of the :class:`AppGroup` group that supports\n    loading more commands from the configured Flask app.  Normally a\n    developer does not have to interface with this class but there are\n    some very advanced use cases for which it makes sense to create an\n    instance of this. see :ref:`custom-scripts`.\n\n    :param add_default_commands: if this is True then the default run and\n        shell commands will be added.\n    :param add_version_option: adds the ``--version`` option.\n    :param create_app: an optional callback that is passed the script info and\n        returns the loaded app.\n    :param load_dotenv: Load the nearest :file:`.env` and :file:`.flaskenv`\n        files to set environment variables. Will also change the working\n        directory to the directory containing the first file found.\n    :param set_debug_flag: Set the app's debug flag.\n\n    .. versionchanged:: 2.2\n        Added the ``-A/--app``, ``--debug/--no-debug``, ``-e/--env-file`` options.\n\n    .. versionchanged:: 2.2\n        An app context is pushed when running ``app.cli`` commands, so\n        ``@with_appcontext`` is no longer required for those commands.\n\n    .. versionchanged:: 1.0\n        If installed, python-dotenv will be used to load environment variables\n        from :file:`.env` and :file:`.flaskenv` files.\n    \"\"\"\n\n    def __init__(\n        self,\n        add_default_commands: bool = True,\n        create_app: t.Callable[..., Flask] | None = None,\n        add_version_option: bool = True,\n        load_dotenv: bool = True,\n        set_debug_flag: bool = True,\n        **extra: t.Any,\n    ) -> None:\n        params = list(extra.pop(\"params\", None) or ())\n        # Processing is done with option callbacks instead of a group\n        # callback. This allows users to make a custom group callback\n        # without losing the behavior. --env-file must come first so\n        # that it is eagerly evaluated before --app.\n        params.extend((_env_file_option, _app_option, _debug_option))\n\n        if add_version_option:\n            params.append(version_option)\n\n        if \"context_settings\" not in extra:\n            extra[\"context_settings\"] = {}\n\n        extra[\"context_settings\"].setdefault(\"auto_envvar_prefix\", \"FLASK\")\n\n        super().__init__(params=params, **extra)\n\n        self.create_app = create_app\n        self.load_dotenv = load_dotenv\n        self.set_debug_flag = set_debug_flag\n\n        if add_default_commands:\n            self.add_command(run_command)\n            self.add_command(shell_command)\n            self.add_command(routes_command)\n\n        self._loaded_plugin_commands = False\n\n    def _load_plugin_commands(self) -> None:\n        if self._loaded_plugin_commands:\n            return\n\n        if sys.version_info >= (3, 10):\n            from importlib import metadata\n        else:\n            # Use a backport on Python < 3.10. We technically have\n            # importlib.metadata on 3.8+, but the API changed in 3.10,\n            # so use the backport for consistency.\n            import importlib_metadata as metadata\n\n        for ep in metadata.entry_points(group=\"flask.commands\"):\n            self.add_command(ep.load(), ep.name)\n\n        self._loaded_plugin_commands = True\n\n    def get_command(self, ctx: click.Context, name: str) -> click.Command | None:\n        self._load_plugin_commands()\n        # Look up built-in and plugin commands, which should be\n        # available even if the app fails to load.\n        rv = super().get_command(ctx, name)\n\n        if rv is not None:\n            return rv\n\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Look up commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            app = info.load_app()\n        except NoAppException as e:\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n            return None\n\n        # Push an app context for the loaded app unless it is already\n        # active somehow. This makes the context available to parameter\n        # and command callbacks without needing @with_appcontext.\n        if not current_app or current_app._get_current_object() is not app:  # type: ignore[attr-defined]\n            ctx.with_resource(app.app_context())\n\n        return app.cli.get_command(ctx, name)\n\n    def list_commands(self, ctx: click.Context) -> list[str]:\n        self._load_plugin_commands()\n        # Start with the built-in and plugin commands.\n        rv = set(super().list_commands(ctx))\n        info = ctx.ensure_object(ScriptInfo)\n\n        # Add commands provided by the app, showing an error and\n        # continuing if the app couldn't be loaded.\n        try:\n            rv.update(info.load_app().cli.list_commands(ctx))\n        except NoAppException as e:\n            # When an app couldn't be loaded, show the error message\n            # without the traceback.\n            click.secho(f\"Error: {e.format_message()}\\n\", err=True, fg=\"red\")\n        except Exception:\n            # When any other errors occurred during loading, show the\n            # full traceback.\n            click.secho(f\"{traceback.format_exc()}\\n\", err=True, fg=\"red\")\n\n        return sorted(rv)\n\n    def make_context(\n        self,\n        info_name: str | None,\n        args: list[str],\n        parent: click.Context | None = None,\n        **extra: t.Any,\n    ) -> click.Context:\n        # Set a flag to tell app.run to become a no-op. If app.run was\n        # not in a __name__ == __main__ guard, it would start the server\n        # when importing, blocking whatever command is being called.\n        os.environ[\"FLASK_RUN_FROM_CLI\"] = \"true\"\n\n        # Attempt to load .env and .flask env files. The --env-file\n        # option can cause another file to be loaded.\n        if get_load_dotenv(self.load_dotenv):\n            load_dotenv()\n\n        if \"obj\" not in extra and \"obj\" not in self.context_settings:\n            extra[\"obj\"] = ScriptInfo(\n                create_app=self.create_app, set_debug_flag=self.set_debug_flag\n            )\n\n        return super().make_context(info_name, args, parent=parent, **extra)\n\n    def parse_args(self, ctx: click.Context, args: list[str]) -> list[str]:\n        if not args and self.no_args_is_help:\n            # Attempt to load --env-file and --app early in case they\n            # were given as env vars. Otherwise no_args_is_help will not\n            # see commands from app.cli.\n            _env_file_option.handle_parse_result(ctx, {}, [])\n            _app_option.handle_parse_result(ctx, {}, [])\n\n        return super().parse_args(ctx, args)\n\n\ndef _path_is_ancestor(path: str, other: str) -> bool:\n    \"\"\"Take ``other`` and remove the length of ``path`` from it. Then join it\n    to ``path``. If it is the original value, ``path`` is an ancestor of\n    ``other``.\"\"\"\n    return os.path.join(path, other[len(path) :].lstrip(os.sep)) == other\n\n\ndef load_dotenv(path: str | os.PathLike[str] | None = None) -> bool:\n    \"\"\"Load \"dotenv\" files in order of precedence to set environment variables.\n\n    If an env var is already set it is not overwritten, so earlier files in the\n    list are preferred over later files.\n\n    This is a no-op if `python-dotenv`_ is not installed.\n\n    .. _python-dotenv: https://github.com/theskumar/python-dotenv#readme\n\n    :param path: Load the file at this location instead of searching.\n    :return: ``True`` if a file was loaded.\n\n    .. versionchanged:: 2.0\n        The current directory is not changed to the location of the\n        loaded file.\n\n    .. versionchanged:: 2.0\n        When loading the env files, set the default encoding to UTF-8.\n\n    .. versionchanged:: 1.1.0\n        Returns ``False`` when python-dotenv is not installed, or when\n        the given path isn't a file.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    try:\n        import dotenv\n    except ImportError:\n        if path or os.path.isfile(\".env\") or os.path.isfile(\".flaskenv\"):\n            click.secho(\n                \" * Tip: There are .env or .flaskenv files present.\"\n                ' Do \"pip install python-dotenv\" to use them.',\n                fg=\"yellow\",\n                err=True,\n            )\n\n        return False\n\n    # Always return after attempting to load a given path, don't load\n    # the default files.\n    if path is not None:\n        if os.path.isfile(path):\n            return dotenv.load_dotenv(path, encoding=\"utf-8\")\n\n        return False\n\n    loaded = False\n\n    for name in (\".env\", \".flaskenv\"):\n        path = dotenv.find_dotenv(name, usecwd=True)\n\n        if not path:\n            continue\n\n        dotenv.load_dotenv(path, encoding=\"utf-8\")\n        loaded = True\n\n    return loaded  # True if at least one file was located and loaded.\n\n\ndef show_server_banner(debug: bool, app_import_path: str | None) -> None:\n    \"\"\"Show extra startup messages the first time the server is run,\n    ignoring the reloader.\n    \"\"\"\n    if is_running_from_reloader():\n        return\n\n    if app_import_path is not None:\n        click.echo(f\" * Serving Flask app '{app_import_path}'\")\n\n    if debug is not None:\n        click.echo(f\" * Debug mode: {'on' if debug else 'off'}\")\n\n\nclass CertParamType(click.ParamType):\n    \"\"\"Click option type for the ``--cert`` option. Allows either an\n    existing file, the string ``'adhoc'``, or an import for a\n    :class:`~ssl.SSLContext` object.\n    \"\"\"\n\n    name = \"path\"\n\n    def __init__(self) -> None:\n        self.path_type = click.Path(exists=True, dir_okay=False, resolve_path=True)\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        try:\n            import ssl\n        except ImportError:\n            raise click.BadParameter(\n                'Using \"--cert\" requires Python to be compiled with SSL support.',\n                ctx,\n                param,\n            ) from None\n\n        try:\n            return self.path_type(value, param, ctx)\n        except click.BadParameter:\n            value = click.STRING(value, param, ctx).lower()\n\n            if value == \"adhoc\":\n                try:\n                    import cryptography  # noqa: F401\n                except ImportError:\n                    raise click.BadParameter(\n                        \"Using ad-hoc certificates requires the cryptography library.\",\n                        ctx,\n                        param,\n                    ) from None\n\n                return value\n\n            obj = import_string(value, silent=True)\n\n            if isinstance(obj, ssl.SSLContext):\n                return obj\n\n            raise\n\n\ndef _validate_key(ctx: click.Context, param: click.Parameter, value: t.Any) -> t.Any:\n    \"\"\"The ``--key`` option must be specified when ``--cert`` is a file.\n    Modifies the ``cert`` param to be a ``(cert, key)`` pair if needed.\n    \"\"\"\n    cert = ctx.params.get(\"cert\")\n    is_adhoc = cert == \"adhoc\"\n\n    try:\n        import ssl\n    except ImportError:\n        is_context = False\n    else:\n        is_context = isinstance(cert, ssl.SSLContext)\n\n    if value is not None:\n        if is_adhoc:\n            raise click.BadParameter(\n                'When \"--cert\" is \"adhoc\", \"--key\" is not used.', ctx, param\n            )\n\n        if is_context:\n            raise click.BadParameter(\n                'When \"--cert\" is an SSLContext object, \"--key\" is not used.',\n                ctx,\n                param,\n            )\n\n        if not cert:\n            raise click.BadParameter('\"--cert\" must also be specified.', ctx, param)\n\n        ctx.params[\"cert\"] = cert, value\n\n    else:\n        if cert and not (is_adhoc or is_context):\n            raise click.BadParameter('Required when using \"--cert\".', ctx, param)\n\n    return value\n\n\nclass SeparatedPathType(click.Path):\n    \"\"\"Click option type that accepts a list of values separated by the\n    OS's path separator (``:``, ``;`` on Windows). Each value is\n    validated as a :class:`click.Path` type.\n    \"\"\"\n\n    def convert(\n        self, value: t.Any, param: click.Parameter | None, ctx: click.Context | None\n    ) -> t.Any:\n        items = self.split_envvar_value(value)\n        # can't call no-arg super() inside list comprehension until Python 3.12\n        super_convert = super().convert\n        return [super_convert(item, param, ctx) for item in items]\n\n\n@click.command(\"run\", short_help=\"Run a development server.\")\n@click.option(\"--host\", \"-h\", default=\"127.0.0.1\", help=\"The interface to bind to.\")\n@click.option(\"--port\", \"-p\", default=5000, help=\"The port to bind to.\")\n@click.option(\n    \"--cert\",\n    type=CertParamType(),\n    help=\"Specify a certificate file to use HTTPS.\",\n    is_eager=True,\n)\n@click.option(\n    \"--key\",\n    type=click.Path(exists=True, dir_okay=False, resolve_path=True),\n    callback=_validate_key,\n    expose_value=False,\n    help=\"The key file to use when specifying a certificate.\",\n)\n@click.option(\n    \"--reload/--no-reload\",\n    default=None,\n    help=\"Enable or disable the reloader. By default the reloader \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--debugger/--no-debugger\",\n    default=None,\n    help=\"Enable or disable the debugger. By default the debugger \"\n    \"is active if debug is enabled.\",\n)\n@click.option(\n    \"--with-threads/--without-threads\",\n    default=True,\n    help=\"Enable or disable multithreading.\",\n)\n@click.option(\n    \"--extra-files\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Extra files that trigger a reload on change. Multiple paths\"\n        f\" are separated by {os.path.pathsep!r}.\"\n    ),\n)\n@click.option(\n    \"--exclude-patterns\",\n    default=None,\n    type=SeparatedPathType(),\n    help=(\n        \"Files matching these fnmatch patterns will not trigger a reload\"\n        \" on change. Multiple patterns are separated by\"\n        f\" {os.path.pathsep!r}.\"\n    ),\n)\n@pass_script_info\ndef run_command(\n    info: ScriptInfo,\n    host: str,\n    port: int,\n    reload: bool,\n    debugger: bool,\n    with_threads: bool,\n    cert: ssl.SSLContext | tuple[str, str | None] | t.Literal[\"adhoc\"] | None,\n    extra_files: list[str] | None,\n    exclude_patterns: list[str] | None,\n) -> None:\n    \"\"\"Run a local development server.\n\n    This server is for development purposes only. It does not provide\n    the stability, security, or performance of production WSGI servers.\n\n    The reloader and debugger are enabled by default with the '--debug'\n    option.\n    \"\"\"\n    try:\n        app: WSGIApplication = info.load_app()\n    except Exception as e:\n        if is_running_from_reloader():\n            # When reloading, print out the error immediately, but raise\n            # it later so the debugger or server can handle it.\n            traceback.print_exc()\n            err = e\n\n            def app(\n                environ: WSGIEnvironment, start_response: StartResponse\n            ) -> cabc.Iterable[bytes]:\n                raise err from None\n\n        else:\n            # When not reloading, raise the error immediately so the\n            # command fails.\n            raise e from None\n\n    debug = get_debug_flag()\n\n    if reload is None:\n        reload = debug\n\n    if debugger is None:\n        debugger = debug\n\n    show_server_banner(debug, info.app_import_path)\n\n    run_simple(\n        host,\n        port,\n        app,\n        use_reloader=reload,\n        use_debugger=debugger,\n        threaded=with_threads,\n        ssl_context=cert,\n        extra_files=extra_files,\n        exclude_patterns=exclude_patterns,\n    )\n\n\nrun_command.params.insert(0, _debug_option)\n\n\n@click.command(\"shell\", short_help=\"Run a shell in the app context.\")\n@with_appcontext\ndef shell_command() -> None:\n    \"\"\"Run an interactive Python shell in the context of a given\n    Flask application.  The application will populate the default\n    namespace of this shell according to its configuration.\n\n    This is useful for executing small snippets of management code\n    without having to manually configure the application.\n    \"\"\"\n    import code\n\n    banner = (\n        f\"Python {sys.version} on {sys.platform}\\n\"\n        f\"App: {current_app.import_name}\\n\"\n        f\"Instance: {current_app.instance_path}\"\n    )\n    ctx: dict[str, t.Any] = {}\n\n    # Support the regular Python interpreter startup script if someone\n    # is using it.\n    startup = os.environ.get(\"PYTHONSTARTUP\")\n    if startup and os.path.isfile(startup):\n        with open(startup) as f:\n            eval(compile(f.read(), startup, \"exec\"), ctx)\n\n    ctx.update(current_app.make_shell_context())\n\n    # Site, customize, or startup script can set a hook to call when\n    # entering interactive mode. The default one sets up readline with\n    # tab and history completion.\n    interactive_hook = getattr(sys, \"__interactivehook__\", None)\n\n    if interactive_hook is not None:\n        try:\n            import readline\n            from rlcompleter import Completer\n        except ImportError:\n            pass\n        else:\n            # rlcompleter uses __main__.__dict__ by default, which is\n            # flask.__main__. Use the shell context instead.\n            readline.set_completer(Completer(ctx).complete)\n\n        interactive_hook()\n\n    code.interact(banner=banner, local=ctx)\n\n\n@click.command(\"routes\", short_help=\"Show the routes for the app.\")\n@click.option(\n    \"--sort\",\n    \"-s\",\n    type=click.Choice((\"endpoint\", \"methods\", \"domain\", \"rule\", \"match\")),\n    default=\"endpoint\",\n    help=(\n        \"Method to sort routes by. 'match' is the order that Flask will match routes\"\n        \" when dispatching a request.\"\n    ),\n)\n@click.option(\"--all-methods\", is_flag=True, help=\"Show HEAD and OPTIONS methods.\")\n@with_appcontext\ndef routes_command(sort: str, all_methods: bool) -> None:\n    \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n    rules = list(current_app.url_map.iter_rules())\n\n    if not rules:\n        click.echo(\"No routes were registered.\")\n        return\n\n    ignored_methods = set() if all_methods else {\"HEAD\", \"OPTIONS\"}\n    host_matching = current_app.url_map.host_matching\n    has_domain = any(rule.host if host_matching else rule.subdomain for rule in rules)\n    rows = []\n\n    for rule in rules:\n        row = [\n            rule.endpoint,\n            \", \".join(sorted((rule.methods or set()) - ignored_methods)),\n        ]\n\n        if has_domain:\n            row.append((rule.host if host_matching else rule.subdomain) or \"\")\n\n        row.append(rule.rule)\n        rows.append(row)\n\n    headers = [\"Endpoint\", \"Methods\"]\n    sorts = [\"endpoint\", \"methods\"]\n\n    if has_domain:\n        headers.append(\"Host\" if host_matching else \"Subdomain\")\n        sorts.append(\"domain\")\n\n    headers.append(\"Rule\")\n    sorts.append(\"rule\")\n\n    try:\n        rows.sort(key=itemgetter(sorts.index(sort)))\n    except ValueError:\n        pass\n\n    rows.insert(0, headers)\n    widths = [max(len(row[i]) for row in rows) for i in range(len(headers))]\n    rows.insert(1, [\"-\" * w for w in widths])\n    template = \"  \".join(f\"{{{i}:<{w}}}\" for i, w in enumerate(widths))\n\n    for row in rows:\n        click.echo(template.format(*row))\n\n\ncli = FlaskGroup(\n    name=\"flask\",\n    help=\"\"\"\\\nA general utility script for Flask applications.\n\nAn application to load must be given with the '--app' option,\n'FLASK_APP' environment variable, or with a 'wsgi.py' or 'app.py' file\nin the current directory.\n\"\"\",\n)\n\n\ndef main() -> None:\n    cli.main()\n\n\nif __name__ == \"__main__\":\n    main()\n",
      "bug_category": "modularity",
      "error_type": "modularity",
      "confidence": 0.4
    },
    {
      "bug_id": "2ca068147bfa",
      "repo": "flask",
      "commit_hash": "1af8f95",
      "commit_message": "fix super call in list comprehension",
      "file_path": "tests/test_cli.py",
      "language": "python",
      "code_before": "# This file was part of Flask-CLI and was modified under the terms of\n# its Revised BSD License. Copyright \u00a9 2015 CERN.\nimport importlib.metadata\nimport os\nimport platform\nimport ssl\nimport sys\nimport types\nfrom functools import partial\nfrom pathlib import Path\n\nimport click\nimport pytest\nfrom _pytest.monkeypatch import notset\nfrom click.testing import CliRunner\n\nfrom flask import Blueprint\nfrom flask import current_app\nfrom flask import Flask\nfrom flask.cli import AppGroup\nfrom flask.cli import find_best_app\nfrom flask.cli import FlaskGroup\nfrom flask.cli import get_version\nfrom flask.cli import load_dotenv\nfrom flask.cli import locate_app\nfrom flask.cli import NoAppException\nfrom flask.cli import prepare_import\nfrom flask.cli import run_command\nfrom flask.cli import ScriptInfo\nfrom flask.cli import with_appcontext\n\ncwd = Path.cwd()\ntest_path = (Path(__file__) / \"..\" / \"test_apps\").resolve()\n\n\n@pytest.fixture\ndef runner():\n    return CliRunner()\n\n\ndef test_cli_name(test_apps):\n    \"\"\"Make sure the CLI object's name is the app's name and not the app itself\"\"\"\n    from cliapp.app import testapp\n\n    assert testapp.cli.name == testapp.name\n\n\ndef test_find_best_app(test_apps):\n    class Module:\n        app = Flask(\"appname\")\n\n    assert find_best_app(Module) == Module.app\n\n    class Module:\n        application = Flask(\"appname\")\n\n    assert find_best_app(Module) == Module.application\n\n    class Module:\n        myapp = Flask(\"appname\")\n\n    assert find_best_app(Module) == Module.myapp\n\n    class Module:\n        @staticmethod\n        def create_app():\n            return Flask(\"appname\")\n\n    app = find_best_app(Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(**kwargs):\n            return Flask(\"appname\")\n\n    app = find_best_app(Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def make_app():\n            return Flask(\"appname\")\n\n    app = find_best_app(Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        myapp = Flask(\"appname1\")\n\n        @staticmethod\n        def create_app():\n            return Flask(\"appname2\")\n\n    assert find_best_app(Module) == Module.myapp\n\n    class Module:\n        myapp = Flask(\"appname1\")\n\n        @staticmethod\n        def create_app():\n            return Flask(\"appname2\")\n\n    assert find_best_app(Module) == Module.myapp\n\n    class Module:\n        pass\n\n    pytest.raises(NoAppException, find_best_app, Module)\n\n    class Module:\n        myapp1 = Flask(\"appname1\")\n        myapp2 = Flask(\"appname2\")\n\n    pytest.raises(NoAppException, find_best_app, Module)\n\n    class Module:\n        @staticmethod\n        def create_app(foo, bar):\n            return Flask(\"appname2\")\n\n    pytest.raises(NoAppException, find_best_app, Module)\n\n    class Module:\n        @staticmethod\n        def create_app():\n            raise TypeError(\"bad bad factory!\")\n\n    pytest.raises(TypeError, find_best_app, Module)\n\n\n@pytest.mark.parametrize(\n    \"value,path,result\",\n    (\n        (\"test\", cwd, \"test\"),\n        (\"test.py\", cwd, \"test\"),\n        (\"a/test\", cwd / \"a\", \"test\"),\n        (\"test/__init__.py\", cwd, \"test\"),\n        (\"test/__init__\", cwd, \"test\"),\n        # nested package\n        (\n            test_path / \"cliapp\" / \"inner1\" / \"__init__\",\n            test_path,\n            \"cliapp.inner1\",\n        ),\n        (\n            test_path / \"cliapp\" / \"inner1\" / \"inner2\",\n            test_path,\n            \"cliapp.inner1.inner2\",\n        ),\n        # dotted name\n        (\"test.a.b\", cwd, \"test.a.b\"),\n        (test_path / \"cliapp.app\", test_path, \"cliapp.app\"),\n        # not a Python file, will be caught during import\n        (test_path / \"cliapp\" / \"message.txt\", test_path, \"cliapp.message.txt\"),\n    ),\n)\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs.\n    \"\"\"\n    original_path = sys.path[:]\n\n    def reset_path():\n        sys.path[:] = original_path\n\n    request.addfinalizer(reset_path)\n\n    assert prepare_import(value) == result\n    assert sys.path[0] == str(path)\n\n\n@pytest.mark.parametrize(\n    \"iname,aname,result\",\n    (\n        (\"cliapp.app\", None, \"testapp\"),\n        (\"cliapp.app\", \"testapp\", \"testapp\"),\n        (\"cliapp.factory\", None, \"app\"),\n        (\"cliapp.factory\", \"create_app\", \"app\"),\n        (\"cliapp.factory\", \"create_app()\", \"app\"),\n        (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\")', \"app2_foo_bar\"),\n        # trailing comma space\n        (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\", )', \"app2_foo_bar\"),\n        # strip whitespace\n        (\"cliapp.factory\", \" create_app () \", \"app\"),\n    ),\n)\ndef test_locate_app(test_apps, iname, aname, result):\n    assert locate_app(iname, aname).name == result\n\n\n@pytest.mark.parametrize(\n    \"iname,aname\",\n    (\n        (\"notanapp.py\", None),\n        (\"cliapp/app\", None),\n        (\"cliapp.app\", \"notanapp\"),\n        # not enough arguments\n        (\"cliapp.factory\", 'create_app2(\"foo\")'),\n        # invalid identifier\n        (\"cliapp.factory\", \"create_app(\"),\n        # no app returned\n        (\"cliapp.factory\", \"no_app\"),\n        # nested import error\n        (\"cliapp.importerrorapp\", None),\n        # not a Python file\n        (\"cliapp.message.txt\", None),\n    ),\n)\ndef test_locate_app_raises(test_apps, iname, aname):\n    with pytest.raises(NoAppException):\n        locate_app(iname, aname)\n\n\ndef test_locate_app_suppress_raise(test_apps):\n    app = locate_app(\"notanapp.py\", None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False)\n\n\ndef test_get_version(test_apps, capsys):\n    class MockCtx:\n        resilient_parsing = False\n        color = None\n\n        def exit(self):\n            return\n\n    ctx = MockCtx()\n    get_version(ctx, None, \"test\")\n    out, err = capsys.readouterr()\n    assert f\"Python {platform.python_version()}\" in out\n    assert f\"Flask {importlib.metadata.version('flask')}\" in out\n    assert f\"Werkzeug {importlib.metadata.version('werkzeug')}\" in out\n\n\ndef test_scriptinfo(test_apps, monkeypatch):\n    obj = ScriptInfo(app_import_path=\"cliapp.app:testapp\")\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n    assert obj.load_app() is app\n\n    # import app with module's absolute path\n    cli_app_path = str(test_path / \"cliapp\" / \"app.py\")\n\n    obj = ScriptInfo(app_import_path=cli_app_path)\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n    assert obj.load_app() is app\n    obj = ScriptInfo(app_import_path=f\"{cli_app_path}:testapp\")\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n    assert obj.load_app() is app\n\n    def create_app():\n        return Flask(\"createapp\")\n\n    obj = ScriptInfo(create_app=create_app)\n    app = obj.load_app()\n    assert app.name == \"createapp\"\n    assert obj.load_app() is app\n\n    obj = ScriptInfo()\n    pytest.raises(NoAppException, obj.load_app)\n\n    # import app from wsgi.py in current directory\n    monkeypatch.chdir(test_path / \"helloworld\")\n    obj = ScriptInfo()\n    app = obj.load_app()\n    assert app.name == \"hello\"\n\n    # import app from app.py in current directory\n    monkeypatch.chdir(test_path / \"cliapp\")\n    obj = ScriptInfo()\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n\n\ndef test_app_cli_has_app_context(app, runner):\n    def _param_cb(ctx, param, value):\n        # current_app should be available in parameter callbacks\n        return bool(current_app)\n\n    @app.cli.command()\n    @click.argument(\"value\", callback=_param_cb)\n    def check(value):\n        app = click.get_current_context().obj.load_app()\n        # the loaded app should be the same as current_app\n        same_app = current_app._get_current_object() is app\n        return same_app, value\n\n    cli = FlaskGroup(create_app=lambda: app)\n    result = runner.invoke(cli, [\"check\", \"x\"], standalone_mode=False)\n    assert result.return_value == (True, True)\n\n\ndef test_with_appcontext(runner):\n    @click.command()\n    @with_appcontext\n    def testcmd():\n        click.echo(current_app.name)\n\n    obj = ScriptInfo(create_app=lambda: Flask(\"testapp\"))\n\n    result = runner.invoke(testcmd, obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testapp\\n\"\n\n\ndef test_appgroup_app_context(runner):\n    @click.group(cls=AppGroup)\n    def cli():\n        pass\n\n    @cli.command()\n    def test():\n        click.echo(current_app.name)\n\n    @cli.group()\n    def subgroup():\n        pass\n\n    @subgroup.command()\n    def test2():\n        click.echo(current_app.name)\n\n    obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))\n\n    result = runner.invoke(cli, [\"test\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testappgroup\\n\"\n\n    result = runner.invoke(cli, [\"subgroup\", \"test2\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testappgroup\\n\"\n\n\ndef test_flaskgroup_app_context(runner):\n    def create_app():\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app)\n    def cli(**params):\n        pass\n\n    @cli.command()\n    def test():\n        click.echo(current_app.name)\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"flaskgroup\\n\"\n\n\n@pytest.mark.parametrize(\"set_debug_flag\", (True, False))\ndef test_flaskgroup_debug(runner, set_debug_flag):\n    def create_app():\n        app = Flask(\"flaskgroup\")\n        app.debug = True\n        return app\n\n    @click.group(cls=FlaskGroup, create_app=create_app, set_debug_flag=set_debug_flag)\n    def cli(**params):\n        pass\n\n    @cli.command()\n    def test():\n        click.echo(str(current_app.debug))\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == f\"{not set_debug_flag}\\n\"\n\n\ndef test_flaskgroup_nested(app, runner):\n    cli = click.Group(\"cli\")\n    flask_group = FlaskGroup(name=\"flask\", create_app=lambda: app)\n    cli.add_command(flask_group)\n\n    @flask_group.command()\n    def show():\n        click.echo(current_app.name)\n\n    result = runner.invoke(cli, [\"flask\", \"show\"])\n    assert result.output == \"flask_test\\n\"\n\n\ndef test_no_command_echo_loading_error():\n    from flask.cli import cli\n\n    runner = CliRunner(mix_stderr=False)\n    result = runner.invoke(cli, [\"missing\"])\n    assert result.exit_code == 2\n    assert \"FLASK_APP\" in result.stderr\n    assert \"Usage:\" in result.stderr\n\n\ndef test_help_echo_loading_error():\n    from flask.cli import cli\n\n    runner = CliRunner(mix_stderr=False)\n    result = runner.invoke(cli, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"FLASK_APP\" in result.stderr\n    assert \"Usage:\" in result.stdout\n\n\ndef test_help_echo_exception():\n    def create_app():\n        raise Exception(\"oh no\")\n\n    cli = FlaskGroup(create_app=create_app)\n    runner = CliRunner(mix_stderr=False)\n    result = runner.invoke(cli, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"Exception: oh no\" in result.stderr\n    assert \"Usage:\" in result.stdout\n\n\nclass TestRoutes:\n    @pytest.fixture\n    def app(self):\n        app = Flask(__name__)\n        app.add_url_rule(\n            \"/get_post/<int:x>/<int:y>\",\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"yyy_get_post\",\n        )\n        app.add_url_rule(\"/zzz_post\", methods=[\"POST\"], endpoint=\"aaa_post\")\n        return app\n\n    @pytest.fixture\n    def invoke(self, app, runner):\n        cli = FlaskGroup(create_app=lambda: app)\n        return partial(runner.invoke, cli)\n\n    def expect_order(self, order, output):\n        # skip the header and match the start of each row\n        for expect, line in zip(order, output.splitlines()[2:]):\n            # do this instead of startswith for nicer pytest output\n            assert line[: len(expect)] == expect\n\n    def test_simple(self, invoke):\n        result = invoke([\"routes\"])\n        assert result.exit_code == 0\n        self.expect_order([\"aaa_post\", \"static\", \"yyy_get_post\"], result.output)\n\n    def test_sort(self, app, invoke):\n        default_output = invoke([\"routes\"]).output\n        endpoint_output = invoke([\"routes\", \"-s\", \"endpoint\"]).output\n        assert default_output == endpoint_output\n        self.expect_order(\n            [\"static\", \"yyy_get_post\", \"aaa_post\"],\n            invoke([\"routes\", \"-s\", \"methods\"]).output,\n        )\n        self.expect_order(\n            [\"yyy_get_post\", \"static\", \"aaa_post\"],\n            invoke([\"routes\", \"-s\", \"rule\"]).output,\n        )\n        match_order = [r.endpoint for r in app.url_map.iter_rules()]\n        self.expect_order(match_order, invoke([\"routes\", \"-s\", \"match\"]).output)\n\n    def test_all_methods(self, invoke):\n        output = invoke([\"routes\"]).output\n        assert \"GET, HEAD, OPTIONS, POST\" not in output\n        output = invoke([\"routes\", \"--all-methods\"]).output\n        assert \"GET, HEAD, OPTIONS, POST\" in output\n\n    def test_no_routes(self, runner):\n        app = Flask(__name__, static_folder=None)\n        cli = FlaskGroup(create_app=lambda: app)\n        result = runner.invoke(cli, [\"routes\"])\n        assert result.exit_code == 0\n        assert \"No routes were registered.\" in result.output\n\n    def test_subdomain(self, runner):\n        app = Flask(__name__, static_folder=None)\n        app.add_url_rule(\"/a\", subdomain=\"a\", endpoint=\"a\")\n        app.add_url_rule(\"/b\", subdomain=\"b\", endpoint=\"b\")\n        cli = FlaskGroup(create_app=lambda: app)\n        result = runner.invoke(cli, [\"routes\"])\n        assert result.exit_code == 0\n        assert \"Subdomain\" in result.output\n\n    def test_host(self, runner):\n        app = Flask(__name__, static_folder=None, host_matching=True)\n        app.add_url_rule(\"/a\", host=\"a\", endpoint=\"a\")\n        app.add_url_rule(\"/b\", host=\"b\", endpoint=\"b\")\n        cli = FlaskGroup(create_app=lambda: app)\n        result = runner.invoke(cli, [\"routes\"])\n        assert result.exit_code == 0\n        assert \"Host\" in result.output\n\n\ndef dotenv_not_available():\n    try:\n        import dotenv  # noqa: F401\n    except ImportError:\n        return True\n\n    return False\n\n\nneed_dotenv = pytest.mark.skipif(\n    dotenv_not_available(), reason=\"dotenv is not installed\"\n)\n\n\n@need_dotenv\ndef test_load_dotenv(monkeypatch):\n    # can't use monkeypatch.delitem since the keys don't exist yet\n    for item in (\"FOO\", \"BAR\", \"SPAM\", \"HAM\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    monkeypatch.setenv(\"EGGS\", \"3\")\n    monkeypatch.chdir(test_path)\n    assert load_dotenv()\n    assert Path.cwd() == test_path\n    # .flaskenv doesn't overwrite .env\n    assert os.environ[\"FOO\"] == \"env\"\n    # set only in .flaskenv\n    assert os.environ[\"BAR\"] == \"bar\"\n    # set only in .env\n    assert os.environ[\"SPAM\"] == \"1\"\n    # set manually, files don't overwrite\n    assert os.environ[\"EGGS\"] == \"3\"\n    # test env file encoding\n    assert os.environ[\"HAM\"] == \"\u706b\u817f\"\n    # Non existent file should not load\n    assert not load_dotenv(\"non-existent-file\")\n\n\n@need_dotenv\ndef test_dotenv_path(monkeypatch):\n    for item in (\"FOO\", \"BAR\", \"EGGS\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    load_dotenv(test_path / \".flaskenv\")\n    assert Path.cwd() == cwd\n    assert \"FOO\" in os.environ\n\n\ndef test_dotenv_optional(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"dotenv\", None)\n    monkeypatch.chdir(test_path)\n    load_dotenv()\n    assert \"FOO\" not in os.environ\n\n\n@need_dotenv\ndef test_disable_dotenv_from_env(monkeypatch, runner):\n    monkeypatch.chdir(test_path)\n    monkeypatch.setitem(os.environ, \"FLASK_SKIP_DOTENV\", \"1\")\n    runner.invoke(FlaskGroup())\n    assert \"FOO\" not in os.environ\n\n\ndef test_run_cert_path():\n    # no key\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", __file__])\n\n    # no cert\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--key\", __file__])\n\n    # cert specified first\n    ctx = run_command.make_context(\"run\", [\"--cert\", __file__, \"--key\", __file__])\n    assert ctx.params[\"cert\"] == (__file__, __file__)\n\n    # key specified first\n    ctx = run_command.make_context(\"run\", [\"--key\", __file__, \"--cert\", __file__])\n    assert ctx.params[\"cert\"] == (__file__, __file__)\n\n\ndef test_run_cert_adhoc(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"cryptography\", None)\n\n    # cryptography not installed\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"adhoc\"])\n\n    # cryptography installed\n    monkeypatch.setitem(sys.modules, \"cryptography\", types.ModuleType(\"cryptography\"))\n    ctx = run_command.make_context(\"run\", [\"--cert\", \"adhoc\"])\n    assert ctx.params[\"cert\"] == \"adhoc\"\n\n    # no key with adhoc\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"adhoc\", \"--key\", __file__])\n\n\ndef test_run_cert_import(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"not_here\", None)\n\n    # ImportError\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"not_here\"])\n\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"flask\"])\n\n    # SSLContext\n    ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n\n    monkeypatch.setitem(sys.modules, \"ssl_context\", ssl_context)\n    ctx = run_command.make_context(\"run\", [\"--cert\", \"ssl_context\"])\n    assert ctx.params[\"cert\"] is ssl_context\n\n    # no --key with SSLContext\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"ssl_context\", \"--key\", __file__])\n\n\ndef test_run_cert_no_ssl(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"ssl\", None)\n\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"not_here\"])\n\n\ndef test_cli_blueprints(app):\n    \"\"\"Test blueprint commands register correctly to the application\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    nested = Blueprint(\"nested\", __name__)\n    merged = Blueprint(\"merged\", __name__, cli_group=None)\n    late = Blueprint(\"late\", __name__)\n\n    @custom.cli.command(\"custom\")\n    def custom_command():\n        click.echo(\"custom_result\")\n\n    @nested.cli.command(\"nested\")\n    def nested_command():\n        click.echo(\"nested_result\")\n\n    @merged.cli.command(\"merged\")\n    def merged_command():\n        click.echo(\"merged_result\")\n\n    @late.cli.command(\"late\")\n    def late_command():\n        click.echo(\"late_result\")\n\n    app.register_blueprint(custom)\n    app.register_blueprint(nested)\n    app.register_blueprint(merged)\n    app.register_blueprint(late, cli_group=\"late_registration\")\n\n    app_runner = app.test_cli_runner()\n\n    result = app_runner.invoke(args=[\"customized\", \"custom\"])\n    assert \"custom_result\" in result.output\n\n    result = app_runner.invoke(args=[\"nested\", \"nested\"])\n    assert \"nested_result\" in result.output\n\n    result = app_runner.invoke(args=[\"merged\"])\n    assert \"merged_result\" in result.output\n\n    result = app_runner.invoke(args=[\"late_registration\", \"late\"])\n    assert \"late_result\" in result.output\n\n\ndef test_cli_empty(app):\n    \"\"\"If a Blueprint's CLI group is empty, do not register it.\"\"\"\n    bp = Blueprint(\"blue\", __name__, cli_group=\"blue\")\n    app.register_blueprint(bp)\n\n    result = app.test_cli_runner().invoke(args=[\"blue\", \"--help\"])\n    assert result.exit_code == 2, f\"Unexpected success:\\n\\n{result.output}\"\n",
      "code_after": "# This file was part of Flask-CLI and was modified under the terms of\n# its Revised BSD License. Copyright \u00a9 2015 CERN.\nimport importlib.metadata\nimport os\nimport platform\nimport ssl\nimport sys\nimport types\nfrom functools import partial\nfrom pathlib import Path\n\nimport click\nimport pytest\nfrom _pytest.monkeypatch import notset\nfrom click.testing import CliRunner\n\nfrom flask import Blueprint\nfrom flask import current_app\nfrom flask import Flask\nfrom flask.cli import AppGroup\nfrom flask.cli import find_best_app\nfrom flask.cli import FlaskGroup\nfrom flask.cli import get_version\nfrom flask.cli import load_dotenv\nfrom flask.cli import locate_app\nfrom flask.cli import NoAppException\nfrom flask.cli import prepare_import\nfrom flask.cli import run_command\nfrom flask.cli import ScriptInfo\nfrom flask.cli import with_appcontext\n\ncwd = Path.cwd()\ntest_path = (Path(__file__) / \"..\" / \"test_apps\").resolve()\n\n\n@pytest.fixture\ndef runner():\n    return CliRunner()\n\n\ndef test_cli_name(test_apps):\n    \"\"\"Make sure the CLI object's name is the app's name and not the app itself\"\"\"\n    from cliapp.app import testapp\n\n    assert testapp.cli.name == testapp.name\n\n\ndef test_find_best_app(test_apps):\n    class Module:\n        app = Flask(\"appname\")\n\n    assert find_best_app(Module) == Module.app\n\n    class Module:\n        application = Flask(\"appname\")\n\n    assert find_best_app(Module) == Module.application\n\n    class Module:\n        myapp = Flask(\"appname\")\n\n    assert find_best_app(Module) == Module.myapp\n\n    class Module:\n        @staticmethod\n        def create_app():\n            return Flask(\"appname\")\n\n    app = find_best_app(Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def create_app(**kwargs):\n            return Flask(\"appname\")\n\n    app = find_best_app(Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        @staticmethod\n        def make_app():\n            return Flask(\"appname\")\n\n    app = find_best_app(Module)\n    assert isinstance(app, Flask)\n    assert app.name == \"appname\"\n\n    class Module:\n        myapp = Flask(\"appname1\")\n\n        @staticmethod\n        def create_app():\n            return Flask(\"appname2\")\n\n    assert find_best_app(Module) == Module.myapp\n\n    class Module:\n        myapp = Flask(\"appname1\")\n\n        @staticmethod\n        def create_app():\n            return Flask(\"appname2\")\n\n    assert find_best_app(Module) == Module.myapp\n\n    class Module:\n        pass\n\n    pytest.raises(NoAppException, find_best_app, Module)\n\n    class Module:\n        myapp1 = Flask(\"appname1\")\n        myapp2 = Flask(\"appname2\")\n\n    pytest.raises(NoAppException, find_best_app, Module)\n\n    class Module:\n        @staticmethod\n        def create_app(foo, bar):\n            return Flask(\"appname2\")\n\n    pytest.raises(NoAppException, find_best_app, Module)\n\n    class Module:\n        @staticmethod\n        def create_app():\n            raise TypeError(\"bad bad factory!\")\n\n    pytest.raises(TypeError, find_best_app, Module)\n\n\n@pytest.mark.parametrize(\n    \"value,path,result\",\n    (\n        (\"test\", cwd, \"test\"),\n        (\"test.py\", cwd, \"test\"),\n        (\"a/test\", cwd / \"a\", \"test\"),\n        (\"test/__init__.py\", cwd, \"test\"),\n        (\"test/__init__\", cwd, \"test\"),\n        # nested package\n        (\n            test_path / \"cliapp\" / \"inner1\" / \"__init__\",\n            test_path,\n            \"cliapp.inner1\",\n        ),\n        (\n            test_path / \"cliapp\" / \"inner1\" / \"inner2\",\n            test_path,\n            \"cliapp.inner1.inner2\",\n        ),\n        # dotted name\n        (\"test.a.b\", cwd, \"test.a.b\"),\n        (test_path / \"cliapp.app\", test_path, \"cliapp.app\"),\n        # not a Python file, will be caught during import\n        (test_path / \"cliapp\" / \"message.txt\", test_path, \"cliapp.message.txt\"),\n    ),\n)\ndef test_prepare_import(request, value, path, result):\n    \"\"\"Expect the correct path to be set and the correct import and app names\n    to be returned.\n\n    :func:`prepare_exec_for_file` has a side effect where the parent directory\n    of the given import is added to :data:`sys.path`. This is reset after the\n    test runs.\n    \"\"\"\n    original_path = sys.path[:]\n\n    def reset_path():\n        sys.path[:] = original_path\n\n    request.addfinalizer(reset_path)\n\n    assert prepare_import(value) == result\n    assert sys.path[0] == str(path)\n\n\n@pytest.mark.parametrize(\n    \"iname,aname,result\",\n    (\n        (\"cliapp.app\", None, \"testapp\"),\n        (\"cliapp.app\", \"testapp\", \"testapp\"),\n        (\"cliapp.factory\", None, \"app\"),\n        (\"cliapp.factory\", \"create_app\", \"app\"),\n        (\"cliapp.factory\", \"create_app()\", \"app\"),\n        (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\")', \"app2_foo_bar\"),\n        # trailing comma space\n        (\"cliapp.factory\", 'create_app2(\"foo\", \"bar\", )', \"app2_foo_bar\"),\n        # strip whitespace\n        (\"cliapp.factory\", \" create_app () \", \"app\"),\n    ),\n)\ndef test_locate_app(test_apps, iname, aname, result):\n    assert locate_app(iname, aname).name == result\n\n\n@pytest.mark.parametrize(\n    \"iname,aname\",\n    (\n        (\"notanapp.py\", None),\n        (\"cliapp/app\", None),\n        (\"cliapp.app\", \"notanapp\"),\n        # not enough arguments\n        (\"cliapp.factory\", 'create_app2(\"foo\")'),\n        # invalid identifier\n        (\"cliapp.factory\", \"create_app(\"),\n        # no app returned\n        (\"cliapp.factory\", \"no_app\"),\n        # nested import error\n        (\"cliapp.importerrorapp\", None),\n        # not a Python file\n        (\"cliapp.message.txt\", None),\n    ),\n)\ndef test_locate_app_raises(test_apps, iname, aname):\n    with pytest.raises(NoAppException):\n        locate_app(iname, aname)\n\n\ndef test_locate_app_suppress_raise(test_apps):\n    app = locate_app(\"notanapp.py\", None, raise_if_not_found=False)\n    assert app is None\n\n    # only direct import error is suppressed\n    with pytest.raises(NoAppException):\n        locate_app(\"cliapp.importerrorapp\", None, raise_if_not_found=False)\n\n\ndef test_get_version(test_apps, capsys):\n    class MockCtx:\n        resilient_parsing = False\n        color = None\n\n        def exit(self):\n            return\n\n    ctx = MockCtx()\n    get_version(ctx, None, \"test\")\n    out, err = capsys.readouterr()\n    assert f\"Python {platform.python_version()}\" in out\n    assert f\"Flask {importlib.metadata.version('flask')}\" in out\n    assert f\"Werkzeug {importlib.metadata.version('werkzeug')}\" in out\n\n\ndef test_scriptinfo(test_apps, monkeypatch):\n    obj = ScriptInfo(app_import_path=\"cliapp.app:testapp\")\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n    assert obj.load_app() is app\n\n    # import app with module's absolute path\n    cli_app_path = str(test_path / \"cliapp\" / \"app.py\")\n\n    obj = ScriptInfo(app_import_path=cli_app_path)\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n    assert obj.load_app() is app\n    obj = ScriptInfo(app_import_path=f\"{cli_app_path}:testapp\")\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n    assert obj.load_app() is app\n\n    def create_app():\n        return Flask(\"createapp\")\n\n    obj = ScriptInfo(create_app=create_app)\n    app = obj.load_app()\n    assert app.name == \"createapp\"\n    assert obj.load_app() is app\n\n    obj = ScriptInfo()\n    pytest.raises(NoAppException, obj.load_app)\n\n    # import app from wsgi.py in current directory\n    monkeypatch.chdir(test_path / \"helloworld\")\n    obj = ScriptInfo()\n    app = obj.load_app()\n    assert app.name == \"hello\"\n\n    # import app from app.py in current directory\n    monkeypatch.chdir(test_path / \"cliapp\")\n    obj = ScriptInfo()\n    app = obj.load_app()\n    assert app.name == \"testapp\"\n\n\ndef test_app_cli_has_app_context(app, runner):\n    def _param_cb(ctx, param, value):\n        # current_app should be available in parameter callbacks\n        return bool(current_app)\n\n    @app.cli.command()\n    @click.argument(\"value\", callback=_param_cb)\n    def check(value):\n        app = click.get_current_context().obj.load_app()\n        # the loaded app should be the same as current_app\n        same_app = current_app._get_current_object() is app\n        return same_app, value\n\n    cli = FlaskGroup(create_app=lambda: app)\n    result = runner.invoke(cli, [\"check\", \"x\"], standalone_mode=False)\n    assert result.return_value == (True, True)\n\n\ndef test_with_appcontext(runner):\n    @click.command()\n    @with_appcontext\n    def testcmd():\n        click.echo(current_app.name)\n\n    obj = ScriptInfo(create_app=lambda: Flask(\"testapp\"))\n\n    result = runner.invoke(testcmd, obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testapp\\n\"\n\n\ndef test_appgroup_app_context(runner):\n    @click.group(cls=AppGroup)\n    def cli():\n        pass\n\n    @cli.command()\n    def test():\n        click.echo(current_app.name)\n\n    @cli.group()\n    def subgroup():\n        pass\n\n    @subgroup.command()\n    def test2():\n        click.echo(current_app.name)\n\n    obj = ScriptInfo(create_app=lambda: Flask(\"testappgroup\"))\n\n    result = runner.invoke(cli, [\"test\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testappgroup\\n\"\n\n    result = runner.invoke(cli, [\"subgroup\", \"test2\"], obj=obj)\n    assert result.exit_code == 0\n    assert result.output == \"testappgroup\\n\"\n\n\ndef test_flaskgroup_app_context(runner):\n    def create_app():\n        return Flask(\"flaskgroup\")\n\n    @click.group(cls=FlaskGroup, create_app=create_app)\n    def cli(**params):\n        pass\n\n    @cli.command()\n    def test():\n        click.echo(current_app.name)\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == \"flaskgroup\\n\"\n\n\n@pytest.mark.parametrize(\"set_debug_flag\", (True, False))\ndef test_flaskgroup_debug(runner, set_debug_flag):\n    def create_app():\n        app = Flask(\"flaskgroup\")\n        app.debug = True\n        return app\n\n    @click.group(cls=FlaskGroup, create_app=create_app, set_debug_flag=set_debug_flag)\n    def cli(**params):\n        pass\n\n    @cli.command()\n    def test():\n        click.echo(str(current_app.debug))\n\n    result = runner.invoke(cli, [\"test\"])\n    assert result.exit_code == 0\n    assert result.output == f\"{not set_debug_flag}\\n\"\n\n\ndef test_flaskgroup_nested(app, runner):\n    cli = click.Group(\"cli\")\n    flask_group = FlaskGroup(name=\"flask\", create_app=lambda: app)\n    cli.add_command(flask_group)\n\n    @flask_group.command()\n    def show():\n        click.echo(current_app.name)\n\n    result = runner.invoke(cli, [\"flask\", \"show\"])\n    assert result.output == \"flask_test\\n\"\n\n\ndef test_no_command_echo_loading_error():\n    from flask.cli import cli\n\n    runner = CliRunner(mix_stderr=False)\n    result = runner.invoke(cli, [\"missing\"])\n    assert result.exit_code == 2\n    assert \"FLASK_APP\" in result.stderr\n    assert \"Usage:\" in result.stderr\n\n\ndef test_help_echo_loading_error():\n    from flask.cli import cli\n\n    runner = CliRunner(mix_stderr=False)\n    result = runner.invoke(cli, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"FLASK_APP\" in result.stderr\n    assert \"Usage:\" in result.stdout\n\n\ndef test_help_echo_exception():\n    def create_app():\n        raise Exception(\"oh no\")\n\n    cli = FlaskGroup(create_app=create_app)\n    runner = CliRunner(mix_stderr=False)\n    result = runner.invoke(cli, [\"--help\"])\n    assert result.exit_code == 0\n    assert \"Exception: oh no\" in result.stderr\n    assert \"Usage:\" in result.stdout\n\n\nclass TestRoutes:\n    @pytest.fixture\n    def app(self):\n        app = Flask(__name__)\n        app.add_url_rule(\n            \"/get_post/<int:x>/<int:y>\",\n            methods=[\"GET\", \"POST\"],\n            endpoint=\"yyy_get_post\",\n        )\n        app.add_url_rule(\"/zzz_post\", methods=[\"POST\"], endpoint=\"aaa_post\")\n        return app\n\n    @pytest.fixture\n    def invoke(self, app, runner):\n        cli = FlaskGroup(create_app=lambda: app)\n        return partial(runner.invoke, cli)\n\n    def expect_order(self, order, output):\n        # skip the header and match the start of each row\n        for expect, line in zip(order, output.splitlines()[2:]):\n            # do this instead of startswith for nicer pytest output\n            assert line[: len(expect)] == expect\n\n    def test_simple(self, invoke):\n        result = invoke([\"routes\"])\n        assert result.exit_code == 0\n        self.expect_order([\"aaa_post\", \"static\", \"yyy_get_post\"], result.output)\n\n    def test_sort(self, app, invoke):\n        default_output = invoke([\"routes\"]).output\n        endpoint_output = invoke([\"routes\", \"-s\", \"endpoint\"]).output\n        assert default_output == endpoint_output\n        self.expect_order(\n            [\"static\", \"yyy_get_post\", \"aaa_post\"],\n            invoke([\"routes\", \"-s\", \"methods\"]).output,\n        )\n        self.expect_order(\n            [\"yyy_get_post\", \"static\", \"aaa_post\"],\n            invoke([\"routes\", \"-s\", \"rule\"]).output,\n        )\n        match_order = [r.endpoint for r in app.url_map.iter_rules()]\n        self.expect_order(match_order, invoke([\"routes\", \"-s\", \"match\"]).output)\n\n    def test_all_methods(self, invoke):\n        output = invoke([\"routes\"]).output\n        assert \"GET, HEAD, OPTIONS, POST\" not in output\n        output = invoke([\"routes\", \"--all-methods\"]).output\n        assert \"GET, HEAD, OPTIONS, POST\" in output\n\n    def test_no_routes(self, runner):\n        app = Flask(__name__, static_folder=None)\n        cli = FlaskGroup(create_app=lambda: app)\n        result = runner.invoke(cli, [\"routes\"])\n        assert result.exit_code == 0\n        assert \"No routes were registered.\" in result.output\n\n    def test_subdomain(self, runner):\n        app = Flask(__name__, static_folder=None)\n        app.add_url_rule(\"/a\", subdomain=\"a\", endpoint=\"a\")\n        app.add_url_rule(\"/b\", subdomain=\"b\", endpoint=\"b\")\n        cli = FlaskGroup(create_app=lambda: app)\n        result = runner.invoke(cli, [\"routes\"])\n        assert result.exit_code == 0\n        assert \"Subdomain\" in result.output\n\n    def test_host(self, runner):\n        app = Flask(__name__, static_folder=None, host_matching=True)\n        app.add_url_rule(\"/a\", host=\"a\", endpoint=\"a\")\n        app.add_url_rule(\"/b\", host=\"b\", endpoint=\"b\")\n        cli = FlaskGroup(create_app=lambda: app)\n        result = runner.invoke(cli, [\"routes\"])\n        assert result.exit_code == 0\n        assert \"Host\" in result.output\n\n\ndef dotenv_not_available():\n    try:\n        import dotenv  # noqa: F401\n    except ImportError:\n        return True\n\n    return False\n\n\nneed_dotenv = pytest.mark.skipif(\n    dotenv_not_available(), reason=\"dotenv is not installed\"\n)\n\n\n@need_dotenv\ndef test_load_dotenv(monkeypatch):\n    # can't use monkeypatch.delitem since the keys don't exist yet\n    for item in (\"FOO\", \"BAR\", \"SPAM\", \"HAM\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    monkeypatch.setenv(\"EGGS\", \"3\")\n    monkeypatch.chdir(test_path)\n    assert load_dotenv()\n    assert Path.cwd() == test_path\n    # .flaskenv doesn't overwrite .env\n    assert os.environ[\"FOO\"] == \"env\"\n    # set only in .flaskenv\n    assert os.environ[\"BAR\"] == \"bar\"\n    # set only in .env\n    assert os.environ[\"SPAM\"] == \"1\"\n    # set manually, files don't overwrite\n    assert os.environ[\"EGGS\"] == \"3\"\n    # test env file encoding\n    assert os.environ[\"HAM\"] == \"\u706b\u817f\"\n    # Non existent file should not load\n    assert not load_dotenv(\"non-existent-file\")\n\n\n@need_dotenv\ndef test_dotenv_path(monkeypatch):\n    for item in (\"FOO\", \"BAR\", \"EGGS\"):\n        monkeypatch._setitem.append((os.environ, item, notset))\n\n    load_dotenv(test_path / \".flaskenv\")\n    assert Path.cwd() == cwd\n    assert \"FOO\" in os.environ\n\n\ndef test_dotenv_optional(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"dotenv\", None)\n    monkeypatch.chdir(test_path)\n    load_dotenv()\n    assert \"FOO\" not in os.environ\n\n\n@need_dotenv\ndef test_disable_dotenv_from_env(monkeypatch, runner):\n    monkeypatch.chdir(test_path)\n    monkeypatch.setitem(os.environ, \"FLASK_SKIP_DOTENV\", \"1\")\n    runner.invoke(FlaskGroup())\n    assert \"FOO\" not in os.environ\n\n\ndef test_run_cert_path():\n    # no key\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", __file__])\n\n    # no cert\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--key\", __file__])\n\n    # cert specified first\n    ctx = run_command.make_context(\"run\", [\"--cert\", __file__, \"--key\", __file__])\n    assert ctx.params[\"cert\"] == (__file__, __file__)\n\n    # key specified first\n    ctx = run_command.make_context(\"run\", [\"--key\", __file__, \"--cert\", __file__])\n    assert ctx.params[\"cert\"] == (__file__, __file__)\n\n\ndef test_run_cert_adhoc(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"cryptography\", None)\n\n    # cryptography not installed\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"adhoc\"])\n\n    # cryptography installed\n    monkeypatch.setitem(sys.modules, \"cryptography\", types.ModuleType(\"cryptography\"))\n    ctx = run_command.make_context(\"run\", [\"--cert\", \"adhoc\"])\n    assert ctx.params[\"cert\"] == \"adhoc\"\n\n    # no key with adhoc\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"adhoc\", \"--key\", __file__])\n\n\ndef test_run_cert_import(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"not_here\", None)\n\n    # ImportError\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"not_here\"])\n\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"flask\"])\n\n    # SSLContext\n    ssl_context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n\n    monkeypatch.setitem(sys.modules, \"ssl_context\", ssl_context)\n    ctx = run_command.make_context(\"run\", [\"--cert\", \"ssl_context\"])\n    assert ctx.params[\"cert\"] is ssl_context\n\n    # no --key with SSLContext\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"ssl_context\", \"--key\", __file__])\n\n\ndef test_run_cert_no_ssl(monkeypatch):\n    monkeypatch.setitem(sys.modules, \"ssl\", None)\n\n    with pytest.raises(click.BadParameter):\n        run_command.make_context(\"run\", [\"--cert\", \"not_here\"])\n\n\ndef test_cli_blueprints(app):\n    \"\"\"Test blueprint commands register correctly to the application\"\"\"\n    custom = Blueprint(\"custom\", __name__, cli_group=\"customized\")\n    nested = Blueprint(\"nested\", __name__)\n    merged = Blueprint(\"merged\", __name__, cli_group=None)\n    late = Blueprint(\"late\", __name__)\n\n    @custom.cli.command(\"custom\")\n    def custom_command():\n        click.echo(\"custom_result\")\n\n    @nested.cli.command(\"nested\")\n    def nested_command():\n        click.echo(\"nested_result\")\n\n    @merged.cli.command(\"merged\")\n    def merged_command():\n        click.echo(\"merged_result\")\n\n    @late.cli.command(\"late\")\n    def late_command():\n        click.echo(\"late_result\")\n\n    app.register_blueprint(custom)\n    app.register_blueprint(nested)\n    app.register_blueprint(merged)\n    app.register_blueprint(late, cli_group=\"late_registration\")\n\n    app_runner = app.test_cli_runner()\n\n    result = app_runner.invoke(args=[\"customized\", \"custom\"])\n    assert \"custom_result\" in result.output\n\n    result = app_runner.invoke(args=[\"nested\", \"nested\"])\n    assert \"nested_result\" in result.output\n\n    result = app_runner.invoke(args=[\"merged\"])\n    assert \"merged_result\" in result.output\n\n    result = app_runner.invoke(args=[\"late_registration\", \"late\"])\n    assert \"late_result\" in result.output\n\n\ndef test_cli_empty(app):\n    \"\"\"If a Blueprint's CLI group is empty, do not register it.\"\"\"\n    bp = Blueprint(\"blue\", __name__, cli_group=\"blue\")\n    app.register_blueprint(bp)\n\n    result = app.test_cli_runner().invoke(args=[\"blue\", \"--help\"])\n    assert result.exit_code == 2, f\"Unexpected success:\\n\\n{result.output}\"\n\n\ndef test_run_exclude_patterns():\n    ctx = run_command.make_context(\"run\", [\"--exclude-patterns\", __file__])\n    assert ctx.params[\"exclude_patterns\"] == [__file__]\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 0.6
    },
    {
      "bug_id": "e1143d0aab0d",
      "repo": "rich",
      "commit_hash": "76a7b89",
      "commit_message": "change lambda with broken typing to def",
      "file_path": "rich/pager.py",
      "language": "python",
      "code_before": "from abc import ABC, abstractmethod\nfrom typing import Any, Callable\n\n\nclass Pager(ABC):\n    \"\"\"Base class for a pager.\"\"\"\n\n    @abstractmethod\n    def show(self, content: str) -> None:\n        \"\"\"Show content in pager.\n\n        Args:\n            content (str): Content to be displayed.\n        \"\"\"\n\n\nclass SystemPager(Pager):\n    \"\"\"Uses the pager installed on the system.\"\"\"\n\n    _pager: Callable[[Any, str], Any] = lambda self, content: __import__(\"pydoc\").pager(\n        content\n    )\n\n    def show(self, content: str) -> None:\n        \"\"\"Use the same pager used by pydoc.\"\"\"\n        self._pager(content)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from .__main__ import make_test_card\n    from .console import Console\n\n    console = Console()\n    with console.pager(styles=True):\n        console.print(make_test_card())\n",
      "code_after": "from abc import ABC, abstractmethod\nfrom typing import Any, Callable\n\n\nclass Pager(ABC):\n    \"\"\"Base class for a pager.\"\"\"\n\n    @abstractmethod\n    def show(self, content: str) -> None:\n        \"\"\"Show content in pager.\n\n        Args:\n            content (str): Content to be displayed.\n        \"\"\"\n\n\nclass SystemPager(Pager):\n    \"\"\"Uses the pager installed on the system.\"\"\"\n\n    def _pager(self, content: str) -> Any:\n        return __import__(\"pydoc\").pager(content)\n\n    def show(self, content: str) -> None:\n        \"\"\"Use the same pager used by pydoc.\"\"\"\n        self._pager(content)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from .__main__ import make_test_card\n    from .console import Console\n\n    console = Console()\n    with console.pager(styles=True):\n        console.print(make_test_card())\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 1.0
    },
    {
      "bug_id": "ce3df6315ce8",
      "repo": "rich",
      "commit_hash": "655b521",
      "commit_message": "test fixes",
      "file_path": "rich/style.py",
      "language": "python",
      "code_before": "import sys\nfrom functools import lru_cache\nfrom marshal import dumps, loads\nfrom random import randint\nfrom typing import Any, Dict, Iterable, List, Optional, Type, Union, cast\n\nfrom . import errors\nfrom .color import Color, ColorParseError, ColorSystem, blend_rgb\nfrom .repr import Result, rich_repr\nfrom .terminal_theme import DEFAULT_TERMINAL_THEME, TerminalTheme\n\n# Style instances and style definitions are often interchangeable\nStyleType = Union[str, \"Style\"]\n\n\nclass _Bit:\n    \"\"\"A descriptor to get/set a style attribute bit.\"\"\"\n\n    __slots__ = [\"bit\"]\n\n    def __init__(self, bit_no: int) -> None:\n        self.bit = 1 << bit_no\n\n    def __get__(self, obj: \"Style\", objtype: Type[\"Style\"]) -> Optional[bool]:\n        if obj._set_attributes & self.bit:\n            return obj._attributes & self.bit != 0\n        return None\n\n\n@rich_repr\nclass Style:\n    \"\"\"A terminal style.\n\n    A terminal style consists of a color (`color`), a background color (`bgcolor`), and a number of attributes, such\n    as bold, italic etc. The attributes have 3 states: they can either be on\n    (``True``), off (``False``), or not set (``None``).\n\n    Args:\n        color (Union[Color, str], optional): Color of terminal text. Defaults to None.\n        bgcolor (Union[Color, str], optional): Color of terminal background. Defaults to None.\n        bold (bool, optional): Enable bold text. Defaults to None.\n        dim (bool, optional): Enable dim text. Defaults to None.\n        italic (bool, optional): Enable italic text. Defaults to None.\n        underline (bool, optional): Enable underlined text. Defaults to None.\n        blink (bool, optional): Enabled blinking text. Defaults to None.\n        blink2 (bool, optional): Enable fast blinking text. Defaults to None.\n        reverse (bool, optional): Enabled reverse text. Defaults to None.\n        conceal (bool, optional): Enable concealed text. Defaults to None.\n        strike (bool, optional): Enable strikethrough text. Defaults to None.\n        underline2 (bool, optional): Enable doubly underlined text. Defaults to None.\n        frame (bool, optional): Enable framed text. Defaults to None.\n        encircle (bool, optional): Enable encircled text. Defaults to None.\n        overline (bool, optional): Enable overlined text. Defaults to None.\n        link (str, link): Link URL. Defaults to None.\n\n    \"\"\"\n\n    _color: Optional[Color]\n    _bgcolor: Optional[Color]\n    _attributes: int\n    _set_attributes: int\n    _hash: Optional[int]\n    _null: bool\n    _meta: Optional[bytes]\n\n    __slots__ = [\n        \"_color\",\n        \"_bgcolor\",\n        \"_attributes\",\n        \"_set_attributes\",\n        \"_link\",\n        \"_link_id\",\n        \"_ansi\",\n        \"_style_definition\",\n        \"_hash\",\n        \"_null\",\n        \"_meta\",\n    ]\n\n    # maps bits on to SGR parameter\n    _style_map = {\n        0: \"1\",\n        1: \"2\",\n        2: \"3\",\n        3: \"4\",\n        4: \"5\",\n        5: \"6\",\n        6: \"7\",\n        7: \"8\",\n        8: \"9\",\n        9: \"21\",\n        10: \"51\",\n        11: \"52\",\n        12: \"53\",\n    }\n\n    STYLE_ATTRIBUTES = {\n        \"dim\": \"dim\",\n        \"d\": \"dim\",\n        \"bold\": \"bold\",\n        \"b\": \"bold\",\n        \"italic\": \"italic\",\n        \"i\": \"italic\",\n        \"underline\": \"underline\",\n        \"u\": \"underline\",\n        \"blink\": \"blink\",\n        \"blink2\": \"blink2\",\n        \"reverse\": \"reverse\",\n        \"r\": \"reverse\",\n        \"conceal\": \"conceal\",\n        \"c\": \"conceal\",\n        \"strike\": \"strike\",\n        \"s\": \"strike\",\n        \"underline2\": \"underline2\",\n        \"uu\": \"underline2\",\n        \"frame\": \"frame\",\n        \"encircle\": \"encircle\",\n        \"overline\": \"overline\",\n        \"o\": \"overline\",\n    }\n\n    def __init__(\n        self,\n        *,\n        color: Optional[Union[Color, str]] = None,\n        bgcolor: Optional[Union[Color, str]] = None,\n        bold: Optional[bool] = None,\n        dim: Optional[bool] = None,\n        italic: Optional[bool] = None,\n        underline: Optional[bool] = None,\n        blink: Optional[bool] = None,\n        blink2: Optional[bool] = None,\n        reverse: Optional[bool] = None,\n        conceal: Optional[bool] = None,\n        strike: Optional[bool] = None,\n        underline2: Optional[bool] = None,\n        frame: Optional[bool] = None,\n        encircle: Optional[bool] = None,\n        overline: Optional[bool] = None,\n        link: Optional[str] = None,\n        meta: Optional[Dict[str, Any]] = None,\n    ):\n        self._ansi: Optional[str] = None\n        self._style_definition: Optional[str] = None\n\n        def _make_color(color: Union[Color, str]) -> Color:\n            return color if isinstance(color, Color) else Color.parse(color)\n\n        self._color = None if color is None else _make_color(color)\n        self._bgcolor = None if bgcolor is None else _make_color(bgcolor)\n        self._set_attributes = sum(\n            (\n                bold is not None,\n                dim is not None and 2,\n                italic is not None and 4,\n                underline is not None and 8,\n                blink is not None and 16,\n                blink2 is not None and 32,\n                reverse is not None and 64,\n                conceal is not None and 128,\n                strike is not None and 256,\n                underline2 is not None and 512,\n                frame is not None and 1024,\n                encircle is not None and 2048,\n                overline is not None and 4096,\n            )\n        )\n        self._attributes = (\n            sum(\n                (\n                    bold and 1 or 0,\n                    dim and 2 or 0,\n                    italic and 4 or 0,\n                    underline and 8 or 0,\n                    blink and 16 or 0,\n                    blink2 and 32 or 0,\n                    reverse and 64 or 0,\n                    conceal and 128 or 0,\n                    strike and 256 or 0,\n                    underline2 and 512 or 0,\n                    frame and 1024 or 0,\n                    encircle and 2048 or 0,\n                    overline and 4096 or 0,\n                )\n            )\n            if self._set_attributes\n            else 0\n        )\n\n        self._link = link\n        self._meta = None if meta is None else dumps(meta)\n        self._link_id = (\n            f\"{randint(0, 999999)}{hash(self._meta)}\" if (link or meta) else \"\"\n        )\n        self._hash: Optional[int] = None\n        self._null = not (self._set_attributes or color or bgcolor or link or meta)\n\n    @classmethod\n    def null(cls) -> \"Style\":\n        \"\"\"Create an 'null' style, equivalent to Style(), but more performant.\"\"\"\n        return NULL_STYLE\n\n    @classmethod\n    def from_color(\n        cls, color: Optional[Color] = None, bgcolor: Optional[Color] = None\n    ) -> \"Style\":\n        \"\"\"Create a new style with colors and no attributes.\n\n        Returns:\n            color (Optional[Color]): A (foreground) color, or None for no color. Defaults to None.\n            bgcolor (Optional[Color]): A (background) color, or None for no color. Defaults to None.\n        \"\"\"\n        style: Style = cls.__new__(Style)\n        style._ansi = None\n        style._style_definition = None\n        style._color = color\n        style._bgcolor = bgcolor\n        style._set_attributes = 0\n        style._attributes = 0\n        style._link = None\n        style._link_id = \"\"\n        style._meta = None\n        style._null = not (color or bgcolor)\n        style._hash = None\n        return style\n\n    @classmethod\n    def from_meta(cls, meta: Optional[Dict[str, Any]]) -> \"Style\":\n        \"\"\"Create a new style with meta data.\n\n        Returns:\n            meta (Optional[Dict[str, Any]]): A dictionary of meta data. Defaults to None.\n        \"\"\"\n        style: Style = cls.__new__(Style)\n        style._ansi = None\n        style._style_definition = None\n        style._color = None\n        style._bgcolor = None\n        style._set_attributes = 0\n        style._attributes = 0\n        style._link = None\n        style._meta = dumps(meta)\n        style._link_id = f\"{randint(0, 999999)}{hash(style._meta)}\"\n        style._hash = None\n        style._null = not (meta)\n        return style\n\n    @classmethod\n    def on(cls, meta: Optional[Dict[str, Any]] = None, **handlers: Any) -> \"Style\":\n        \"\"\"Create a blank style with meta information.\n\n        Example:\n            style = Style.on(click=self.on_click)\n\n        Args:\n            meta (Optional[Dict[str, Any]], optional): An optional dict of meta information.\n            **handlers (Any): Keyword arguments are translated in to handlers.\n\n        Returns:\n            Style: A Style with meta information attached.\n        \"\"\"\n        meta = {} if meta is None else meta\n        meta.update({f\"@{key}\": value for key, value in handlers.items()})\n        return cls.from_meta(meta)\n\n    bold = _Bit(0)\n    dim = _Bit(1)\n    italic = _Bit(2)\n    underline = _Bit(3)\n    blink = _Bit(4)\n    blink2 = _Bit(5)\n    reverse = _Bit(6)\n    conceal = _Bit(7)\n    strike = _Bit(8)\n    underline2 = _Bit(9)\n    frame = _Bit(10)\n    encircle = _Bit(11)\n    overline = _Bit(12)\n\n    @property\n    def link_id(self) -> str:\n        \"\"\"Get a link id, used in ansi code for links.\"\"\"\n        return self._link_id\n\n    def __str__(self) -> str:\n        \"\"\"Re-generate style definition from attributes.\"\"\"\n        if self._style_definition is None:\n            attributes: List[str] = []\n            append = attributes.append\n            bits = self._set_attributes\n            if bits & 0b0000000001111:\n                if bits & 1:\n                    append(\"bold\" if self.bold else \"not bold\")\n                if bits & (1 << 1):\n                    append(\"dim\" if self.dim else \"not dim\")\n                if bits & (1 << 2):\n                    append(\"italic\" if self.italic else \"not italic\")\n                if bits & (1 << 3):\n                    append(\"underline\" if self.underline else \"not underline\")\n            if bits & 0b0000111110000:\n                if bits & (1 << 4):\n                    append(\"blink\" if self.blink else \"not blink\")\n                if bits & (1 << 5):\n                    append(\"blink2\" if self.blink2 else \"not blink2\")\n                if bits & (1 << 6):\n                    append(\"reverse\" if self.reverse else \"not reverse\")\n                if bits & (1 << 7):\n                    append(\"conceal\" if self.conceal else \"not conceal\")\n                if bits & (1 << 8):\n                    append(\"strike\" if self.strike else \"not strike\")\n            if bits & 0b1111000000000:\n                if bits & (1 << 9):\n                    append(\"underline2\" if self.underline2 else \"not underline2\")\n                if bits & (1 << 10):\n                    append(\"frame\" if self.frame else \"not frame\")\n                if bits & (1 << 11):\n                    append(\"encircle\" if self.encircle else \"not encircle\")\n                if bits & (1 << 12):\n                    append(\"overline\" if self.overline else \"not overline\")\n            if self._color is not None:\n                append(self._color.name)\n            if self._bgcolor is not None:\n                append(\"on\")\n                append(self._bgcolor.name)\n            if self._link:\n                append(\"link\")\n                append(self._link)\n            self._style_definition = \" \".join(attributes) or \"none\"\n        return self._style_definition\n\n    def __bool__(self) -> bool:\n        \"\"\"A Style is false if it has no attributes, colors, or links.\"\"\"\n        return not self._null\n\n    def _make_ansi_codes(self, color_system: ColorSystem) -> str:\n        \"\"\"Generate ANSI codes for this style.\n\n        Args:\n            color_system (ColorSystem): Color system.\n\n        Returns:\n            str: String containing codes.\n        \"\"\"\n\n        if self._ansi is None:\n            sgr: List[str] = []\n            append = sgr.append\n            _style_map = self._style_map\n            attributes = self._attributes & self._set_attributes\n            if attributes:\n                if attributes & 1:\n                    append(_style_map[0])\n                if attributes & 2:\n                    append(_style_map[1])\n                if attributes & 4:\n                    append(_style_map[2])\n                if attributes & 8:\n                    append(_style_map[3])\n                if attributes & 0b0000111110000:\n                    for bit in range(4, 9):\n                        if attributes & (1 << bit):\n                            append(_style_map[bit])\n                if attributes & 0b1111000000000:\n                    for bit in range(9, 13):\n                        if attributes & (1 << bit):\n                            append(_style_map[bit])\n            if self._color is not None:\n                sgr.extend(self._color.downgrade(color_system).get_ansi_codes())\n            if self._bgcolor is not None:\n                sgr.extend(\n                    self._bgcolor.downgrade(color_system).get_ansi_codes(\n                        foreground=False\n                    )\n                )\n            self._ansi = \";\".join(sgr)\n        return self._ansi\n\n    @classmethod\n    @lru_cache(maxsize=1024)\n    def normalize(cls, style: str) -> str:\n        \"\"\"Normalize a style definition so that styles with the same effect have the same string\n        representation.\n\n        Args:\n            style (str): A style definition.\n\n        Returns:\n            str: Normal form of style definition.\n        \"\"\"\n        try:\n            return str(cls.parse(style))\n        except errors.StyleSyntaxError:\n            return style.strip().lower()\n\n    @classmethod\n    def pick_first(cls, *values: Optional[StyleType]) -> StyleType:\n        \"\"\"Pick first non-None style.\"\"\"\n        for value in values:\n            if value is not None:\n                return value\n        raise ValueError(\"expected at least one non-None style\")\n\n    def __rich_repr__(self) -> Result:\n        yield \"color\", self.color, None\n        yield \"bgcolor\", self.bgcolor, None\n        yield \"bold\", self.bold, None,\n        yield \"dim\", self.dim, None,\n        yield \"italic\", self.italic, None\n        yield \"underline\", self.underline, None,\n        yield \"blink\", self.blink, None\n        yield \"blink2\", self.blink2, None\n        yield \"reverse\", self.reverse, None\n        yield \"conceal\", self.conceal, None\n        yield \"strike\", self.strike, None\n        yield \"underline2\", self.underline2, None\n        yield \"frame\", self.frame, None\n        yield \"encircle\", self.encircle, None\n        yield \"link\", self.link, None\n        if self._meta:\n            yield \"meta\", self.meta\n\n    def __eq__(self, other: Any) -> bool:\n        if not isinstance(other, Style):\n            return NotImplemented\n        return self.__hash__() == other.__hash__()\n\n    def __ne__(self, other: Any) -> bool:\n        if not isinstance(other, Style):\n            return NotImplemented\n        return self.__hash__() != other.__hash__()\n\n    def __hash__(self) -> int:\n        if self._hash is not None:\n            return self._hash\n        self._hash = hash(\n            (\n                self._color,\n                self._bgcolor,\n                self._attributes,\n                self._set_attributes,\n                self._link,\n                self._meta,\n            )\n        )\n        return self._hash\n\n    @property\n    def color(self) -> Optional[Color]:\n        \"\"\"The foreground color or None if it is not set.\"\"\"\n        return self._color\n\n    @property\n    def bgcolor(self) -> Optional[Color]:\n        \"\"\"The background color or None if it is not set.\"\"\"\n        return self._bgcolor\n\n    @property\n    def link(self) -> Optional[str]:\n        \"\"\"Link text, if set.\"\"\"\n        return self._link\n\n    @property\n    def transparent_background(self) -> bool:\n        \"\"\"Check if the style specified a transparent background.\"\"\"\n        return self.bgcolor is None or self.bgcolor.is_default\n\n    @property\n    def background_style(self) -> \"Style\":\n        \"\"\"A Style with background only.\"\"\"\n        return Style(bgcolor=self.bgcolor)\n\n    @property\n    def meta(self) -> Dict[str, Any]:\n        \"\"\"Get meta information (can not be changed after construction).\"\"\"\n        return {} if self._meta is None else cast(Dict[str, Any], loads(self._meta))\n\n    @property\n    def without_color(self) -> \"Style\":\n        \"\"\"Get a copy of the style with color removed.\"\"\"\n        if self._null:\n            return NULL_STYLE\n        style: Style = self.__new__(Style)\n        style._ansi = None\n        style._style_definition = None\n        style._color = None\n        style._bgcolor = None\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = self._link\n        style._link_id = f\"{randint(0, 999999)}\" if self._link else \"\"\n        style._null = False\n        style._meta = None\n        style._hash = None\n        return style\n\n    @classmethod\n    @lru_cache(maxsize=4096)\n    def parse(cls, style_definition: str) -> \"Style\":\n        \"\"\"Parse a style definition.\n\n        Args:\n            style_definition (str): A string containing a style.\n\n        Raises:\n            errors.StyleSyntaxError: If the style definition syntax is invalid.\n\n        Returns:\n            `Style`: A Style instance.\n        \"\"\"\n        if style_definition.strip() == \"none\" or not style_definition:\n            return cls.null()\n\n        STYLE_ATTRIBUTES = cls.STYLE_ATTRIBUTES\n        color: Optional[str] = None\n        bgcolor: Optional[str] = None\n        attributes: Dict[str, Optional[Any]] = {}\n        link: Optional[str] = None\n\n        words = iter(style_definition.split())\n        for original_word in words:\n            word = original_word.lower()\n            if word == \"on\":\n                word = next(words, \"\")\n                if not word:\n                    raise errors.StyleSyntaxError(\"color expected after 'on'\")\n                try:\n                    Color.parse(word)\n                except ColorParseError as error:\n                    raise errors.StyleSyntaxError(\n                        f\"unable to parse {word!r} as background color; {error}\"\n                    ) from None\n                bgcolor = word\n\n            elif word == \"not\":\n                word = next(words, \"\")\n                attribute = STYLE_ATTRIBUTES.get(word)\n                if attribute is None:\n                    raise errors.StyleSyntaxError(\n                        f\"expected style attribute after 'not', found {word!r}\"\n                    )\n                attributes[attribute] = False\n\n            elif word == \"link\":\n                word = next(words, \"\")\n                if not word:\n                    raise errors.StyleSyntaxError(\"URL expected after 'link'\")\n                link = word\n\n            elif word in STYLE_ATTRIBUTES:\n                attributes[STYLE_ATTRIBUTES[word]] = True\n\n            else:\n                try:\n                    Color.parse(word)\n                except ColorParseError as error:\n                    raise errors.StyleSyntaxError(\n                        f\"unable to parse {word!r} as color; {error}\"\n                    ) from None\n                color = word\n        style = Style(color=color, bgcolor=bgcolor, link=link, **attributes)\n        return style\n\n    @lru_cache(maxsize=1024)\n    def get_html_style(self, theme: Optional[TerminalTheme] = None) -> str:\n        \"\"\"Get a CSS style rule.\"\"\"\n        theme = theme or DEFAULT_TERMINAL_THEME\n        css: List[str] = []\n        append = css.append\n\n        color = self.color\n        bgcolor = self.bgcolor\n        if self.reverse:\n            color, bgcolor = bgcolor, color\n        if self.dim:\n            foreground_color = (\n                theme.foreground_color if color is None else color.get_truecolor(theme)\n            )\n            color = Color.from_triplet(\n                blend_rgb(foreground_color, theme.background_color, 0.5)\n            )\n        if color is not None:\n            theme_color = color.get_truecolor(theme)\n            append(f\"color: {theme_color.hex}\")\n            append(f\"text-decoration-color: {theme_color.hex}\")\n        if bgcolor is not None:\n            theme_color = bgcolor.get_truecolor(theme, foreground=False)\n            append(f\"background-color: {theme_color.hex}\")\n        if self.bold:\n            append(\"font-weight: bold\")\n        if self.italic:\n            append(\"font-style: italic\")\n        if self.underline:\n            append(\"text-decoration: underline\")\n        if self.strike:\n            append(\"text-decoration: line-through\")\n        if self.overline:\n            append(\"text-decoration: overline\")\n        return \"; \".join(css)\n\n    @classmethod\n    def combine(cls, styles: Iterable[\"Style\"]) -> \"Style\":\n        \"\"\"Combine styles and get result.\n\n        Args:\n            styles (Iterable[Style]): Styles to combine.\n\n        Returns:\n            Style: A new style instance.\n        \"\"\"\n        iter_styles = iter(styles)\n        return sum(iter_styles, next(iter_styles))\n\n    @classmethod\n    def chain(cls, *styles: \"Style\") -> \"Style\":\n        \"\"\"Combine styles from positional argument in to a single style.\n\n        Args:\n            *styles (Iterable[Style]): Styles to combine.\n\n        Returns:\n            Style: A new style instance.\n        \"\"\"\n        iter_styles = iter(styles)\n        return sum(iter_styles, next(iter_styles))\n\n    def copy(self) -> \"Style\":\n        \"\"\"Get a copy of this style.\n\n        Returns:\n            Style: A new Style instance with identical attributes.\n        \"\"\"\n        if self._null:\n            return NULL_STYLE\n        style: Style = self.__new__(Style)\n        style._ansi = self._ansi\n        style._style_definition = self._style_definition\n        style._color = self._color\n        style._bgcolor = self._bgcolor\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = self._link\n        style._link_id = f\"{randint(0, 999999)}\" if self._link else \"\"\n        style._hash = self._hash\n        style._null = False\n        style._meta = self._meta\n        return style\n\n    @lru_cache(maxsize=128)\n    def clear_meta_and_links(self) -> \"Style\":\n        \"\"\"Get a copy of this style with link and meta information removed.\n\n        Returns:\n            Style: New style object.\n        \"\"\"\n        if self._null:\n            return NULL_STYLE\n        style: Style = self.__new__(Style)\n        style._ansi = self._ansi\n        style._style_definition = self._style_definition\n        style._color = self._color\n        style._bgcolor = self._bgcolor\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = None\n        style._link_id = \"\"\n        style._hash = None\n        style._null = False\n        style._meta = None\n        return style\n\n    def update_link(self, link: Optional[str] = None) -> \"Style\":\n        \"\"\"Get a copy with a different value for link.\n\n        Args:\n            link (str, optional): New value for link. Defaults to None.\n\n        Returns:\n            Style: A new Style instance.\n        \"\"\"\n        style: Style = self.__new__(Style)\n        style._ansi = self._ansi\n        style._style_definition = self._style_definition\n        style._color = self._color\n        style._bgcolor = self._bgcolor\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = link\n        style._link_id = f\"{randint(0, 999999)}\" if link else \"\"\n        style._hash = None\n        style._null = False\n        style._meta = self._meta\n        return style\n\n    def render(\n        self,\n        text: str = \"\",\n        *,\n        color_system: Optional[ColorSystem] = ColorSystem.TRUECOLOR,\n        legacy_windows: bool = False,\n    ) -> str:\n        \"\"\"Render the ANSI codes for the style.\n\n        Args:\n            text (str, optional): A string to style. Defaults to \"\".\n            color_system (Optional[ColorSystem], optional): Color system to render to. Defaults to ColorSystem.TRUECOLOR.\n\n        Returns:\n            str: A string containing ANSI style codes.\n        \"\"\"\n        if not text or color_system is None:\n            return text\n        attrs = self._ansi or self._make_ansi_codes(color_system)\n        rendered = f\"\\x1b[{attrs}m{text}\\x1b[0m\" if attrs else text\n        if self._link and not legacy_windows:\n            rendered = (\n                f\"\\x1b]8;id={self._link_id};{self._link}\\x1b\\\\{rendered}\\x1b]8;;\\x1b\\\\\"\n            )\n        return rendered\n\n    def test(self, text: Optional[str] = None) -> None:\n        \"\"\"Write text with style directly to terminal.\n\n        This method is for testing purposes only.\n\n        Args:\n            text (Optional[str], optional): Text to style or None for style name.\n\n        \"\"\"\n        text = text or str(self)\n        sys.stdout.write(f\"{self.render(text)}\\n\")\n\n    @lru_cache(maxsize=1024)\n    def _add(self, style: Optional[\"Style\"]) -> \"Style\":\n        if style is None or style._null:\n            return self\n        if self._null:\n            return style\n        new_style: Style = self.__new__(Style)\n        new_style._ansi = None\n        new_style._style_definition = None\n        new_style._color = style._color or self._color\n        new_style._bgcolor = style._bgcolor or self._bgcolor\n        new_style._attributes = (self._attributes & ~style._set_attributes) | (\n            style._attributes & style._set_attributes\n        )\n        new_style._set_attributes = self._set_attributes | style._set_attributes\n        new_style._link = style._link or self._link\n        new_style._link_id = style._link_id or self._link_id\n        new_style._null = style._null\n        if self._meta and style._meta:\n            new_style._meta = dumps({**self.meta, **style.meta})\n        else:\n            new_style._meta = self._meta or style._meta\n        new_style._hash = None\n        return new_style\n\n    def __add__(self, style: Optional[\"Style\"]) -> \"Style\":\n        combined_style = self._add(style)\n        return combined_style.copy() if combined_style.link else combined_style\n\n\nNULL_STYLE = Style()\n\n\nclass StyleStack:\n    \"\"\"A stack of styles.\"\"\"\n\n    __slots__ = [\"_stack\"]\n\n    def __init__(self, default_style: \"Style\") -> None:\n        self._stack: List[Style] = [default_style]\n\n    def __repr__(self) -> str:\n        return f\"<stylestack {self._stack!r}>\"\n\n    @property\n    def current(self) -> Style:\n        \"\"\"Get the Style at the top of the stack.\"\"\"\n        return self._stack[-1]\n\n    def push(self, style: Style) -> None:\n        \"\"\"Push a new style on to the stack.\n\n        Args:\n            style (Style): New style to combine with current style.\n        \"\"\"\n        self._stack.append(self._stack[-1] + style)\n\n    def pop(self) -> Style:\n        \"\"\"Pop last style and discard.\n\n        Returns:\n            Style: New current style (also available as stack.current)\n        \"\"\"\n        self._stack.pop()\n        return self._stack[-1]\n",
      "code_after": "import sys\nfrom functools import lru_cache\nfrom operator import attrgetter\nfrom pickle import dumps, loads\nfrom random import randint\nfrom typing import Any, Dict, Iterable, List, Optional, Type, Union, cast\n\nfrom . import errors\nfrom .color import Color, ColorParseError, ColorSystem, blend_rgb\nfrom .repr import Result, rich_repr\nfrom .terminal_theme import DEFAULT_TERMINAL_THEME, TerminalTheme\n\n_hash_getter = attrgetter(\n    \"_color\", \"_bgcolor\", \"_attributes\", \"_set_attributes\", \"_link\", \"_meta\"\n)\n\n# Style instances and style definitions are often interchangeable\nStyleType = Union[str, \"Style\"]\n\n\nclass _Bit:\n    \"\"\"A descriptor to get/set a style attribute bit.\"\"\"\n\n    __slots__ = [\"bit\"]\n\n    def __init__(self, bit_no: int) -> None:\n        self.bit = 1 << bit_no\n\n    def __get__(self, obj: \"Style\", objtype: Type[\"Style\"]) -> Optional[bool]:\n        if obj._set_attributes & self.bit:\n            return obj._attributes & self.bit != 0\n        return None\n\n\n@rich_repr\nclass Style:\n    \"\"\"A terminal style.\n\n    A terminal style consists of a color (`color`), a background color (`bgcolor`), and a number of attributes, such\n    as bold, italic etc. The attributes have 3 states: they can either be on\n    (``True``), off (``False``), or not set (``None``).\n\n    Args:\n        color (Union[Color, str], optional): Color of terminal text. Defaults to None.\n        bgcolor (Union[Color, str], optional): Color of terminal background. Defaults to None.\n        bold (bool, optional): Enable bold text. Defaults to None.\n        dim (bool, optional): Enable dim text. Defaults to None.\n        italic (bool, optional): Enable italic text. Defaults to None.\n        underline (bool, optional): Enable underlined text. Defaults to None.\n        blink (bool, optional): Enabled blinking text. Defaults to None.\n        blink2 (bool, optional): Enable fast blinking text. Defaults to None.\n        reverse (bool, optional): Enabled reverse text. Defaults to None.\n        conceal (bool, optional): Enable concealed text. Defaults to None.\n        strike (bool, optional): Enable strikethrough text. Defaults to None.\n        underline2 (bool, optional): Enable doubly underlined text. Defaults to None.\n        frame (bool, optional): Enable framed text. Defaults to None.\n        encircle (bool, optional): Enable encircled text. Defaults to None.\n        overline (bool, optional): Enable overlined text. Defaults to None.\n        link (str, link): Link URL. Defaults to None.\n\n    \"\"\"\n\n    _color: Optional[Color]\n    _bgcolor: Optional[Color]\n    _attributes: int\n    _set_attributes: int\n    _hash: Optional[int]\n    _null: bool\n    _meta: Optional[bytes]\n\n    __slots__ = [\n        \"_color\",\n        \"_bgcolor\",\n        \"_attributes\",\n        \"_set_attributes\",\n        \"_link\",\n        \"_link_id\",\n        \"_ansi\",\n        \"_style_definition\",\n        \"_hash\",\n        \"_null\",\n        \"_meta\",\n    ]\n\n    # maps bits on to SGR parameter\n    _style_map = {\n        0: \"1\",\n        1: \"2\",\n        2: \"3\",\n        3: \"4\",\n        4: \"5\",\n        5: \"6\",\n        6: \"7\",\n        7: \"8\",\n        8: \"9\",\n        9: \"21\",\n        10: \"51\",\n        11: \"52\",\n        12: \"53\",\n    }\n\n    STYLE_ATTRIBUTES = {\n        \"dim\": \"dim\",\n        \"d\": \"dim\",\n        \"bold\": \"bold\",\n        \"b\": \"bold\",\n        \"italic\": \"italic\",\n        \"i\": \"italic\",\n        \"underline\": \"underline\",\n        \"u\": \"underline\",\n        \"blink\": \"blink\",\n        \"blink2\": \"blink2\",\n        \"reverse\": \"reverse\",\n        \"r\": \"reverse\",\n        \"conceal\": \"conceal\",\n        \"c\": \"conceal\",\n        \"strike\": \"strike\",\n        \"s\": \"strike\",\n        \"underline2\": \"underline2\",\n        \"uu\": \"underline2\",\n        \"frame\": \"frame\",\n        \"encircle\": \"encircle\",\n        \"overline\": \"overline\",\n        \"o\": \"overline\",\n    }\n\n    def __init__(\n        self,\n        *,\n        color: Optional[Union[Color, str]] = None,\n        bgcolor: Optional[Union[Color, str]] = None,\n        bold: Optional[bool] = None,\n        dim: Optional[bool] = None,\n        italic: Optional[bool] = None,\n        underline: Optional[bool] = None,\n        blink: Optional[bool] = None,\n        blink2: Optional[bool] = None,\n        reverse: Optional[bool] = None,\n        conceal: Optional[bool] = None,\n        strike: Optional[bool] = None,\n        underline2: Optional[bool] = None,\n        frame: Optional[bool] = None,\n        encircle: Optional[bool] = None,\n        overline: Optional[bool] = None,\n        link: Optional[str] = None,\n        meta: Optional[Dict[str, Any]] = None,\n    ):\n        self._ansi: Optional[str] = None\n        self._style_definition: Optional[str] = None\n\n        def _make_color(color: Union[Color, str]) -> Color:\n            return color if isinstance(color, Color) else Color.parse(color)\n\n        self._color = None if color is None else _make_color(color)\n        self._bgcolor = None if bgcolor is None else _make_color(bgcolor)\n        self._set_attributes = sum(\n            (\n                bold is not None,\n                dim is not None and 2,\n                italic is not None and 4,\n                underline is not None and 8,\n                blink is not None and 16,\n                blink2 is not None and 32,\n                reverse is not None and 64,\n                conceal is not None and 128,\n                strike is not None and 256,\n                underline2 is not None and 512,\n                frame is not None and 1024,\n                encircle is not None and 2048,\n                overline is not None and 4096,\n            )\n        )\n        self._attributes = (\n            sum(\n                (\n                    bold and 1 or 0,\n                    dim and 2 or 0,\n                    italic and 4 or 0,\n                    underline and 8 or 0,\n                    blink and 16 or 0,\n                    blink2 and 32 or 0,\n                    reverse and 64 or 0,\n                    conceal and 128 or 0,\n                    strike and 256 or 0,\n                    underline2 and 512 or 0,\n                    frame and 1024 or 0,\n                    encircle and 2048 or 0,\n                    overline and 4096 or 0,\n                )\n            )\n            if self._set_attributes\n            else 0\n        )\n\n        self._link = link\n        self._meta = None if meta is None else dumps(meta)\n        self._link_id = (\n            f\"{randint(0, 999999)}{hash(self._meta)}\" if (link or meta) else \"\"\n        )\n        self._hash: Optional[int] = None\n        self._null = not (self._set_attributes or color or bgcolor or link or meta)\n\n    @classmethod\n    def null(cls) -> \"Style\":\n        \"\"\"Create an 'null' style, equivalent to Style(), but more performant.\"\"\"\n        return NULL_STYLE\n\n    @classmethod\n    def from_color(\n        cls, color: Optional[Color] = None, bgcolor: Optional[Color] = None\n    ) -> \"Style\":\n        \"\"\"Create a new style with colors and no attributes.\n\n        Returns:\n            color (Optional[Color]): A (foreground) color, or None for no color. Defaults to None.\n            bgcolor (Optional[Color]): A (background) color, or None for no color. Defaults to None.\n        \"\"\"\n        style: Style = cls.__new__(Style)\n        style._ansi = None\n        style._style_definition = None\n        style._color = color\n        style._bgcolor = bgcolor\n        style._set_attributes = 0\n        style._attributes = 0\n        style._link = None\n        style._link_id = \"\"\n        style._meta = None\n        style._null = not (color or bgcolor)\n        style._hash = None\n        return style\n\n    @classmethod\n    def from_meta(cls, meta: Optional[Dict[str, Any]]) -> \"Style\":\n        \"\"\"Create a new style with meta data.\n\n        Returns:\n            meta (Optional[Dict[str, Any]]): A dictionary of meta data. Defaults to None.\n        \"\"\"\n        style: Style = cls.__new__(Style)\n        style._ansi = None\n        style._style_definition = None\n        style._color = None\n        style._bgcolor = None\n        style._set_attributes = 0\n        style._attributes = 0\n        style._link = None\n        style._meta = dumps(meta)\n        style._link_id = f\"{randint(0, 999999)}{hash(style._meta)}\"\n        style._hash = None\n        style._null = not (meta)\n        return style\n\n    @classmethod\n    def on(cls, meta: Optional[Dict[str, Any]] = None, **handlers: Any) -> \"Style\":\n        \"\"\"Create a blank style with meta information.\n\n        Example:\n            style = Style.on(click=self.on_click)\n\n        Args:\n            meta (Optional[Dict[str, Any]], optional): An optional dict of meta information.\n            **handlers (Any): Keyword arguments are translated in to handlers.\n\n        Returns:\n            Style: A Style with meta information attached.\n        \"\"\"\n        meta = {} if meta is None else meta\n        meta.update({f\"@{key}\": value for key, value in handlers.items()})\n        return cls.from_meta(meta)\n\n    bold = _Bit(0)\n    dim = _Bit(1)\n    italic = _Bit(2)\n    underline = _Bit(3)\n    blink = _Bit(4)\n    blink2 = _Bit(5)\n    reverse = _Bit(6)\n    conceal = _Bit(7)\n    strike = _Bit(8)\n    underline2 = _Bit(9)\n    frame = _Bit(10)\n    encircle = _Bit(11)\n    overline = _Bit(12)\n\n    @property\n    def link_id(self) -> str:\n        \"\"\"Get a link id, used in ansi code for links.\"\"\"\n        return self._link_id\n\n    def __str__(self) -> str:\n        \"\"\"Re-generate style definition from attributes.\"\"\"\n        if self._style_definition is None:\n            attributes: List[str] = []\n            append = attributes.append\n            bits = self._set_attributes\n            if bits & 0b0000000001111:\n                if bits & 1:\n                    append(\"bold\" if self.bold else \"not bold\")\n                if bits & (1 << 1):\n                    append(\"dim\" if self.dim else \"not dim\")\n                if bits & (1 << 2):\n                    append(\"italic\" if self.italic else \"not italic\")\n                if bits & (1 << 3):\n                    append(\"underline\" if self.underline else \"not underline\")\n            if bits & 0b0000111110000:\n                if bits & (1 << 4):\n                    append(\"blink\" if self.blink else \"not blink\")\n                if bits & (1 << 5):\n                    append(\"blink2\" if self.blink2 else \"not blink2\")\n                if bits & (1 << 6):\n                    append(\"reverse\" if self.reverse else \"not reverse\")\n                if bits & (1 << 7):\n                    append(\"conceal\" if self.conceal else \"not conceal\")\n                if bits & (1 << 8):\n                    append(\"strike\" if self.strike else \"not strike\")\n            if bits & 0b1111000000000:\n                if bits & (1 << 9):\n                    append(\"underline2\" if self.underline2 else \"not underline2\")\n                if bits & (1 << 10):\n                    append(\"frame\" if self.frame else \"not frame\")\n                if bits & (1 << 11):\n                    append(\"encircle\" if self.encircle else \"not encircle\")\n                if bits & (1 << 12):\n                    append(\"overline\" if self.overline else \"not overline\")\n            if self._color is not None:\n                append(self._color.name)\n            if self._bgcolor is not None:\n                append(\"on\")\n                append(self._bgcolor.name)\n            if self._link:\n                append(\"link\")\n                append(self._link)\n            self._style_definition = \" \".join(attributes) or \"none\"\n        return self._style_definition\n\n    def __bool__(self) -> bool:\n        \"\"\"A Style is false if it has no attributes, colors, or links.\"\"\"\n        return not self._null\n\n    def _make_ansi_codes(self, color_system: ColorSystem) -> str:\n        \"\"\"Generate ANSI codes for this style.\n\n        Args:\n            color_system (ColorSystem): Color system.\n\n        Returns:\n            str: String containing codes.\n        \"\"\"\n\n        if self._ansi is None:\n            sgr: List[str] = []\n            append = sgr.append\n            _style_map = self._style_map\n            attributes = self._attributes & self._set_attributes\n            if attributes:\n                if attributes & 1:\n                    append(_style_map[0])\n                if attributes & 2:\n                    append(_style_map[1])\n                if attributes & 4:\n                    append(_style_map[2])\n                if attributes & 8:\n                    append(_style_map[3])\n                if attributes & 0b0000111110000:\n                    for bit in range(4, 9):\n                        if attributes & (1 << bit):\n                            append(_style_map[bit])\n                if attributes & 0b1111000000000:\n                    for bit in range(9, 13):\n                        if attributes & (1 << bit):\n                            append(_style_map[bit])\n            if self._color is not None:\n                sgr.extend(self._color.downgrade(color_system).get_ansi_codes())\n            if self._bgcolor is not None:\n                sgr.extend(\n                    self._bgcolor.downgrade(color_system).get_ansi_codes(\n                        foreground=False\n                    )\n                )\n            self._ansi = \";\".join(sgr)\n        return self._ansi\n\n    @classmethod\n    @lru_cache(maxsize=1024)\n    def normalize(cls, style: str) -> str:\n        \"\"\"Normalize a style definition so that styles with the same effect have the same string\n        representation.\n\n        Args:\n            style (str): A style definition.\n\n        Returns:\n            str: Normal form of style definition.\n        \"\"\"\n        try:\n            return str(cls.parse(style))\n        except errors.StyleSyntaxError:\n            return style.strip().lower()\n\n    @classmethod\n    def pick_first(cls, *values: Optional[StyleType]) -> StyleType:\n        \"\"\"Pick first non-None style.\"\"\"\n        for value in values:\n            if value is not None:\n                return value\n        raise ValueError(\"expected at least one non-None style\")\n\n    def __rich_repr__(self) -> Result:\n        yield \"color\", self.color, None\n        yield \"bgcolor\", self.bgcolor, None\n        yield \"bold\", self.bold, None,\n        yield \"dim\", self.dim, None,\n        yield \"italic\", self.italic, None\n        yield \"underline\", self.underline, None,\n        yield \"blink\", self.blink, None\n        yield \"blink2\", self.blink2, None\n        yield \"reverse\", self.reverse, None\n        yield \"conceal\", self.conceal, None\n        yield \"strike\", self.strike, None\n        yield \"underline2\", self.underline2, None\n        yield \"frame\", self.frame, None\n        yield \"encircle\", self.encircle, None\n        yield \"link\", self.link, None\n        if self._meta:\n            yield \"meta\", self.meta\n\n    def __eq__(self, other: Any) -> bool:\n        if not isinstance(other, Style):\n            return NotImplemented\n        return self.__hash__() == other.__hash__()\n\n    def __ne__(self, other: Any) -> bool:\n        if not isinstance(other, Style):\n            return NotImplemented\n        return self.__hash__() != other.__hash__()\n\n    def __hash__(self) -> int:\n        if self._hash is not None:\n            return self._hash\n        self._hash = hash(_hash_getter(self))\n        return self._hash\n\n    @property\n    def color(self) -> Optional[Color]:\n        \"\"\"The foreground color or None if it is not set.\"\"\"\n        return self._color\n\n    @property\n    def bgcolor(self) -> Optional[Color]:\n        \"\"\"The background color or None if it is not set.\"\"\"\n        return self._bgcolor\n\n    @property\n    def link(self) -> Optional[str]:\n        \"\"\"Link text, if set.\"\"\"\n        return self._link\n\n    @property\n    def transparent_background(self) -> bool:\n        \"\"\"Check if the style specified a transparent background.\"\"\"\n        return self.bgcolor is None or self.bgcolor.is_default\n\n    @property\n    def background_style(self) -> \"Style\":\n        \"\"\"A Style with background only.\"\"\"\n        return Style(bgcolor=self.bgcolor)\n\n    @property\n    def meta(self) -> Dict[str, Any]:\n        \"\"\"Get meta information (can not be changed after construction).\"\"\"\n        return {} if self._meta is None else cast(Dict[str, Any], loads(self._meta))\n\n    @property\n    def without_color(self) -> \"Style\":\n        \"\"\"Get a copy of the style with color removed.\"\"\"\n        if self._null:\n            return NULL_STYLE\n        style: Style = self.__new__(Style)\n        style._ansi = None\n        style._style_definition = None\n        style._color = None\n        style._bgcolor = None\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = self._link\n        style._link_id = f\"{randint(0, 999999)}\" if self._link else \"\"\n        style._null = False\n        style._meta = None\n        style._hash = None\n        return style\n\n    @classmethod\n    @lru_cache(maxsize=4096)\n    def parse(cls, style_definition: str) -> \"Style\":\n        \"\"\"Parse a style definition.\n\n        Args:\n            style_definition (str): A string containing a style.\n\n        Raises:\n            errors.StyleSyntaxError: If the style definition syntax is invalid.\n\n        Returns:\n            `Style`: A Style instance.\n        \"\"\"\n        if style_definition.strip() == \"none\" or not style_definition:\n            return cls.null()\n\n        STYLE_ATTRIBUTES = cls.STYLE_ATTRIBUTES\n        color: Optional[str] = None\n        bgcolor: Optional[str] = None\n        attributes: Dict[str, Optional[Any]] = {}\n        link: Optional[str] = None\n\n        words = iter(style_definition.split())\n        for original_word in words:\n            word = original_word.lower()\n            if word == \"on\":\n                word = next(words, \"\")\n                if not word:\n                    raise errors.StyleSyntaxError(\"color expected after 'on'\")\n                try:\n                    Color.parse(word)\n                except ColorParseError as error:\n                    raise errors.StyleSyntaxError(\n                        f\"unable to parse {word!r} as background color; {error}\"\n                    ) from None\n                bgcolor = word\n\n            elif word == \"not\":\n                word = next(words, \"\")\n                attribute = STYLE_ATTRIBUTES.get(word)\n                if attribute is None:\n                    raise errors.StyleSyntaxError(\n                        f\"expected style attribute after 'not', found {word!r}\"\n                    )\n                attributes[attribute] = False\n\n            elif word == \"link\":\n                word = next(words, \"\")\n                if not word:\n                    raise errors.StyleSyntaxError(\"URL expected after 'link'\")\n                link = word\n\n            elif word in STYLE_ATTRIBUTES:\n                attributes[STYLE_ATTRIBUTES[word]] = True\n\n            else:\n                try:\n                    Color.parse(word)\n                except ColorParseError as error:\n                    raise errors.StyleSyntaxError(\n                        f\"unable to parse {word!r} as color; {error}\"\n                    ) from None\n                color = word\n        style = Style(color=color, bgcolor=bgcolor, link=link, **attributes)\n        return style\n\n    @lru_cache(maxsize=1024)\n    def get_html_style(self, theme: Optional[TerminalTheme] = None) -> str:\n        \"\"\"Get a CSS style rule.\"\"\"\n        theme = theme or DEFAULT_TERMINAL_THEME\n        css: List[str] = []\n        append = css.append\n\n        color = self.color\n        bgcolor = self.bgcolor\n        if self.reverse:\n            color, bgcolor = bgcolor, color\n        if self.dim:\n            foreground_color = (\n                theme.foreground_color if color is None else color.get_truecolor(theme)\n            )\n            color = Color.from_triplet(\n                blend_rgb(foreground_color, theme.background_color, 0.5)\n            )\n        if color is not None:\n            theme_color = color.get_truecolor(theme)\n            append(f\"color: {theme_color.hex}\")\n            append(f\"text-decoration-color: {theme_color.hex}\")\n        if bgcolor is not None:\n            theme_color = bgcolor.get_truecolor(theme, foreground=False)\n            append(f\"background-color: {theme_color.hex}\")\n        if self.bold:\n            append(\"font-weight: bold\")\n        if self.italic:\n            append(\"font-style: italic\")\n        if self.underline:\n            append(\"text-decoration: underline\")\n        if self.strike:\n            append(\"text-decoration: line-through\")\n        if self.overline:\n            append(\"text-decoration: overline\")\n        return \"; \".join(css)\n\n    @classmethod\n    def combine(cls, styles: Iterable[\"Style\"]) -> \"Style\":\n        \"\"\"Combine styles and get result.\n\n        Args:\n            styles (Iterable[Style]): Styles to combine.\n\n        Returns:\n            Style: A new style instance.\n        \"\"\"\n        iter_styles = iter(styles)\n        return sum(iter_styles, next(iter_styles))\n\n    @classmethod\n    def chain(cls, *styles: \"Style\") -> \"Style\":\n        \"\"\"Combine styles from positional argument in to a single style.\n\n        Args:\n            *styles (Iterable[Style]): Styles to combine.\n\n        Returns:\n            Style: A new style instance.\n        \"\"\"\n        iter_styles = iter(styles)\n        return sum(iter_styles, next(iter_styles))\n\n    def copy(self) -> \"Style\":\n        \"\"\"Get a copy of this style.\n\n        Returns:\n            Style: A new Style instance with identical attributes.\n        \"\"\"\n        if self._null:\n            return NULL_STYLE\n        style: Style = self.__new__(Style)\n        style._ansi = self._ansi\n        style._style_definition = self._style_definition\n        style._color = self._color\n        style._bgcolor = self._bgcolor\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = self._link\n        style._link_id = f\"{randint(0, 999999)}\" if self._link else \"\"\n        style._hash = self._hash\n        style._null = False\n        style._meta = self._meta\n        return style\n\n    @lru_cache(maxsize=128)\n    def clear_meta_and_links(self) -> \"Style\":\n        \"\"\"Get a copy of this style with link and meta information removed.\n\n        Returns:\n            Style: New style object.\n        \"\"\"\n        if self._null:\n            return NULL_STYLE\n        style: Style = self.__new__(Style)\n        style._ansi = self._ansi\n        style._style_definition = self._style_definition\n        style._color = self._color\n        style._bgcolor = self._bgcolor\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = None\n        style._link_id = \"\"\n        style._hash = None\n        style._null = False\n        style._meta = None\n        return style\n\n    def update_link(self, link: Optional[str] = None) -> \"Style\":\n        \"\"\"Get a copy with a different value for link.\n\n        Args:\n            link (str, optional): New value for link. Defaults to None.\n\n        Returns:\n            Style: A new Style instance.\n        \"\"\"\n        style: Style = self.__new__(Style)\n        style._ansi = self._ansi\n        style._style_definition = self._style_definition\n        style._color = self._color\n        style._bgcolor = self._bgcolor\n        style._attributes = self._attributes\n        style._set_attributes = self._set_attributes\n        style._link = link\n        style._link_id = f\"{randint(0, 999999)}\" if link else \"\"\n        style._hash = None\n        style._null = False\n        style._meta = self._meta\n        return style\n\n    def render(\n        self,\n        text: str = \"\",\n        *,\n        color_system: Optional[ColorSystem] = ColorSystem.TRUECOLOR,\n        legacy_windows: bool = False,\n    ) -> str:\n        \"\"\"Render the ANSI codes for the style.\n\n        Args:\n            text (str, optional): A string to style. Defaults to \"\".\n            color_system (Optional[ColorSystem], optional): Color system to render to. Defaults to ColorSystem.TRUECOLOR.\n\n        Returns:\n            str: A string containing ANSI style codes.\n        \"\"\"\n        if not text or color_system is None:\n            return text\n        attrs = self._ansi or self._make_ansi_codes(color_system)\n        rendered = f\"\\x1b[{attrs}m{text}\\x1b[0m\" if attrs else text\n        if self._link and not legacy_windows:\n            rendered = (\n                f\"\\x1b]8;id={self._link_id};{self._link}\\x1b\\\\{rendered}\\x1b]8;;\\x1b\\\\\"\n            )\n        return rendered\n\n    def test(self, text: Optional[str] = None) -> None:\n        \"\"\"Write text with style directly to terminal.\n\n        This method is for testing purposes only.\n\n        Args:\n            text (Optional[str], optional): Text to style or None for style name.\n\n        \"\"\"\n        text = text or str(self)\n        sys.stdout.write(f\"{self.render(text)}\\n\")\n\n    @lru_cache(maxsize=1024)\n    def _add(self, style: Optional[\"Style\"]) -> \"Style\":\n        if style is None or style._null:\n            return self\n        if self._null:\n            return style\n        new_style: Style = self.__new__(Style)\n        new_style._ansi = None\n        new_style._style_definition = None\n        new_style._color = style._color or self._color\n        new_style._bgcolor = style._bgcolor or self._bgcolor\n        new_style._attributes = (self._attributes & ~style._set_attributes) | (\n            style._attributes & style._set_attributes\n        )\n        new_style._set_attributes = self._set_attributes | style._set_attributes\n        new_style._link = style._link or self._link\n        new_style._link_id = style._link_id or self._link_id\n        new_style._null = style._null\n        if self._meta and style._meta:\n            new_style._meta = dumps({**self.meta, **style.meta})\n        else:\n            new_style._meta = self._meta or style._meta\n        new_style._hash = None\n        return new_style\n\n    def __add__(self, style: Optional[\"Style\"]) -> \"Style\":\n        combined_style = self._add(style)\n        return combined_style.copy() if combined_style.link else combined_style\n\n\nNULL_STYLE = Style()\n\n\nclass StyleStack:\n    \"\"\"A stack of styles.\"\"\"\n\n    __slots__ = [\"_stack\"]\n\n    def __init__(self, default_style: \"Style\") -> None:\n        self._stack: List[Style] = [default_style]\n\n    def __repr__(self) -> str:\n        return f\"<stylestack {self._stack!r}>\"\n\n    @property\n    def current(self) -> Style:\n        \"\"\"Get the Style at the top of the stack.\"\"\"\n        return self._stack[-1]\n\n    def push(self, style: Style) -> None:\n        \"\"\"Push a new style on to the stack.\n\n        Args:\n            style (Style): New style to combine with current style.\n        \"\"\"\n        self._stack.append(self._stack[-1] + style)\n\n    def pop(self) -> Style:\n        \"\"\"Pop last style and discard.\n\n        Returns:\n            Style: New current style (also available as stack.current)\n        \"\"\"\n        self._stack.pop()\n        return self._stack[-1]\n",
      "bug_category": "import",
      "error_type": "import_error",
      "confidence": 0.2
    },
    {
      "bug_id": "8323878df759",
      "repo": "rich",
      "commit_hash": "655b521",
      "commit_message": "test fixes",
      "file_path": "tests/test_inspect.py",
      "language": "python",
      "code_before": "import io\nimport sys\nfrom types import ModuleType\nfrom typing import Sequence, Type\n\nimport pytest\n\nfrom rich import inspect\nfrom rich._inspect import (\n    get_object_types_mro,\n    get_object_types_mro_as_strings,\n    is_object_one_of_types,\n)\nfrom rich.console import Console\n\nskip_py38 = pytest.mark.skipif(\n    sys.version_info.minor == 8 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.8\",\n)\n\nskip_py39 = pytest.mark.skipif(\n    sys.version_info.minor == 9 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.9\",\n)\n\nskip_py310 = pytest.mark.skipif(\n    sys.version_info.minor == 10 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.10\",\n)\n\nskip_py311 = pytest.mark.skipif(\n    sys.version_info.minor == 11 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.11\",\n)\n\nskip_py312 = pytest.mark.skipif(\n    sys.version_info.minor == 12 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.12\",\n)\n\nskip_py313 = pytest.mark.skipif(\n    sys.version_info.minor == 13 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.13\",\n)\n\nskip_pypy3 = pytest.mark.skipif(\n    hasattr(sys, \"pypy_version_info\"),\n    reason=\"rendered differently on pypy3\",\n)\n\n\ndef render(obj, methods=False, value=False, width=50) -> str:\n    console = Console(file=io.StringIO(), width=width, legacy_windows=False)\n    inspect(obj, console=console, methods=methods, value=value)\n    return console.file.getvalue()\n\n\nclass InspectError(Exception):\n    def __str__(self) -> str:\n        return \"INSPECT ERROR\"\n\n\nclass Foo:\n    \"\"\"Foo test\n\n    Second line\n    \"\"\"\n\n    def __init__(self, foo: int) -> None:\n        \"\"\"constructor docs.\"\"\"\n        self.foo = foo\n\n    @property\n    def broken(self):\n        raise InspectError()\n\n    def method(self, a, b) -> str:\n        \"\"\"Multi line\n\n        docs.\n        \"\"\"\n        return \"test\"\n\n    def __dir__(self):\n        return [\"__init__\", \"broken\", \"method\"]\n\n\nclass FooSubclass(Foo):\n    pass\n\n\ndef test_render():\n    console = Console(width=100, file=io.StringIO(), legacy_windows=False)\n\n    foo = Foo(\"hello\")\n    inspect(foo, console=console, all=True, value=False)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'tests.test_inspect.Foo'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 Foo test                                                     \u2502\\n\u2502                                                              \u2502\\n\u2502   broken = InspectError()                                    \u2502\\n\u2502 __init__ = def __init__(foo: int) -> None: constructor docs. \u2502\\n\u2502   method = def method(a, b) -> str: Multi line               \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    assert result == expected\n\n\n@skip_pypy3\ndef test_inspect_text():\n    num_attributes = 34 if sys.version_info >= (3, 11) else 33\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'str'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 str(object='') -> str                          \u2502\\n\"\n        \"\u2502 str(bytes_or_buffer[, encoding[, errors]]) ->  \u2502\\n\"\n        \"\u2502 str                                            \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        f\"\u2502 {num_attributes} attribute(s) not shown. Run                 \u2502\\n\"\n        \"\u2502 inspect(inspect) for options.                  \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    print(repr(expected))\n    assert render(\"Hello\") == expected\n\n\n@skip_pypy3\ndef test_inspect_empty_dict():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'dict'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 dict() -> new empty dictionary                 \u2502\\n\"\n        \"\u2502 dict(mapping) -> new dictionary initialized    \u2502\\n\"\n        \"\u2502 from a mapping object's                        \u2502\\n\"\n        \"\u2502     (key, value) pairs                         \u2502\\n\"\n        \"\u2502 dict(iterable) -> new dictionary initialized   \u2502\\n\"\n        \"\u2502 as if via:                                     \u2502\\n\"\n        \"\u2502     d = {}                                     \u2502\\n\"\n        \"\u2502     for k, v in iterable:                      \u2502\\n\"\n        \"\u2502         d[k] = v                               \u2502\\n\"\n        \"\u2502 dict(**kwargs) -> new dictionary initialized   \u2502\\n\"\n        \"\u2502 with the name=value pairs                      \u2502\\n\"\n        \"\u2502     in the keyword argument list.  For         \u2502\\n\"\n        \"\u2502 example:  dict(one=1, two=2)                   \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n    )\n    assert render({}).startswith(expected)\n\n\n@skip_py313\n@skip_py312\n@skip_py311\n@skip_pypy3\ndef test_inspect_builtin_function_except_python311():\n    # Pre-3.11 Python versions - print builtin has no signature available\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <built-in function print> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 def print(...)                                 \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 print(value, ..., sep=' ', end='\\\\n',           \u2502\\n\"\n        \"\u2502 file=sys.stdout, flush=False)                  \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 29 attribute(s) not shown. Run                 \u2502\\n\"\n        \"\u2502 inspect(inspect) for options.                  \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(print) == expected\n\n\n@pytest.mark.skipif(\n    sys.version_info < (3, 11), reason=\"print builtin signature only available on 3.11+\"\n)\n@skip_pypy3\ndef test_inspect_builtin_function_only_python311():\n    # On 3.11, the print builtin *does* have a signature, unlike in prior versions\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <built-in function print> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 def print(*args, sep=' ', end='\\\\n', file=None, \u2502\\n\"\n        \"\u2502 flush=False):                                  \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 Prints the values to a stream, or to           \u2502\\n\"\n        \"\u2502 sys.stdout by default.                         \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 30 attribute(s) not shown. Run                 \u2502\\n\"\n        \"\u2502 inspect(inspect) for options.                  \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(print) == expected\n\n\n@skip_pypy3\ndef test_inspect_coroutine():\n    async def coroutine():\n        pass\n\n    expected = (\n        \"\u256d\u2500 <function test_inspect_coroutine.<locals>.cor\u2500\u256e\\n\"\n        \"\u2502 async def                                      \u2502\\n\"\n        \"\u2502 test_inspect_coroutine.<locals>.coroutine():   \u2502\\n\"\n    )\n    assert render(coroutine).startswith(expected)\n\n\ndef test_inspect_integer():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer        \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer \u2502\\n\"\n        \"\u2502                            \u2502\\n\"\n        \"\u2502 denominator = 1            \u2502\\n\"\n        \"\u2502        imag = 0            \u2502\\n\"\n        \"\u2502   numerator = 1            \u2502\\n\"\n        \"\u2502        real = 1            \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert expected == render(1)\n\n\ndef test_inspect_integer_with_value():\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 int([x]) -> integer        \u2502\\n\u2502 int(x, base=10) -> integer \u2502\\n\u2502                            \u2502\\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\\n\u2502 \u2502 1                      \u2502 \u2502\\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\\n\u2502                            \u2502\\n\u2502 denominator = 1            \u2502\\n\u2502        imag = 0            \u2502\\n\u2502   numerator = 1            \u2502\\n\u2502        real = 1            \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    value = render(1, value=True)\n    print(repr(value))\n    assert value == expected\n\n\n@skip_py310\n@skip_py311\n@skip_py312\n@skip_py313\ndef test_inspect_integer_with_methods_python38_and_python39():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer                            \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer                     \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502      denominator = 1                           \u2502\\n\"\n        \"\u2502             imag = 0                           \u2502\\n\"\n        \"\u2502        numerator = 1                           \u2502\\n\"\n        \"\u2502             real = 1                           \u2502\\n\"\n        \"\u2502 as_integer_ratio = def as_integer_ratio():     \u2502\\n\"\n        \"\u2502                    Return integer ratio.       \u2502\\n\"\n        \"\u2502       bit_length = def bit_length(): Number of \u2502\\n\"\n        \"\u2502                    bits necessary to represent \u2502\\n\"\n        \"\u2502                    self in binary.             \u2502\\n\"\n        \"\u2502        conjugate = def conjugate(...) Returns  \u2502\\n\"\n        \"\u2502                    self, the complex conjugate \u2502\\n\"\n        \"\u2502                    of any int.                 \u2502\\n\"\n        \"\u2502       from_bytes = def from_bytes(bytes,       \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return the   \u2502\\n\"\n        \"\u2502                    integer represented by the  \u2502\\n\"\n        \"\u2502                    given array of bytes.       \u2502\\n\"\n        \"\u2502         to_bytes = def to_bytes(length,        \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return an    \u2502\\n\"\n        \"\u2502                    array of bytes representing \u2502\\n\"\n        \"\u2502                    an integer.                 \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(1, methods=True) == expected\n\n\n@skip_py38\n@skip_py39\n@skip_py311\n@skip_py312\n@skip_py313\ndef test_inspect_integer_with_methods_python310only():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer                            \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer                     \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502      denominator = 1                           \u2502\\n\"\n        \"\u2502             imag = 0                           \u2502\\n\"\n        \"\u2502        numerator = 1                           \u2502\\n\"\n        \"\u2502             real = 1                           \u2502\\n\"\n        \"\u2502 as_integer_ratio = def as_integer_ratio():     \u2502\\n\"\n        \"\u2502                    Return integer ratio.       \u2502\\n\"\n        \"\u2502        bit_count = def bit_count(): Number of  \u2502\\n\"\n        \"\u2502                    ones in the binary          \u2502\\n\"\n        \"\u2502                    representation of the       \u2502\\n\"\n        \"\u2502                    absolute value of self.     \u2502\\n\"\n        \"\u2502       bit_length = def bit_length(): Number of \u2502\\n\"\n        \"\u2502                    bits necessary to represent \u2502\\n\"\n        \"\u2502                    self in binary.             \u2502\\n\"\n        \"\u2502        conjugate = def conjugate(...) Returns  \u2502\\n\"\n        \"\u2502                    self, the complex conjugate \u2502\\n\"\n        \"\u2502                    of any int.                 \u2502\\n\"\n        \"\u2502       from_bytes = def from_bytes(bytes,       \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return the   \u2502\\n\"\n        \"\u2502                    integer represented by the  \u2502\\n\"\n        \"\u2502                    given array of bytes.       \u2502\\n\"\n        \"\u2502         to_bytes = def to_bytes(length,        \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return an    \u2502\\n\"\n        \"\u2502                    array of bytes representing \u2502\\n\"\n        \"\u2502                    an integer.                 \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(1, methods=True) == expected\n\n\n@skip_py38\n@skip_py39\n@skip_py310\n@skip_py312\n@skip_py313\ndef test_inspect_integer_with_methods_python311():\n    # to_bytes and from_bytes methods on int had minor signature change -\n    # they now, as of 3.11, have default values for all of their parameters\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer                            \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer                     \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502      denominator = 1                           \u2502\\n\"\n        \"\u2502             imag = 0                           \u2502\\n\"\n        \"\u2502        numerator = 1                           \u2502\\n\"\n        \"\u2502             real = 1                           \u2502\\n\"\n        \"\u2502 as_integer_ratio = def as_integer_ratio():     \u2502\\n\"\n        \"\u2502                    Return integer ratio.       \u2502\\n\"\n        \"\u2502        bit_count = def bit_count(): Number of  \u2502\\n\"\n        \"\u2502                    ones in the binary          \u2502\\n\"\n        \"\u2502                    representation of the       \u2502\\n\"\n        \"\u2502                    absolute value of self.     \u2502\\n\"\n        \"\u2502       bit_length = def bit_length(): Number of \u2502\\n\"\n        \"\u2502                    bits necessary to represent \u2502\\n\"\n        \"\u2502                    self in binary.             \u2502\\n\"\n        \"\u2502        conjugate = def conjugate(...) Returns  \u2502\\n\"\n        \"\u2502                    self, the complex conjugate \u2502\\n\"\n        \"\u2502                    of any int.                 \u2502\\n\"\n        \"\u2502       from_bytes = def from_bytes(bytes,       \u2502\\n\"\n        \"\u2502                    byteorder='big', *,         \u2502\\n\"\n        \"\u2502                    signed=False): Return the   \u2502\\n\"\n        \"\u2502                    integer represented by the  \u2502\\n\"\n        \"\u2502                    given array of bytes.       \u2502\\n\"\n        \"\u2502         to_bytes = def to_bytes(length=1,      \u2502\\n\"\n        \"\u2502                    byteorder='big', *,         \u2502\\n\"\n        \"\u2502                    signed=False): Return an    \u2502\\n\"\n        \"\u2502                    array of bytes representing \u2502\\n\"\n        \"\u2502                    an integer.                 \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(1, methods=True) == expected\n\n\n@skip_pypy3\ndef test_broken_call_attr():\n    class NotCallable:\n        __call__ = 5  # Passes callable() but isn't really callable\n\n        def __repr__(self):\n            return \"NotCallable()\"\n\n    class Foo:\n        foo = NotCallable()\n\n    foo = Foo()\n    assert callable(foo.foo)\n    expected = \"\u256d\u2500 <class 'tests.test_inspect.test_broken_call_attr.<locals>.Foo'> \u2500\u256e\\n\u2502 foo = NotCallable()                                               \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    result = render(foo, methods=True, width=100)\n    print(repr(result))\n    assert expected == result\n\n\ndef test_inspect_swig_edge_case():\n    \"\"\"Issue #1838 - Edge case with Faiss library - object with empty dir()\"\"\"\n\n    class Thing:\n        @property\n        def __class__(self):\n            raise AttributeError\n\n    thing = Thing()\n    try:\n        inspect(thing)\n    except Exception as e:\n        assert False, f\"Object with no __class__ shouldn't raise {e}\"\n\n\ndef test_inspect_module_with_class():\n    def function():\n        pass\n\n    class Thing:\n        \"\"\"Docstring\"\"\"\n\n        pass\n\n    module = ModuleType(\"my_module\")\n    module.SomeClass = Thing\n    module.function = function\n\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <module 'my_module'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502  function = def function():              \u2502\\n\"\n        \"\u2502 SomeClass = class SomeClass(): Docstring \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(module, methods=True) == expected\n\n\n@pytest.mark.parametrize(\n    \"special_character,expected_replacement\",\n    (\n        (\"\\a\", \"\\\\a\"),\n        (\"\\b\", \"\\\\b\"),\n        (\"\\f\", \"\\\\f\"),\n        (\"\\r\", \"\\\\r\"),\n        (\"\\v\", \"\\\\v\"),\n    ),\n)\ndef test_can_handle_special_characters_in_docstrings(\n    special_character: str, expected_replacement: str\n) -> None:\n    class Something:\n        class Thing:\n            pass\n\n    Something.Thing.__doc__ = f\"\"\"\n    Multiline docstring\n    with {special_character} should be handled\n    \"\"\"\n\n    expected = \"\"\"\\\n\u256d\u2500 <class 'tests.test_inspect.test_can_handle_sp\u2500\u256e\n\u2502 class                                          \u2502\n\u2502 test_can_handle_special_characters_in_docstrin \u2502\n\u2502 gs.<locals>.Something():                       \u2502\n\u2502                                                \u2502\n\u2502 Thing = class Thing():                         \u2502\n\u2502         Multiline docstring                    \u2502\n\u2502         with %s should be handled              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\"\"\" % (\n        expected_replacement\n    )\n    assert render(Something, methods=True) == expected\n\n\n@pytest.mark.parametrize(\n    \"obj,expected_result\",\n    (\n        [object, (object,)],\n        [object(), (object,)],\n        [\"hi\", (str, object)],\n        [str, (str, object)],\n        [Foo(1), (Foo, object)],\n        [Foo, (Foo, object)],\n        [FooSubclass(1), (FooSubclass, Foo, object)],\n        [FooSubclass, (FooSubclass, Foo, object)],\n    ),\n)\ndef test_object_types_mro(obj: object, expected_result: Sequence[Type]):\n    assert get_object_types_mro(obj) == expected_result\n\n\n@pytest.mark.parametrize(\n    \"obj,expected_result\",\n    (\n        # fmt: off\n        [\"hi\", [\"builtins.str\", \"builtins.object\"]],\n        [str, [\"builtins.str\", \"builtins.object\"]],\n        [Foo(1), [f\"{__name__}.Foo\", \"builtins.object\"]],\n        [Foo, [f\"{__name__}.Foo\", \"builtins.object\"]],\n        [FooSubclass(1),\n         [f\"{__name__}.FooSubclass\", f\"{__name__}.Foo\", \"builtins.object\"]],\n        [FooSubclass,\n         [f\"{__name__}.FooSubclass\", f\"{__name__}.Foo\", \"builtins.object\"]],\n        # fmt: on\n    ),\n)\ndef test_object_types_mro_as_strings(obj: object, expected_result: Sequence[str]):\n    assert get_object_types_mro_as_strings(obj) == expected_result\n\n\n@pytest.mark.parametrize(\n    \"obj,types,expected_result\",\n    (\n        # fmt: off\n        [\"hi\", [\"builtins.str\"], True],\n        [str, [\"builtins.str\"], True],\n        [\"hi\", [\"builtins.str\", \"foo\"], True],\n        [str, [\"builtins.str\", \"foo\"], True],\n        [Foo(1), [f\"{__name__}.Foo\"], True],\n        [Foo, [f\"{__name__}.Foo\"], True],\n        [Foo(1), [\"builtins.str\", f\"{__name__}.Foo\"], True],\n        [Foo, [\"builtins.int\", f\"{__name__}.Foo\"], True],\n        [Foo(1), [f\"{__name__}.FooSubclass\"], False],\n        [Foo, [f\"{__name__}.FooSubclass\"], False],\n        [Foo(1), [f\"{__name__}.FooSubclass\", f\"{__name__}.Foo\"], True],\n        [Foo, [f\"{__name__}.Foo\", f\"{__name__}.FooSubclass\"], True],\n        # fmt: on\n    ),\n)\ndef test_object_is_one_of_types(\n    obj: object, types: Sequence[str], expected_result: bool\n):\n    assert is_object_one_of_types(obj, types) is expected_result\n",
      "code_after": "import io\nimport sys\nfrom types import ModuleType\nfrom typing import Sequence, Type\n\nimport pytest\n\nfrom rich import inspect\nfrom rich._inspect import (\n    get_object_types_mro,\n    get_object_types_mro_as_strings,\n    is_object_one_of_types,\n)\nfrom rich.console import Console\n\nskip_py38 = pytest.mark.skipif(\n    sys.version_info.minor == 8 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.8\",\n)\n\nskip_py39 = pytest.mark.skipif(\n    sys.version_info.minor == 9 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.9\",\n)\n\nskip_py310 = pytest.mark.skipif(\n    sys.version_info.minor == 10 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.10\",\n)\n\nskip_py311 = pytest.mark.skipif(\n    sys.version_info.minor == 11 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.11\",\n)\n\nskip_py312 = pytest.mark.skipif(\n    sys.version_info.minor == 12 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.12\",\n)\n\nskip_py313 = pytest.mark.skipif(\n    sys.version_info.minor == 13 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.13\",\n)\n\nskip_py314 = pytest.mark.skipif(\n    sys.version_info.minor == 14 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.14\",\n)\n\n\nskip_pypy3 = pytest.mark.skipif(\n    hasattr(sys, \"pypy_version_info\"),\n    reason=\"rendered differently on pypy3\",\n)\n\n\ndef render(obj, methods=False, value=False, width=50) -> str:\n    console = Console(file=io.StringIO(), width=width, legacy_windows=False)\n    inspect(obj, console=console, methods=methods, value=value)\n    return console.file.getvalue()\n\n\nclass InspectError(Exception):\n    def __str__(self) -> str:\n        return \"INSPECT ERROR\"\n\n\nclass Foo:\n    \"\"\"Foo test\n\n    Second line\n    \"\"\"\n\n    def __init__(self, foo: int) -> None:\n        \"\"\"constructor docs.\"\"\"\n        self.foo = foo\n\n    @property\n    def broken(self):\n        raise InspectError()\n\n    def method(self, a, b) -> str:\n        \"\"\"Multi line\n\n        docs.\n        \"\"\"\n        return \"test\"\n\n    def __dir__(self):\n        return [\"__init__\", \"broken\", \"method\"]\n\n\nclass FooSubclass(Foo):\n    pass\n\n\ndef test_render():\n    console = Console(width=100, file=io.StringIO(), legacy_windows=False)\n\n    foo = Foo(\"hello\")\n    inspect(foo, console=console, all=True, value=False)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'tests.test_inspect.Foo'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 Foo test                                                     \u2502\\n\u2502                                                              \u2502\\n\u2502   broken = InspectError()                                    \u2502\\n\u2502 __init__ = def __init__(foo: int) -> None: constructor docs. \u2502\\n\u2502   method = def method(a, b) -> str: Multi line               \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    assert result == expected\n\n\n@skip_pypy3\ndef test_inspect_text():\n    num_attributes = 34 if sys.version_info >= (3, 11) else 33\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'str'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 str(object='') -> str                          \u2502\\n\"\n        \"\u2502 str(bytes_or_buffer[, encoding[, errors]]) ->  \u2502\\n\"\n        \"\u2502 str                                            \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        f\"\u2502 {num_attributes} attribute(s) not shown. Run                 \u2502\\n\"\n        \"\u2502 inspect(inspect) for options.                  \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    print(repr(expected))\n    assert render(\"Hello\") == expected\n\n\n@skip_pypy3\ndef test_inspect_empty_dict():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'dict'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 dict() -> new empty dictionary                 \u2502\\n\"\n        \"\u2502 dict(mapping) -> new dictionary initialized    \u2502\\n\"\n        \"\u2502 from a mapping object's                        \u2502\\n\"\n        \"\u2502     (key, value) pairs                         \u2502\\n\"\n        \"\u2502 dict(iterable) -> new dictionary initialized   \u2502\\n\"\n        \"\u2502 as if via:                                     \u2502\\n\"\n        \"\u2502     d = {}                                     \u2502\\n\"\n        \"\u2502     for k, v in iterable:                      \u2502\\n\"\n        \"\u2502         d[k] = v                               \u2502\\n\"\n        \"\u2502 dict(**kwargs) -> new dictionary initialized   \u2502\\n\"\n        \"\u2502 with the name=value pairs                      \u2502\\n\"\n        \"\u2502     in the keyword argument list.  For         \u2502\\n\"\n        \"\u2502 example:  dict(one=1, two=2)                   \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n    )\n    assert render({}).startswith(expected)\n\n\n@skip_py314\n@skip_py313\n@skip_py312\n@skip_py311\n@skip_pypy3\ndef test_inspect_builtin_function_except_python311():\n    # Pre-3.11 Python versions - print builtin has no signature available\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <built-in function print> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 def print(...)                                 \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 print(value, ..., sep=' ', end='\\\\n',           \u2502\\n\"\n        \"\u2502 file=sys.stdout, flush=False)                  \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 29 attribute(s) not shown. Run                 \u2502\\n\"\n        \"\u2502 inspect(inspect) for options.                  \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(print) == expected\n\n\n@pytest.mark.skipif(\n    sys.version_info < (3, 11), reason=\"print builtin signature only available on 3.11+\"\n)\n@skip_pypy3\ndef test_inspect_builtin_function_only_python311():\n    # On 3.11, the print builtin *does* have a signature, unlike in prior versions\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <built-in function print> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 def print(*args, sep=' ', end='\\\\n', file=None, \u2502\\n\"\n        \"\u2502 flush=False):                                  \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 Prints the values to a stream, or to           \u2502\\n\"\n        \"\u2502 sys.stdout by default.                         \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502 30 attribute(s) not shown. Run                 \u2502\\n\"\n        \"\u2502 inspect(inspect) for options.                  \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(print) == expected\n\n\n@skip_pypy3\ndef test_inspect_coroutine():\n    async def coroutine():\n        pass\n\n    expected = (\n        \"\u256d\u2500 <function test_inspect_coroutine.<locals>.cor\u2500\u256e\\n\"\n        \"\u2502 async def                                      \u2502\\n\"\n        \"\u2502 test_inspect_coroutine.<locals>.coroutine():   \u2502\\n\"\n    )\n    assert render(coroutine).startswith(expected)\n\n\ndef test_inspect_integer():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer        \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer \u2502\\n\"\n        \"\u2502                            \u2502\\n\"\n        \"\u2502 denominator = 1            \u2502\\n\"\n        \"\u2502        imag = 0            \u2502\\n\"\n        \"\u2502   numerator = 1            \u2502\\n\"\n        \"\u2502        real = 1            \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert expected == render(1)\n\n\ndef test_inspect_integer_with_value():\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 int([x]) -> integer        \u2502\\n\u2502 int(x, base=10) -> integer \u2502\\n\u2502                            \u2502\\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\\n\u2502 \u2502 1                      \u2502 \u2502\\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\\n\u2502                            \u2502\\n\u2502 denominator = 1            \u2502\\n\u2502        imag = 0            \u2502\\n\u2502   numerator = 1            \u2502\\n\u2502        real = 1            \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    value = render(1, value=True)\n    print(repr(value))\n    assert value == expected\n\n\n@skip_py310\n@skip_py311\n@skip_py312\n@skip_py313\n@skip_py314\ndef test_inspect_integer_with_methods_python38_and_python39():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer                            \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer                     \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502      denominator = 1                           \u2502\\n\"\n        \"\u2502             imag = 0                           \u2502\\n\"\n        \"\u2502        numerator = 1                           \u2502\\n\"\n        \"\u2502             real = 1                           \u2502\\n\"\n        \"\u2502 as_integer_ratio = def as_integer_ratio():     \u2502\\n\"\n        \"\u2502                    Return integer ratio.       \u2502\\n\"\n        \"\u2502       bit_length = def bit_length(): Number of \u2502\\n\"\n        \"\u2502                    bits necessary to represent \u2502\\n\"\n        \"\u2502                    self in binary.             \u2502\\n\"\n        \"\u2502        conjugate = def conjugate(...) Returns  \u2502\\n\"\n        \"\u2502                    self, the complex conjugate \u2502\\n\"\n        \"\u2502                    of any int.                 \u2502\\n\"\n        \"\u2502       from_bytes = def from_bytes(bytes,       \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return the   \u2502\\n\"\n        \"\u2502                    integer represented by the  \u2502\\n\"\n        \"\u2502                    given array of bytes.       \u2502\\n\"\n        \"\u2502         to_bytes = def to_bytes(length,        \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return an    \u2502\\n\"\n        \"\u2502                    array of bytes representing \u2502\\n\"\n        \"\u2502                    an integer.                 \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(1, methods=True) == expected\n\n\n@skip_py38\n@skip_py39\n@skip_py311\n@skip_py312\n@skip_py313\n@skip_py314\ndef test_inspect_integer_with_methods_python310only():\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer                            \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer                     \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502      denominator = 1                           \u2502\\n\"\n        \"\u2502             imag = 0                           \u2502\\n\"\n        \"\u2502        numerator = 1                           \u2502\\n\"\n        \"\u2502             real = 1                           \u2502\\n\"\n        \"\u2502 as_integer_ratio = def as_integer_ratio():     \u2502\\n\"\n        \"\u2502                    Return integer ratio.       \u2502\\n\"\n        \"\u2502        bit_count = def bit_count(): Number of  \u2502\\n\"\n        \"\u2502                    ones in the binary          \u2502\\n\"\n        \"\u2502                    representation of the       \u2502\\n\"\n        \"\u2502                    absolute value of self.     \u2502\\n\"\n        \"\u2502       bit_length = def bit_length(): Number of \u2502\\n\"\n        \"\u2502                    bits necessary to represent \u2502\\n\"\n        \"\u2502                    self in binary.             \u2502\\n\"\n        \"\u2502        conjugate = def conjugate(...) Returns  \u2502\\n\"\n        \"\u2502                    self, the complex conjugate \u2502\\n\"\n        \"\u2502                    of any int.                 \u2502\\n\"\n        \"\u2502       from_bytes = def from_bytes(bytes,       \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return the   \u2502\\n\"\n        \"\u2502                    integer represented by the  \u2502\\n\"\n        \"\u2502                    given array of bytes.       \u2502\\n\"\n        \"\u2502         to_bytes = def to_bytes(length,        \u2502\\n\"\n        \"\u2502                    byteorder, *,               \u2502\\n\"\n        \"\u2502                    signed=False): Return an    \u2502\\n\"\n        \"\u2502                    array of bytes representing \u2502\\n\"\n        \"\u2502                    an integer.                 \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(1, methods=True) == expected\n\n\n@skip_py38\n@skip_py39\n@skip_py310\n@skip_py312\n@skip_py313\n@skip_py314\ndef test_inspect_integer_with_methods_python311():\n    # to_bytes and from_bytes methods on int had minor signature change -\n    # they now, as of 3.11, have default values for all of their parameters\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <class 'int'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502 int([x]) -> integer                            \u2502\\n\"\n        \"\u2502 int(x, base=10) -> integer                     \u2502\\n\"\n        \"\u2502                                                \u2502\\n\"\n        \"\u2502      denominator = 1                           \u2502\\n\"\n        \"\u2502             imag = 0                           \u2502\\n\"\n        \"\u2502        numerator = 1                           \u2502\\n\"\n        \"\u2502             real = 1                           \u2502\\n\"\n        \"\u2502 as_integer_ratio = def as_integer_ratio():     \u2502\\n\"\n        \"\u2502                    Return integer ratio.       \u2502\\n\"\n        \"\u2502        bit_count = def bit_count(): Number of  \u2502\\n\"\n        \"\u2502                    ones in the binary          \u2502\\n\"\n        \"\u2502                    representation of the       \u2502\\n\"\n        \"\u2502                    absolute value of self.     \u2502\\n\"\n        \"\u2502       bit_length = def bit_length(): Number of \u2502\\n\"\n        \"\u2502                    bits necessary to represent \u2502\\n\"\n        \"\u2502                    self in binary.             \u2502\\n\"\n        \"\u2502        conjugate = def conjugate(...) Returns  \u2502\\n\"\n        \"\u2502                    self, the complex conjugate \u2502\\n\"\n        \"\u2502                    of any int.                 \u2502\\n\"\n        \"\u2502       from_bytes = def from_bytes(bytes,       \u2502\\n\"\n        \"\u2502                    byteorder='big', *,         \u2502\\n\"\n        \"\u2502                    signed=False): Return the   \u2502\\n\"\n        \"\u2502                    integer represented by the  \u2502\\n\"\n        \"\u2502                    given array of bytes.       \u2502\\n\"\n        \"\u2502         to_bytes = def to_bytes(length=1,      \u2502\\n\"\n        \"\u2502                    byteorder='big', *,         \u2502\\n\"\n        \"\u2502                    signed=False): Return an    \u2502\\n\"\n        \"\u2502                    array of bytes representing \u2502\\n\"\n        \"\u2502                    an integer.                 \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(1, methods=True) == expected\n\n\n@skip_pypy3\ndef test_broken_call_attr():\n    class NotCallable:\n        __call__ = 5  # Passes callable() but isn't really callable\n\n        def __repr__(self):\n            return \"NotCallable()\"\n\n    class Foo:\n        foo = NotCallable()\n\n    foo = Foo()\n    assert callable(foo.foo)\n    expected = \"\u256d\u2500 <class 'tests.test_inspect.test_broken_call_attr.<locals>.Foo'> \u2500\u256e\\n\u2502 foo = NotCallable()                                               \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    result = render(foo, methods=True, width=100)\n    print(repr(result))\n    assert expected == result\n\n\ndef test_inspect_swig_edge_case():\n    \"\"\"Issue #1838 - Edge case with Faiss library - object with empty dir()\"\"\"\n\n    class Thing:\n        @property\n        def __class__(self):\n            raise AttributeError\n\n    thing = Thing()\n    try:\n        inspect(thing)\n    except Exception as e:\n        assert False, f\"Object with no __class__ shouldn't raise {e}\"\n\n\ndef test_inspect_module_with_class():\n    def function():\n        pass\n\n    class Thing:\n        \"\"\"Docstring\"\"\"\n\n        pass\n\n    module = ModuleType(\"my_module\")\n    module.SomeClass = Thing\n    module.function = function\n\n    expected = (\n        \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 <module 'my_module'> \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\"\n        \"\u2502  function = def function():              \u2502\\n\"\n        \"\u2502 SomeClass = class SomeClass(): Docstring \u2502\\n\"\n        \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    )\n    assert render(module, methods=True) == expected\n\n\n@pytest.mark.parametrize(\n    \"special_character,expected_replacement\",\n    (\n        (\"\\a\", \"\\\\a\"),\n        (\"\\b\", \"\\\\b\"),\n        (\"\\f\", \"\\\\f\"),\n        (\"\\r\", \"\\\\r\"),\n        (\"\\v\", \"\\\\v\"),\n    ),\n)\ndef test_can_handle_special_characters_in_docstrings(\n    special_character: str, expected_replacement: str\n) -> None:\n    class Something:\n        class Thing:\n            pass\n\n    Something.Thing.__doc__ = f\"\"\"\n    Multiline docstring\n    with {special_character} should be handled\n    \"\"\"\n\n    expected = \"\"\"\\\n\u256d\u2500 <class 'tests.test_inspect.test_can_handle_sp\u2500\u256e\n\u2502 class                                          \u2502\n\u2502 test_can_handle_special_characters_in_docstrin \u2502\n\u2502 gs.<locals>.Something():                       \u2502\n\u2502                                                \u2502\n\u2502 Thing = class Thing():                         \u2502\n\u2502         Multiline docstring                    \u2502\n\u2502         with %s should be handled              \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\"\"\" % (\n        expected_replacement\n    )\n    assert render(Something, methods=True) == expected\n\n\n@pytest.mark.parametrize(\n    \"obj,expected_result\",\n    (\n        [object, (object,)],\n        [object(), (object,)],\n        [\"hi\", (str, object)],\n        [str, (str, object)],\n        [Foo(1), (Foo, object)],\n        [Foo, (Foo, object)],\n        [FooSubclass(1), (FooSubclass, Foo, object)],\n        [FooSubclass, (FooSubclass, Foo, object)],\n    ),\n)\ndef test_object_types_mro(obj: object, expected_result: Sequence[Type]):\n    assert get_object_types_mro(obj) == expected_result\n\n\n@pytest.mark.parametrize(\n    \"obj,expected_result\",\n    (\n        # fmt: off\n        [\"hi\", [\"builtins.str\", \"builtins.object\"]],\n        [str, [\"builtins.str\", \"builtins.object\"]],\n        [Foo(1), [f\"{__name__}.Foo\", \"builtins.object\"]],\n        [Foo, [f\"{__name__}.Foo\", \"builtins.object\"]],\n        [FooSubclass(1),\n         [f\"{__name__}.FooSubclass\", f\"{__name__}.Foo\", \"builtins.object\"]],\n        [FooSubclass,\n         [f\"{__name__}.FooSubclass\", f\"{__name__}.Foo\", \"builtins.object\"]],\n        # fmt: on\n    ),\n)\ndef test_object_types_mro_as_strings(obj: object, expected_result: Sequence[str]):\n    assert get_object_types_mro_as_strings(obj) == expected_result\n\n\n@pytest.mark.parametrize(\n    \"obj,types,expected_result\",\n    (\n        # fmt: off\n        [\"hi\", [\"builtins.str\"], True],\n        [str, [\"builtins.str\"], True],\n        [\"hi\", [\"builtins.str\", \"foo\"], True],\n        [str, [\"builtins.str\", \"foo\"], True],\n        [Foo(1), [f\"{__name__}.Foo\"], True],\n        [Foo, [f\"{__name__}.Foo\"], True],\n        [Foo(1), [\"builtins.str\", f\"{__name__}.Foo\"], True],\n        [Foo, [\"builtins.int\", f\"{__name__}.Foo\"], True],\n        [Foo(1), [f\"{__name__}.FooSubclass\"], False],\n        [Foo, [f\"{__name__}.FooSubclass\"], False],\n        [Foo(1), [f\"{__name__}.FooSubclass\", f\"{__name__}.Foo\"], True],\n        [Foo, [f\"{__name__}.Foo\", f\"{__name__}.FooSubclass\"], True],\n        # fmt: on\n    ),\n)\ndef test_object_is_one_of_types(\n    obj: object, types: Sequence[str], expected_result: bool\n):\n    assert is_object_one_of_types(obj, types) is expected_result\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "e19b44e5bbd0",
      "repo": "rich",
      "commit_hash": "655b521",
      "commit_message": "test fixes",
      "file_path": "tests/test_pretty.py",
      "language": "python",
      "code_before": "import collections\nimport io\nimport sys\nfrom array import array\nfrom collections import UserDict, defaultdict, deque\nfrom dataclasses import dataclass, field\nfrom typing import Any, List, NamedTuple\n\nimport attr\nimport pytest\n\nfrom rich.console import Console\nfrom rich.measure import Measurement\nfrom rich.pretty import Node, Pretty, _ipy_display_hook, install, pprint, pretty_repr\nfrom rich.text import Text\n\nskip_py38 = pytest.mark.skipif(\n    sys.version_info.minor == 8 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.8\",\n)\nskip_py39 = pytest.mark.skipif(\n    sys.version_info.minor == 9 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.9\",\n)\nskip_py310 = pytest.mark.skipif(\n    sys.version_info.minor == 10 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.10\",\n)\nskip_py311 = pytest.mark.skipif(\n    sys.version_info.minor == 11 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.11\",\n)\nskip_py312 = pytest.mark.skipif(\n    sys.version_info.minor == 12 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.12\",\n)\nskip_py313 = pytest.mark.skipif(\n    sys.version_info.minor == 13 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.13\",\n)\n\n\ndef test_install() -> None:\n    console = Console(file=io.StringIO())\n    dh = sys.displayhook\n    install(console)\n    sys.displayhook(\"foo\")\n    assert console.file.getvalue() == \"'foo'\\n\"\n    assert sys.displayhook is not dh\n\n\ndef test_install_max_depth() -> None:\n    console = Console(file=io.StringIO())\n    dh = sys.displayhook\n    install(console, max_depth=1)\n    sys.displayhook({\"foo\": {\"bar\": True}})\n    assert console.file.getvalue() == \"{'foo': {...}}\\n\"\n    assert sys.displayhook is not dh\n\n\ndef test_ipy_display_hook__repr_html() -> None:\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def _repr_html_(self):\n            return \"hello\"\n\n    console.begin_capture()\n    _ipy_display_hook(Thing(), console=console)\n\n    # Rendering delegated to notebook because _repr_html_ method exists\n    assert console.end_capture() == \"\"\n\n\ndef test_ipy_display_hook__multiple_special_reprs() -> None:\n    \"\"\"\n    The case where there are multiple IPython special _repr_*_\n    methods on the object, and one of them returns None but another\n    one does not.\n    \"\"\"\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def __repr__(self):\n            return \"A Thing\"\n\n        def _repr_latex_(self):\n            return None\n\n        def _repr_html_(self):\n            return \"hello\"\n\n    result = _ipy_display_hook(Thing(), console=console)\n    assert result == \"A Thing\"\n\n\ndef test_ipy_display_hook__no_special_repr_methods() -> None:\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def __repr__(self) -> str:\n            return \"hello\"\n\n    result = _ipy_display_hook(Thing(), console=console)\n    # should be repr as-is\n    assert result == \"hello\"\n\n\ndef test_ipy_display_hook__special_repr_raises_exception() -> None:\n    \"\"\"\n    When an IPython special repr method raises an exception,\n    we treat it as if it doesn't exist and look for the next.\n    \"\"\"\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def _repr_markdown_(self):\n            raise Exception()\n\n        def _repr_latex_(self):\n            return None\n\n        def _repr_html_(self):\n            return \"hello\"\n\n        def __repr__(self):\n            return \"therepr\"\n\n    result = _ipy_display_hook(Thing(), console=console)\n    assert result == \"therepr\"\n\n\ndef test_ipy_display_hook__console_renderables_on_newline() -> None:\n    console = Console(file=io.StringIO(), force_jupyter=True)\n    console.begin_capture()\n    result = _ipy_display_hook(Text(\"hello\"), console=console)\n    assert result == \"\\nhello\"\n\n\ndef test_pretty() -> None:\n    test = {\n        \"foo\": [1, 2, 3, (4, 5, {6}, 7, 8, {9}), {}],\n        \"bar\": {\"egg\": \"baz\", \"words\": [\"Hello World\"] * 10},\n        False: \"foo\",\n        True: \"\",\n        \"text\": (\"Hello World\", \"foo bar baz egg\"),\n    }\n\n    result = pretty_repr(test, max_width=80)\n    print(result)\n    expected = \"{\\n    'foo': [1, 2, 3, (4, 5, {6}, 7, 8, {9}), {}],\\n    'bar': {\\n        'egg': 'baz',\\n        'words': [\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World'\\n        ]\\n    },\\n    False: 'foo',\\n    True: '',\\n    'text': ('Hello World', 'foo bar baz egg')\\n}\"\n    print(expected)\n    assert result == expected\n\n\n@dataclass\nclass ExampleDataclass:\n    foo: int\n    bar: str\n    ignore: int = field(repr=False)\n    baz: List[str] = field(default_factory=list)\n    last: int = field(default=1, repr=False)\n\n\n@dataclass\nclass Empty:\n    pass\n\n\ndef test_pretty_dataclass() -> None:\n    dc = ExampleDataclass(1000, \"Hello, World\", 999, [\"foo\", \"bar\", \"baz\"])\n    result = pretty_repr(dc, max_width=80)\n    print(repr(result))\n    assert (\n        result\n        == \"ExampleDataclass(foo=1000, bar='Hello, World', baz=['foo', 'bar', 'baz'])\"\n    )\n    result = pretty_repr(dc, max_width=16)\n    print(repr(result))\n    assert (\n        result\n        == \"ExampleDataclass(\\n    foo=1000,\\n    bar='Hello, World',\\n    baz=[\\n        'foo',\\n        'bar',\\n        'baz'\\n    ]\\n)\"\n    )\n    dc.bar = dc\n    result = pretty_repr(dc, max_width=80)\n    print(repr(result))\n    assert result == \"ExampleDataclass(foo=1000, bar=..., baz=['foo', 'bar', 'baz'])\"\n\n\ndef test_empty_dataclass() -> None:\n    assert pretty_repr(Empty()) == \"Empty()\"\n    assert pretty_repr([Empty()]) == \"[Empty()]\"\n\n\nclass StockKeepingUnit(NamedTuple):\n    name: str\n    description: str\n    price: float\n    category: str\n    reviews: List[str]\n\n\ndef test_pretty_namedtuple() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n\n    example_namedtuple = StockKeepingUnit(\n        \"Sparkling British Spring Water\",\n        \"Carbonated spring water\",\n        0.9,\n        \"water\",\n        [\"its amazing!\", \"its terrible!\"],\n    )\n\n    result = pretty_repr(example_namedtuple)\n\n    print(result)\n    assert (\n        result\n        == \"\"\"StockKeepingUnit(\n    name='Sparkling British Spring Water',\n    description='Carbonated spring water',\n    price=0.9,\n    category='water',\n    reviews=['its amazing!', 'its terrible!']\n)\"\"\"\n    )\n\n\ndef test_pretty_namedtuple_length_one_no_trailing_comma() -> None:\n    instance = collections.namedtuple(\"Thing\", [\"name\"])(name=\"Bob\")\n    assert pretty_repr(instance) == \"Thing(name='Bob')\"\n\n\ndef test_pretty_namedtuple_empty() -> None:\n    instance = collections.namedtuple(\"Thing\", [])()\n    assert pretty_repr(instance) == \"Thing()\"\n\n\ndef test_pretty_namedtuple_custom_repr() -> None:\n    class Thing(NamedTuple):\n        def __repr__(self):\n            return \"XX\"\n\n    assert pretty_repr(Thing()) == \"XX\"\n\n\ndef test_pretty_namedtuple_fields_invalid_type() -> None:\n    class LooksLikeANamedTupleButIsnt(tuple):\n        _fields = \"blah\"\n\n    instance = LooksLikeANamedTupleButIsnt()\n    result = pretty_repr(instance)\n    assert result == \"()\"  # Treated as tuple\n\n\ndef test_pretty_namedtuple_max_depth() -> None:\n    instance = {\"unit\": StockKeepingUnit(\"a\", \"b\", 1.0, \"c\", [\"d\", \"e\"])}\n    result = pretty_repr(instance, max_depth=1)\n    assert result == \"{'unit': StockKeepingUnit(...)}\"\n\n\ndef test_small_width() -> None:\n    test = [\"Hello world! 12345\"]\n    result = pretty_repr(test, max_width=10)\n    expected = \"[\\n    'Hello world! 12345'\\n]\"\n    assert result == expected\n\n\ndef test_ansi_in_pretty_repr() -> None:\n    class Hello:\n        def __repr__(self):\n            return \"Hello \\x1b[38;5;239mWorld!\"\n\n    pretty = Pretty(Hello())\n\n    console = Console(file=io.StringIO(), record=True)\n    console.print(pretty)\n    result = console.export_text()\n\n    assert result == \"Hello World!\\n\"\n\n\ndef test_broken_repr() -> None:\n    class BrokenRepr:\n        def __repr__(self):\n            1 / 0\n\n    test = [BrokenRepr()]\n    result = pretty_repr(test)\n    expected = \"[<repr-error 'division by zero'>]\"\n    assert result == expected\n\n\ndef test_broken_getattr() -> None:\n    class BrokenAttr:\n        def __getattr__(self, name):\n            1 / 0\n\n        def __repr__(self):\n            return \"BrokenAttr()\"\n\n    test = BrokenAttr()\n    result = pretty_repr(test)\n    assert result == \"BrokenAttr()\"\n\n\ndef test_reference_cycle_container() -> None:\n    test = []\n    test.append(test)\n    res = pretty_repr(test)\n    assert res == \"[...]\"\n\n    test = [1, []]\n    test[1].append(test)\n    res = pretty_repr(test)\n    assert res == \"[1, [...]]\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = [2]\n    test = [1, [a, a]]\n    res = pretty_repr(test)\n    assert res == \"[1, [[2], [2]]]\"\n\n\ndef test_reference_cycle_namedtuple() -> None:\n    class Example(NamedTuple):\n        x: int\n        y: Any\n\n    test = Example(1, [Example(2, [])])\n    test.y[0].y.append(test)\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=[...])])\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_reference_cycle_dataclass() -> None:\n    @dataclass\n    class Example:\n        x: int\n        y: Any\n\n    test = Example(1, None)\n    test.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=...)\"\n\n    test = Example(1, Example(2, None))\n    test.y.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=Example(x=2, y=...))\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_reference_cycle_attrs() -> None:\n    @attr.define\n    class Example:\n        x: int\n        y: Any\n\n    test = Example(1, None)\n    test.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=...)\"\n\n    test = Example(1, Example(2, None))\n    test.y.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=Example(x=2, y=...))\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_reference_cycle_custom_repr() -> None:\n    class Example:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n\n        def __rich_repr__(self):\n            yield (\"x\", self.x)\n            yield (\"y\", self.y)\n\n    test = Example(1, None)\n    test.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=...)\"\n\n    test = Example(1, Example(2, None))\n    test.y.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=Example(x=2, y=...))\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_max_depth() -> None:\n    d = {}\n    d[\"foo\"] = {\"fob\": {\"a\": [1, 2, 3], \"b\": {\"z\": \"x\", \"y\": [\"a\", \"b\", \"c\"]}}}\n\n    assert pretty_repr(d, max_depth=0) == \"{...}\"\n    assert pretty_repr(d, max_depth=1) == \"{'foo': {...}}\"\n    assert pretty_repr(d, max_depth=2) == \"{'foo': {'fob': {...}}}\"\n    assert pretty_repr(d, max_depth=3) == \"{'foo': {'fob': {'a': [...], 'b': {...}}}}\"\n    assert (\n        pretty_repr(d, max_width=100, max_depth=4)\n        == \"{'foo': {'fob': {'a': [1, 2, 3], 'b': {'z': 'x', 'y': [...]}}}}\"\n    )\n    assert (\n        pretty_repr(d, max_width=100, max_depth=5)\n        == \"{'foo': {'fob': {'a': [1, 2, 3], 'b': {'z': 'x', 'y': ['a', 'b', 'c']}}}}\"\n    )\n    assert (\n        pretty_repr(d, max_width=100, max_depth=None)\n        == \"{'foo': {'fob': {'a': [1, 2, 3], 'b': {'z': 'x', 'y': ['a', 'b', 'c']}}}}\"\n    )\n\n\ndef test_max_depth_rich_repr() -> None:\n    class Foo:\n        def __init__(self, foo):\n            self.foo = foo\n\n        def __rich_repr__(self):\n            yield \"foo\", self.foo\n\n    class Bar:\n        def __init__(self, bar):\n            self.bar = bar\n\n        def __rich_repr__(self):\n            yield \"bar\", self.bar\n\n    assert (\n        pretty_repr(Foo(foo=Bar(bar=Foo(foo=[]))), max_depth=2)\n        == \"Foo(foo=Bar(bar=Foo(...)))\"\n    )\n\n\ndef test_max_depth_attrs() -> None:\n    @attr.define\n    class Foo:\n        foo = attr.field()\n\n    @attr.define\n    class Bar:\n        bar = attr.field()\n\n    assert (\n        pretty_repr(Foo(foo=Bar(bar=Foo(foo=[]))), max_depth=2)\n        == \"Foo(foo=Bar(bar=Foo(...)))\"\n    )\n\n\ndef test_max_depth_dataclass() -> None:\n    @dataclass\n    class Foo:\n        foo: object\n\n    @dataclass\n    class Bar:\n        bar: object\n\n    assert (\n        pretty_repr(Foo(foo=Bar(bar=Foo(foo=[]))), max_depth=2)\n        == \"Foo(foo=Bar(bar=Foo(...)))\"\n    )\n\n\ndef test_defaultdict() -> None:\n    test_dict = defaultdict(int, {\"foo\": 2})\n    result = pretty_repr(test_dict)\n    assert result == \"defaultdict(<class 'int'>, {'foo': 2})\"\n\n\ndef test_deque() -> None:\n    test_deque = deque([1, 2, 3])\n    result = pretty_repr(test_deque)\n    assert result == \"deque([1, 2, 3])\"\n    test_deque = deque([1, 2, 3], maxlen=None)\n    result = pretty_repr(test_deque)\n    assert result == \"deque([1, 2, 3])\"\n    test_deque = deque([1, 2, 3], maxlen=5)\n    result = pretty_repr(test_deque)\n    assert result == \"deque([1, 2, 3], maxlen=5)\"\n    test_deque = deque([1, 2, 3], maxlen=0)\n    result = pretty_repr(test_deque)\n    assert result == \"deque(maxlen=0)\"\n    test_deque = deque([])\n    result = pretty_repr(test_deque)\n    assert result == \"deque()\"\n    test_deque = deque([], maxlen=None)\n    result = pretty_repr(test_deque)\n    assert result == \"deque()\"\n    test_deque = deque([], maxlen=5)\n    result = pretty_repr(test_deque)\n    assert result == \"deque(maxlen=5)\"\n    test_deque = deque([], maxlen=0)\n    result = pretty_repr(test_deque)\n    assert result == \"deque(maxlen=0)\"\n\n\ndef test_array() -> None:\n    test_array = array(\"I\", [1, 2, 3])\n    result = pretty_repr(test_array)\n    assert result == \"array('I', [1, 2, 3])\"\n\n\ndef test_tuple_of_one() -> None:\n    assert pretty_repr((1,)) == \"(1,)\"\n\n\ndef test_node() -> None:\n    node = Node(\"abc\")\n    assert pretty_repr(node) == \"abc: \"\n\n\ndef test_indent_lines() -> None:\n    console = Console(width=100, color_system=None)\n    console.begin_capture()\n    console.print(Pretty([100, 200], indent_guides=True), width=8)\n    expected = \"\"\"\\\n[\n\u2502   100,\n\u2502   200\n]\n\"\"\"\n    result = console.end_capture()\n    print(repr(result))\n    print(result)\n    assert result == expected\n\n\ndef test_pprint() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint(1, console=console)\n    assert console.end_capture() == \"1\\n\"\n\n\ndef test_pprint_max_values() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], console=console, max_length=2)\n    assert console.end_capture() == \"[1, 2, ... +8]\\n\"\n\n\ndef test_pprint_max_items() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint({\"foo\": 1, \"bar\": 2, \"egg\": 3}, console=console, max_length=2)\n    assert console.end_capture() == \"\"\"{'foo': 1, 'bar': 2, ... +1}\\n\"\"\"\n\n\ndef test_pprint_max_string() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint([\"Hello\" * 20], console=console, max_string=8)\n    assert console.end_capture() == \"\"\"['HelloHel'+92]\\n\"\"\"\n\n\ndef test_tuples() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint((1,), console=console)\n    pprint((1,), expand_all=True, console=console)\n    pprint(((1,),), expand_all=True, console=console)\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"(1,)\\n(\\n\u2502   1,\\n)\\n(\\n\u2502   (\\n\u2502   \u2502   1,\\n\u2502   ),\\n)\\n\"\n    print(result)\n    print(\"--\")\n    print(expected)\n    assert result == expected\n\n\ndef test_newline() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    console.print(Pretty((1,), insert_line=True, expand_all=True))\n    result = console.end_capture()\n    expected = \"\\n(\\n    1,\\n)\\n\"\n    assert result == expected\n\n\ndef test_empty_repr() -> None:\n    class Foo:\n        def __repr__(self):\n            return \"\"\n\n    assert pretty_repr(Foo()) == \"\"\n\n\ndef test_attrs() -> None:\n    @attr.define\n    class Point:\n        x: int\n        y: int\n        foo: str = attr.field(repr=str.upper)\n        z: int = 0\n\n    result = pretty_repr(Point(1, 2, foo=\"bar\"))\n    print(repr(result))\n    expected = \"Point(x=1, y=2, foo=BAR, z=0)\"\n    assert result == expected\n\n\ndef test_attrs_empty() -> None:\n    @attr.define\n    class Nada:\n        pass\n\n    result = pretty_repr(Nada())\n    print(repr(result))\n    expected = \"Nada()\"\n    assert result == expected\n\n\n@skip_py310\n@skip_py311\n@skip_py312\n@skip_py313\ndef test_attrs_broken() -> None:\n    @attr.define\n    class Foo:\n        bar: int\n\n    foo = Foo(1)\n    del foo.bar\n    result = pretty_repr(foo)\n    print(repr(result))\n    expected = \"Foo(bar=AttributeError('bar'))\"\n    assert result == expected\n\n\n@skip_py38\n@skip_py39\ndef test_attrs_broken_310() -> None:\n    @attr.define\n    class Foo:\n        bar: int\n\n    foo = Foo(1)\n    del foo.bar\n    result = pretty_repr(foo)\n    print(repr(result))\n    if sys.version_info >= (3, 13):\n        expected = \"Foo(\\n    bar=AttributeError(\\\"'tests.test_pretty.test_attrs_broken_310.<locals>.Foo' object has no attribute 'bar'\\\")\\n)\"\n    else:\n        expected = \"Foo(bar=AttributeError(\\\"'Foo' object has no attribute 'bar'\\\"))\"\n    assert result == expected\n\n\ndef test_user_dict() -> None:\n    class D1(UserDict):\n        pass\n\n    class D2(UserDict):\n        def __repr__(self):\n            return \"FOO\"\n\n    d1 = D1({\"foo\": \"bar\"})\n    d2 = D2({\"foo\": \"bar\"})\n    result = pretty_repr(d1, expand_all=True)\n    print(repr(result))\n    assert result == \"{\\n    'foo': 'bar'\\n}\"\n    result = pretty_repr(d2, expand_all=True)\n    print(repr(result))\n    assert result == \"FOO\"\n\n\ndef test_lying_attribute() -> None:\n    \"\"\"Test getattr doesn't break rich repr protocol\"\"\"\n\n    class Foo:\n        def __getattr__(self, attr):\n            return \"foo\"\n\n    foo = Foo()\n    result = pretty_repr(foo)\n    assert \"Foo\" in result\n\n\ndef test_measure_pretty() -> None:\n    \"\"\"Test measure respects expand_all\"\"\"\n    # https://github.com/Textualize/rich/issues/1998\n    console = Console()\n    pretty = Pretty([\"alpha\", \"beta\", \"delta\", \"gamma\"], expand_all=True)\n\n    measurement = console.measure(pretty)\n    assert measurement == Measurement(12, 12)\n\n\ndef test_tuple_rich_repr() -> None:\n    \"\"\"\n    Test that can use None as key to have tuple positional values.\n    \"\"\"\n\n    class Foo:\n        def __rich_repr__(self):\n            yield None, (1,)\n\n    assert pretty_repr(Foo()) == \"Foo((1,))\"\n\n\ndef test_tuple_rich_repr_default() -> None:\n    \"\"\"\n    Test that can use None as key to have tuple positional values and with a default.\n    \"\"\"\n\n    class Foo:\n        def __rich_repr__(self):\n            yield None, (1,), (1,)\n\n    assert pretty_repr(Foo()) == \"Foo()\"\n\n\ndef test_dataclass_no_attribute() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3417\"\"\"\n    from dataclasses import dataclass, field\n\n    @dataclass(eq=False)\n    class BadDataclass:\n        item: int = field(init=False)\n\n    # item is not provided\n    bad_data_class = BadDataclass()\n\n    console = Console()\n    with console.capture() as capture:\n        console.print(bad_data_class)\n\n    expected = \"BadDataclass()\\n\"\n    result = capture.get()\n    assert result == expected\n",
      "code_after": "import collections\nimport io\nimport sys\nfrom array import array\nfrom collections import UserDict, defaultdict, deque\nfrom dataclasses import dataclass, field\nfrom typing import Any, List, NamedTuple\n\nimport attr\nimport pytest\n\nfrom rich.console import Console\nfrom rich.measure import Measurement\nfrom rich.pretty import Node, Pretty, _ipy_display_hook, install, pprint, pretty_repr\nfrom rich.text import Text\n\nskip_py38 = pytest.mark.skipif(\n    sys.version_info.minor == 8 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.8\",\n)\nskip_py39 = pytest.mark.skipif(\n    sys.version_info.minor == 9 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.9\",\n)\nskip_py310 = pytest.mark.skipif(\n    sys.version_info.minor == 10 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.10\",\n)\nskip_py311 = pytest.mark.skipif(\n    sys.version_info.minor == 11 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.11\",\n)\nskip_py312 = pytest.mark.skipif(\n    sys.version_info.minor == 12 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.12\",\n)\nskip_py313 = pytest.mark.skipif(\n    sys.version_info.minor == 13 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.13\",\n)\nskip_py314 = pytest.mark.skipif(\n    sys.version_info.minor == 14 and sys.version_info.major == 3,\n    reason=\"rendered differently on py3.14\",\n)\n\n\ndef test_install() -> None:\n    console = Console(file=io.StringIO())\n    dh = sys.displayhook\n    install(console)\n    sys.displayhook(\"foo\")\n    assert console.file.getvalue() == \"'foo'\\n\"\n    assert sys.displayhook is not dh\n\n\ndef test_install_max_depth() -> None:\n    console = Console(file=io.StringIO())\n    dh = sys.displayhook\n    install(console, max_depth=1)\n    sys.displayhook({\"foo\": {\"bar\": True}})\n    assert console.file.getvalue() == \"{'foo': {...}}\\n\"\n    assert sys.displayhook is not dh\n\n\ndef test_ipy_display_hook__repr_html() -> None:\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def _repr_html_(self):\n            return \"hello\"\n\n    console.begin_capture()\n    _ipy_display_hook(Thing(), console=console)\n\n    # Rendering delegated to notebook because _repr_html_ method exists\n    assert console.end_capture() == \"\"\n\n\ndef test_ipy_display_hook__multiple_special_reprs() -> None:\n    \"\"\"\n    The case where there are multiple IPython special _repr_*_\n    methods on the object, and one of them returns None but another\n    one does not.\n    \"\"\"\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def __repr__(self):\n            return \"A Thing\"\n\n        def _repr_latex_(self):\n            return None\n\n        def _repr_html_(self):\n            return \"hello\"\n\n    result = _ipy_display_hook(Thing(), console=console)\n    assert result == \"A Thing\"\n\n\ndef test_ipy_display_hook__no_special_repr_methods() -> None:\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def __repr__(self) -> str:\n            return \"hello\"\n\n    result = _ipy_display_hook(Thing(), console=console)\n    # should be repr as-is\n    assert result == \"hello\"\n\n\ndef test_ipy_display_hook__special_repr_raises_exception() -> None:\n    \"\"\"\n    When an IPython special repr method raises an exception,\n    we treat it as if it doesn't exist and look for the next.\n    \"\"\"\n    console = Console(file=io.StringIO(), force_jupyter=True)\n\n    class Thing:\n        def _repr_markdown_(self):\n            raise Exception()\n\n        def _repr_latex_(self):\n            return None\n\n        def _repr_html_(self):\n            return \"hello\"\n\n        def __repr__(self):\n            return \"therepr\"\n\n    result = _ipy_display_hook(Thing(), console=console)\n    assert result == \"therepr\"\n\n\ndef test_ipy_display_hook__console_renderables_on_newline() -> None:\n    console = Console(file=io.StringIO(), force_jupyter=True)\n    console.begin_capture()\n    result = _ipy_display_hook(Text(\"hello\"), console=console)\n    assert result == \"\\nhello\"\n\n\ndef test_pretty() -> None:\n    test = {\n        \"foo\": [1, 2, 3, (4, 5, {6}, 7, 8, {9}), {}],\n        \"bar\": {\"egg\": \"baz\", \"words\": [\"Hello World\"] * 10},\n        False: \"foo\",\n        True: \"\",\n        \"text\": (\"Hello World\", \"foo bar baz egg\"),\n    }\n\n    result = pretty_repr(test, max_width=80)\n    print(result)\n    expected = \"{\\n    'foo': [1, 2, 3, (4, 5, {6}, 7, 8, {9}), {}],\\n    'bar': {\\n        'egg': 'baz',\\n        'words': [\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World',\\n            'Hello World'\\n        ]\\n    },\\n    False: 'foo',\\n    True: '',\\n    'text': ('Hello World', 'foo bar baz egg')\\n}\"\n    print(expected)\n    assert result == expected\n\n\n@dataclass\nclass ExampleDataclass:\n    foo: int\n    bar: str\n    ignore: int = field(repr=False)\n    baz: List[str] = field(default_factory=list)\n    last: int = field(default=1, repr=False)\n\n\n@dataclass\nclass Empty:\n    pass\n\n\ndef test_pretty_dataclass() -> None:\n    dc = ExampleDataclass(1000, \"Hello, World\", 999, [\"foo\", \"bar\", \"baz\"])\n    result = pretty_repr(dc, max_width=80)\n    print(repr(result))\n    assert (\n        result\n        == \"ExampleDataclass(foo=1000, bar='Hello, World', baz=['foo', 'bar', 'baz'])\"\n    )\n    result = pretty_repr(dc, max_width=16)\n    print(repr(result))\n    assert (\n        result\n        == \"ExampleDataclass(\\n    foo=1000,\\n    bar='Hello, World',\\n    baz=[\\n        'foo',\\n        'bar',\\n        'baz'\\n    ]\\n)\"\n    )\n    dc.bar = dc\n    result = pretty_repr(dc, max_width=80)\n    print(repr(result))\n    assert result == \"ExampleDataclass(foo=1000, bar=..., baz=['foo', 'bar', 'baz'])\"\n\n\ndef test_empty_dataclass() -> None:\n    assert pretty_repr(Empty()) == \"Empty()\"\n    assert pretty_repr([Empty()]) == \"[Empty()]\"\n\n\nclass StockKeepingUnit(NamedTuple):\n    name: str\n    description: str\n    price: float\n    category: str\n    reviews: List[str]\n\n\ndef test_pretty_namedtuple() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n\n    example_namedtuple = StockKeepingUnit(\n        \"Sparkling British Spring Water\",\n        \"Carbonated spring water\",\n        0.9,\n        \"water\",\n        [\"its amazing!\", \"its terrible!\"],\n    )\n\n    result = pretty_repr(example_namedtuple)\n\n    print(result)\n    assert (\n        result\n        == \"\"\"StockKeepingUnit(\n    name='Sparkling British Spring Water',\n    description='Carbonated spring water',\n    price=0.9,\n    category='water',\n    reviews=['its amazing!', 'its terrible!']\n)\"\"\"\n    )\n\n\ndef test_pretty_namedtuple_length_one_no_trailing_comma() -> None:\n    instance = collections.namedtuple(\"Thing\", [\"name\"])(name=\"Bob\")\n    assert pretty_repr(instance) == \"Thing(name='Bob')\"\n\n\ndef test_pretty_namedtuple_empty() -> None:\n    instance = collections.namedtuple(\"Thing\", [])()\n    assert pretty_repr(instance) == \"Thing()\"\n\n\ndef test_pretty_namedtuple_custom_repr() -> None:\n    class Thing(NamedTuple):\n        def __repr__(self):\n            return \"XX\"\n\n    assert pretty_repr(Thing()) == \"XX\"\n\n\ndef test_pretty_namedtuple_fields_invalid_type() -> None:\n    class LooksLikeANamedTupleButIsnt(tuple):\n        _fields = \"blah\"\n\n    instance = LooksLikeANamedTupleButIsnt()\n    result = pretty_repr(instance)\n    assert result == \"()\"  # Treated as tuple\n\n\ndef test_pretty_namedtuple_max_depth() -> None:\n    instance = {\"unit\": StockKeepingUnit(\"a\", \"b\", 1.0, \"c\", [\"d\", \"e\"])}\n    result = pretty_repr(instance, max_depth=1)\n    assert result == \"{'unit': StockKeepingUnit(...)}\"\n\n\ndef test_small_width() -> None:\n    test = [\"Hello world! 12345\"]\n    result = pretty_repr(test, max_width=10)\n    expected = \"[\\n    'Hello world! 12345'\\n]\"\n    assert result == expected\n\n\ndef test_ansi_in_pretty_repr() -> None:\n    class Hello:\n        def __repr__(self):\n            return \"Hello \\x1b[38;5;239mWorld!\"\n\n    pretty = Pretty(Hello())\n\n    console = Console(file=io.StringIO(), record=True)\n    console.print(pretty)\n    result = console.export_text()\n\n    assert result == \"Hello World!\\n\"\n\n\ndef test_broken_repr() -> None:\n    class BrokenRepr:\n        def __repr__(self):\n            1 / 0\n\n    test = [BrokenRepr()]\n    result = pretty_repr(test)\n    expected = \"[<repr-error 'division by zero'>]\"\n    assert result == expected\n\n\ndef test_broken_getattr() -> None:\n    class BrokenAttr:\n        def __getattr__(self, name):\n            1 / 0\n\n        def __repr__(self):\n            return \"BrokenAttr()\"\n\n    test = BrokenAttr()\n    result = pretty_repr(test)\n    assert result == \"BrokenAttr()\"\n\n\ndef test_reference_cycle_container() -> None:\n    test = []\n    test.append(test)\n    res = pretty_repr(test)\n    assert res == \"[...]\"\n\n    test = [1, []]\n    test[1].append(test)\n    res = pretty_repr(test)\n    assert res == \"[1, [...]]\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = [2]\n    test = [1, [a, a]]\n    res = pretty_repr(test)\n    assert res == \"[1, [[2], [2]]]\"\n\n\ndef test_reference_cycle_namedtuple() -> None:\n    class Example(NamedTuple):\n        x: int\n        y: Any\n\n    test = Example(1, [Example(2, [])])\n    test.y[0].y.append(test)\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=[...])])\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_reference_cycle_dataclass() -> None:\n    @dataclass\n    class Example:\n        x: int\n        y: Any\n\n    test = Example(1, None)\n    test.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=...)\"\n\n    test = Example(1, Example(2, None))\n    test.y.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=Example(x=2, y=...))\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_reference_cycle_attrs() -> None:\n    @attr.define\n    class Example:\n        x: int\n        y: Any\n\n    test = Example(1, None)\n    test.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=...)\"\n\n    test = Example(1, Example(2, None))\n    test.y.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=Example(x=2, y=...))\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_reference_cycle_custom_repr() -> None:\n    class Example:\n        def __init__(self, x, y):\n            self.x = x\n            self.y = y\n\n        def __rich_repr__(self):\n            yield (\"x\", self.x)\n            yield (\"y\", self.y)\n\n    test = Example(1, None)\n    test.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=...)\"\n\n    test = Example(1, Example(2, None))\n    test.y.y = test\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=Example(x=2, y=...))\"\n\n    # Not a cyclic reference, just a repeated reference\n    a = Example(2, None)\n    test = Example(1, [a, a])\n    res = pretty_repr(test)\n    assert res == \"Example(x=1, y=[Example(x=2, y=None), Example(x=2, y=None)])\"\n\n\ndef test_max_depth() -> None:\n    d = {}\n    d[\"foo\"] = {\"fob\": {\"a\": [1, 2, 3], \"b\": {\"z\": \"x\", \"y\": [\"a\", \"b\", \"c\"]}}}\n\n    assert pretty_repr(d, max_depth=0) == \"{...}\"\n    assert pretty_repr(d, max_depth=1) == \"{'foo': {...}}\"\n    assert pretty_repr(d, max_depth=2) == \"{'foo': {'fob': {...}}}\"\n    assert pretty_repr(d, max_depth=3) == \"{'foo': {'fob': {'a': [...], 'b': {...}}}}\"\n    assert (\n        pretty_repr(d, max_width=100, max_depth=4)\n        == \"{'foo': {'fob': {'a': [1, 2, 3], 'b': {'z': 'x', 'y': [...]}}}}\"\n    )\n    assert (\n        pretty_repr(d, max_width=100, max_depth=5)\n        == \"{'foo': {'fob': {'a': [1, 2, 3], 'b': {'z': 'x', 'y': ['a', 'b', 'c']}}}}\"\n    )\n    assert (\n        pretty_repr(d, max_width=100, max_depth=None)\n        == \"{'foo': {'fob': {'a': [1, 2, 3], 'b': {'z': 'x', 'y': ['a', 'b', 'c']}}}}\"\n    )\n\n\ndef test_max_depth_rich_repr() -> None:\n    class Foo:\n        def __init__(self, foo):\n            self.foo = foo\n\n        def __rich_repr__(self):\n            yield \"foo\", self.foo\n\n    class Bar:\n        def __init__(self, bar):\n            self.bar = bar\n\n        def __rich_repr__(self):\n            yield \"bar\", self.bar\n\n    assert (\n        pretty_repr(Foo(foo=Bar(bar=Foo(foo=[]))), max_depth=2)\n        == \"Foo(foo=Bar(bar=Foo(...)))\"\n    )\n\n\ndef test_max_depth_attrs() -> None:\n    @attr.define\n    class Foo:\n        foo = attr.field()\n\n    @attr.define\n    class Bar:\n        bar = attr.field()\n\n    assert (\n        pretty_repr(Foo(foo=Bar(bar=Foo(foo=[]))), max_depth=2)\n        == \"Foo(foo=Bar(bar=Foo(...)))\"\n    )\n\n\ndef test_max_depth_dataclass() -> None:\n    @dataclass\n    class Foo:\n        foo: object\n\n    @dataclass\n    class Bar:\n        bar: object\n\n    assert (\n        pretty_repr(Foo(foo=Bar(bar=Foo(foo=[]))), max_depth=2)\n        == \"Foo(foo=Bar(bar=Foo(...)))\"\n    )\n\n\ndef test_defaultdict() -> None:\n    test_dict = defaultdict(int, {\"foo\": 2})\n    result = pretty_repr(test_dict)\n    assert result == \"defaultdict(<class 'int'>, {'foo': 2})\"\n\n\ndef test_deque() -> None:\n    test_deque = deque([1, 2, 3])\n    result = pretty_repr(test_deque)\n    assert result == \"deque([1, 2, 3])\"\n    test_deque = deque([1, 2, 3], maxlen=None)\n    result = pretty_repr(test_deque)\n    assert result == \"deque([1, 2, 3])\"\n    test_deque = deque([1, 2, 3], maxlen=5)\n    result = pretty_repr(test_deque)\n    assert result == \"deque([1, 2, 3], maxlen=5)\"\n    test_deque = deque([1, 2, 3], maxlen=0)\n    result = pretty_repr(test_deque)\n    assert result == \"deque(maxlen=0)\"\n    test_deque = deque([])\n    result = pretty_repr(test_deque)\n    assert result == \"deque()\"\n    test_deque = deque([], maxlen=None)\n    result = pretty_repr(test_deque)\n    assert result == \"deque()\"\n    test_deque = deque([], maxlen=5)\n    result = pretty_repr(test_deque)\n    assert result == \"deque(maxlen=5)\"\n    test_deque = deque([], maxlen=0)\n    result = pretty_repr(test_deque)\n    assert result == \"deque(maxlen=0)\"\n\n\ndef test_array() -> None:\n    test_array = array(\"I\", [1, 2, 3])\n    result = pretty_repr(test_array)\n    assert result == \"array('I', [1, 2, 3])\"\n\n\ndef test_tuple_of_one() -> None:\n    assert pretty_repr((1,)) == \"(1,)\"\n\n\ndef test_node() -> None:\n    node = Node(\"abc\")\n    assert pretty_repr(node) == \"abc: \"\n\n\ndef test_indent_lines() -> None:\n    console = Console(width=100, color_system=None)\n    console.begin_capture()\n    console.print(Pretty([100, 200], indent_guides=True), width=8)\n    expected = \"\"\"\\\n[\n\u2502   100,\n\u2502   200\n]\n\"\"\"\n    result = console.end_capture()\n    print(repr(result))\n    print(result)\n    assert result == expected\n\n\ndef test_pprint() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint(1, console=console)\n    assert console.end_capture() == \"1\\n\"\n\n\ndef test_pprint_max_values() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], console=console, max_length=2)\n    assert console.end_capture() == \"[1, 2, ... +8]\\n\"\n\n\ndef test_pprint_max_items() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint({\"foo\": 1, \"bar\": 2, \"egg\": 3}, console=console, max_length=2)\n    assert console.end_capture() == \"\"\"{'foo': 1, 'bar': 2, ... +1}\\n\"\"\"\n\n\ndef test_pprint_max_string() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint([\"Hello\" * 20], console=console, max_string=8)\n    assert console.end_capture() == \"\"\"['HelloHel'+92]\\n\"\"\"\n\n\ndef test_tuples() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    pprint((1,), console=console)\n    pprint((1,), expand_all=True, console=console)\n    pprint(((1,),), expand_all=True, console=console)\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"(1,)\\n(\\n\u2502   1,\\n)\\n(\\n\u2502   (\\n\u2502   \u2502   1,\\n\u2502   ),\\n)\\n\"\n    print(result)\n    print(\"--\")\n    print(expected)\n    assert result == expected\n\n\ndef test_newline() -> None:\n    console = Console(color_system=None)\n    console.begin_capture()\n    console.print(Pretty((1,), insert_line=True, expand_all=True))\n    result = console.end_capture()\n    expected = \"\\n(\\n    1,\\n)\\n\"\n    assert result == expected\n\n\ndef test_empty_repr() -> None:\n    class Foo:\n        def __repr__(self):\n            return \"\"\n\n    assert pretty_repr(Foo()) == \"\"\n\n\ndef test_attrs() -> None:\n    @attr.define\n    class Point:\n        x: int\n        y: int\n        foo: str = attr.field(repr=str.upper)\n        z: int = 0\n\n    result = pretty_repr(Point(1, 2, foo=\"bar\"))\n    print(repr(result))\n    expected = \"Point(x=1, y=2, foo=BAR, z=0)\"\n    assert result == expected\n\n\ndef test_attrs_empty() -> None:\n    @attr.define\n    class Nada:\n        pass\n\n    result = pretty_repr(Nada())\n    print(repr(result))\n    expected = \"Nada()\"\n    assert result == expected\n\n\n@skip_py310\n@skip_py311\n@skip_py312\n@skip_py313\n@skip_py314\ndef test_attrs_broken() -> None:\n    @attr.define\n    class Foo:\n        bar: int\n\n    foo = Foo(1)\n    del foo.bar\n    result = pretty_repr(foo)\n    print(repr(result))\n    expected = \"Foo(bar=AttributeError('bar'))\"\n    assert result == expected\n\n\n@skip_py38\n@skip_py39\ndef test_attrs_broken_310() -> None:\n    @attr.define\n    class Foo:\n        bar: int\n\n    foo = Foo(1)\n    del foo.bar\n    result = pretty_repr(foo)\n    print(repr(result))\n    if sys.version_info >= (3, 13):\n        expected = \"Foo(\\n    bar=AttributeError(\\\"'tests.test_pretty.test_attrs_broken_310.<locals>.Foo' object has no attribute 'bar'\\\")\\n)\"\n    else:\n        expected = \"Foo(bar=AttributeError(\\\"'Foo' object has no attribute 'bar'\\\"))\"\n    assert result == expected\n\n\ndef test_user_dict() -> None:\n    class D1(UserDict):\n        pass\n\n    class D2(UserDict):\n        def __repr__(self):\n            return \"FOO\"\n\n    d1 = D1({\"foo\": \"bar\"})\n    d2 = D2({\"foo\": \"bar\"})\n    result = pretty_repr(d1, expand_all=True)\n    print(repr(result))\n    assert result == \"{\\n    'foo': 'bar'\\n}\"\n    result = pretty_repr(d2, expand_all=True)\n    print(repr(result))\n    assert result == \"FOO\"\n\n\ndef test_lying_attribute() -> None:\n    \"\"\"Test getattr doesn't break rich repr protocol\"\"\"\n\n    class Foo:\n        def __getattr__(self, attr):\n            return \"foo\"\n\n    foo = Foo()\n    result = pretty_repr(foo)\n    assert \"Foo\" in result\n\n\ndef test_measure_pretty() -> None:\n    \"\"\"Test measure respects expand_all\"\"\"\n    # https://github.com/Textualize/rich/issues/1998\n    console = Console()\n    pretty = Pretty([\"alpha\", \"beta\", \"delta\", \"gamma\"], expand_all=True)\n\n    measurement = console.measure(pretty)\n    assert measurement == Measurement(12, 12)\n\n\ndef test_tuple_rich_repr() -> None:\n    \"\"\"\n    Test that can use None as key to have tuple positional values.\n    \"\"\"\n\n    class Foo:\n        def __rich_repr__(self):\n            yield None, (1,)\n\n    assert pretty_repr(Foo()) == \"Foo((1,))\"\n\n\ndef test_tuple_rich_repr_default() -> None:\n    \"\"\"\n    Test that can use None as key to have tuple positional values and with a default.\n    \"\"\"\n\n    class Foo:\n        def __rich_repr__(self):\n            yield None, (1,), (1,)\n\n    assert pretty_repr(Foo()) == \"Foo()\"\n\n\ndef test_dataclass_no_attribute() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3417\"\"\"\n    from dataclasses import dataclass, field\n\n    @dataclass(eq=False)\n    class BadDataclass:\n        item: int = field(init=False)\n\n    # item is not provided\n    bad_data_class = BadDataclass()\n\n    console = Console()\n    with console.capture() as capture:\n        console.print(bad_data_class)\n\n    expected = \"BadDataclass()\\n\"\n    result = capture.get()\n    assert result == expected\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "8105eb9fedda",
      "repo": "rich",
      "commit_hash": "655b521",
      "commit_message": "test fixes",
      "file_path": "tests/test_text.py",
      "language": "python",
      "code_before": "import re\nfrom io import StringIO\nfrom typing import List\n\nimport pytest\n\nfrom rich.console import Console, Group\nfrom rich.measure import Measurement\nfrom rich.style import Style\nfrom rich.text import Span, Text\n\n\ndef test_span():\n    span = Span(1, 10, \"foo\")\n    repr(span)\n    assert bool(span)\n    assert not Span(10, 10, \"foo\")\n\n\ndef test_span_split():\n    assert Span(5, 10, \"foo\").split(2) == (Span(5, 10, \"foo\"), None)\n    assert Span(5, 10, \"foo\").split(15) == (Span(5, 10, \"foo\"), None)\n    assert Span(0, 10, \"foo\").split(5) == (Span(0, 5, \"foo\"), Span(5, 10, \"foo\"))\n\n\ndef test_span_move():\n    assert Span(5, 10, \"foo\").move(2) == Span(7, 12, \"foo\")\n\n\ndef test_span_right_crop():\n    assert Span(5, 10, \"foo\").right_crop(15) == Span(5, 10, \"foo\")\n    assert Span(5, 10, \"foo\").right_crop(7) == Span(5, 7, \"foo\")\n\n\ndef test_len():\n    assert len(Text(\"foo\")) == 3\n\n\ndef test_cell_len():\n    assert Text(\"foo\").cell_len == 3\n    assert Text(\"\ud83d\ude00\").cell_len == 2\n\n\ndef test_bool():\n    assert Text(\"foo\")\n    assert not Text(\"\")\n\n\ndef test_str():\n    assert str(Text(\"foo\")) == \"foo\"\n\n\ndef test_repr():\n    assert isinstance(repr(Text(\"foo\")), str)\n\n\ndef test_add():\n    text = Text(\"foo\") + Text(\"bar\")\n    assert str(text) == \"foobar\"\n    assert Text(\"foo\").__add__(1) == NotImplemented\n\n\ndef test_eq():\n    assert Text(\"foo\") == Text(\"foo\")\n    assert Text(\"foo\") != Text(\"bar\")\n    assert Text(\"foo\").__eq__(1) == NotImplemented\n\n\ndef test_contain():\n    text = Text(\"foobar\")\n    assert \"foo\" in text\n    assert \"foo \" not in text\n    assert Text(\"bar\") in text\n    assert None not in text\n\n\ndef test_plain_property():\n    text = Text(\"foo\")\n    text.append(\"bar\")\n    text.append(\"baz\")\n    assert text.plain == \"foobarbaz\"\n\n\ndef test_plain_property_setter():\n    text = Text(\"foo\")\n    text.plain = \"bar\"\n    assert str(text) == \"bar\"\n    text = Text()\n    text.append(\"Hello, World\", \"bold\")\n    text.plain = \"Hello\"\n    assert str(text) == \"Hello\"\n    assert text._spans == [Span(0, 5, \"bold\")]\n\n\ndef test_from_markup():\n    text = Text.from_markup(\"Hello, [bold]World![/bold]\")\n    assert str(text) == \"Hello, World!\"\n    assert text._spans == [Span(7, 13, \"bold\")]\n\n\ndef test_from_ansi():\n    text = Text.from_ansi(\"Hello, \\033[1mWorld!\\033[0m\")\n    assert str(text) == \"Hello, World!\"\n    assert text._spans == [Span(7, 13, Style(bold=True))]\n\n    text = Text.from_ansi(\"Hello, \\033[1m\\nWorld!\\033[0m\")\n    assert str(text) == \"Hello, \\nWorld!\"\n    assert text._spans == [Span(8, 14, Style(bold=True))]\n\n    text = Text.from_ansi(\"\\033[1mBOLD\\033[m not bold\")\n    assert str(text) == \"BOLD not bold\"\n    assert text._spans == [Span(0, 4, Style(bold=True))]\n\n    text = Text.from_ansi(\"\\033[1m\\033[Kfoo barmbaz\")\n    assert str(text) == \"foo barmbaz\"\n    assert text._spans == [Span(0, 11, Style(bold=True))]\n\n\ndef test_copy():\n    text = Text()\n    text.append(\"Hello\", \"bold\")\n    text.append(\" \")\n    text.append(\"World\", \"italic\")\n    test_copy = text.copy()\n    assert text == test_copy\n    assert text is not test_copy\n\n\ndef test_rstrip():\n    text = Text(\"Hello, World!    \")\n    text.rstrip()\n    assert str(text) == \"Hello, World!\"\n\n\ndef test_rstrip_end():\n    text = Text(\"Hello, World!    \")\n    text.rstrip_end(14)\n    assert str(text) == \"Hello, World! \"\n\n\ndef test_stylize():\n    text = Text(\"Hello, World!\")\n    text.stylize(\"bold\", 7, 11)\n    assert text._spans == [Span(7, 11, \"bold\")]\n    text.stylize(\"bold\", 20, 25)\n    assert text._spans == [Span(7, 11, \"bold\")]\n\n\ndef test_stylize_before():\n    text = Text(\"Hello, World!\")\n    text.stylize(\"bold\", 0, 5)\n    text.stylize_before(\"italic\", 2, 7)\n    assert text._spans == [Span(2, 7, \"italic\"), Span(0, 5, \"bold\")]\n\n\ndef test_stylize_negative_index():\n    text = Text(\"Hello, World!\")\n    text.stylize(\"bold\", -6, -1)\n    assert text._spans == [Span(7, 12, \"bold\")]\n\n\ndef test_highlight_regex():\n    # As a string\n    text = Text(\"peek-a-boo\")\n\n    count = text.highlight_regex(r\"NEVER_MATCH\", \"red\")\n    assert count == 0\n    assert len(text._spans) == 0\n\n    # text: peek-a-boo\n    # indx: 0123456789\n    count = text.highlight_regex(r\"[a|e|o]+\", \"red\")\n    assert count == 3\n    assert sorted(text._spans) == [\n        Span(1, 3, \"red\"),\n        Span(5, 6, \"red\"),\n        Span(8, 10, \"red\"),\n    ]\n\n    text = Text(\"Ada Lovelace, Alan Turing\")\n\n    count = text.highlight_regex(\n        r\"(?P<yellow>[A-Za-z]+)[ ]+(?P<red>[A-Za-z]+)(?P<NEVER_MATCH>NEVER_MATCH)*\"\n    )\n\n    # The number of matched name should be 2\n    assert count == 2\n    assert sorted(text._spans) == [\n        Span(0, 3, \"yellow\"),  # Ada\n        Span(4, 12, \"red\"),  # Lovelace\n        Span(14, 18, \"yellow\"),  # Alan\n        Span(19, 25, \"red\"),  # Turing\n    ]\n\n    # As a regular expression object\n    text = Text(\"peek-a-boo\")\n\n    count = text.highlight_regex(re.compile(r\"NEVER_MATCH\"), \"red\")\n    assert count == 0\n    assert len(text._spans) == 0\n\n    # text: peek-a-boo\n    # indx: 0123456789\n    count = text.highlight_regex(re.compile(r\"[a|e|o]+\"), \"red\")\n    assert count == 3\n    assert sorted(text._spans) == [\n        Span(1, 3, \"red\"),\n        Span(5, 6, \"red\"),\n        Span(8, 10, \"red\"),\n    ]\n\n    text = Text(\"Ada Lovelace, Alan Turing\")\n\n    count = text.highlight_regex(\n        re.compile(\n            r\"(?P<yellow>[A-Za-z]+)[ ]+(?P<red>[A-Za-z]+)(?P<NEVER_MATCH>NEVER_MATCH)*\"\n        )\n    )\n\n    # The number of matched name should be 2\n    assert count == 2\n    assert sorted(text._spans) == [\n        Span(0, 3, \"yellow\"),  # Ada\n        Span(4, 12, \"red\"),  # Lovelace\n        Span(14, 18, \"yellow\"),  # Alan\n        Span(19, 25, \"red\"),  # Turing\n    ]\n\n\ndef test_highlight_regex_callable():\n    text = Text(\"Vulnerability CVE-2018-6543 detected\")\n    re_cve = r\"CVE-\\d{4}-\\d+\"\n    compiled_re_cve = re.compile(r\"CVE-\\d{4}-\\d+\")\n\n    def get_style(text: str) -> Style:\n        return Style.parse(\n            f\"bold yellow link https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword={text}\"\n        )\n\n    # string\n    count = text.highlight_regex(re_cve, get_style)\n    assert count == 1\n    assert len(text._spans) == 1\n    assert text._spans[0].start == 14\n    assert text._spans[0].end == 27\n    assert (\n        text._spans[0].style.link\n        == \"https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=CVE-2018-6543\"\n    )\n\n    # Clear the tracked _spans for the regular expression object's use\n    text._spans.clear()\n\n    # regular expression object\n    count = text.highlight_regex(compiled_re_cve, get_style)\n    assert count == 1\n    assert len(text._spans) == 1\n    assert text._spans[0].start == 14\n    assert text._spans[0].end == 27\n    assert (\n        text._spans[0].style.link\n        == \"https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=CVE-2018-6543\"\n    )\n\n\ndef test_highlight_words():\n    text = Text(\"Do NOT! touch anything!\")\n    words = [\"NOT\", \"!\"]\n    count = text.highlight_words(words, \"red\")\n    assert count == 3\n    assert sorted(text._spans) == [\n        Span(3, 6, \"red\"),  # NOT\n        Span(6, 7, \"red\"),  # !\n        Span(22, 23, \"red\"),  # !\n    ]\n\n    # regex escape test\n    text = Text(\"[o|u]aeiou\")\n    words = [\"[a|e|i]\", \"[o|u]\"]\n    count = text.highlight_words(words, \"red\")\n    assert count == 1\n    assert text._spans == [Span(0, 5, \"red\")]\n\n    # case sensitive\n    text = Text(\"AB Ab aB ab\")\n    words = [\"AB\"]\n\n    count = text.highlight_words(words, \"red\")\n    assert count == 1\n    assert text._spans == [Span(0, 2, \"red\")]\n\n    text = Text(\"AB Ab aB ab\")\n    count = text.highlight_words(words, \"red\", case_sensitive=False)\n    assert count == 4\n\n\ndef test_set_length():\n    text = Text(\"Hello\")\n    text.set_length(5)\n    assert text == Text(\"Hello\")\n\n    text = Text(\"Hello\")\n    text.set_length(10)\n    assert text == Text(\"Hello     \")\n\n    text = Text(\"Hello World\")\n    text.stylize(\"bold\", 0, 5)\n    text.stylize(\"italic\", 7, 9)\n\n    text.set_length(3)\n    expected = Text()\n    expected.append(\"Hel\", \"bold\")\n    assert text == expected\n\n\ndef test_console_width():\n    console = Console()\n    text = Text(\"Hello World!\\nfoobarbaz\")\n    assert text.__rich_measure__(console, 80) == Measurement(9, 12)\n    assert Text(\" \" * 4).__rich_measure__(console, 80) == Measurement(4, 4)\n    assert Text(\" \\n  \\n   \").__rich_measure__(console, 80) == Measurement(3, 3)\n\n\ndef test_join():\n    text = Text(\"bar\").join([Text(\"foo\", \"red\"), Text(\"baz\", \"blue\")])\n    assert str(text) == \"foobarbaz\"\n    assert text._spans == [Span(0, 3, \"red\"), Span(6, 9, \"blue\")]\n\n\ndef test_trim_spans():\n    text = Text(\"Hello\")\n    text._spans[:] = [Span(0, 3, \"red\"), Span(3, 6, \"green\"), Span(6, 9, \"blue\")]\n    text._trim_spans()\n    assert text._spans == [Span(0, 3, \"red\"), Span(3, 5, \"green\")]\n\n\ndef test_pad_left():\n    text = Text(\"foo\")\n    text.pad_left(3, \"X\")\n    assert str(text) == \"XXXfoo\"\n\n\ndef test_pad_right():\n    text = Text(\"foo\")\n    text.pad_right(3, \"X\")\n    assert str(text) == \"fooXXX\"\n\n\ndef test_append():\n    text = Text(\"foo\")\n    text.append(\"bar\")\n    assert str(text) == \"foobar\"\n    text.append(Text(\"baz\", \"bold\"))\n    assert str(text) == \"foobarbaz\"\n    assert text._spans == [Span(6, 9, \"bold\")]\n\n    with pytest.raises(ValueError):\n        text.append(Text(\"foo\"), \"bar\")\n\n    with pytest.raises(TypeError):\n        text.append(1)\n\n\ndef test_append_text():\n    text = Text(\"foo\")\n    text.append_text(Text(\"bar\", style=\"bold\"))\n    assert str(text) == \"foobar\"\n    assert text._spans == [Span(3, 6, \"bold\")]\n\n\ndef test_end():\n    console = Console(width=20, file=StringIO())\n    text = Group(Text.from_markup(\"foo\", end=\" \"), Text.from_markup(\"bar\"))\n    console.print(text)\n    assert console.file.getvalue() == \"foo bar\\n\"\n\n\ndef test_split():\n    text = Text()\n    text.append(\"foo\", \"red\")\n    text.append(\"\\n\")\n    text.append(\"bar\", \"green\")\n    text.append(\"\\n\")\n\n    line1 = Text()\n    line1.append(\"foo\", \"red\")\n    line2 = Text()\n    line2.append(\"bar\", \"green\")\n    split = text.split(\"\\n\")\n    assert len(split) == 2\n    assert split[0] == line1\n    assert split[1] == line2\n\n    assert list(Text(\"foo\").split(\"\\n\")) == [Text(\"foo\")]\n\n\ndef test_split_spans():\n    text = Text.from_markup(\"[red]Hello\\n[b]World\")\n    lines = text.split(\"\\n\")\n    assert lines[0].plain == \"Hello\"\n    assert lines[1].plain == \"World\"\n    assert lines[0].spans == [Span(0, 5, \"red\")]\n    assert lines[1].spans == [Span(0, 5, \"red\"), Span(0, 5, \"bold\")]\n\n\ndef test_divide():\n    lines = Text(\"foo\").divide([])\n    assert len(lines) == 1\n    assert lines[0] == Text(\"foo\")\n\n    text = Text()\n    text.append(\"foo\", \"bold\")\n    lines = text.divide([1, 2])\n    assert len(lines) == 3\n    assert str(lines[0]) == \"f\"\n    assert str(lines[1]) == \"o\"\n    assert str(lines[2]) == \"o\"\n    assert lines[0]._spans == [Span(0, 1, \"bold\")]\n    assert lines[1]._spans == [Span(0, 1, \"bold\")]\n    assert lines[2]._spans == [Span(0, 1, \"bold\")]\n\n    text = Text()\n    text.append(\"foo\", \"red\")\n    text.append(\"bar\", \"green\")\n    text.append(\"baz\", \"blue\")\n    lines = text.divide([8])\n    assert len(lines) == 2\n    assert str(lines[0]) == \"foobarba\"\n    assert str(lines[1]) == \"z\"\n    assert lines[0]._spans == [\n        Span(0, 3, \"red\"),\n        Span(3, 6, \"green\"),\n        Span(6, 8, \"blue\"),\n    ]\n    assert lines[1]._spans == [Span(0, 1, \"blue\")]\n\n    lines = text.divide([1])\n    assert len(lines) == 2\n    assert str(lines[0]) == \"f\"\n    assert str(lines[1]) == \"oobarbaz\"\n    assert lines[0]._spans == [Span(0, 1, \"red\")]\n    assert lines[1]._spans == [\n        Span(0, 2, \"red\"),\n        Span(2, 5, \"green\"),\n        Span(5, 8, \"blue\"),\n    ]\n\n\ndef test_right_crop():\n    text = Text()\n    text.append(\"foobar\", \"red\")\n    text.right_crop(3)\n    assert str(text) == \"foo\"\n    assert text._spans == [Span(0, 3, \"red\")]\n\n\ndef test_wrap_3():\n    text = Text(\"foo bar baz\")\n    lines = text.wrap(Console(), 3)\n    print(repr(lines))\n    assert len(lines) == 3\n    assert lines[0] == Text(\"foo\")\n    assert lines[1] == Text(\"bar\")\n    assert lines[2] == Text(\"baz\")\n\n\ndef test_wrap_4():\n    text = Text(\"foo bar baz\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n    assert len(lines) == 3\n    assert lines[0] == Text(\"foo \")\n    assert lines[1] == Text(\"bar \")\n    assert lines[2] == Text(\"baz \")\n\n\ndef test_wrap_wrapped_word_length_greater_than_available_width():\n    text = Text(\"1234 12345678\")\n    lines = text.wrap(Console(), 7)\n    assert lines._lines == [\n        Text(\"1234 \"),\n        Text(\"1234567\"),\n        Text(\"8\"),\n    ]\n\n\ndef test_wrap_cjk():\n    text = Text(\"\u308f\u3055\u3073\")\n    lines = text.wrap(Console(), 4)\n    assert lines._lines == [\n        Text(\"\u308f\u3055\"),\n        Text(\"\u3073\"),\n    ]\n\n\ndef test_wrap_cjk_width_mid_character():\n    text = Text(\"\u308f\u3055\u3073\")\n    lines = text.wrap(Console(), 3)\n    assert lines._lines == [\n        Text(\"\u308f\"),\n        Text(\"\u3055\"),\n        Text(\"\u3073\"),\n    ]\n\n\ndef test_wrap_cjk_mixed():\n    \"\"\"Regression test covering https://github.com/Textualize/rich/issues/3176 and\n    https://github.com/Textualize/textual/issues/3567 - double width characters could\n    result in text going missing when wrapping.\"\"\"\n    text = Text(\"123\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3057\u305f\")\n    console = Console(width=20)  # let's ensure the width passed to wrap() wins.\n\n    wrapped_lines = text.wrap(console, width=8)\n    with console.capture() as capture:\n        console.print(wrapped_lines)\n\n    assert capture.get() == \"123\u3042\u308a\\n\u304c\u3068\u3046\u3054\\n\u3056\u3044\u307e\u3057\\n\u305f\\n\"\n\n\ndef test_wrap_long():\n    text = Text(\"abracadabra\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n    assert len(lines) == 3\n    assert lines[0] == Text(\"abra\")\n    assert lines[1] == Text(\"cada\")\n    assert lines[2] == Text(\"bra \")\n\n\ndef test_wrap_overflow():\n    text = Text(\"Some more words\")\n    lines = text.wrap(Console(), 4, overflow=\"ellipsis\")\n    assert (len(lines)) == 3\n    assert lines[0] == Text(\"Some\")\n    assert lines[1] == Text(\"more\")\n    assert lines[2] == Text(\"wor\u2026\")\n\n\ndef test_wrap_overflow_long():\n    text = Text(\"bigword\" * 10)\n    lines = text.wrap(Console(), 4, overflow=\"ellipsis\")\n    assert len(lines) == 1\n    assert lines[0] == Text(\"big\u2026\")\n\n\ndef test_wrap_long_words():\n    text = Text(\"XX 12345678912\")\n    lines = text.wrap(Console(), 4)\n\n    assert lines._lines == [\n        Text(\"XX \"),\n        Text(\"1234\"),\n        Text(\"5678\"),\n        Text(\"912\"),\n    ]\n\n\ndef test_wrap_long_words_2():\n    # https://github.com/Textualize/rich/issues/2273\n    text = Text(\"Hello, World...123\")\n    lines = text.wrap(Console(), 10)\n    assert lines._lines == [\n        Text(\"Hello, \"),\n        Text(\"World...12\"),\n        Text(\"3\"),\n    ]\n\n\ndef test_wrap_long_words_followed_by_other_words():\n    \"\"\"After folding a word across multiple lines, we should continue from\n    the next word immediately after the folded word (don't take a newline\n    following completion of the folded word).\"\"\"\n    text = Text(\"123 12345678 123 123\")\n    lines = text.wrap(Console(), 6)\n    assert lines._lines == [\n        Text(\"123 \"),\n        Text(\"123456\"),\n        Text(\"78 123\"),\n        Text(\"123\"),\n    ]\n\n\ndef test_wrap_long_word_preceeded_by_word_of_full_line_length():\n    \"\"\"The width of the first word is the same as the available width.\n    Ensures that folding works correctly when there's no space available\n    on the current line.\"\"\"\n    text = Text(\"123456 12345678 123 123\")\n    lines = text.wrap(Console(), 6)\n    assert lines._lines == [\n        Text(\"123456\"),\n        Text(\"123456\"),\n        Text(\"78 123\"),\n        Text(\"123\"),\n    ]\n\n\ndef test_wrap_multiple_consecutive_spaces():\n    \"\"\"Adding multiple consecutive spaces at the end of a line does not impact\n    the location at which a break will be added during the process of wrapping.\"\"\"\n    text = Text(\"123456    12345678 123 123\")\n    lines = text.wrap(Console(), 6)\n    assert lines._lines == [\n        Text(\"123456\"),\n        Text(\"123456\"),\n        Text(\"78 123\"),\n        Text(\"123\"),\n    ]\n\n\ndef test_wrap_long_words_justify_left():\n    text = Text(\"X 123456789\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n\n    assert len(lines) == 4\n    assert lines[0] == Text(\"X   \")\n    assert lines[1] == Text(\"1234\")\n    assert lines[2] == Text(\"5678\")\n    assert lines[3] == Text(\"9   \")\n\n\ndef test_wrap_leading_and_trailing_whitespace():\n    text = Text(\"   123  456 789   \")\n    lines = text.wrap(Console(), 4)\n    assert lines._lines == [\n        Text(\"   1\"),\n        Text(\"23  \"),\n        Text(\"456 \"),\n        Text(\"789 \"),\n    ]\n\n\ndef test_no_wrap_no_crop():\n    text = Text(\"Hello World!\" * 3)\n\n    console = Console(width=20, file=StringIO())\n    console.print(text, no_wrap=True)\n    console.print(text, no_wrap=True, crop=False, overflow=\"ignore\")\n\n    print(repr(console.file.getvalue()))\n    assert (\n        console.file.getvalue()\n        == \"Hello World!Hello Wo\\nHello World!Hello World!Hello World!\\n\"\n    )\n\n\ndef test_fit():\n    text = Text(\"Hello\\nWorld\")\n    lines = text.fit(3)\n    assert str(lines[0]) == \"Hel\"\n    assert str(lines[1]) == \"Wor\"\n\n\ndef test_wrap_tabs():\n    text = Text(\"foo\\tbar\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n    assert len(lines) == 2\n    assert str(lines[0]) == \"foo \"\n    assert str(lines[1]) == \"bar \"\n\n\ndef test_render():\n    console = Console(width=15, record=True)\n    text = Text.from_markup(\n        \"[u][b]Where[/b] there is a [i]Will[/i], there is a Way.[/u]\"\n    )\n    console.print(text)\n    output = console.export_text(styles=True)\n    expected = \"\\x1b[1;4mWhere\\x1b[0m\\x1b[4m there is \\x1b[0m\\n\\x1b[4ma \\x1b[0m\\x1b[3;4mWill\\x1b[0m\\x1b[4m, there \\x1b[0m\\n\\x1b[4mis a Way.\\x1b[0m\\n\"\n    assert output == expected\n\n\ndef test_render_simple():\n    console = Console(width=80)\n    console.begin_capture()\n    console.print(Text(\"foo\"))\n    result = console.end_capture()\n    assert result == \"foo\\n\"\n\n\n@pytest.mark.parametrize(\n    \"print_text,result\",\n    [\n        ((\".\"), \".\\n\"),\n        ((\".\", \".\"), \". .\\n\"),\n        ((\"Hello\", \"World\", \"!\"), \"Hello World !\\n\"),\n    ],\n)\ndef test_print(print_text, result):\n    console = Console(record=True)\n    console.print(*print_text)\n    assert console.export_text(styles=False) == result\n\n\n@pytest.mark.parametrize(\n    \"print_text,result\",\n    [\n        ((\".\"), \".X\"),\n        ((\".\", \".\"), \"..X\"),\n        ((\"Hello\", \"World\", \"!\"), \"HelloWorld!X\"),\n    ],\n)\ndef test_print_sep_end(print_text, result):\n    console = Console(record=True, file=StringIO())\n    console.print(*print_text, sep=\"\", end=\"X\")\n    assert console.file.getvalue() == result\n\n\ndef test_tabs_to_spaces():\n    text = Text(\"\\tHello\\tWorld\", tab_size=8)\n    text.expand_tabs()\n    assert text.plain == \"        Hello   World\"\n\n    text = Text(\"\\tHello\\tWorld\", tab_size=4)\n    text.expand_tabs()\n    assert text.plain == \"    Hello   World\"\n\n    text = Text(\".\\t..\\t...\\t....\\t\", tab_size=4)\n    text.expand_tabs()\n    assert text.plain == \".   ..  ... ....    \"\n\n    text = Text(\"No Tabs\")\n    text.expand_tabs()\n    assert text.plain == \"No Tabs\"\n\n    text = Text(\"No Tabs\", style=\"bold\")\n    text.expand_tabs()\n    assert text.plain == \"No Tabs\"\n    assert text.style == \"bold\"\n\n\n@pytest.mark.parametrize(\n    \"markup,tab_size,expected_text,expected_spans\",\n    [\n        (\"\", 4, \"\", []),\n        (\"\\t\", 4, \"    \", []),\n        (\"\\tbar\", 4, \"    bar\", []),\n        (\"foo\\tbar\", 4, \"foo bar\", []),\n        (\"foo\\nbar\\nbaz\", 4, \"foo\\nbar\\nbaz\", []),\n        (\n            \"[bold]foo\\tbar\",\n            4,\n            \"foo bar\",\n            [\n                Span(0, 4, \"bold\"),\n                Span(4, 7, \"bold\"),\n            ],\n        ),\n        (\n            \"[bold]\\tbar\",\n            4,\n            \"    bar\",\n            [\n                Span(0, 4, \"bold\"),\n                Span(4, 7, \"bold\"),\n            ],\n        ),\n        (\n            \"\\t[bold]bar\",\n            4,\n            \"    bar\",\n            [\n                Span(4, 7, \"bold\"),\n            ],\n        ),\n        (\n            \"[red]foo\\tbar\\n[green]egg\\tbaz\",\n            8,\n            \"foo     bar\\negg     baz\",\n            [\n                Span(0, 8, \"red\"),\n                Span(8, 12, \"red\"),\n                Span(12, 20, \"red\"),\n                Span(12, 20, \"green\"),\n                Span(20, 23, \"red\"),\n                Span(20, 23, \"green\"),\n            ],\n        ),\n        (\n            \"[bold]X\\tY\",\n            8,\n            \"X       Y\",\n            [\n                Span(0, 8, \"bold\"),\n                Span(8, 9, \"bold\"),\n            ],\n        ),\n        (\n            \"[bold]\ud83d\udca9\\t\ud83d\udca9\",\n            8,\n            \"\ud83d\udca9      \ud83d\udca9\",\n            [\n                Span(0, 7, \"bold\"),\n                Span(7, 8, \"bold\"),\n            ],\n        ),\n        (\n            \"[bold]\ud83d\udca9\ud83d\udca9\ud83d\udca9\ud83d\udca9\\t\ud83d\udca9\",\n            8,\n            \"\ud83d\udca9\ud83d\udca9\ud83d\udca9\ud83d\udca9        \ud83d\udca9\",\n            [\n                Span(0, 12, \"bold\"),\n                Span(12, 13, \"bold\"),\n            ],\n        ),\n    ],\n)\ndef test_tabs_to_spaces_spans(\n    markup: str, tab_size: int, expected_text: str, expected_spans: List[Span]\n):\n    \"\"\"Test spans are correct after expand_tabs\"\"\"\n    text = Text.from_markup(markup)\n    text.expand_tabs(tab_size)\n    print(text._spans)\n    assert text.plain == expected_text\n    assert text._spans == expected_spans\n\n\ndef test_markup_switch():\n    \"\"\"Test markup can be disabled.\"\"\"\n    console = Console(file=StringIO(), markup=False)\n    console.print(\"[bold]foo[/bold]\")\n    assert console.file.getvalue() == \"[bold]foo[/bold]\\n\"\n\n\ndef test_emoji():\n    \"\"\"Test printing emoji codes.\"\"\"\n    console = Console(file=StringIO())\n    console.print(\":+1:\")\n    assert console.file.getvalue() == \"\ud83d\udc4d\\n\"\n\n\ndef test_emoji_switch():\n    \"\"\"Test emoji can be disabled.\"\"\"\n    console = Console(file=StringIO(), emoji=False)\n    console.print(\":+1:\")\n    assert console.file.getvalue() == \":+1:\\n\"\n\n\ndef test_assemble():\n    text = Text.assemble(\"foo\", (\"bar\", \"bold\"))\n    assert str(text) == \"foobar\"\n    assert text._spans == [Span(3, 6, \"bold\")]\n\n\ndef test_assemble_meta():\n    text = Text.assemble(\"foo\", (\"bar\", \"bold\"), meta={\"foo\": \"bar\"})\n    assert str(text) == \"foobar\"\n    assert text._spans == [Span(3, 6, \"bold\"), Span(0, 6, Style(meta={\"foo\": \"bar\"}))]\n    console = Console()\n    assert text.get_style_at_offset(console, 0).meta == {\"foo\": \"bar\"}\n\n\ndef test_styled():\n    text = Text.styled(\"foo\", \"bold red\")\n    assert text.style == \"\"\n    assert str(text) == \"foo\"\n    assert text._spans == [Span(0, 3, \"bold red\")]\n\n\ndef test_strip_control_codes():\n    text = Text(\"foo\\rbar\")\n    assert str(text) == \"foobar\"\n    text.append(\"\\x08\")\n    assert str(text) == \"foobar\"\n\n\ndef test_get_style_at_offset():\n    console = Console()\n    text = Text.from_markup(\"Hello [b]World[/b]\")\n    assert text.get_style_at_offset(console, 0) == Style()\n    assert text.get_style_at_offset(console, 6) == Style(bold=True)\n\n\n@pytest.mark.parametrize(\n    \"input, count, expected\",\n    [\n        (\"Hello\", 10, \"Hello\"),\n        (\"Hello\", 5, \"Hello\"),\n        (\"Hello\", 4, \"Hel\u2026\"),\n        (\"Hello\", 3, \"He\u2026\"),\n        (\"Hello\", 2, \"H\u2026\"),\n        (\"Hello\", 1, \"\u2026\"),\n    ],\n)\ndef test_truncate_ellipsis(input, count, expected):\n    text = Text(input)\n    text.truncate(count, overflow=\"ellipsis\")\n    assert text.plain == expected\n\n\n@pytest.mark.parametrize(\n    \"input, count, expected\",\n    [\n        (\"Hello\", 5, \"Hello\"),\n        (\"Hello\", 10, \"Hello     \"),\n        (\"Hello\", 3, \"He\u2026\"),\n    ],\n)\ndef test_truncate_ellipsis_pad(input, count, expected):\n    text = Text(input)\n    text.truncate(count, overflow=\"ellipsis\", pad=True)\n    assert text.plain == expected\n\n\ndef test_pad():\n    text = Text(\"foo\")\n    text.pad(2)\n    assert text.plain == \"  foo  \"\n\n\ndef test_align_left():\n    text = Text(\"foo\")\n    text.align(\"left\", 10)\n    assert text.plain == \"foo       \"\n\n\ndef test_align_right():\n    text = Text(\"foo\")\n    text.align(\"right\", 10)\n    assert text.plain == \"       foo\"\n\n\ndef test_align_center():\n    text = Text(\"foo\")\n    text.align(\"center\", 10)\n    assert text.plain == \"   foo    \"\n\n\ndef test_detect_indentation():\n    text = \"\"\"\\\nfoo\n    bar\n    \"\"\"\n    assert Text(text).detect_indentation() == 4\n    text = \"\"\"\\\nfoo\n    bar\n      baz\n    \"\"\"\n    assert Text(text).detect_indentation() == 2\n    assert Text(\"\").detect_indentation() == 1\n    assert Text(\" \").detect_indentation() == 1\n\n\ndef test_indentation_guides():\n    text = Text(\n        \"\"\"\\\nfor a in range(10):\n    print(a)\n\nfoo = [\n    1,\n    {\n        2\n    }\n]\n\n\"\"\"\n    )\n    result = text.with_indent_guides()\n    print(result.plain)\n    print(repr(result.plain))\n    expected = \"for a in range(10):\\n\u2502   print(a)\\n\\nfoo = [\\n\u2502   1,\\n\u2502   {\\n\u2502   \u2502   2\\n\u2502   }\\n]\\n\\n\"\n    assert result.plain == expected\n\n\ndef test_slice():\n    text = Text.from_markup(\"[red]foo [bold]bar[/red] baz[/bold]\")\n    assert text[0] == Text(\"f\", spans=[Span(0, 1, \"red\")])\n    assert text[4] == Text(\"b\", spans=[Span(0, 1, \"red\"), Span(0, 1, \"bold\")])\n\n    assert text[:3] == Text(\"foo\", spans=[Span(0, 3, \"red\")])\n    assert text[:4] == Text(\"foo \", spans=[Span(0, 4, \"red\")])\n    assert text[:5] == Text(\"foo b\", spans=[Span(0, 5, \"red\"), Span(4, 5, \"bold\")])\n    assert text[4:] == Text(\"bar baz\", spans=[Span(0, 3, \"red\"), Span(0, 7, \"bold\")])\n\n    with pytest.raises(TypeError):\n        text[::-1]\n\n\ndef test_wrap_invalid_style():\n    # https://github.com/textualize/rich/issues/987\n    console = Console(width=100, color_system=\"truecolor\")\n    a = \"[#######.................] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx [#######.................]\"\n    console.print(a, justify=\"full\")\n\n\ndef test_apply_meta():\n    text = Text(\"foobar\")\n    text.apply_meta({\"foo\": \"bar\"}, 1, 3)\n\n    console = Console()\n    assert text.get_style_at_offset(console, 0).meta == {}\n    assert text.get_style_at_offset(console, 1).meta == {\"foo\": \"bar\"}\n    assert text.get_style_at_offset(console, 2).meta == {\"foo\": \"bar\"}\n    assert text.get_style_at_offset(console, 3).meta == {}\n\n\ndef test_on():\n    console = Console()\n    text = Text(\"foo\")\n    text.on({\"foo\": \"bar\"}, click=\"CLICK\")\n    expected = {\"foo\": \"bar\", \"@click\": \"CLICK\"}\n    assert text.get_style_at_offset(console, 0).meta == expected\n    assert text.get_style_at_offset(console, 1).meta == expected\n    assert text.get_style_at_offset(console, 2).meta == expected\n\n\ndef test_markup_property():\n    assert Text(\"\").markup == \"\"\n    assert Text(\"foo\").markup == \"foo\"\n    assert Text(\"foo\", style=\"bold\").markup == \"[bold]foo[/bold]\"\n    assert Text.from_markup(\"foo [red]bar[/red]\").markup == \"foo [red]bar[/red]\"\n    assert (\n        Text.from_markup(\"foo [red]bar[/red]\", style=\"bold\").markup\n        == \"[bold]foo [red]bar[/red][/bold]\"\n    )\n    assert (\n        Text.from_markup(\"[bold]foo [italic]bar[/bold] baz[/italic]\").markup\n        == \"[bold]foo [italic]bar[/bold] baz[/italic]\"\n    )\n    assert Text(\"[bold]foo\").markup == \"\\\\[bold]foo\"\n\n\ndef test_extend_style():\n    text = Text.from_markup(\"[red]foo[/red] [bold]bar\")\n    text.extend_style(0)\n\n    assert text.plain == \"foo bar\"\n    assert text.spans == [Span(0, 3, \"red\"), Span(4, 7, \"bold\")]\n\n    text.extend_style(-1)\n    assert text.plain == \"foo bar\"\n    assert text.spans == [Span(0, 3, \"red\"), Span(4, 7, \"bold\")]\n\n    text.extend_style(2)\n    assert text.plain == \"foo bar  \"\n    assert text.spans == [Span(0, 3, \"red\"), Span(4, 9, \"bold\")]\n\n\ndef test_append_tokens() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3014\"\"\"\n\n    console = Console()\n    t = Text().append_tokens(\n        [\n            (\n                \"long text that will be wrapped with a control code \\r\\n\",\n                \"red\",\n            ),\n        ]\n    )\n    with console.capture() as capture:\n        console.print(t, width=40)\n\n    output = capture.get()\n    print(repr(output))\n    assert output == \"long text that will be wrapped with a \\ncontrol code \\n\\n\"\n\n\ndef test_append_loop_regression() -> None:\n    \"\"\"Regression text for https://github.com/Textualize/rich/issues/3479\"\"\"\n    a = Text(\"one\", \"blue\")\n    a.append(a)\n    assert a.plain == \"oneone\"\n\n    b = Text(\"two\", \"blue\")\n    b.append_text(b)\n    assert b.plain == \"twotwo\"\n",
      "code_after": "import re\nfrom io import StringIO\nfrom typing import List\n\nimport pytest\n\nfrom rich.console import Console, Group\nfrom rich.measure import Measurement\nfrom rich.style import Style\nfrom rich.text import Span, Text\n\n\ndef test_span():\n    span = Span(1, 10, \"foo\")\n    repr(span)\n    assert bool(span)\n    assert not Span(10, 10, \"foo\")\n\n\ndef test_span_split():\n    assert Span(5, 10, \"foo\").split(2) == (Span(5, 10, \"foo\"), None)\n    assert Span(5, 10, \"foo\").split(15) == (Span(5, 10, \"foo\"), None)\n    assert Span(0, 10, \"foo\").split(5) == (Span(0, 5, \"foo\"), Span(5, 10, \"foo\"))\n\n\ndef test_span_move():\n    assert Span(5, 10, \"foo\").move(2) == Span(7, 12, \"foo\")\n\n\ndef test_span_right_crop():\n    assert Span(5, 10, \"foo\").right_crop(15) == Span(5, 10, \"foo\")\n    assert Span(5, 10, \"foo\").right_crop(7) == Span(5, 7, \"foo\")\n\n\ndef test_len():\n    assert len(Text(\"foo\")) == 3\n\n\ndef test_cell_len():\n    assert Text(\"foo\").cell_len == 3\n    assert Text(\"\ud83d\ude00\").cell_len == 2\n\n\ndef test_bool():\n    assert Text(\"foo\")\n    assert not Text(\"\")\n\n\ndef test_str():\n    assert str(Text(\"foo\")) == \"foo\"\n\n\ndef test_repr():\n    assert isinstance(repr(Text(\"foo\")), str)\n\n\ndef test_add():\n    text = Text(\"foo\") + Text(\"bar\")\n    assert str(text) == \"foobar\"\n    assert Text(\"foo\").__add__(1) == NotImplemented\n\n\ndef test_eq():\n    assert Text(\"foo\") == Text(\"foo\")\n    assert Text(\"foo\") != Text(\"bar\")\n    assert Text(\"foo\").__eq__(1) == NotImplemented\n\n\ndef test_contain():\n    text = Text(\"foobar\")\n    assert \"foo\" in text\n    assert \"foo \" not in text\n    assert Text(\"bar\") in text\n    assert None not in text\n\n\ndef test_plain_property():\n    text = Text(\"foo\")\n    text.append(\"bar\")\n    text.append(\"baz\")\n    assert text.plain == \"foobarbaz\"\n\n\ndef test_plain_property_setter():\n    text = Text(\"foo\")\n    text.plain = \"bar\"\n    assert str(text) == \"bar\"\n    text = Text()\n    text.append(\"Hello, World\", \"bold\")\n    text.plain = \"Hello\"\n    assert str(text) == \"Hello\"\n    assert text._spans == [Span(0, 5, \"bold\")]\n\n\ndef test_from_markup():\n    text = Text.from_markup(\"Hello, [bold]World![/bold]\")\n    assert str(text) == \"Hello, World!\"\n    assert text._spans == [Span(7, 13, \"bold\")]\n\n\ndef test_from_ansi():\n    text = Text.from_ansi(\"Hello, \\033[1mWorld!\\033[0m\")\n    assert str(text) == \"Hello, World!\"\n    assert text._spans == [Span(7, 13, Style(bold=True))]\n\n    text = Text.from_ansi(\"Hello, \\033[1m\\nWorld!\\033[0m\")\n    assert str(text) == \"Hello, \\nWorld!\"\n    assert text._spans == [Span(8, 14, Style(bold=True))]\n\n    text = Text.from_ansi(\"\\033[1mBOLD\\033[m not bold\")\n    assert str(text) == \"BOLD not bold\"\n    assert text._spans == [Span(0, 4, Style(bold=True))]\n\n    text = Text.from_ansi(\"\\033[1m\\033[Kfoo barmbaz\")\n    assert str(text) == \"foo barmbaz\"\n    assert text._spans == [Span(0, 11, Style(bold=True))]\n\n\ndef test_copy():\n    text = Text()\n    text.append(\"Hello\", \"bold\")\n    text.append(\" \")\n    text.append(\"World\", \"italic\")\n    test_copy = text.copy()\n    assert text == test_copy\n    assert text is not test_copy\n\n\ndef test_rstrip():\n    text = Text(\"Hello, World!    \")\n    text.rstrip()\n    assert str(text) == \"Hello, World!\"\n\n\ndef test_rstrip_end():\n    text = Text(\"Hello, World!    \")\n    text.rstrip_end(14)\n    assert str(text) == \"Hello, World! \"\n\n\ndef test_stylize():\n    text = Text(\"Hello, World!\")\n    text.stylize(\"bold\", 7, 11)\n    assert text._spans == [Span(7, 11, \"bold\")]\n    text.stylize(\"bold\", 20, 25)\n    assert text._spans == [Span(7, 11, \"bold\")]\n\n\ndef test_stylize_before():\n    text = Text(\"Hello, World!\")\n    text.stylize(\"bold\", 0, 5)\n    text.stylize_before(\"italic\", 2, 7)\n    assert text._spans == [Span(2, 7, \"italic\"), Span(0, 5, \"bold\")]\n\n\ndef test_stylize_negative_index():\n    text = Text(\"Hello, World!\")\n    text.stylize(\"bold\", -6, -1)\n    assert text._spans == [Span(7, 12, \"bold\")]\n\n\ndef test_highlight_regex():\n    # As a string\n    text = Text(\"peek-a-boo\")\n\n    count = text.highlight_regex(r\"NEVER_MATCH\", \"red\")\n    assert count == 0\n    assert len(text._spans) == 0\n\n    # text: peek-a-boo\n    # indx: 0123456789\n    count = text.highlight_regex(r\"[a|e|o]+\", \"red\")\n    assert count == 3\n    assert sorted(text._spans) == [\n        Span(1, 3, \"red\"),\n        Span(5, 6, \"red\"),\n        Span(8, 10, \"red\"),\n    ]\n\n    text = Text(\"Ada Lovelace, Alan Turing\")\n\n    count = text.highlight_regex(\n        r\"(?P<yellow>[A-Za-z]+)[ ]+(?P<red>[A-Za-z]+)(?P<NEVER_MATCH>NEVER_MATCH)*\"\n    )\n\n    # The number of matched name should be 2\n    assert count == 2\n    assert sorted(text._spans) == [\n        Span(0, 3, \"yellow\"),  # Ada\n        Span(4, 12, \"red\"),  # Lovelace\n        Span(14, 18, \"yellow\"),  # Alan\n        Span(19, 25, \"red\"),  # Turing\n    ]\n\n    # As a regular expression object\n    text = Text(\"peek-a-boo\")\n\n    count = text.highlight_regex(re.compile(r\"NEVER_MATCH\"), \"red\")\n    assert count == 0\n    assert len(text._spans) == 0\n\n    # text: peek-a-boo\n    # indx: 0123456789\n    count = text.highlight_regex(re.compile(r\"[a|e|o]+\"), \"red\")\n    assert count == 3\n    assert sorted(text._spans) == [\n        Span(1, 3, \"red\"),\n        Span(5, 6, \"red\"),\n        Span(8, 10, \"red\"),\n    ]\n\n    text = Text(\"Ada Lovelace, Alan Turing\")\n\n    count = text.highlight_regex(\n        re.compile(\n            r\"(?P<yellow>[A-Za-z]+)[ ]+(?P<red>[A-Za-z]+)(?P<NEVER_MATCH>NEVER_MATCH)*\"\n        )\n    )\n\n    # The number of matched name should be 2\n    assert count == 2\n    assert sorted(text._spans) == [\n        Span(0, 3, \"yellow\"),  # Ada\n        Span(4, 12, \"red\"),  # Lovelace\n        Span(14, 18, \"yellow\"),  # Alan\n        Span(19, 25, \"red\"),  # Turing\n    ]\n\n\ndef test_highlight_regex_callable():\n    text = Text(\"Vulnerability CVE-2018-6543 detected\")\n    re_cve = r\"CVE-\\d{4}-\\d+\"\n    compiled_re_cve = re.compile(r\"CVE-\\d{4}-\\d+\")\n\n    def get_style(text: str) -> Style:\n        return Style.parse(\n            f\"bold yellow link https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword={text}\"\n        )\n\n    # string\n    count = text.highlight_regex(re_cve, get_style)\n    assert count == 1\n    assert len(text._spans) == 1\n    assert text._spans[0].start == 14\n    assert text._spans[0].end == 27\n    assert (\n        text._spans[0].style.link\n        == \"https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=CVE-2018-6543\"\n    )\n\n    # Clear the tracked _spans for the regular expression object's use\n    text._spans.clear()\n\n    # regular expression object\n    count = text.highlight_regex(compiled_re_cve, get_style)\n    assert count == 1\n    assert len(text._spans) == 1\n    assert text._spans[0].start == 14\n    assert text._spans[0].end == 27\n    assert (\n        text._spans[0].style.link\n        == \"https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=CVE-2018-6543\"\n    )\n\n\ndef test_highlight_words():\n    text = Text(\"Do NOT! touch anything!\")\n    words = [\"NOT\", \"!\"]\n    count = text.highlight_words(words, \"red\")\n    assert count == 3\n    assert sorted(text._spans) == [\n        Span(3, 6, \"red\"),  # NOT\n        Span(6, 7, \"red\"),  # !\n        Span(22, 23, \"red\"),  # !\n    ]\n\n    # regex escape test\n    text = Text(\"[o|u]aeiou\")\n    words = [\"[a|e|i]\", \"[o|u]\"]\n    count = text.highlight_words(words, \"red\")\n    assert count == 1\n    assert text._spans == [Span(0, 5, \"red\")]\n\n    # case sensitive\n    text = Text(\"AB Ab aB ab\")\n    words = [\"AB\"]\n\n    count = text.highlight_words(words, \"red\")\n    assert count == 1\n    assert text._spans == [Span(0, 2, \"red\")]\n\n    text = Text(\"AB Ab aB ab\")\n    count = text.highlight_words(words, \"red\", case_sensitive=False)\n    assert count == 4\n\n\ndef test_set_length():\n    text = Text(\"Hello\")\n    text.set_length(5)\n    assert text == Text(\"Hello\")\n\n    text = Text(\"Hello\")\n    text.set_length(10)\n    assert text == Text(\"Hello     \")\n\n    text = Text(\"Hello World\")\n    text.stylize(\"bold\", 0, 5)\n    text.stylize(\"italic\", 7, 9)\n\n    text.set_length(3)\n    expected = Text()\n    expected.append(\"Hel\", \"bold\")\n    assert text == expected\n\n\ndef test_console_width():\n    console = Console()\n    text = Text(\"Hello World!\\nfoobarbaz\")\n    assert text.__rich_measure__(console, 80) == Measurement(9, 12)\n    assert Text(\" \" * 4).__rich_measure__(console, 80) == Measurement(4, 4)\n    assert Text(\" \\n  \\n   \").__rich_measure__(console, 80) == Measurement(3, 3)\n\n\ndef test_join():\n    text = Text(\"bar\").join([Text(\"foo\", \"red\"), Text(\"baz\", \"blue\")])\n    assert str(text) == \"foobarbaz\"\n    assert text._spans == [Span(0, 3, \"red\"), Span(6, 9, \"blue\")]\n\n\ndef test_trim_spans():\n    text = Text(\"Hello\")\n    text._spans[:] = [Span(0, 3, \"red\"), Span(3, 6, \"green\"), Span(6, 9, \"blue\")]\n    text._trim_spans()\n    assert text._spans == [Span(0, 3, \"red\"), Span(3, 5, \"green\")]\n\n\ndef test_pad_left():\n    text = Text(\"foo\")\n    text.pad_left(3, \"X\")\n    assert str(text) == \"XXXfoo\"\n\n\ndef test_pad_right():\n    text = Text(\"foo\")\n    text.pad_right(3, \"X\")\n    assert str(text) == \"fooXXX\"\n\n\ndef test_append():\n    text = Text(\"foo\")\n    text.append(\"bar\")\n    assert str(text) == \"foobar\"\n    text.append(Text(\"baz\", \"bold\"))\n    assert str(text) == \"foobarbaz\"\n    assert text._spans == [Span(6, 9, \"bold\")]\n\n    with pytest.raises(ValueError):\n        text.append(Text(\"foo\"), \"bar\")\n\n    with pytest.raises(TypeError):\n        text.append(1)\n\n\ndef test_append_text():\n    text = Text(\"foo\")\n    text.append_text(Text(\"bar\", style=\"bold\"))\n    assert str(text) == \"foobar\"\n    assert text._spans == [Span(3, 6, \"bold\")]\n\n\ndef test_end():\n    console = Console(width=20, file=StringIO())\n    text = Group(Text.from_markup(\"foo\", end=\" \"), Text.from_markup(\"bar\"))\n    console.print(text)\n    assert console.file.getvalue() == \"foo bar\\n\"\n\n\ndef test_split():\n    text = Text()\n    text.append(\"foo\", \"red\")\n    text.append(\"\\n\")\n    text.append(\"bar\", \"green\")\n    text.append(\"\\n\")\n\n    line1 = Text()\n    line1.append(\"foo\", \"red\")\n    line2 = Text()\n    line2.append(\"bar\", \"green\")\n    split = text.split(\"\\n\")\n    assert len(split) == 2\n    assert split[0] == line1\n    assert split[1] == line2\n\n    assert list(Text(\"foo\").split(\"\\n\")) == [Text(\"foo\")]\n\n\ndef test_split_spans():\n    text = Text.from_markup(\"[red]Hello\\n[b]World\")\n    lines = text.split(\"\\n\")\n    assert lines[0].plain == \"Hello\"\n    assert lines[1].plain == \"World\"\n    assert lines[0].spans == [Span(0, 5, \"red\")]\n    assert lines[1].spans == [Span(0, 5, \"red\"), Span(0, 5, \"bold\")]\n\n\ndef test_divide():\n    lines = Text(\"foo\").divide([])\n    assert len(lines) == 1\n    assert lines[0] == Text(\"foo\")\n\n    text = Text()\n    text.append(\"foo\", \"bold\")\n    lines = text.divide([1, 2])\n    assert len(lines) == 3\n    assert str(lines[0]) == \"f\"\n    assert str(lines[1]) == \"o\"\n    assert str(lines[2]) == \"o\"\n    assert lines[0]._spans == [Span(0, 1, \"bold\")]\n    assert lines[1]._spans == [Span(0, 1, \"bold\")]\n    assert lines[2]._spans == [Span(0, 1, \"bold\")]\n\n    text = Text()\n    text.append(\"foo\", \"red\")\n    text.append(\"bar\", \"green\")\n    text.append(\"baz\", \"blue\")\n    lines = text.divide([8])\n    assert len(lines) == 2\n    assert str(lines[0]) == \"foobarba\"\n    assert str(lines[1]) == \"z\"\n    assert lines[0]._spans == [\n        Span(0, 3, \"red\"),\n        Span(3, 6, \"green\"),\n        Span(6, 8, \"blue\"),\n    ]\n    assert lines[1]._spans == [Span(0, 1, \"blue\")]\n\n    lines = text.divide([1])\n    assert len(lines) == 2\n    assert str(lines[0]) == \"f\"\n    assert str(lines[1]) == \"oobarbaz\"\n    assert lines[0]._spans == [Span(0, 1, \"red\")]\n    assert lines[1]._spans == [\n        Span(0, 2, \"red\"),\n        Span(2, 5, \"green\"),\n        Span(5, 8, \"blue\"),\n    ]\n\n\ndef test_right_crop():\n    text = Text()\n    text.append(\"foobar\", \"red\")\n    text.right_crop(3)\n    assert str(text) == \"foo\"\n    assert text._spans == [Span(0, 3, \"red\")]\n\n\ndef test_wrap_3():\n    text = Text(\"foo bar baz\")\n    lines = text.wrap(Console(), 3)\n    print(repr(lines))\n    assert len(lines) == 3\n    assert lines[0] == Text(\"foo\")\n    assert lines[1] == Text(\"bar\")\n    assert lines[2] == Text(\"baz\")\n\n\ndef test_wrap_4():\n    text = Text(\"foo bar baz\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n    assert len(lines) == 3\n    assert lines[0] == Text(\"foo \")\n    assert lines[1] == Text(\"bar \")\n    assert lines[2] == Text(\"baz \")\n\n\ndef test_wrap_wrapped_word_length_greater_than_available_width():\n    text = Text(\"1234 12345678\")\n    lines = text.wrap(Console(), 7)\n    assert lines._lines == [\n        Text(\"1234 \"),\n        Text(\"1234567\"),\n        Text(\"8\"),\n    ]\n\n\ndef test_wrap_cjk():\n    text = Text(\"\u308f\u3055\u3073\")\n    lines = text.wrap(Console(), 4)\n    assert lines._lines == [\n        Text(\"\u308f\u3055\"),\n        Text(\"\u3073\"),\n    ]\n\n\ndef test_wrap_cjk_width_mid_character():\n    text = Text(\"\u308f\u3055\u3073\")\n    lines = text.wrap(Console(), 3)\n    assert lines._lines == [\n        Text(\"\u308f\"),\n        Text(\"\u3055\"),\n        Text(\"\u3073\"),\n    ]\n\n\ndef test_wrap_cjk_mixed():\n    \"\"\"Regression test covering https://github.com/Textualize/rich/issues/3176 and\n    https://github.com/Textualize/textual/issues/3567 - double width characters could\n    result in text going missing when wrapping.\"\"\"\n    text = Text(\"123\u3042\u308a\u304c\u3068\u3046\u3054\u3056\u3044\u307e\u3057\u305f\")\n    console = Console(width=20)  # let's ensure the width passed to wrap() wins.\n\n    wrapped_lines = text.wrap(console, width=8)\n    with console.capture() as capture:\n        console.print(wrapped_lines)\n\n    assert capture.get() == \"123\u3042\u308a\\n\u304c\u3068\u3046\u3054\\n\u3056\u3044\u307e\u3057\\n\u305f\\n\"\n\n\ndef test_wrap_long():\n    text = Text(\"abracadabra\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n    assert len(lines) == 3\n    assert lines[0] == Text(\"abra\")\n    assert lines[1] == Text(\"cada\")\n    assert lines[2] == Text(\"bra \")\n\n\ndef test_wrap_overflow():\n    text = Text(\"Some more words\")\n    lines = text.wrap(Console(), 4, overflow=\"ellipsis\")\n    assert (len(lines)) == 3\n    assert lines[0] == Text(\"Some\")\n    assert lines[1] == Text(\"more\")\n    assert lines[2] == Text(\"wor\u2026\")\n\n\ndef test_wrap_overflow_long():\n    text = Text(\"bigword\" * 10)\n    lines = text.wrap(Console(), 4, overflow=\"ellipsis\")\n    assert len(lines) == 1\n    assert lines[0] == Text(\"big\u2026\")\n\n\ndef test_wrap_long_words():\n    text = Text(\"XX 12345678912\")\n    lines = text.wrap(Console(), 4)\n\n    assert lines._lines == [\n        Text(\"XX \"),\n        Text(\"1234\"),\n        Text(\"5678\"),\n        Text(\"912\"),\n    ]\n\n\ndef test_wrap_long_words_2():\n    # https://github.com/Textualize/rich/issues/2273\n    text = Text(\"Hello, World...123\")\n    lines = text.wrap(Console(), 10)\n    assert lines._lines == [\n        Text(\"Hello, \"),\n        Text(\"World...12\"),\n        Text(\"3\"),\n    ]\n\n\ndef test_wrap_long_words_followed_by_other_words():\n    \"\"\"After folding a word across multiple lines, we should continue from\n    the next word immediately after the folded word (don't take a newline\n    following completion of the folded word).\"\"\"\n    text = Text(\"123 12345678 123 123\")\n    lines = text.wrap(Console(), 6)\n    assert lines._lines == [\n        Text(\"123 \"),\n        Text(\"123456\"),\n        Text(\"78 123\"),\n        Text(\"123\"),\n    ]\n\n\ndef test_wrap_long_word_preceeded_by_word_of_full_line_length():\n    \"\"\"The width of the first word is the same as the available width.\n    Ensures that folding works correctly when there's no space available\n    on the current line.\"\"\"\n    text = Text(\"123456 12345678 123 123\")\n    lines = text.wrap(Console(), 6)\n    assert lines._lines == [\n        Text(\"123456\"),\n        Text(\"123456\"),\n        Text(\"78 123\"),\n        Text(\"123\"),\n    ]\n\n\ndef test_wrap_multiple_consecutive_spaces():\n    \"\"\"Adding multiple consecutive spaces at the end of a line does not impact\n    the location at which a break will be added during the process of wrapping.\"\"\"\n    text = Text(\"123456    12345678 123 123\")\n    lines = text.wrap(Console(), 6)\n    assert lines._lines == [\n        Text(\"123456\"),\n        Text(\"123456\"),\n        Text(\"78 123\"),\n        Text(\"123\"),\n    ]\n\n\ndef test_wrap_long_words_justify_left():\n    text = Text(\"X 123456789\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n\n    assert len(lines) == 4\n    assert lines[0] == Text(\"X   \")\n    assert lines[1] == Text(\"1234\")\n    assert lines[2] == Text(\"5678\")\n    assert lines[3] == Text(\"9   \")\n\n\ndef test_wrap_leading_and_trailing_whitespace():\n    text = Text(\"   123  456 789   \")\n    lines = text.wrap(Console(), 4)\n    assert lines._lines == [\n        Text(\"   1\"),\n        Text(\"23  \"),\n        Text(\"456 \"),\n        Text(\"789 \"),\n    ]\n\n\ndef test_no_wrap_no_crop():\n    text = Text(\"Hello World!\" * 3)\n\n    console = Console(width=20, file=StringIO())\n    console.print(text, no_wrap=True)\n    console.print(text, no_wrap=True, crop=False, overflow=\"ignore\")\n\n    print(repr(console.file.getvalue()))\n    assert (\n        console.file.getvalue()\n        == \"Hello World!Hello Wo\\nHello World!Hello World!Hello World!\\n\"\n    )\n\n\ndef test_fit():\n    text = Text(\"Hello\\nWorld\")\n    lines = text.fit(3)\n    assert str(lines[0]) == \"Hel\"\n    assert str(lines[1]) == \"Wor\"\n\n\ndef test_wrap_tabs():\n    text = Text(\"foo\\tbar\", justify=\"left\")\n    lines = text.wrap(Console(), 4)\n    assert len(lines) == 2\n    assert str(lines[0]) == \"foo \"\n    assert str(lines[1]) == \"bar \"\n\n\ndef test_render():\n    console = Console(width=15, record=True)\n    text = Text.from_markup(\n        \"[u][b]Where[/b] there is a [i]Will[/i], there is a Way.[/u]\"\n    )\n    console.print(text)\n    output = console.export_text(styles=True)\n    expected = \"\\x1b[1;4mWhere\\x1b[0m\\x1b[4m there is \\x1b[0m\\n\\x1b[4ma \\x1b[0m\\x1b[3;4mWill\\x1b[0m\\x1b[4m, there \\x1b[0m\\n\\x1b[4mis a Way.\\x1b[0m\\n\"\n    assert output == expected\n\n\ndef test_render_simple():\n    console = Console(width=80)\n    console.begin_capture()\n    console.print(Text(\"foo\"))\n    result = console.end_capture()\n    assert result == \"foo\\n\"\n\n\n@pytest.mark.parametrize(\n    \"print_text,result\",\n    [\n        ((\".\"), \".\\n\"),\n        ((\".\", \".\"), \". .\\n\"),\n        ((\"Hello\", \"World\", \"!\"), \"Hello World !\\n\"),\n    ],\n)\ndef test_print(print_text, result):\n    console = Console(record=True)\n    console.print(*print_text)\n    assert console.export_text(styles=False) == result\n\n\n@pytest.mark.parametrize(\n    \"print_text,result\",\n    [\n        ((\".\"), \".X\"),\n        ((\".\", \".\"), \"..X\"),\n        ((\"Hello\", \"World\", \"!\"), \"HelloWorld!X\"),\n    ],\n)\ndef test_print_sep_end(print_text, result):\n    console = Console(record=True, file=StringIO())\n    console.print(*print_text, sep=\"\", end=\"X\")\n    assert console.file.getvalue() == result\n\n\ndef test_tabs_to_spaces():\n    text = Text(\"\\tHello\\tWorld\", tab_size=8)\n    text.expand_tabs()\n    assert text.plain == \"        Hello   World\"\n\n    text = Text(\"\\tHello\\tWorld\", tab_size=4)\n    text.expand_tabs()\n    assert text.plain == \"    Hello   World\"\n\n    text = Text(\".\\t..\\t...\\t....\\t\", tab_size=4)\n    text.expand_tabs()\n    assert text.plain == \".   ..  ... ....    \"\n\n    text = Text(\"No Tabs\")\n    text.expand_tabs()\n    assert text.plain == \"No Tabs\"\n\n    text = Text(\"No Tabs\", style=\"bold\")\n    text.expand_tabs()\n    assert text.plain == \"No Tabs\"\n    assert text.style == \"bold\"\n\n\n@pytest.mark.parametrize(\n    \"markup,tab_size,expected_text,expected_spans\",\n    [\n        (\"\", 4, \"\", []),\n        (\"\\t\", 4, \"    \", []),\n        (\"\\tbar\", 4, \"    bar\", []),\n        (\"foo\\tbar\", 4, \"foo bar\", []),\n        (\"foo\\nbar\\nbaz\", 4, \"foo\\nbar\\nbaz\", []),\n        (\n            \"[bold]foo\\tbar\",\n            4,\n            \"foo bar\",\n            [\n                Span(0, 4, \"bold\"),\n                Span(4, 7, \"bold\"),\n            ],\n        ),\n        (\n            \"[bold]\\tbar\",\n            4,\n            \"    bar\",\n            [\n                Span(0, 4, \"bold\"),\n                Span(4, 7, \"bold\"),\n            ],\n        ),\n        (\n            \"\\t[bold]bar\",\n            4,\n            \"    bar\",\n            [\n                Span(4, 7, \"bold\"),\n            ],\n        ),\n        (\n            \"[red]foo\\tbar\\n[green]egg\\tbaz\",\n            8,\n            \"foo     bar\\negg     baz\",\n            [\n                Span(0, 8, \"red\"),\n                Span(8, 12, \"red\"),\n                Span(12, 20, \"red\"),\n                Span(12, 20, \"green\"),\n                Span(20, 23, \"red\"),\n                Span(20, 23, \"green\"),\n            ],\n        ),\n        (\n            \"[bold]X\\tY\",\n            8,\n            \"X       Y\",\n            [\n                Span(0, 8, \"bold\"),\n                Span(8, 9, \"bold\"),\n            ],\n        ),\n        (\n            \"[bold]\ud83d\udca9\\t\ud83d\udca9\",\n            8,\n            \"\ud83d\udca9      \ud83d\udca9\",\n            [\n                Span(0, 7, \"bold\"),\n                Span(7, 8, \"bold\"),\n            ],\n        ),\n        (\n            \"[bold]\ud83d\udca9\ud83d\udca9\ud83d\udca9\ud83d\udca9\\t\ud83d\udca9\",\n            8,\n            \"\ud83d\udca9\ud83d\udca9\ud83d\udca9\ud83d\udca9        \ud83d\udca9\",\n            [\n                Span(0, 12, \"bold\"),\n                Span(12, 13, \"bold\"),\n            ],\n        ),\n    ],\n)\ndef test_tabs_to_spaces_spans(\n    markup: str, tab_size: int, expected_text: str, expected_spans: List[Span]\n):\n    \"\"\"Test spans are correct after expand_tabs\"\"\"\n    text = Text.from_markup(markup)\n    text.expand_tabs(tab_size)\n    print(text._spans)\n    assert text.plain == expected_text\n    assert text._spans == expected_spans\n\n\ndef test_markup_switch():\n    \"\"\"Test markup can be disabled.\"\"\"\n    console = Console(file=StringIO(), markup=False)\n    console.print(\"[bold]foo[/bold]\")\n    assert console.file.getvalue() == \"[bold]foo[/bold]\\n\"\n\n\ndef test_emoji():\n    \"\"\"Test printing emoji codes.\"\"\"\n    console = Console(file=StringIO())\n    console.print(\":+1:\")\n    assert console.file.getvalue() == \"\ud83d\udc4d\\n\"\n\n\ndef test_emoji_switch():\n    \"\"\"Test emoji can be disabled.\"\"\"\n    console = Console(file=StringIO(), emoji=False)\n    console.print(\":+1:\")\n    assert console.file.getvalue() == \":+1:\\n\"\n\n\ndef test_assemble():\n    text = Text.assemble(\"foo\", (\"bar\", \"bold\"))\n    assert str(text) == \"foobar\"\n    assert text._spans == [Span(3, 6, \"bold\")]\n\n\ndef test_assemble_meta():\n    text = Text.assemble(\"foo\", (\"bar\", \"bold\"), meta={\"foo\": \"bar\"})\n    assert str(text) == \"foobar\"\n\n    spans = text._spans\n    expected = [Span(3, 6, \"bold\"), Span(0, 6, Style(meta={\"foo\": \"bar\"}))]\n\n    assert spans == expected\n\n    console = Console()\n    assert text.get_style_at_offset(console, 0).meta == {\"foo\": \"bar\"}\n\n\ndef test_styled():\n    text = Text.styled(\"foo\", \"bold red\")\n    assert text.style == \"\"\n    assert str(text) == \"foo\"\n    assert text._spans == [Span(0, 3, \"bold red\")]\n\n\ndef test_strip_control_codes():\n    text = Text(\"foo\\rbar\")\n    assert str(text) == \"foobar\"\n    text.append(\"\\x08\")\n    assert str(text) == \"foobar\"\n\n\ndef test_get_style_at_offset():\n    console = Console()\n    text = Text.from_markup(\"Hello [b]World[/b]\")\n    assert text.get_style_at_offset(console, 0) == Style()\n    assert text.get_style_at_offset(console, 6) == Style(bold=True)\n\n\n@pytest.mark.parametrize(\n    \"input, count, expected\",\n    [\n        (\"Hello\", 10, \"Hello\"),\n        (\"Hello\", 5, \"Hello\"),\n        (\"Hello\", 4, \"Hel\u2026\"),\n        (\"Hello\", 3, \"He\u2026\"),\n        (\"Hello\", 2, \"H\u2026\"),\n        (\"Hello\", 1, \"\u2026\"),\n    ],\n)\ndef test_truncate_ellipsis(input, count, expected):\n    text = Text(input)\n    text.truncate(count, overflow=\"ellipsis\")\n    assert text.plain == expected\n\n\n@pytest.mark.parametrize(\n    \"input, count, expected\",\n    [\n        (\"Hello\", 5, \"Hello\"),\n        (\"Hello\", 10, \"Hello     \"),\n        (\"Hello\", 3, \"He\u2026\"),\n    ],\n)\ndef test_truncate_ellipsis_pad(input, count, expected):\n    text = Text(input)\n    text.truncate(count, overflow=\"ellipsis\", pad=True)\n    assert text.plain == expected\n\n\ndef test_pad():\n    text = Text(\"foo\")\n    text.pad(2)\n    assert text.plain == \"  foo  \"\n\n\ndef test_align_left():\n    text = Text(\"foo\")\n    text.align(\"left\", 10)\n    assert text.plain == \"foo       \"\n\n\ndef test_align_right():\n    text = Text(\"foo\")\n    text.align(\"right\", 10)\n    assert text.plain == \"       foo\"\n\n\ndef test_align_center():\n    text = Text(\"foo\")\n    text.align(\"center\", 10)\n    assert text.plain == \"   foo    \"\n\n\ndef test_detect_indentation():\n    text = \"\"\"\\\nfoo\n    bar\n    \"\"\"\n    assert Text(text).detect_indentation() == 4\n    text = \"\"\"\\\nfoo\n    bar\n      baz\n    \"\"\"\n    assert Text(text).detect_indentation() == 2\n    assert Text(\"\").detect_indentation() == 1\n    assert Text(\" \").detect_indentation() == 1\n\n\ndef test_indentation_guides():\n    text = Text(\n        \"\"\"\\\nfor a in range(10):\n    print(a)\n\nfoo = [\n    1,\n    {\n        2\n    }\n]\n\n\"\"\"\n    )\n    result = text.with_indent_guides()\n    print(result.plain)\n    print(repr(result.plain))\n    expected = \"for a in range(10):\\n\u2502   print(a)\\n\\nfoo = [\\n\u2502   1,\\n\u2502   {\\n\u2502   \u2502   2\\n\u2502   }\\n]\\n\\n\"\n    assert result.plain == expected\n\n\ndef test_slice():\n    text = Text.from_markup(\"[red]foo [bold]bar[/red] baz[/bold]\")\n    assert text[0] == Text(\"f\", spans=[Span(0, 1, \"red\")])\n    assert text[4] == Text(\"b\", spans=[Span(0, 1, \"red\"), Span(0, 1, \"bold\")])\n\n    assert text[:3] == Text(\"foo\", spans=[Span(0, 3, \"red\")])\n    assert text[:4] == Text(\"foo \", spans=[Span(0, 4, \"red\")])\n    assert text[:5] == Text(\"foo b\", spans=[Span(0, 5, \"red\"), Span(4, 5, \"bold\")])\n    assert text[4:] == Text(\"bar baz\", spans=[Span(0, 3, \"red\"), Span(0, 7, \"bold\")])\n\n    with pytest.raises(TypeError):\n        text[::-1]\n\n\ndef test_wrap_invalid_style():\n    # https://github.com/textualize/rich/issues/987\n    console = Console(width=100, color_system=\"truecolor\")\n    a = \"[#######.................] xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx [#######.................]\"\n    console.print(a, justify=\"full\")\n\n\ndef test_apply_meta():\n    text = Text(\"foobar\")\n    text.apply_meta({\"foo\": \"bar\"}, 1, 3)\n\n    console = Console()\n    assert text.get_style_at_offset(console, 0).meta == {}\n    assert text.get_style_at_offset(console, 1).meta == {\"foo\": \"bar\"}\n    assert text.get_style_at_offset(console, 2).meta == {\"foo\": \"bar\"}\n    assert text.get_style_at_offset(console, 3).meta == {}\n\n\ndef test_on():\n    console = Console()\n    text = Text(\"foo\")\n    text.on({\"foo\": \"bar\"}, click=\"CLICK\")\n    expected = {\"foo\": \"bar\", \"@click\": \"CLICK\"}\n    assert text.get_style_at_offset(console, 0).meta == expected\n    assert text.get_style_at_offset(console, 1).meta == expected\n    assert text.get_style_at_offset(console, 2).meta == expected\n\n\ndef test_markup_property():\n    assert Text(\"\").markup == \"\"\n    assert Text(\"foo\").markup == \"foo\"\n    assert Text(\"foo\", style=\"bold\").markup == \"[bold]foo[/bold]\"\n    assert Text.from_markup(\"foo [red]bar[/red]\").markup == \"foo [red]bar[/red]\"\n    assert (\n        Text.from_markup(\"foo [red]bar[/red]\", style=\"bold\").markup\n        == \"[bold]foo [red]bar[/red][/bold]\"\n    )\n    assert (\n        Text.from_markup(\"[bold]foo [italic]bar[/bold] baz[/italic]\").markup\n        == \"[bold]foo [italic]bar[/bold] baz[/italic]\"\n    )\n    assert Text(\"[bold]foo\").markup == \"\\\\[bold]foo\"\n\n\ndef test_extend_style():\n    text = Text.from_markup(\"[red]foo[/red] [bold]bar\")\n    text.extend_style(0)\n\n    assert text.plain == \"foo bar\"\n    assert text.spans == [Span(0, 3, \"red\"), Span(4, 7, \"bold\")]\n\n    text.extend_style(-1)\n    assert text.plain == \"foo bar\"\n    assert text.spans == [Span(0, 3, \"red\"), Span(4, 7, \"bold\")]\n\n    text.extend_style(2)\n    assert text.plain == \"foo bar  \"\n    assert text.spans == [Span(0, 3, \"red\"), Span(4, 9, \"bold\")]\n\n\ndef test_append_tokens() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3014\"\"\"\n\n    console = Console()\n    t = Text().append_tokens(\n        [\n            (\n                \"long text that will be wrapped with a control code \\r\\n\",\n                \"red\",\n            ),\n        ]\n    )\n    with console.capture() as capture:\n        console.print(t, width=40)\n\n    output = capture.get()\n    print(repr(output))\n    assert output == \"long text that will be wrapped with a \\ncontrol code \\n\\n\"\n\n\ndef test_append_loop_regression() -> None:\n    \"\"\"Regression text for https://github.com/Textualize/rich/issues/3479\"\"\"\n    a = Text(\"one\", \"blue\")\n    a.append(a)\n    assert a.plain == \"oneone\"\n\n    b = Text(\"two\", \"blue\")\n    b.append_text(b)\n    assert b.plain == \"twotwo\"\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "d6b3bbb0bd3c",
      "repo": "rich",
      "commit_hash": "b96cd22",
      "commit_message": "typing fix",
      "file_path": "rich/traceback.py",
      "language": "python",
      "code_before": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        _visited_exceptions: Optional[set[BaseException]] = None,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        grouped_exceptions: Set[BaseException] = (\n            set() if _visited_exceptions is None else _visited_exceptions\n        )\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        if exception in grouped_exceptions:\n                            continue\n                        grouped_exceptions.add(exception)\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                                _visited_exceptions=grouped_exceptions,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            if not grouped_exceptions:\n                cause = getattr(exc_value, \"__cause__\", None)\n                if cause is not None and cause is not exc_value:\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    # __traceback__ can be None, e.g. for exceptions raised by the\n                    # 'multiprocessing' module\n                    traceback = cause.__traceback__\n                    is_cause = True\n                    continue\n\n                cause = exc_value.__context__\n                if cause is not None and not getattr(\n                    exc_value, \"__suppress_context__\", False\n                ):\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    traceback = cause.__traceback__\n                    is_cause = False\n                    continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield \"\"\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code_lines = linecache.getlines(frame.filename)\n                    code = \"\".join(code_lines)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n\n                        # Stylize a line at a time\n                        # So that indentation isn't underlined (which looks bad)\n                        for line1, column1, column2 in _iter_syntax_lines(start, end):\n                            try:\n                                if column1 == 0:\n                                    line = code_lines[line1 - 1]\n                                    column1 = len(line) - len(line.lstrip())\n                                if column2 == -1:\n                                    column2 = len(code_lines[line1 - 1])\n                            except IndexError:\n                                # Being defensive here\n                                # If last_instruction reports a line out-of-bounds, we don't want to crash\n                                continue\n\n                            syntax.stylize_range(\n                                style=\"traceback.error_range\",\n                                start=(line1, column1),\n                                end=(line1, column2),\n                            )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "code_after": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        _visited_exceptions: Optional[Set[BaseException]] = None,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        grouped_exceptions: Set[BaseException] = (\n            set() if _visited_exceptions is None else _visited_exceptions\n        )\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        if exception in grouped_exceptions:\n                            continue\n                        grouped_exceptions.add(exception)\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                                _visited_exceptions=grouped_exceptions,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            if not grouped_exceptions:\n                cause = getattr(exc_value, \"__cause__\", None)\n                if cause is not None and cause is not exc_value:\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    # __traceback__ can be None, e.g. for exceptions raised by the\n                    # 'multiprocessing' module\n                    traceback = cause.__traceback__\n                    is_cause = True\n                    continue\n\n                cause = exc_value.__context__\n                if cause is not None and not getattr(\n                    exc_value, \"__suppress_context__\", False\n                ):\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    traceback = cause.__traceback__\n                    is_cause = False\n                    continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield \"\"\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code_lines = linecache.getlines(frame.filename)\n                    code = \"\".join(code_lines)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n\n                        # Stylize a line at a time\n                        # So that indentation isn't underlined (which looks bad)\n                        for line1, column1, column2 in _iter_syntax_lines(start, end):\n                            try:\n                                if column1 == 0:\n                                    line = code_lines[line1 - 1]\n                                    column1 = len(line) - len(line.lstrip())\n                                if column2 == -1:\n                                    column2 = len(code_lines[line1 - 1])\n                            except IndexError:\n                                # Being defensive here\n                                # If last_instruction reports a line out-of-bounds, we don't want to crash\n                                continue\n\n                            syntax.stylize_range(\n                                style=\"traceback.error_range\",\n                                start=(line1, column1),\n                                end=(line1, column2),\n                            )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "b3b41a34e521",
      "repo": "rich",
      "commit_hash": "1dcc3f6",
      "commit_message": "typing fix",
      "file_path": "rich/traceback.py",
      "language": "python",
      "code_before": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        _visited_exceptions: set[BaseException] | None = None,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        grouped_exceptions: set[BaseException] = (\n            set() if _visited_exceptions is None else _visited_exceptions\n        )\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        if exception in grouped_exceptions:\n                            continue\n                        grouped_exceptions.add(exception)\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                                _visited_exceptions=grouped_exceptions,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            if not grouped_exceptions:\n                cause = getattr(exc_value, \"__cause__\", None)\n                if cause is not None and cause is not exc_value:\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    # __traceback__ can be None, e.g. for exceptions raised by the\n                    # 'multiprocessing' module\n                    traceback = cause.__traceback__\n                    is_cause = True\n                    continue\n\n                cause = exc_value.__context__\n                if cause is not None and not getattr(\n                    exc_value, \"__suppress_context__\", False\n                ):\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    traceback = cause.__traceback__\n                    is_cause = False\n                    continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield \"\"\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code_lines = linecache.getlines(frame.filename)\n                    code = \"\".join(code_lines)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n\n                        # Stylize a line at a time\n                        # So that indentation isn't underlined (which looks bad)\n                        for line1, column1, column2 in _iter_syntax_lines(start, end):\n                            try:\n                                if column1 == 0:\n                                    line = code_lines[line1 - 1]\n                                    column1 = len(line) - len(line.lstrip())\n                                if column2 == -1:\n                                    column2 = len(code_lines[line1 - 1])\n                            except IndexError:\n                                # Being defensive here\n                                # If last_instruction reports a line out-of-bounds, we don't want to crash\n                                continue\n\n                            syntax.stylize_range(\n                                style=\"traceback.error_range\",\n                                start=(line1, column1),\n                                end=(line1, column2),\n                            )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "code_after": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Set,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        _visited_exceptions: Optional[set[BaseException]] = None,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        grouped_exceptions: Set[BaseException] = (\n            set() if _visited_exceptions is None else _visited_exceptions\n        )\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        if exception in grouped_exceptions:\n                            continue\n                        grouped_exceptions.add(exception)\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                                _visited_exceptions=grouped_exceptions,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            if not grouped_exceptions:\n                cause = getattr(exc_value, \"__cause__\", None)\n                if cause is not None and cause is not exc_value:\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    # __traceback__ can be None, e.g. for exceptions raised by the\n                    # 'multiprocessing' module\n                    traceback = cause.__traceback__\n                    is_cause = True\n                    continue\n\n                cause = exc_value.__context__\n                if cause is not None and not getattr(\n                    exc_value, \"__suppress_context__\", False\n                ):\n                    exc_type = cause.__class__\n                    exc_value = cause\n                    traceback = cause.__traceback__\n                    is_cause = False\n                    continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield \"\"\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code_lines = linecache.getlines(frame.filename)\n                    code = \"\".join(code_lines)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n\n                        # Stylize a line at a time\n                        # So that indentation isn't underlined (which looks bad)\n                        for line1, column1, column2 in _iter_syntax_lines(start, end):\n                            try:\n                                if column1 == 0:\n                                    line = code_lines[line1 - 1]\n                                    column1 = len(line) - len(line.lstrip())\n                                if column2 == -1:\n                                    column2 = len(code_lines[line1 - 1])\n                            except IndexError:\n                                # Being defensive here\n                                # If last_instruction reports a line out-of-bounds, we don't want to crash\n                                continue\n\n                            syntax.stylize_range(\n                                style=\"traceback.error_range\",\n                                start=(line1, column1),\n                                end=(line1, column2),\n                            )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.6
    },
    {
      "bug_id": "5a364fa10638",
      "repo": "rich",
      "commit_hash": "348447b",
      "commit_message": "typing fix",
      "file_path": "rich/live.py",
      "language": "python",
      "code_before": "import sys\nfrom threading import Event, RLock, Thread\nfrom types import TracebackType\nfrom typing import IO, Any, Callable, List, Optional, TextIO, Type, cast\n\nfrom . import get_console\nfrom .console import Console, ConsoleRenderable, Group, RenderableType, RenderHook\nfrom .control import Control\nfrom .file_proxy import FileProxy\nfrom .jupyter import JupyterMixin\nfrom .live_render import LiveRender, VerticalOverflowMethod\nfrom .screen import Screen\nfrom .text import Text\n\n\nclass _RefreshThread(Thread):\n    \"\"\"A thread that calls refresh() at regular intervals.\"\"\"\n\n    def __init__(self, live: \"Live\", refresh_per_second: float) -> None:\n        self.live = live\n        self.refresh_per_second = refresh_per_second\n        self.done = Event()\n        super().__init__(daemon=True)\n\n    def stop(self) -> None:\n        self.done.set()\n\n    def run(self) -> None:\n        while not self.done.wait(1 / self.refresh_per_second):\n            with self.live._lock:\n                if not self.done.is_set():\n                    self.live.refresh()\n\n\nclass Live(JupyterMixin, RenderHook):\n    \"\"\"Renders an auto-updating live display of any given renderable.\n\n    Args:\n        renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.\n        console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.\n        screen (bool, optional): Enable alternate screen mode. Defaults to False.\n        auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True\n        refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.\n        transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.\n        redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.\n        redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.\n        vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to \"ellipsis\".\n        get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: Optional[RenderableType] = None,\n        *,\n        console: Optional[Console] = None,\n        screen: bool = False,\n        auto_refresh: bool = True,\n        refresh_per_second: float = 4,\n        transient: bool = False,\n        redirect_stdout: bool = True,\n        redirect_stderr: bool = True,\n        vertical_overflow: VerticalOverflowMethod = \"ellipsis\",\n        get_renderable: Optional[Callable[[], RenderableType]] = None,\n    ) -> None:\n        assert refresh_per_second > 0, \"refresh_per_second must be > 0\"\n        self._renderable = renderable\n        self.console = console if console is not None else get_console()\n        self._screen = screen\n        self._alt_screen = False\n\n        self._redirect_stdout = redirect_stdout\n        self._redirect_stderr = redirect_stderr\n        self._restore_stdout: Optional[IO[str]] = None\n        self._restore_stderr: Optional[IO[str]] = None\n\n        self._lock = RLock()\n        self.ipy_widget: Optional[Any] = None\n        self.auto_refresh = auto_refresh\n        self._started: bool = False\n        self.transient = True if screen else transient\n\n        self._refresh_thread: Optional[_RefreshThread] = None\n        self.refresh_per_second = refresh_per_second\n\n        self.vertical_overflow = vertical_overflow\n        self._get_renderable = get_renderable\n        self._live_render = LiveRender(\n            self.get_renderable(), vertical_overflow=vertical_overflow\n        )\n        self._nested = False\n\n    @property\n    def is_started(self) -> bool:\n        \"\"\"Check if live display has been started.\"\"\"\n        return self._started\n\n    def get_renderable(self) -> RenderableType:\n        renderable = (\n            self._get_renderable()\n            if self._get_renderable is not None\n            else self._renderable\n        )\n        return renderable or \"\"\n\n    def start(self, refresh: bool = False) -> None:\n        \"\"\"Start live rendering display.\n\n        Args:\n            refresh (bool, optional): Also refresh. Defaults to False.\n        \"\"\"\n        with self._lock:\n            if self._started:\n                return\n            self._started = True\n\n            if not self.console.set_live(self):\n                self._nested = True\n                return\n\n            if self._screen:\n                self._alt_screen = self.console.set_alt_screen(True)\n            self.console.show_cursor(False)\n            self._enable_redirect_io()\n            self.console.push_render_hook(self)\n            if refresh:\n                try:\n                    self.refresh()\n                except Exception:\n                    # If refresh fails, we want to stop the redirection of sys.stderr,\n                    # so the error stacktrace is properly displayed in the terminal.\n                    # (or, if the code that calls Rich captures the exception and wants to display something,\n                    # let this be displayed in the terminal).\n                    self.stop()\n                    raise\n            if self.auto_refresh:\n                self._refresh_thread = _RefreshThread(self, self.refresh_per_second)\n                self._refresh_thread.start()\n\n    def stop(self) -> None:\n        \"\"\"Stop live rendering display.\"\"\"\n        with self._lock:\n            if not self._started:\n                return\n            self._started = False\n            self.console.clear_live()\n            if self._nested:\n                if not self.transient:\n                    self.console.print(self.renderable)\n                return\n\n            if self.auto_refresh and self._refresh_thread is not None:\n                self._refresh_thread.stop()\n                self._refresh_thread = None\n            # allow it to fully render on the last even if overflow\n            self.vertical_overflow = \"visible\"\n            with self.console:\n                try:\n                    if not self._alt_screen and not self.console.is_jupyter:\n                        self.refresh()\n                finally:\n                    self._disable_redirect_io()\n                    self.console.pop_render_hook()\n                    if not self._alt_screen and self.console.is_terminal:\n                        self.console.line()\n                    self.console.show_cursor(True)\n                    if self._alt_screen:\n                        self.console.set_alt_screen(False)\n                    if self.transient and not self._alt_screen:\n                        self.console.control(self._live_render.restore_cursor())\n                    if self.ipy_widget is not None and self.transient:\n                        self.ipy_widget.close()  # pragma: no cover\n\n    def __enter__(self) -> \"Live\":\n        self.start(refresh=self._renderable is not None)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.stop()\n\n    def _enable_redirect_io(self) -> None:\n        \"\"\"Enable redirecting of stdout / stderr.\"\"\"\n        if self.console.is_terminal or self.console.is_jupyter:\n            if self._redirect_stdout and not isinstance(sys.stdout, FileProxy):\n                self._restore_stdout = sys.stdout\n                sys.stdout = cast(\"TextIO\", FileProxy(self.console, sys.stdout))\n            if self._redirect_stderr and not isinstance(sys.stderr, FileProxy):\n                self._restore_stderr = sys.stderr\n                sys.stderr = cast(\"TextIO\", FileProxy(self.console, sys.stderr))\n\n    def _disable_redirect_io(self) -> None:\n        \"\"\"Disable redirecting of stdout / stderr.\"\"\"\n        if self._restore_stdout:\n            sys.stdout = cast(\"TextIO\", self._restore_stdout)\n            self._restore_stdout = None\n        if self._restore_stderr:\n            sys.stderr = cast(\"TextIO\", self._restore_stderr)\n            self._restore_stderr = None\n\n    @property\n    def renderable(self) -> RenderableType:\n        \"\"\"Get the renderable that is being displayed\n\n        Returns:\n            RenderableType: Displayed renderable.\n        \"\"\"\n        live_stack = self.console._live_stack\n        if live_stack and self is live_stack[0]:\n            renderable = Group(*[live.get_renderable() for live in live_stack])\n        else:\n            renderable = self.get_renderable()\n        return Screen(renderable) if self._alt_screen else renderable\n\n    def update(self, renderable: RenderableType, *, refresh: bool = False) -> None:\n        \"\"\"Update the renderable that is being displayed\n\n        Args:\n            renderable (RenderableType): New renderable to use.\n            refresh (bool, optional): Refresh the display. Defaults to False.\n        \"\"\"\n        if isinstance(renderable, str):\n            renderable = self.console.render_str(renderable)\n        with self._lock:\n            self._renderable = renderable\n            if refresh:\n                self.refresh()\n\n    def refresh(self) -> None:\n        \"\"\"Update the display of the Live Render.\"\"\"\n        with self._lock:\n            self._live_render.set_renderable(self.renderable)\n            if self._nested:\n                if self.console._live_stack:\n                    self.console._live_stack[0].refresh()\n                return\n\n            if self.console.is_jupyter:  # pragma: no cover\n                try:\n                    from IPython.display import display\n                    from ipywidgets import Output\n                except ImportError:\n                    import warnings\n\n                    warnings.warn('install \"ipywidgets\" for Jupyter support')\n                else:\n                    if self.ipy_widget is None:\n                        self.ipy_widget = Output()\n                        display(self.ipy_widget)\n\n                    with self.ipy_widget:\n                        self.ipy_widget.clear_output(wait=True)\n                        self.console.print(self._live_render.renderable)\n            elif self.console.is_terminal and not self.console.is_dumb_terminal:\n                with self.console:\n                    self.console.print(Control())\n            elif (\n                not self._started and not self.transient\n            ):  # if it is finished allow files or dumb-terminals to see final result\n                with self.console:\n                    self.console.print(Control())\n\n    def process_renderables(\n        self, renderables: List[ConsoleRenderable]\n    ) -> List[ConsoleRenderable]:\n        \"\"\"Process renderables to restore cursor and display progress.\"\"\"\n        self._live_render.vertical_overflow = self.vertical_overflow\n        if self.console.is_interactive:\n            # lock needs acquiring as user can modify live_render renderable at any time unlike in Progress.\n            with self._lock:\n                reset = (\n                    Control.home()\n                    if self._alt_screen\n                    else self._live_render.position_cursor()\n                )\n                renderables = [reset, *renderables, self._live_render]\n        elif (\n            not self._started and not self.transient\n        ):  # if it is finished render the final output for files or dumb_terminals\n            renderables = [*renderables, self._live_render]\n\n        return renderables\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import random\n    import time\n    from itertools import cycle\n    from typing import Dict, List, Tuple\n\n    from .align import Align\n    from .console import Console\n    from .live import Live as Live\n    from .panel import Panel\n    from .rule import Rule\n    from .syntax import Syntax\n    from .table import Table\n\n    console = Console()\n\n    syntax = Syntax(\n        '''def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    for value in iter_values:\n        yield False, previous_value\n        previous_value = value\n    yield True, previous_value''',\n        \"python\",\n        line_numbers=True,\n    )\n\n    table = Table(\"foo\", \"bar\", \"baz\")\n    table.add_row(\"1\", \"2\", \"3\")\n\n    progress_renderables = [\n        \"You can make the terminal shorter and taller to see the live table hide\"\n        \"Text may be printed while the progress bars are rendering.\",\n        Panel(\"In fact, [i]any[/i] renderable will work\"),\n        \"Such as [magenta]tables[/]...\",\n        table,\n        \"Pretty printed structures...\",\n        {\"type\": \"example\", \"text\": \"Pretty printed\"},\n        \"Syntax...\",\n        syntax,\n        Rule(\"Give it a try!\"),\n    ]\n\n    examples = cycle(progress_renderables)\n\n    exchanges = [\n        \"SGD\",\n        \"MYR\",\n        \"EUR\",\n        \"USD\",\n        \"AUD\",\n        \"JPY\",\n        \"CNH\",\n        \"HKD\",\n        \"CAD\",\n        \"INR\",\n        \"DKK\",\n        \"GBP\",\n        \"RUB\",\n        \"NZD\",\n        \"MXN\",\n        \"IDR\",\n        \"TWD\",\n        \"THB\",\n        \"VND\",\n    ]\n    with Live(console=console) as live_table:\n        exchange_rate_dict: Dict[Tuple[str, str], float] = {}\n\n        for index in range(100):\n            select_exchange = exchanges[index % len(exchanges)]\n\n            for exchange in exchanges:\n                if exchange == select_exchange:\n                    continue\n                time.sleep(0.4)\n                if random.randint(0, 10) < 1:\n                    console.log(next(examples))\n                exchange_rate_dict[(select_exchange, exchange)] = 200 / (\n                    (random.random() * 320) + 1\n                )\n                if len(exchange_rate_dict) > len(exchanges) - 1:\n                    exchange_rate_dict.pop(list(exchange_rate_dict.keys())[0])\n                table = Table(title=\"Exchange Rates\")\n\n                table.add_column(\"Source Currency\")\n                table.add_column(\"Destination Currency\")\n                table.add_column(\"Exchange Rate\")\n\n                for (source, dest), exchange_rate in exchange_rate_dict.items():\n                    table.add_row(\n                        source,\n                        dest,\n                        Text(\n                            f\"{exchange_rate:.4f}\",\n                            style=\"red\" if exchange_rate < 1.0 else \"green\",\n                        ),\n                    )\n\n                live_table.update(Align.center(table))\n",
      "code_after": "import sys\nfrom threading import Event, RLock, Thread\nfrom types import TracebackType\nfrom typing import IO, Any, Callable, List, Optional, TextIO, Type, cast\n\nfrom . import get_console\nfrom .console import Console, ConsoleRenderable, Group, RenderableType, RenderHook\nfrom .control import Control\nfrom .file_proxy import FileProxy\nfrom .jupyter import JupyterMixin\nfrom .live_render import LiveRender, VerticalOverflowMethod\nfrom .screen import Screen\nfrom .text import Text\n\n\nclass _RefreshThread(Thread):\n    \"\"\"A thread that calls refresh() at regular intervals.\"\"\"\n\n    def __init__(self, live: \"Live\", refresh_per_second: float) -> None:\n        self.live = live\n        self.refresh_per_second = refresh_per_second\n        self.done = Event()\n        super().__init__(daemon=True)\n\n    def stop(self) -> None:\n        self.done.set()\n\n    def run(self) -> None:\n        while not self.done.wait(1 / self.refresh_per_second):\n            with self.live._lock:\n                if not self.done.is_set():\n                    self.live.refresh()\n\n\nclass Live(JupyterMixin, RenderHook):\n    \"\"\"Renders an auto-updating live display of any given renderable.\n\n    Args:\n        renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.\n        console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.\n        screen (bool, optional): Enable alternate screen mode. Defaults to False.\n        auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True\n        refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.\n        transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.\n        redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.\n        redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.\n        vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to \"ellipsis\".\n        get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: Optional[RenderableType] = None,\n        *,\n        console: Optional[Console] = None,\n        screen: bool = False,\n        auto_refresh: bool = True,\n        refresh_per_second: float = 4,\n        transient: bool = False,\n        redirect_stdout: bool = True,\n        redirect_stderr: bool = True,\n        vertical_overflow: VerticalOverflowMethod = \"ellipsis\",\n        get_renderable: Optional[Callable[[], RenderableType]] = None,\n    ) -> None:\n        assert refresh_per_second > 0, \"refresh_per_second must be > 0\"\n        self._renderable = renderable\n        self.console = console if console is not None else get_console()\n        self._screen = screen\n        self._alt_screen = False\n\n        self._redirect_stdout = redirect_stdout\n        self._redirect_stderr = redirect_stderr\n        self._restore_stdout: Optional[IO[str]] = None\n        self._restore_stderr: Optional[IO[str]] = None\n\n        self._lock = RLock()\n        self.ipy_widget: Optional[Any] = None\n        self.auto_refresh = auto_refresh\n        self._started: bool = False\n        self.transient = True if screen else transient\n\n        self._refresh_thread: Optional[_RefreshThread] = None\n        self.refresh_per_second = refresh_per_second\n\n        self.vertical_overflow = vertical_overflow\n        self._get_renderable = get_renderable\n        self._live_render = LiveRender(\n            self.get_renderable(), vertical_overflow=vertical_overflow\n        )\n        self._nested = False\n\n    @property\n    def is_started(self) -> bool:\n        \"\"\"Check if live display has been started.\"\"\"\n        return self._started\n\n    def get_renderable(self) -> RenderableType:\n        renderable = (\n            self._get_renderable()\n            if self._get_renderable is not None\n            else self._renderable\n        )\n        return renderable or \"\"\n\n    def start(self, refresh: bool = False) -> None:\n        \"\"\"Start live rendering display.\n\n        Args:\n            refresh (bool, optional): Also refresh. Defaults to False.\n        \"\"\"\n        with self._lock:\n            if self._started:\n                return\n            self._started = True\n\n            if not self.console.set_live(self):\n                self._nested = True\n                return\n\n            if self._screen:\n                self._alt_screen = self.console.set_alt_screen(True)\n            self.console.show_cursor(False)\n            self._enable_redirect_io()\n            self.console.push_render_hook(self)\n            if refresh:\n                try:\n                    self.refresh()\n                except Exception:\n                    # If refresh fails, we want to stop the redirection of sys.stderr,\n                    # so the error stacktrace is properly displayed in the terminal.\n                    # (or, if the code that calls Rich captures the exception and wants to display something,\n                    # let this be displayed in the terminal).\n                    self.stop()\n                    raise\n            if self.auto_refresh:\n                self._refresh_thread = _RefreshThread(self, self.refresh_per_second)\n                self._refresh_thread.start()\n\n    def stop(self) -> None:\n        \"\"\"Stop live rendering display.\"\"\"\n        with self._lock:\n            if not self._started:\n                return\n            self._started = False\n            self.console.clear_live()\n            if self._nested:\n                if not self.transient:\n                    self.console.print(self.renderable)\n                return\n\n            if self.auto_refresh and self._refresh_thread is not None:\n                self._refresh_thread.stop()\n                self._refresh_thread = None\n            # allow it to fully render on the last even if overflow\n            self.vertical_overflow = \"visible\"\n            with self.console:\n                try:\n                    if not self._alt_screen and not self.console.is_jupyter:\n                        self.refresh()\n                finally:\n                    self._disable_redirect_io()\n                    self.console.pop_render_hook()\n                    if not self._alt_screen and self.console.is_terminal:\n                        self.console.line()\n                    self.console.show_cursor(True)\n                    if self._alt_screen:\n                        self.console.set_alt_screen(False)\n                    if self.transient and not self._alt_screen:\n                        self.console.control(self._live_render.restore_cursor())\n                    if self.ipy_widget is not None and self.transient:\n                        self.ipy_widget.close()  # pragma: no cover\n\n    def __enter__(self) -> \"Live\":\n        self.start(refresh=self._renderable is not None)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.stop()\n\n    def _enable_redirect_io(self) -> None:\n        \"\"\"Enable redirecting of stdout / stderr.\"\"\"\n        if self.console.is_terminal or self.console.is_jupyter:\n            if self._redirect_stdout and not isinstance(sys.stdout, FileProxy):\n                self._restore_stdout = sys.stdout\n                sys.stdout = cast(\"TextIO\", FileProxy(self.console, sys.stdout))\n            if self._redirect_stderr and not isinstance(sys.stderr, FileProxy):\n                self._restore_stderr = sys.stderr\n                sys.stderr = cast(\"TextIO\", FileProxy(self.console, sys.stderr))\n\n    def _disable_redirect_io(self) -> None:\n        \"\"\"Disable redirecting of stdout / stderr.\"\"\"\n        if self._restore_stdout:\n            sys.stdout = cast(\"TextIO\", self._restore_stdout)\n            self._restore_stdout = None\n        if self._restore_stderr:\n            sys.stderr = cast(\"TextIO\", self._restore_stderr)\n            self._restore_stderr = None\n\n    @property\n    def renderable(self) -> RenderableType:\n        \"\"\"Get the renderable that is being displayed\n\n        Returns:\n            RenderableType: Displayed renderable.\n        \"\"\"\n        live_stack = self.console._live_stack\n        renderable: RenderableType\n        if live_stack and self is live_stack[0]:\n            renderable = Group(*[live.get_renderable() for live in live_stack])\n        else:\n            renderable = self.get_renderable()\n        return Screen(renderable) if self._alt_screen else renderable\n\n    def update(self, renderable: RenderableType, *, refresh: bool = False) -> None:\n        \"\"\"Update the renderable that is being displayed\n\n        Args:\n            renderable (RenderableType): New renderable to use.\n            refresh (bool, optional): Refresh the display. Defaults to False.\n        \"\"\"\n        if isinstance(renderable, str):\n            renderable = self.console.render_str(renderable)\n        with self._lock:\n            self._renderable = renderable\n            if refresh:\n                self.refresh()\n\n    def refresh(self) -> None:\n        \"\"\"Update the display of the Live Render.\"\"\"\n        with self._lock:\n            self._live_render.set_renderable(self.renderable)\n            if self._nested:\n                if self.console._live_stack:\n                    self.console._live_stack[0].refresh()\n                return\n\n            if self.console.is_jupyter:  # pragma: no cover\n                try:\n                    from IPython.display import display\n                    from ipywidgets import Output\n                except ImportError:\n                    import warnings\n\n                    warnings.warn('install \"ipywidgets\" for Jupyter support')\n                else:\n                    if self.ipy_widget is None:\n                        self.ipy_widget = Output()\n                        display(self.ipy_widget)\n\n                    with self.ipy_widget:\n                        self.ipy_widget.clear_output(wait=True)\n                        self.console.print(self._live_render.renderable)\n            elif self.console.is_terminal and not self.console.is_dumb_terminal:\n                with self.console:\n                    self.console.print(Control())\n            elif (\n                not self._started and not self.transient\n            ):  # if it is finished allow files or dumb-terminals to see final result\n                with self.console:\n                    self.console.print(Control())\n\n    def process_renderables(\n        self, renderables: List[ConsoleRenderable]\n    ) -> List[ConsoleRenderable]:\n        \"\"\"Process renderables to restore cursor and display progress.\"\"\"\n        self._live_render.vertical_overflow = self.vertical_overflow\n        if self.console.is_interactive:\n            # lock needs acquiring as user can modify live_render renderable at any time unlike in Progress.\n            with self._lock:\n                reset = (\n                    Control.home()\n                    if self._alt_screen\n                    else self._live_render.position_cursor()\n                )\n                renderables = [reset, *renderables, self._live_render]\n        elif (\n            not self._started and not self.transient\n        ):  # if it is finished render the final output for files or dumb_terminals\n            renderables = [*renderables, self._live_render]\n\n        return renderables\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import random\n    import time\n    from itertools import cycle\n    from typing import Dict, List, Tuple\n\n    from .align import Align\n    from .console import Console\n    from .live import Live as Live\n    from .panel import Panel\n    from .rule import Rule\n    from .syntax import Syntax\n    from .table import Table\n\n    console = Console()\n\n    syntax = Syntax(\n        '''def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    for value in iter_values:\n        yield False, previous_value\n        previous_value = value\n    yield True, previous_value''',\n        \"python\",\n        line_numbers=True,\n    )\n\n    table = Table(\"foo\", \"bar\", \"baz\")\n    table.add_row(\"1\", \"2\", \"3\")\n\n    progress_renderables = [\n        \"You can make the terminal shorter and taller to see the live table hide\"\n        \"Text may be printed while the progress bars are rendering.\",\n        Panel(\"In fact, [i]any[/i] renderable will work\"),\n        \"Such as [magenta]tables[/]...\",\n        table,\n        \"Pretty printed structures...\",\n        {\"type\": \"example\", \"text\": \"Pretty printed\"},\n        \"Syntax...\",\n        syntax,\n        Rule(\"Give it a try!\"),\n    ]\n\n    examples = cycle(progress_renderables)\n\n    exchanges = [\n        \"SGD\",\n        \"MYR\",\n        \"EUR\",\n        \"USD\",\n        \"AUD\",\n        \"JPY\",\n        \"CNH\",\n        \"HKD\",\n        \"CAD\",\n        \"INR\",\n        \"DKK\",\n        \"GBP\",\n        \"RUB\",\n        \"NZD\",\n        \"MXN\",\n        \"IDR\",\n        \"TWD\",\n        \"THB\",\n        \"VND\",\n    ]\n    with Live(console=console) as live_table:\n        exchange_rate_dict: Dict[Tuple[str, str], float] = {}\n\n        for index in range(100):\n            select_exchange = exchanges[index % len(exchanges)]\n\n            for exchange in exchanges:\n                if exchange == select_exchange:\n                    continue\n                time.sleep(0.4)\n                if random.randint(0, 10) < 1:\n                    console.log(next(examples))\n                exchange_rate_dict[(select_exchange, exchange)] = 200 / (\n                    (random.random() * 320) + 1\n                )\n                if len(exchange_rate_dict) > len(exchanges) - 1:\n                    exchange_rate_dict.pop(list(exchange_rate_dict.keys())[0])\n                table = Table(title=\"Exchange Rates\")\n\n                table.add_column(\"Source Currency\")\n                table.add_column(\"Destination Currency\")\n                table.add_column(\"Exchange Rate\")\n\n                for (source, dest), exchange_rate in exchange_rate_dict.items():\n                    table.add_row(\n                        source,\n                        dest,\n                        Text(\n                            f\"{exchange_rate:.4f}\",\n                            style=\"red\" if exchange_rate < 1.0 else \"green\",\n                        ),\n                    )\n\n                live_table.update(Align.center(table))\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "300a72c5f28e",
      "repo": "rich",
      "commit_hash": "82afcb4",
      "commit_message": "test fixes",
      "file_path": "rich/live.py",
      "language": "python",
      "code_before": "import sys\nfrom threading import Event, RLock, Thread\nfrom types import TracebackType\nfrom typing import IO, Any, Callable, List, Optional, TextIO, Type, cast\n\nfrom . import get_console\nfrom .console import Console, ConsoleRenderable, Group, RenderableType, RenderHook\nfrom .control import Control\nfrom .file_proxy import FileProxy\nfrom .jupyter import JupyterMixin\nfrom .live_render import LiveRender, VerticalOverflowMethod\nfrom .screen import Screen\nfrom .text import Text\n\n\nclass _RefreshThread(Thread):\n    \"\"\"A thread that calls refresh() at regular intervals.\"\"\"\n\n    def __init__(self, live: \"Live\", refresh_per_second: float) -> None:\n        self.live = live\n        self.refresh_per_second = refresh_per_second\n        self.done = Event()\n        super().__init__(daemon=True)\n\n    def stop(self) -> None:\n        self.done.set()\n\n    def run(self) -> None:\n        while not self.done.wait(1 / self.refresh_per_second):\n            with self.live._lock:\n                if not self.done.is_set():\n                    self.live.refresh()\n\n\nclass Live(JupyterMixin, RenderHook):\n    \"\"\"Renders an auto-updating live display of any given renderable.\n\n    Args:\n        renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.\n        console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.\n        screen (bool, optional): Enable alternate screen mode. Defaults to False.\n        auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True\n        refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.\n        transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.\n        redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.\n        redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.\n        vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to \"ellipsis\".\n        get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: Optional[RenderableType] = None,\n        *,\n        console: Optional[Console] = None,\n        screen: bool = False,\n        auto_refresh: bool = True,\n        refresh_per_second: float = 4,\n        transient: bool = False,\n        redirect_stdout: bool = True,\n        redirect_stderr: bool = True,\n        vertical_overflow: VerticalOverflowMethod = \"ellipsis\",\n        get_renderable: Optional[Callable[[], RenderableType]] = None,\n    ) -> None:\n        assert refresh_per_second > 0, \"refresh_per_second must be > 0\"\n        self._renderable = renderable\n        self.console = console if console is not None else get_console()\n        self._screen = screen\n        self._alt_screen = False\n\n        self._redirect_stdout = redirect_stdout\n        self._redirect_stderr = redirect_stderr\n        self._restore_stdout: Optional[IO[str]] = None\n        self._restore_stderr: Optional[IO[str]] = None\n\n        self._lock = RLock()\n        self.ipy_widget: Optional[Any] = None\n        self.auto_refresh = auto_refresh\n        self._started: bool = False\n        self.transient = True if screen else transient\n\n        self._refresh_thread: Optional[_RefreshThread] = None\n        self.refresh_per_second = refresh_per_second\n\n        self.vertical_overflow = vertical_overflow\n        self._get_renderable = get_renderable\n        self._live_render = LiveRender(\n            self.get_renderable(), vertical_overflow=vertical_overflow\n        )\n        self._nested = False\n\n    @property\n    def is_started(self) -> bool:\n        \"\"\"Check if live display has been started.\"\"\"\n        return self._started\n\n    def get_renderable(self) -> RenderableType:\n        renderable = (\n            self._get_renderable()\n            if self._get_renderable is not None\n            else self._renderable\n        )\n        return renderable or \"\"\n\n    def start(self, refresh: bool = False) -> None:\n        \"\"\"Start live rendering display.\n\n        Args:\n            refresh (bool, optional): Also refresh. Defaults to False.\n        \"\"\"\n        with self._lock:\n            if self._started:\n                return\n            self._started = True\n\n            if not self.console.set_live(self):\n                self._nested = True\n                return\n\n            if self._screen:\n                self._alt_screen = self.console.set_alt_screen(True)\n            self.console.show_cursor(False)\n            self._enable_redirect_io()\n            self.console.push_render_hook(self)\n            if refresh:\n                try:\n                    self.refresh()\n                except Exception:\n                    # If refresh fails, we want to stop the redirection of sys.stderr,\n                    # so the error stacktrace is properly displayed in the terminal.\n                    # (or, if the code that calls Rich captures the exception and wants to display something,\n                    # let this be displayed in the terminal).\n                    self.stop()\n                    raise\n            if self.auto_refresh:\n                self._refresh_thread = _RefreshThread(self, self.refresh_per_second)\n                self._refresh_thread.start()\n\n    def stop(self) -> None:\n        \"\"\"Stop live rendering display.\"\"\"\n        with self._lock:\n            if not self._started:\n                return\n            self._started = False\n            self.console.clear_live()\n            if self._nested:\n                if not self.transient:\n                    self.console.print(self.renderable)\n                return\n\n            if self.auto_refresh and self._refresh_thread is not None:\n                self._refresh_thread.stop()\n                self._refresh_thread = None\n            # allow it to fully render on the last even if overflow\n            self.vertical_overflow = \"visible\"\n            with self.console:\n                try:\n                    if not self._alt_screen and not self.console.is_jupyter:\n                        self.refresh()\n                finally:\n                    self._disable_redirect_io()\n                    self.console.pop_render_hook()\n                    if not self._alt_screen and self.console.is_terminal:\n                        self.console.line()\n                    self.console.show_cursor(True)\n                    if self._alt_screen:\n                        self.console.set_alt_screen(False)\n                    if self.transient and not self._alt_screen:\n                        self.console.control(self._live_render.restore_cursor())\n                    if self.ipy_widget is not None and self.transient:\n                        self.ipy_widget.close()  # pragma: no cover\n\n    def __enter__(self) -> \"Live\":\n        self.start(refresh=self._renderable is not None)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.stop()\n\n    def _enable_redirect_io(self) -> None:\n        \"\"\"Enable redirecting of stdout / stderr.\"\"\"\n        if self.console.is_terminal or self.console.is_jupyter:\n            if self._redirect_stdout and not isinstance(sys.stdout, FileProxy):\n                self._restore_stdout = sys.stdout\n                sys.stdout = cast(\"TextIO\", FileProxy(self.console, sys.stdout))\n            if self._redirect_stderr and not isinstance(sys.stderr, FileProxy):\n                self._restore_stderr = sys.stderr\n                sys.stderr = cast(\"TextIO\", FileProxy(self.console, sys.stderr))\n\n    def _disable_redirect_io(self) -> None:\n        \"\"\"Disable redirecting of stdout / stderr.\"\"\"\n        if self._restore_stdout:\n            sys.stdout = cast(\"TextIO\", self._restore_stdout)\n            self._restore_stdout = None\n        if self._restore_stderr:\n            sys.stderr = cast(\"TextIO\", self._restore_stderr)\n            self._restore_stderr = None\n\n    @property\n    def renderable(self) -> RenderableType:\n        \"\"\"Get the renderable that is being displayed\n\n        Returns:\n            RenderableType: Displayed renderable.\n        \"\"\"\n        live_stack = self.console._live_stack\n        if len(live_stack) == 1:\n            renderable = self.get_renderable()\n        else:\n            renderable = Group(*[live.get_renderable() for live in live_stack])\n        return Screen(renderable) if self._alt_screen else renderable\n\n    def update(self, renderable: RenderableType, *, refresh: bool = False) -> None:\n        \"\"\"Update the renderable that is being displayed\n\n        Args:\n            renderable (RenderableType): New renderable to use.\n            refresh (bool, optional): Refresh the display. Defaults to False.\n        \"\"\"\n        if isinstance(renderable, str):\n            renderable = self.console.render_str(renderable)\n        with self._lock:\n            self._renderable = renderable\n            if refresh:\n                self.refresh()\n\n    def refresh(self) -> None:\n        \"\"\"Update the display of the Live Render.\"\"\"\n        with self._lock:\n            self._live_render.set_renderable(self.renderable)\n            if self._nested:\n                if self.console._live_stack:\n                    self.console._live_stack[0].refresh()\n                return\n\n            if self.console.is_jupyter:  # pragma: no cover\n                try:\n                    from IPython.display import display\n                    from ipywidgets import Output\n                except ImportError:\n                    import warnings\n\n                    warnings.warn('install \"ipywidgets\" for Jupyter support')\n                else:\n                    if self.ipy_widget is None:\n                        self.ipy_widget = Output()\n                        display(self.ipy_widget)\n\n                    with self.ipy_widget:\n                        self.ipy_widget.clear_output(wait=True)\n                        self.console.print(self._live_render.renderable)\n            elif self.console.is_terminal and not self.console.is_dumb_terminal:\n                with self.console:\n                    self.console.print(Control())\n            elif (\n                not self._started and not self.transient\n            ):  # if it is finished allow files or dumb-terminals to see final result\n                with self.console:\n                    self.console.print(Control())\n\n    def process_renderables(\n        self, renderables: List[ConsoleRenderable]\n    ) -> List[ConsoleRenderable]:\n        \"\"\"Process renderables to restore cursor and display progress.\"\"\"\n        self._live_render.vertical_overflow = self.vertical_overflow\n        if self.console.is_interactive:\n            # lock needs acquiring as user can modify live_render renderable at any time unlike in Progress.\n            with self._lock:\n                reset = (\n                    Control.home()\n                    if self._alt_screen\n                    else self._live_render.position_cursor()\n                )\n                renderables = [reset, *renderables, self._live_render]\n        elif (\n            not self._started and not self.transient\n        ):  # if it is finished render the final output for files or dumb_terminals\n            renderables = [*renderables, self._live_render]\n\n        return renderables\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import random\n    import time\n    from itertools import cycle\n    from typing import Dict, List, Tuple\n\n    from .align import Align\n    from .console import Console\n    from .live import Live as Live\n    from .panel import Panel\n    from .rule import Rule\n    from .syntax import Syntax\n    from .table import Table\n\n    console = Console()\n\n    syntax = Syntax(\n        '''def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    for value in iter_values:\n        yield False, previous_value\n        previous_value = value\n    yield True, previous_value''',\n        \"python\",\n        line_numbers=True,\n    )\n\n    table = Table(\"foo\", \"bar\", \"baz\")\n    table.add_row(\"1\", \"2\", \"3\")\n\n    progress_renderables = [\n        \"You can make the terminal shorter and taller to see the live table hide\"\n        \"Text may be printed while the progress bars are rendering.\",\n        Panel(\"In fact, [i]any[/i] renderable will work\"),\n        \"Such as [magenta]tables[/]...\",\n        table,\n        \"Pretty printed structures...\",\n        {\"type\": \"example\", \"text\": \"Pretty printed\"},\n        \"Syntax...\",\n        syntax,\n        Rule(\"Give it a try!\"),\n    ]\n\n    examples = cycle(progress_renderables)\n\n    exchanges = [\n        \"SGD\",\n        \"MYR\",\n        \"EUR\",\n        \"USD\",\n        \"AUD\",\n        \"JPY\",\n        \"CNH\",\n        \"HKD\",\n        \"CAD\",\n        \"INR\",\n        \"DKK\",\n        \"GBP\",\n        \"RUB\",\n        \"NZD\",\n        \"MXN\",\n        \"IDR\",\n        \"TWD\",\n        \"THB\",\n        \"VND\",\n    ]\n    with Live(console=console) as live_table:\n        exchange_rate_dict: Dict[Tuple[str, str], float] = {}\n\n        for index in range(100):\n            select_exchange = exchanges[index % len(exchanges)]\n\n            for exchange in exchanges:\n                if exchange == select_exchange:\n                    continue\n                time.sleep(0.4)\n                if random.randint(0, 10) < 1:\n                    console.log(next(examples))\n                exchange_rate_dict[(select_exchange, exchange)] = 200 / (\n                    (random.random() * 320) + 1\n                )\n                if len(exchange_rate_dict) > len(exchanges) - 1:\n                    exchange_rate_dict.pop(list(exchange_rate_dict.keys())[0])\n                table = Table(title=\"Exchange Rates\")\n\n                table.add_column(\"Source Currency\")\n                table.add_column(\"Destination Currency\")\n                table.add_column(\"Exchange Rate\")\n\n                for (source, dest), exchange_rate in exchange_rate_dict.items():\n                    table.add_row(\n                        source,\n                        dest,\n                        Text(\n                            f\"{exchange_rate:.4f}\",\n                            style=\"red\" if exchange_rate < 1.0 else \"green\",\n                        ),\n                    )\n\n                live_table.update(Align.center(table))\n",
      "code_after": "import sys\nfrom threading import Event, RLock, Thread\nfrom types import TracebackType\nfrom typing import IO, Any, Callable, List, Optional, TextIO, Type, cast\n\nfrom . import get_console\nfrom .console import Console, ConsoleRenderable, Group, RenderableType, RenderHook\nfrom .control import Control\nfrom .file_proxy import FileProxy\nfrom .jupyter import JupyterMixin\nfrom .live_render import LiveRender, VerticalOverflowMethod\nfrom .screen import Screen\nfrom .text import Text\n\n\nclass _RefreshThread(Thread):\n    \"\"\"A thread that calls refresh() at regular intervals.\"\"\"\n\n    def __init__(self, live: \"Live\", refresh_per_second: float) -> None:\n        self.live = live\n        self.refresh_per_second = refresh_per_second\n        self.done = Event()\n        super().__init__(daemon=True)\n\n    def stop(self) -> None:\n        self.done.set()\n\n    def run(self) -> None:\n        while not self.done.wait(1 / self.refresh_per_second):\n            with self.live._lock:\n                if not self.done.is_set():\n                    self.live.refresh()\n\n\nclass Live(JupyterMixin, RenderHook):\n    \"\"\"Renders an auto-updating live display of any given renderable.\n\n    Args:\n        renderable (RenderableType, optional): The renderable to live display. Defaults to displaying nothing.\n        console (Console, optional): Optional Console instance. Defaults to an internal Console instance writing to stdout.\n        screen (bool, optional): Enable alternate screen mode. Defaults to False.\n        auto_refresh (bool, optional): Enable auto refresh. If disabled, you will need to call `refresh()` or `update()` with refresh flag. Defaults to True\n        refresh_per_second (float, optional): Number of times per second to refresh the live display. Defaults to 4.\n        transient (bool, optional): Clear the renderable on exit (has no effect when screen=True). Defaults to False.\n        redirect_stdout (bool, optional): Enable redirection of stdout, so ``print`` may be used. Defaults to True.\n        redirect_stderr (bool, optional): Enable redirection of stderr. Defaults to True.\n        vertical_overflow (VerticalOverflowMethod, optional): How to handle renderable when it is too tall for the console. Defaults to \"ellipsis\".\n        get_renderable (Callable[[], RenderableType], optional): Optional callable to get renderable. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: Optional[RenderableType] = None,\n        *,\n        console: Optional[Console] = None,\n        screen: bool = False,\n        auto_refresh: bool = True,\n        refresh_per_second: float = 4,\n        transient: bool = False,\n        redirect_stdout: bool = True,\n        redirect_stderr: bool = True,\n        vertical_overflow: VerticalOverflowMethod = \"ellipsis\",\n        get_renderable: Optional[Callable[[], RenderableType]] = None,\n    ) -> None:\n        assert refresh_per_second > 0, \"refresh_per_second must be > 0\"\n        self._renderable = renderable\n        self.console = console if console is not None else get_console()\n        self._screen = screen\n        self._alt_screen = False\n\n        self._redirect_stdout = redirect_stdout\n        self._redirect_stderr = redirect_stderr\n        self._restore_stdout: Optional[IO[str]] = None\n        self._restore_stderr: Optional[IO[str]] = None\n\n        self._lock = RLock()\n        self.ipy_widget: Optional[Any] = None\n        self.auto_refresh = auto_refresh\n        self._started: bool = False\n        self.transient = True if screen else transient\n\n        self._refresh_thread: Optional[_RefreshThread] = None\n        self.refresh_per_second = refresh_per_second\n\n        self.vertical_overflow = vertical_overflow\n        self._get_renderable = get_renderable\n        self._live_render = LiveRender(\n            self.get_renderable(), vertical_overflow=vertical_overflow\n        )\n        self._nested = False\n\n    @property\n    def is_started(self) -> bool:\n        \"\"\"Check if live display has been started.\"\"\"\n        return self._started\n\n    def get_renderable(self) -> RenderableType:\n        renderable = (\n            self._get_renderable()\n            if self._get_renderable is not None\n            else self._renderable\n        )\n        return renderable or \"\"\n\n    def start(self, refresh: bool = False) -> None:\n        \"\"\"Start live rendering display.\n\n        Args:\n            refresh (bool, optional): Also refresh. Defaults to False.\n        \"\"\"\n        with self._lock:\n            if self._started:\n                return\n            self._started = True\n\n            if not self.console.set_live(self):\n                self._nested = True\n                return\n\n            if self._screen:\n                self._alt_screen = self.console.set_alt_screen(True)\n            self.console.show_cursor(False)\n            self._enable_redirect_io()\n            self.console.push_render_hook(self)\n            if refresh:\n                try:\n                    self.refresh()\n                except Exception:\n                    # If refresh fails, we want to stop the redirection of sys.stderr,\n                    # so the error stacktrace is properly displayed in the terminal.\n                    # (or, if the code that calls Rich captures the exception and wants to display something,\n                    # let this be displayed in the terminal).\n                    self.stop()\n                    raise\n            if self.auto_refresh:\n                self._refresh_thread = _RefreshThread(self, self.refresh_per_second)\n                self._refresh_thread.start()\n\n    def stop(self) -> None:\n        \"\"\"Stop live rendering display.\"\"\"\n        with self._lock:\n            if not self._started:\n                return\n            self._started = False\n            self.console.clear_live()\n            if self._nested:\n                if not self.transient:\n                    self.console.print(self.renderable)\n                return\n\n            if self.auto_refresh and self._refresh_thread is not None:\n                self._refresh_thread.stop()\n                self._refresh_thread = None\n            # allow it to fully render on the last even if overflow\n            self.vertical_overflow = \"visible\"\n            with self.console:\n                try:\n                    if not self._alt_screen and not self.console.is_jupyter:\n                        self.refresh()\n                finally:\n                    self._disable_redirect_io()\n                    self.console.pop_render_hook()\n                    if not self._alt_screen and self.console.is_terminal:\n                        self.console.line()\n                    self.console.show_cursor(True)\n                    if self._alt_screen:\n                        self.console.set_alt_screen(False)\n                    if self.transient and not self._alt_screen:\n                        self.console.control(self._live_render.restore_cursor())\n                    if self.ipy_widget is not None and self.transient:\n                        self.ipy_widget.close()  # pragma: no cover\n\n    def __enter__(self) -> \"Live\":\n        self.start(refresh=self._renderable is not None)\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[Type[BaseException]],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        self.stop()\n\n    def _enable_redirect_io(self) -> None:\n        \"\"\"Enable redirecting of stdout / stderr.\"\"\"\n        if self.console.is_terminal or self.console.is_jupyter:\n            if self._redirect_stdout and not isinstance(sys.stdout, FileProxy):\n                self._restore_stdout = sys.stdout\n                sys.stdout = cast(\"TextIO\", FileProxy(self.console, sys.stdout))\n            if self._redirect_stderr and not isinstance(sys.stderr, FileProxy):\n                self._restore_stderr = sys.stderr\n                sys.stderr = cast(\"TextIO\", FileProxy(self.console, sys.stderr))\n\n    def _disable_redirect_io(self) -> None:\n        \"\"\"Disable redirecting of stdout / stderr.\"\"\"\n        if self._restore_stdout:\n            sys.stdout = cast(\"TextIO\", self._restore_stdout)\n            self._restore_stdout = None\n        if self._restore_stderr:\n            sys.stderr = cast(\"TextIO\", self._restore_stderr)\n            self._restore_stderr = None\n\n    @property\n    def renderable(self) -> RenderableType:\n        \"\"\"Get the renderable that is being displayed\n\n        Returns:\n            RenderableType: Displayed renderable.\n        \"\"\"\n        live_stack = self.console._live_stack\n        if live_stack and self is live_stack[0]:\n            renderable = Group(*[live.get_renderable() for live in live_stack])\n        else:\n            renderable = self.get_renderable()\n        return Screen(renderable) if self._alt_screen else renderable\n\n    def update(self, renderable: RenderableType, *, refresh: bool = False) -> None:\n        \"\"\"Update the renderable that is being displayed\n\n        Args:\n            renderable (RenderableType): New renderable to use.\n            refresh (bool, optional): Refresh the display. Defaults to False.\n        \"\"\"\n        if isinstance(renderable, str):\n            renderable = self.console.render_str(renderable)\n        with self._lock:\n            self._renderable = renderable\n            if refresh:\n                self.refresh()\n\n    def refresh(self) -> None:\n        \"\"\"Update the display of the Live Render.\"\"\"\n        with self._lock:\n            self._live_render.set_renderable(self.renderable)\n            if self._nested:\n                if self.console._live_stack:\n                    self.console._live_stack[0].refresh()\n                return\n\n            if self.console.is_jupyter:  # pragma: no cover\n                try:\n                    from IPython.display import display\n                    from ipywidgets import Output\n                except ImportError:\n                    import warnings\n\n                    warnings.warn('install \"ipywidgets\" for Jupyter support')\n                else:\n                    if self.ipy_widget is None:\n                        self.ipy_widget = Output()\n                        display(self.ipy_widget)\n\n                    with self.ipy_widget:\n                        self.ipy_widget.clear_output(wait=True)\n                        self.console.print(self._live_render.renderable)\n            elif self.console.is_terminal and not self.console.is_dumb_terminal:\n                with self.console:\n                    self.console.print(Control())\n            elif (\n                not self._started and not self.transient\n            ):  # if it is finished allow files or dumb-terminals to see final result\n                with self.console:\n                    self.console.print(Control())\n\n    def process_renderables(\n        self, renderables: List[ConsoleRenderable]\n    ) -> List[ConsoleRenderable]:\n        \"\"\"Process renderables to restore cursor and display progress.\"\"\"\n        self._live_render.vertical_overflow = self.vertical_overflow\n        if self.console.is_interactive:\n            # lock needs acquiring as user can modify live_render renderable at any time unlike in Progress.\n            with self._lock:\n                reset = (\n                    Control.home()\n                    if self._alt_screen\n                    else self._live_render.position_cursor()\n                )\n                renderables = [reset, *renderables, self._live_render]\n        elif (\n            not self._started and not self.transient\n        ):  # if it is finished render the final output for files or dumb_terminals\n            renderables = [*renderables, self._live_render]\n\n        return renderables\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    import random\n    import time\n    from itertools import cycle\n    from typing import Dict, List, Tuple\n\n    from .align import Align\n    from .console import Console\n    from .live import Live as Live\n    from .panel import Panel\n    from .rule import Rule\n    from .syntax import Syntax\n    from .table import Table\n\n    console = Console()\n\n    syntax = Syntax(\n        '''def loop_last(values: Iterable[T]) -> Iterable[Tuple[bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    for value in iter_values:\n        yield False, previous_value\n        previous_value = value\n    yield True, previous_value''',\n        \"python\",\n        line_numbers=True,\n    )\n\n    table = Table(\"foo\", \"bar\", \"baz\")\n    table.add_row(\"1\", \"2\", \"3\")\n\n    progress_renderables = [\n        \"You can make the terminal shorter and taller to see the live table hide\"\n        \"Text may be printed while the progress bars are rendering.\",\n        Panel(\"In fact, [i]any[/i] renderable will work\"),\n        \"Such as [magenta]tables[/]...\",\n        table,\n        \"Pretty printed structures...\",\n        {\"type\": \"example\", \"text\": \"Pretty printed\"},\n        \"Syntax...\",\n        syntax,\n        Rule(\"Give it a try!\"),\n    ]\n\n    examples = cycle(progress_renderables)\n\n    exchanges = [\n        \"SGD\",\n        \"MYR\",\n        \"EUR\",\n        \"USD\",\n        \"AUD\",\n        \"JPY\",\n        \"CNH\",\n        \"HKD\",\n        \"CAD\",\n        \"INR\",\n        \"DKK\",\n        \"GBP\",\n        \"RUB\",\n        \"NZD\",\n        \"MXN\",\n        \"IDR\",\n        \"TWD\",\n        \"THB\",\n        \"VND\",\n    ]\n    with Live(console=console) as live_table:\n        exchange_rate_dict: Dict[Tuple[str, str], float] = {}\n\n        for index in range(100):\n            select_exchange = exchanges[index % len(exchanges)]\n\n            for exchange in exchanges:\n                if exchange == select_exchange:\n                    continue\n                time.sleep(0.4)\n                if random.randint(0, 10) < 1:\n                    console.log(next(examples))\n                exchange_rate_dict[(select_exchange, exchange)] = 200 / (\n                    (random.random() * 320) + 1\n                )\n                if len(exchange_rate_dict) > len(exchanges) - 1:\n                    exchange_rate_dict.pop(list(exchange_rate_dict.keys())[0])\n                table = Table(title=\"Exchange Rates\")\n\n                table.add_column(\"Source Currency\")\n                table.add_column(\"Destination Currency\")\n                table.add_column(\"Exchange Rate\")\n\n                for (source, dest), exchange_rate in exchange_rate_dict.items():\n                    table.add_row(\n                        source,\n                        dest,\n                        Text(\n                            f\"{exchange_rate:.4f}\",\n                            style=\"red\" if exchange_rate < 1.0 else \"green\",\n                        ),\n                    )\n\n                live_table.update(Align.center(table))\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "c10456f26f34",
      "repo": "rich",
      "commit_hash": "82afcb4",
      "commit_message": "test fixes",
      "file_path": "tests/test_console.py",
      "language": "python",
      "code_before": "import datetime\nimport io\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom typing import Optional, Tuple, Type, Union\nfrom unittest import mock\n\nimport pytest\n\nfrom rich import errors\nfrom rich._null_file import NullFile\nfrom rich.color import ColorSystem\nfrom rich.console import (\n    CaptureError,\n    Console,\n    ConsoleDimensions,\n    ConsoleOptions,\n    ScreenUpdate,\n    group,\n)\nfrom rich.control import Control\nfrom rich.measure import measure_renderables\nfrom rich.padding import Padding\nfrom rich.pager import SystemPager\nfrom rich.panel import Panel\nfrom rich.region import Region\nfrom rich.segment import Segment\nfrom rich.status import Status\nfrom rich.style import Style\nfrom rich.text import Text\n\nos.get_terminal_size\n\n\ndef test_dumb_terminal() -> None:\n    console = Console(force_terminal=True, _environ={})\n    assert console.color_system is not None\n\n    console = Console(force_terminal=True, _environ={\"TERM\": \"dumb\"})\n    assert console.color_system is None\n    width, height = console.size\n    assert width == 80\n    assert height == 25\n\n\ndef test_soft_wrap() -> None:\n    console = Console(file=io.StringIO(), width=20, soft_wrap=True)\n    console.print(\"foo \" * 10)\n    assert console.file.getvalue() == \"foo \" * 20\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_16color_terminal() -> None:\n    console = Console(\n        force_terminal=True, _environ={\"TERM\": \"xterm-16color\"}, legacy_windows=False\n    )\n    assert console.color_system == \"standard\"\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_truecolor_terminal() -> None:\n    console = Console(\n        force_terminal=True,\n        legacy_windows=False,\n        _environ={\"COLORTERM\": \"truecolor\", \"TERM\": \"xterm-16color\"},\n    )\n    assert console.color_system == \"truecolor\"\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_kitty_terminal() -> None:\n    console = Console(\n        force_terminal=True,\n        legacy_windows=False,\n        _environ={\"TERM\": \"xterm-kitty\"},\n    )\n    assert console.color_system == \"256\"\n\n\ndef test_console_options_update() -> None:\n    options = ConsoleOptions(\n        ConsoleDimensions(80, 25),\n        max_height=25,\n        legacy_windows=False,\n        min_width=10,\n        max_width=20,\n        is_terminal=False,\n        encoding=\"utf-8\",\n    )\n    options1 = options.update(width=15)\n    assert options1.min_width == 15 and options1.max_width == 15\n\n    options2 = options.update(min_width=5, max_width=15, justify=\"right\")\n    assert (\n        options2.min_width == 5\n        and options2.max_width == 15\n        and options2.justify == \"right\"\n    )\n\n    options_copy = options.update()\n    assert options_copy == options and options_copy is not options\n\n\ndef test_console_options_update_height() -> None:\n    options = ConsoleOptions(\n        ConsoleDimensions(80, 25),\n        max_height=25,\n        legacy_windows=False,\n        min_width=10,\n        max_width=20,\n        is_terminal=False,\n        encoding=\"utf-8\",\n    )\n    assert options.height is None\n    render_options = options.update_height(12)\n    assert options.height is None\n    assert render_options.height == 12\n    assert render_options.max_height == 12\n\n\ndef test_init() -> None:\n    console = Console(color_system=None)\n    assert console._color_system == None\n    console = Console(color_system=\"standard\")\n    assert console._color_system == ColorSystem.STANDARD\n    console = Console(color_system=\"auto\")\n\n\ndef test_size() -> None:\n    console = Console()\n    w, h = console.size\n    assert console.width == w\n\n    console = Console(width=99, height=101, legacy_windows=False)\n    w, h = console.size\n    assert w == 99 and h == 101\n\n\n@pytest.mark.parametrize(\n    \"is_windows,no_descriptor_size,stdin_size,stdout_size,stderr_size,expected_size\",\n    [\n        # on Windows we'll use `os.get_terminal_size()` without arguments...\n        (True, (133, 24), ValueError, ValueError, ValueError, (80, 25)),\n        (False, (133, 24), ValueError, ValueError, ValueError, (80, 25)),\n        # ...while on other OS we'll try to pass stdin, then stdout, then stderr to it:\n        (False, ValueError, (133, 24), ValueError, ValueError, (133, 24)),\n        (False, ValueError, ValueError, (133, 24), ValueError, (133, 24)),\n        (False, ValueError, ValueError, ValueError, (133, 24), (133, 24)),\n        (False, ValueError, ValueError, ValueError, ValueError, (80, 25)),\n    ],\n)\n@mock.patch(\"rich.console.os.get_terminal_size\")\ndef test_size_can_fall_back_to_std_descriptors(\n    get_terminal_size_mock: mock.MagicMock,\n    is_windows: bool,\n    no_descriptor_size: Union[Tuple[int, int], Type[ValueError]],\n    stdin_size: Union[Tuple[int, int], Type[ValueError]],\n    stdout_size: Union[Tuple[int, int], Type[ValueError]],\n    stderr_size: Union[Tuple[int, int], Type[ValueError]],\n    expected_size: Tuple[int, int],\n) -> None:\n    def get_terminal_size_mock_impl(fileno: int = None) -> Tuple[int, int]:\n        value = {\n            None: no_descriptor_size,\n            sys.__stdin__.fileno(): stdin_size,\n            sys.__stdout__.fileno(): stdout_size,\n            sys.__stderr__.fileno(): stderr_size,\n        }[fileno]\n        if value is ValueError:\n            raise value\n        return value\n\n    get_terminal_size_mock.side_effect = get_terminal_size_mock_impl\n\n    console = Console(legacy_windows=False)\n    with mock.patch(\"rich.console.WINDOWS\", new=is_windows):\n        w, h = console.size\n    assert (w, h) == expected_size\n\n\ndef test_repr() -> None:\n    console = Console()\n    assert isinstance(repr(console), str)\n    assert isinstance(str(console), str)\n\n\ndef test_print() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"foo\")\n    assert console.file.getvalue() == \"foo\\n\"\n\n\ndef test_print_multiple() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"foo\", \"bar\")\n    assert console.file.getvalue() == \"foo bar\\n\"\n\n\ndef test_print_text() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(Text(\"foo\", style=\"bold\"))\n    assert console.file.getvalue() == \"\\x1b[1mfoo\\x1b[0m\\n\"\n\n\ndef test_print_text_multiple() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(Text(\"foo\", style=\"bold\"), Text(\"bar\"), \"baz\")\n    assert console.file.getvalue() == \"\\x1b[1mfoo\\x1b[0m bar baz\\n\"\n\n\ndef test_print_json() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json('[false, true, null, \"foo\"]', indent=4)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m[\\x1b[0m\\n    \\x1b[3;91mfalse\\x1b[0m,\\n    \\x1b[3;92mtrue\\x1b[0m,\\n    \\x1b[3;35mnull\\x1b[0m,\\n    \\x1b[32m\"foo\"\\x1b[0m\\n\\x1b[1m]\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_error() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    with pytest.raises(TypeError):\n        console.print_json([\"foo\"], indent=4)\n\n\ndef test_print_json_data() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json(data=[False, True, None, \"foo\"], indent=4)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m[\\x1b[0m\\n    \\x1b[3;91mfalse\\x1b[0m,\\n    \\x1b[3;92mtrue\\x1b[0m,\\n    \\x1b[3;35mnull\\x1b[0m,\\n    \\x1b[32m\"foo\"\\x1b[0m\\n\\x1b[1m]\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_ensure_ascii() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json(data={\"foo\": \"\ud83d\udca9\"}, ensure_ascii=False)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m{\\x1b[0m\\n  \\x1b[1;34m\"foo\"\\x1b[0m: \\x1b[32m\"\ud83d\udca9\"\\x1b[0m\\n\\x1b[1m}\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_with_default_ensure_ascii() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json(data={\"foo\": \"\ud83d\udca9\"})\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m{\\x1b[0m\\n  \\x1b[1;34m\"foo\"\\x1b[0m: \\x1b[32m\"\ud83d\udca9\"\\x1b[0m\\n\\x1b[1m}\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_indent_none() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    data = {\"name\": \"apple\", \"count\": 1}\n    console.print_json(data=data, indent=None)\n    result = console.file.getvalue()\n    expected = '\\x1b[1m{\\x1b[0m\\x1b[1;34m\"name\"\\x1b[0m: \\x1b[32m\"apple\"\\x1b[0m, \\x1b[1;34m\"count\"\\x1b[0m: \\x1b[1;36m1\\x1b[0m\\x1b[1m}\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_console_null_file(monkeypatch) -> None:\n    # When stdout and stderr are null, Console.file should be replaced with NullFile\n    monkeypatch.setattr(\"sys.stdout\", None)\n    monkeypatch.setattr(\"sys.stderr\", None)\n\n    console = Console()\n    assert isinstance(console.file, NullFile)\n\n\ndef test_log() -> None:\n    console = Console(\n        file=io.StringIO(),\n        width=80,\n        color_system=\"truecolor\",\n        log_time_format=\"TIME\",\n        log_path=False,\n        _environ={},\n    )\n    console.log(\"foo\", style=\"red\")\n    expected = \"\\x1b[2;36mTIME\\x1b[0m\\x1b[2;36m \\x1b[0m\\x1b[31mfoo                                                                        \\x1b[0m\\n\"\n    result = console.file.getvalue()\n    print(repr(result))\n    assert result == expected\n\n\ndef test_log_milliseconds() -> None:\n    def time_formatter(timestamp: datetime) -> Text:\n        return Text(\"TIME\")\n\n    console = Console(\n        file=io.StringIO(), width=40, log_time_format=time_formatter, log_path=False\n    )\n    console.log(\"foo\")\n    result = console.file.getvalue()\n    assert result == \"TIME foo                                \\n\"\n\n\ndef test_print_empty() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print()\n    assert console.file.getvalue() == \"\\n\"\n\n\ndef test_markup_highlight() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"'[bold]foo[/bold]'\")\n    assert (\n        console.file.getvalue()\n        == \"\\x1b[32m'\\x1b[0m\\x1b[1;32mfoo\\x1b[0m\\x1b[32m'\\x1b[0m\\n\"\n    )\n\n\ndef test_print_style() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"foo\", style=\"bold\")\n    assert console.file.getvalue() == \"\\x1b[1mfoo\\x1b[0m\\n\"\n\n\ndef test_show_cursor() -> None:\n    console = Console(\n        file=io.StringIO(), force_terminal=True, legacy_windows=False, _environ={}\n    )\n    console.show_cursor(False)\n    console.print(\"foo\")\n    console.show_cursor(True)\n    assert console.file.getvalue() == \"\\x1b[?25lfoo\\n\\x1b[?25h\"\n\n\ndef test_clear() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, _environ={})\n    console.clear()\n    console.clear(home=False)\n    assert console.file.getvalue() == \"\\033[2J\\033[H\" + \"\\033[2J\"\n\n\ndef test_clear_no_terminal() -> None:\n    console = Console(file=io.StringIO())\n    console.clear()\n    console.clear(home=False)\n    assert console.file.getvalue() == \"\"\n\n\ndef test_get_style() -> None:\n    console = Console()\n    console.get_style(\"repr.brace\") == Style(bold=True)\n\n\ndef test_get_style_default() -> None:\n    console = Console()\n    console.get_style(\"foobar\", default=\"red\") == Style(color=\"red\")\n\n\ndef test_get_style_error() -> None:\n    console = Console()\n    with pytest.raises(errors.MissingStyle):\n        console.get_style(\"nosuchstyle\")\n    with pytest.raises(errors.MissingStyle):\n        console.get_style(\"foo bar\")\n\n\ndef test_render_error() -> None:\n    console = Console()\n    with pytest.raises(errors.NotRenderableError):\n        list(console.render([], console.options))\n\n\ndef test_control() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, _environ={})\n    console.control(Control.clear())\n    console.print(\"BAR\")\n    assert console.file.getvalue() == \"\\x1b[2JBAR\\n\"\n\n\ndef test_capture() -> None:\n    console = Console()\n    with console.capture() as capture:\n        with pytest.raises(CaptureError):\n            capture.get()\n        console.print(\"Hello\")\n    assert capture.get() == \"Hello\\n\"\n\n\ndef test_input(monkeypatch, capsys) -> None:\n    def fake_input(prompt=\"\"):\n        console.file.write(prompt)\n        return \"bar\"\n\n    monkeypatch.setattr(\"builtins.input\", fake_input)\n    console = Console()\n    user_input = console.input(prompt=\"foo:\")\n    assert capsys.readouterr().out == \"foo:\"\n    assert user_input == \"bar\"\n\n\ndef test_input_password(monkeypatch, capsys) -> None:\n    def fake_input(prompt, stream=None):\n        console.file.write(prompt)\n        return \"bar\"\n\n    import rich.console\n\n    monkeypatch.setattr(rich.console, \"getpass\", fake_input)\n    console = Console()\n    user_input = console.input(prompt=\"foo:\", password=True)\n    assert capsys.readouterr().out == \"foo:\"\n    assert user_input == \"bar\"\n\n\ndef test_status() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20)\n    status = console.status(\"foo\")\n    assert isinstance(status, Status)\n\n\ndef test_justify_none() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20)\n    console.print(\"FOO\", justify=None)\n    assert console.file.getvalue() == \"FOO\\n\"\n\n\ndef test_justify_left() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20, _environ={})\n    console.print(\"FOO\", justify=\"left\")\n    assert console.file.getvalue() == \"FOO                 \\n\"\n\n\ndef test_justify_center() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20, _environ={})\n    console.print(\"FOO\", justify=\"center\")\n    assert console.file.getvalue() == \"        FOO         \\n\"\n\n\ndef test_justify_right() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20, _environ={})\n    console.print(\"FOO\", justify=\"right\")\n    assert console.file.getvalue() == \"                 FOO\\n\"\n\n\ndef test_justify_renderable_none() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=20,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=None)\n    assert console.file.getvalue() == \"\u256d\u2500\u2500\u2500\u256e\\n\u2502FOO\u2502\\n\u2570\u2500\u2500\u2500\u256f\\n\"\n\n\ndef test_justify_renderable_left() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=10,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=\"left\")\n    assert console.file.getvalue() == \"\u256d\u2500\u2500\u2500\u256e     \\n\u2502FOO\u2502     \\n\u2570\u2500\u2500\u2500\u256f     \\n\"\n\n\ndef test_justify_renderable_center() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=10,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=\"center\")\n    assert console.file.getvalue() == \"  \u256d\u2500\u2500\u2500\u256e   \\n  \u2502FOO\u2502   \\n  \u2570\u2500\u2500\u2500\u256f   \\n\"\n\n\ndef test_justify_renderable_right() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=20,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=\"right\")\n    assert (\n        console.file.getvalue()\n        == \"               \u256d\u2500\u2500\u2500\u256e\\n               \u2502FOO\u2502\\n               \u2570\u2500\u2500\u2500\u256f\\n\"\n    )\n\n\nclass BrokenRenderable:\n    def __rich_console__(self, console, options):\n        pass\n\n\ndef test_render_broken_renderable() -> None:\n    console = Console()\n    broken = BrokenRenderable()\n    with pytest.raises(errors.NotRenderableError):\n        list(console.render(broken, console.options))\n\n\ndef test_export_text() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"[b]foo\")\n    text = console.export_text()\n    expected = \"foo\\n\"\n    assert text == expected\n\n\ndef test_export_html() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"[b]foo <script> 'test' [link=https://example.org]Click[/link]\")\n    html = console.export_html()\n    print(repr(html))\n    expected = '<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n<style>\\n.r1 {font-weight: bold}\\n.r2 {color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold}\\n.r3 {color: #008000; text-decoration-color: #008000; font-weight: bold}\\nbody {\\n    color: #000000;\\n    background-color: #ffffff;\\n}\\n</style>\\n</head>\\n<body>\\n    <pre style=\"font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">foo &lt;</span><span class=\"r2\">script</span><span class=\"r1\">&gt; </span><span class=\"r3\">&#x27;test&#x27;</span><span class=\"r1\"> </span><a class=\"r1\" href=\"https://example.org\">Click</a>\\n</code></pre>\\n</body>\\n</html>\\n'\n    assert html == expected\n\n\ndef test_export_html_inline() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"[b]foo [link=https://example.org]Click[/link]\")\n    html = console.export_html(inline_styles=True)\n    print(repr(html))\n    expected = '<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n<style>\\n\\nbody {\\n    color: #000000;\\n    background-color: #ffffff;\\n}\\n</style>\\n</head>\\n<body>\\n    <pre style=\"font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><code style=\"font-family:inherit\"><span style=\"font-weight: bold\">foo </span><span style=\"font-weight: bold\"><a href=\"https://example.org\">Click</a></span>\\n</code></pre>\\n</body>\\n</html>\\n'\n    assert html == expected\n\n\nEXPECTED_SVG = '<svg class=\"rich-terminal\" viewBox=\"0 0 1238 74.4\" xmlns=\"http://www.w3.org/2000/svg\">\\n    <!-- Generated with Rich https://www.textualize.io -->\\n    <style>\\n\\n    @font-face {\\n        font-family: \"Fira Code\";\\n        src: local(\"FiraCode-Regular\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Regular.woff2\") format(\"woff2\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Regular.woff\") format(\"woff\");\\n        font-style: normal;\\n        font-weight: 400;\\n    }\\n    @font-face {\\n        font-family: \"Fira Code\";\\n        src: local(\"FiraCode-Bold\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Bold.woff2\") format(\"woff2\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Bold.woff\") format(\"woff\");\\n        font-style: bold;\\n        font-weight: 700;\\n    }\\n\\n    .terminal-3526644552-matrix {\\n        font-family: Fira Code, monospace;\\n        font-size: 20px;\\n        line-height: 24.4px;\\n        font-variant-east-asian: full-width;\\n    }\\n\\n    .terminal-3526644552-title {\\n        font-size: 18px;\\n        font-weight: bold;\\n        font-family: arial;\\n    }\\n\\n    .terminal-3526644552-r1 { fill: #608ab1;font-weight: bold }\\n.terminal-3526644552-r2 { fill: #c5c8c6 }\\n    </style>\\n\\n    <defs>\\n    <clipPath id=\"terminal-3526644552-clip-terminal\">\\n      <rect x=\"0\" y=\"0\" width=\"1219.0\" height=\"23.4\" />\\n    </clipPath>\\n    \\n    </defs>\\n\\n    <rect fill=\"#292929\" stroke=\"rgba(255,255,255,0.35)\" stroke-width=\"1\" x=\"1\" y=\"1\" width=\"1236\" height=\"72.4\" rx=\"8\"/><text class=\"terminal-3526644552-title\" fill=\"#c5c8c6\" text-anchor=\"middle\" x=\"618\" y=\"27\">Rich</text>\\n            <g transform=\"translate(26,22)\">\\n            <circle cx=\"0\" cy=\"0\" r=\"7\" fill=\"#ff5f57\"/>\\n            <circle cx=\"22\" cy=\"0\" r=\"7\" fill=\"#febc2e\"/>\\n            <circle cx=\"44\" cy=\"0\" r=\"7\" fill=\"#28c840\"/>\\n            </g>\\n        \\n    <g transform=\"translate(9, 41)\" clip-path=\"url(#terminal-3526644552-clip-terminal)\">\\n    <rect fill=\"#cc555a\" x=\"0\" y=\"1.5\" width=\"36.6\" height=\"24.65\" shape-rendering=\"crispEdges\"/>\\n    <g class=\"terminal-3526644552-matrix\">\\n    <text class=\"terminal-3526644552-r1\" x=\"0\" y=\"20\" textLength=\"36.6\" clip-path=\"url(#terminal-3526644552-line-0)\">foo</text><text class=\"terminal-3526644552-r2\" x=\"48.8\" y=\"20\" textLength=\"61\" clip-path=\"url(#terminal-3526644552-line-0)\">Click</text><text class=\"terminal-3526644552-r2\" x=\"1220\" y=\"20\" textLength=\"12.2\" clip-path=\"url(#terminal-3526644552-line-0)\">\\n</text>\\n    </g>\\n    </g>\\n</svg>\\n'\n\n\ndef test_export_svg() -> None:\n    console = Console(record=True, width=100)\n    console.print(\n        \"[b red on blue reverse]foo[/] [blink][link=https://example.org]Click[/link]\"\n    )\n    svg = console.export_svg()\n    print(repr(svg))\n\n    assert svg == EXPECTED_SVG\n\n\ndef test_export_svg_specified_unique_id() -> None:\n    expected_svg = EXPECTED_SVG.replace(\"terminal-3526644552\", \"given-id\")\n    console = Console(record=True, width=100)\n    console.print(\n        \"[b red on blue reverse]foo[/] [blink][link=https://example.org]Click[/link]\"\n    )\n    svg = console.export_svg(unique_id=\"given-id\")\n    print(repr(svg))\n\n    assert svg == expected_svg\n\n\ndef test_save_svg() -> None:\n    console = Console(record=True, width=100)\n    console.print(\n        \"[b red on blue reverse]foo[/] [blink][link=https://example.org]Click[/link]\"\n    )\n    with tempfile.TemporaryDirectory() as path:\n        export_path = os.path.join(path, \"example.svg\")\n        console.save_svg(export_path)\n        with open(export_path, \"rt\", encoding=\"utf-8\") as svg_file:\n            assert svg_file.read() == EXPECTED_SVG\n\n\ndef test_save_text() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"foo\")\n    with tempfile.TemporaryDirectory() as path:\n        export_path = os.path.join(path, \"rich.txt\")\n        console.save_text(export_path)\n        with open(export_path, \"rt\") as text_file:\n            assert text_file.read() == \"foo\\n\"\n\n\ndef test_save_html() -> None:\n    expected = '<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n<style>\\n\\nbody {\\n    color: #000000;\\n    background-color: #ffffff;\\n}\\n</style>\\n</head>\\n<body>\\n    <pre style=\"font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><code style=\"font-family:inherit\">foo\\n</code></pre>\\n</body>\\n</html>\\n'\n    console = Console(record=True, width=100)\n    console.print(\"foo\")\n    with tempfile.TemporaryDirectory() as path:\n        export_path = os.path.join(path, \"example.html\")\n        console.save_html(export_path)\n        with open(export_path, \"rt\") as html_file:\n            html = html_file.read()\n            print(repr(html))\n            assert html == expected\n\n\ndef test_no_wrap() -> None:\n    console = Console(width=10, file=io.StringIO())\n    console.print(\"foo bar baz egg\", no_wrap=True)\n    assert console.file.getvalue() == \"foo bar ba\\n\"\n\n\ndef test_soft_wrap() -> None:\n    console = Console(width=10, file=io.StringIO())\n    console.print(\"foo bar baz egg\", soft_wrap=True)\n    assert console.file.getvalue() == \"foo bar baz egg\\n\"\n\n\ndef test_unicode_error() -> None:\n    try:\n        with tempfile.TemporaryFile(\"wt\", encoding=\"ascii\") as tmpfile:\n            console = Console(file=tmpfile)\n            console.print(\":vampire:\")\n    except UnicodeEncodeError as error:\n        assert \"PYTHONIOENCODING\" in str(error)\n    else:\n        assert False, \"didn't raise UnicodeEncodeError\"\n\n\ndef test_bell() -> None:\n    console = Console(force_terminal=True, _environ={})\n    console.begin_capture()\n    console.bell()\n    assert console.end_capture() == \"\\x07\"\n\n\ndef test_pager() -> None:\n    console = Console(_environ={})\n\n    pager_content: Optional[str] = None\n\n    def mock_pager(content: str) -> None:\n        nonlocal pager_content\n        pager_content = content\n\n    pager = SystemPager()\n    pager._pager = mock_pager\n\n    with console.pager(pager):\n        console.print(\"[bold]Hello World\")\n    assert pager_content == \"Hello World\\n\"\n\n    with console.pager(pager, styles=True, links=False):\n        console.print(\"[bold link https:/example.org]Hello World\")\n\n    assert pager_content == \"Hello World\\n\"\n\n\ndef test_out() -> None:\n    console = Console(width=10)\n    console.begin_capture()\n    console.out(*([\"foo bar\"] * 5), sep=\".\", end=\"X\")\n    assert console.end_capture() == \"foo bar.foo bar.foo bar.foo bar.foo barX\"\n\n\ndef test_render_group() -> None:\n    @group(fit=False)\n    def renderable():\n        yield \"one\"\n        yield \"two\"\n        yield \"three\"  # <- largest width of 5\n        yield \"four\"\n\n    renderables = [renderable() for _ in range(4)]\n    console = Console(width=42)\n    min_width, _ = measure_renderables(console, console.options, renderables)\n    assert min_width == 42\n\n\ndef test_render_group_fit() -> None:\n    @group()\n    def renderable():\n        yield \"one\"\n        yield \"two\"\n        yield \"three\"  # <- largest width of 5\n        yield \"four\"\n\n    renderables = [renderable() for _ in range(4)]\n\n    console = Console(width=42)\n\n    min_width, _ = measure_renderables(console, console.options, renderables)\n    assert min_width == 5\n\n\ndef test_get_time() -> None:\n    console = Console(\n        get_time=lambda: 99, get_datetime=lambda: datetime.datetime(1974, 7, 5)\n    )\n    assert console.get_time() == 99\n    assert console.get_datetime() == datetime.datetime(1974, 7, 5)\n\n\ndef test_console_style() -> None:\n    console = Console(\n        file=io.StringIO(), color_system=\"truecolor\", force_terminal=True, style=\"red\"\n    )\n    console.print(\"foo\")\n    expected = \"\\x1b[31mfoo\\x1b[0m\\n\"\n    result = console.file.getvalue()\n    assert result == expected\n\n\ndef test_no_color() -> None:\n    console = Console(\n        file=io.StringIO(), color_system=\"truecolor\", force_terminal=True, no_color=True\n    )\n    console.print(\"[bold magenta on red]FOO\")\n    expected = \"\\x1b[1mFOO\\x1b[0m\\n\"\n    result = console.file.getvalue()\n    print(repr(result))\n    assert result == expected\n\n\ndef test_quiet() -> None:\n    console = Console(file=io.StringIO(), quiet=True)\n    console.print(\"Hello, World!\")\n    assert console.file.getvalue() == \"\"\n\n\ndef test_no_nested_live() -> None:\n    console = Console()\n    with pytest.raises(errors.LiveError):\n        with console.status(\"foo\"):\n            with console.status(\"bar\"):\n                pass\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_screen() -> None:\n    console = Console(\n        color_system=None, force_terminal=True, force_interactive=True, _environ={}\n    )\n    with console.capture() as capture:\n        with console.screen():\n            console.print(\"Don't panic\")\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25lDon't panic\\n\\x1b[?1049l\\x1b[?25h\"\n    result = capture.get()\n    print(repr(result))\n    assert result == expected\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_screen_update() -> None:\n    console = Console(\n        width=20, height=4, color_system=\"truecolor\", force_terminal=True, _environ={}\n    )\n    with console.capture() as capture:\n        with console.screen() as screen:\n            screen.update(\"foo\", style=\"blue\")\n            screen.update(\"bar\")\n            screen.update()\n    result = capture.get()\n    print(repr(result))\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25l\\x1b[34mfoo\\x1b[0m\\x1b[34m                 \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\x1b[34mbar\\x1b[0m\\x1b[34m                 \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\x1b[34mbar\\x1b[0m\\x1b[34m                 \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\x1b[?1049l\\x1b[?25h\"\n    assert result == expected\n\n\ndef test_height() -> None:\n    console = Console(width=80, height=46)\n    assert console.height == 46\n\n\ndef test_columns_env() -> None:\n    console = Console(_environ={\"COLUMNS\": \"314\"}, legacy_windows=False)\n    assert console.width == 314\n    # width take precedence\n    console = Console(width=40, _environ={\"COLUMNS\": \"314\"}, legacy_windows=False)\n    assert console.width == 40\n    # Should not fail\n    console = Console(width=40, _environ={\"COLUMNS\": \"broken\"}, legacy_windows=False)\n\n\ndef test_lines_env() -> None:\n    console = Console(_environ={\"LINES\": \"220\"})\n    assert console.height == 220\n    # height take precedence\n    console = Console(height=40, _environ={\"LINES\": \"220\"})\n    assert console.height == 40\n    # Should not fail\n    console = Console(width=40, _environ={\"LINES\": \"broken\"})\n\n\ndef test_screen_update_class() -> None:\n    screen_update = ScreenUpdate([[Segment(\"foo\")], [Segment(\"bar\")]], 5, 10)\n    assert screen_update.x == 5\n    assert screen_update.y == 10\n\n    console = Console(force_terminal=True)\n    console.begin_capture()\n    console.print(screen_update)\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"\\x1b[11;6Hfoo\\x1b[12;6Hbar\"\n    assert result == expected\n\n\ndef test_is_alt_screen() -> None:\n    console = Console(force_terminal=True)\n    if console.legacy_windows:\n        return\n    assert not console.is_alt_screen\n    with console.screen():\n        assert console.is_alt_screen\n    assert not console.is_alt_screen\n\n\ndef test_set_console_title() -> None:\n    console = Console(force_terminal=True, _environ={})\n    if console.legacy_windows:\n        return\n\n    with console.capture() as captured:\n        console.set_window_title(\"hello\")\n\n    result = captured.get()\n    assert result == \"\\x1b]0;hello\\x07\"\n\n\ndef test_update_screen() -> None:\n    console = Console(force_terminal=True, width=20, height=5, _environ={})\n    if console.legacy_windows:\n        return\n    with pytest.raises(errors.NoAltScreen):\n        console.update_screen(\"foo\")\n    console.begin_capture()\n    with console.screen():\n        console.update_screen(\"foo\")\n        console.update_screen(\"bar\", region=Region(2, 3, 8, 4))\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25l\\x1b[1;1Hfoo                 \\x1b[2;1H                    \\x1b[3;1H                    \\x1b[4;1H                    \\x1b[5;1H                    \\x1b[4;3Hbar     \\x1b[5;3H        \\x1b[6;3H        \\x1b[7;3H        \\x1b[?1049l\\x1b[?25h\"\n    assert result == expected\n\n\ndef test_update_screen_lines() -> None:\n    console = Console(force_terminal=True, width=20, height=5)\n    if console.legacy_windows:\n        return\n    with pytest.raises(errors.NoAltScreen):\n        console.update_screen_lines([])\n\n\ndef test_update_options_markup() -> None:\n    console = Console()\n    options = console.options\n    assert options.update(markup=False).markup == False\n    assert options.update(markup=True).markup == True\n\n\ndef test_print_width_zero() -> None:\n    console = Console()\n    with console.capture() as capture:\n        console.print(\"Hello\", width=0)\n    assert capture.get() == \"\"\n\n\ndef test_size_properties() -> None:\n    console = Console(width=80, height=25, legacy_windows=False)\n    assert console.size == ConsoleDimensions(80, 25)\n    console.size = (10, 20)\n    assert console.size == ConsoleDimensions(10, 20)\n    console.width = 5\n    assert console.size == ConsoleDimensions(5, 20)\n    console.height = 10\n    assert console.size == ConsoleDimensions(5, 10)\n\n\ndef test_print_newline_start() -> None:\n    console = Console(width=80, height=25)\n    console.begin_capture()\n    console.print(\"Foo\", new_line_start=True)\n    console.print(\"Foo\\nbar\\n\", new_line_start=True)\n    result = console.end_capture()\n\n    assert result == \"Foo\\n\\nFoo\\nbar\\n\\n\"\n\n\ndef test_is_terminal_broken_file() -> None:\n    console = Console()\n\n    def _mock_isatty():\n        raise ValueError()\n\n    console.file.isatty = _mock_isatty\n\n    assert console.is_terminal == False\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"not relevant on Windows\")\ndef test_detect_color_system() -> None:\n    console = Console(_environ={\"TERM\": \"rxvt-unicode-256color\"}, force_terminal=True)\n    assert console._detect_color_system() == ColorSystem.EIGHT_BIT\n\n\ndef test_reset_height() -> None:\n    \"\"\"Test height is reset when rendering complex renderables.\"\"\"\n\n    # https://github.com/Textualize/rich/issues/2042\n    class Panels:\n        def __rich_console__(self, console, options):\n            yield Panel(\"foo\")\n            yield Panel(\"bar\")\n\n    console = Console(\n        force_terminal=True,\n        color_system=\"truecolor\",\n        width=20,\n        height=40,\n        legacy_windows=False,\n    )\n\n    with console.capture() as capture:\n        console.print(Panel(Panels()), height=12)\n    result = capture.get()\n    print(repr(result))\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\\n\u2502 \u2502 foo          \u2502 \u2502\\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\\n\u2502 \u2502 bar          \u2502 \u2502\\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\\n\u2502                  \u2502\\n\u2502                  \u2502\\n\u2502                  \u2502\\n\u2502                  \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n\n    assert result == expected\n\n\ndef test_render_lines_height_minus_vertical_pad_is_negative() -> None:\n    # https://github.com/Textualize/textual/issues/389\n    console = Console(\n        force_terminal=True,\n        color_system=\"truecolor\",\n        width=20,\n        height=40,\n        legacy_windows=False,\n    )\n    options = console.options.update_height(1)\n\n    # Ensuring that no exception is raised...\n    console.render_lines(Padding(\"hello\", pad=(1, 0)), options=options)\n\n\ndef test_recording_no_stdout_and_no_stderr_files(monkeypatch) -> None:\n    # Rich should work even if there's no file available to write to.\n    # For example, pythonw nullifies output streams.\n    # Built-in print silently no-ops in pythonw.\n    # Related: https://github.com/Textualize/rich/issues/2400\n    monkeypatch.setattr(\"sys.stdout\", None)\n    monkeypatch.setattr(\"sys.stderr\", None)\n    console = Console(record=True)\n    console.print(\"hello world\")\n    text = console.export_text()\n    assert text == \"hello world\\n\"\n\n\ndef test_capturing_no_stdout_and_no_stderr_files(monkeypatch) -> None:\n    monkeypatch.setattr(\"sys.stdout\", None)\n    monkeypatch.setattr(\"sys.stderr\", None)\n    console = Console()\n    with console.capture() as capture:\n        console.print(\"hello world\")\n    assert capture.get() == \"hello world\\n\"\n\n\n@pytest.mark.parametrize(\"env_value\", [\"\", \"something\", \"0\"])\ndef test_force_color(env_value) -> None:\n    # Even though we use a non-tty file, the presence of FORCE_COLOR env var\n    # means is_terminal returns True.\n    console = Console(file=io.StringIO(), _environ={\"FORCE_COLOR\": env_value})\n    assert console.is_terminal\n\n\ndef test_force_color_jupyter() -> None:\n    # FORCE_COLOR above doesn't happen in a Jupyter kernel\n    console = Console(\n        file=io.StringIO(), _environ={\"FORCE_COLOR\": \"1\"}, force_jupyter=True\n    )\n    assert not console.is_terminal\n\n\ndef test_force_color() -> None:\n    console = Console(\n        file=io.StringIO(),\n        _environ={\n            \"FORCE_COLOR\": \"1\",\n            \"TERM\": \"xterm-256color\",\n            \"COLORTERM\": \"truecolor\",\n        },\n    )\n    assert console.color_system in (\"truecolor\", \"windows\")\n\n\ndef test_reenable_highlighting() -> None:\n    \"\"\"Check that when highlighting is disabled, it can be reenabled in print()\"\"\"\n    console = Console(\n        file=io.StringIO(),\n        _environ={\n            \"FORCE_COLOR\": \"1\",\n            \"TERM\": \"xterm-256color\",\n            \"COLORTERM\": \"truecolor\",\n        },\n        highlight=False,\n    )\n    console.print(\"[1, 2, 3]\")\n    console.print(\"[1, 2, 3]\", highlight=True)\n    output = console.file.getvalue()\n    lines = output.splitlines()\n    print(repr(lines))\n    # First line not highlighted\n    assert lines[0] == \"[1, 2, 3]\"\n    # Second line highlighted\n\n    assert (\n        lines[1]\n        == \"\\x1b[1m[\\x1b[0m\\x1b[1;36m1\\x1b[0m, \\x1b[1;36m2\\x1b[0m, \\x1b[1;36m3\\x1b[0m\\x1b[1m]\\x1b[0m\"\n    )\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_brokenpipeerror() -> None:\n    \"\"\"Test BrokenPipe works as expected.\"\"\"\n    which_py, which_head = ([\"which\", cmd] for cmd in (\"python\", \"head\"))\n    rich_cmd = \"python -m rich\".split()\n    for cmd in [which_py, which_head, rich_cmd]:\n        check = subprocess.run(cmd).returncode\n        if check != 0:\n            return  # Only test on suitable Unix platforms\n    head_cmd = \"head -1\".split()\n    proc1 = subprocess.Popen(rich_cmd, stdout=subprocess.PIPE)\n    proc2 = subprocess.Popen(head_cmd, stdin=proc1.stdout, stdout=subprocess.PIPE)\n    proc1.stdout.close()\n    output, _ = proc2.communicate()\n    proc1.wait()\n    proc2.wait()\n    assert proc1.returncode == 1\n    assert proc2.returncode == 0\n\n\ndef test_capture_and_record() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/2563\"\"\"\n\n    console = Console(record=True)\n    print(\"Before Capture started:\")\n    console.print(\"[blue underline]Print 0\")\n    with console.capture() as capture:\n        console.print(\"[blue underline]Print 1\")\n        console.print(\"[blue underline]Print 2\")\n        console.print(\"[blue underline]Print 3\")\n        console.print(\"[blue underline]Print 4\")\n\n    capture_content = capture.get()\n    print(repr(capture_content))\n    assert capture_content == \"Print 1\\nPrint 2\\nPrint 3\\nPrint 4\\n\"\n\n    recorded_content = console.export_text()\n    print(repr(recorded_content))\n    assert recorded_content == \"Print 0\\n\"\n\n\ndef test_tty_compatible() -> None:\n    \"\"\"Check TTY_COMPATIBLE environment var.\"\"\"\n\n    class FakeTTY:\n        \"\"\"An file file-like which reports it is a TTY.\"\"\"\n\n        def __init__(self) -> None:\n            self.called_isatty = False\n\n        def isatty(self) -> bool:\n            self.called_isatty = True\n            return True\n\n    class FakeFile:\n        \"\"\"A file object that reports False for isatty\"\"\"\n\n        def __init__(self) -> None:\n            self.called_isatty = False\n\n        def isatty(self) -> bool:\n            self.called_isatty = True\n            return False\n\n    # Console file is not a TTY\n    console = Console(file=FakeFile())\n    # Not a TTY, so is_terminal should be False\n    assert not console.is_terminal\n    # Should have called isatty to auto-detect tty support\n    assert console.file.called_isatty\n\n    # Not a terminal\n    console = Console(file=FakeFile(), _environ={\"TTY_COMPATIBLE\": \"1\"})\n    # env TTY_COMPATIBLE=1 should report that it is a terminal\n    assert console.is_terminal\n    # Should not have called file.isattry\n    assert not console.file.called_isatty\n\n    # File is a fake TTY\n    console = Console(file=FakeTTY())\n    # Should report True\n    assert console.is_terminal\n    # SHould have auto-detected\n    assert console.file.called_isatty\n\n    # File is a fake TTY\n    console = Console(file=FakeTTY(), _environ={\"TTY_COMPATIBLE\": \"\"})\n    # Blank TTY_COMPATIBLE should auto-detect, so is_terminal is True\n    assert console.is_terminal\n    # Should have auto-detected\n    assert console.file.called_isatty\n\n    # File is a fake TTY\n    console = Console(file=FakeTTY(), _environ={\"TTY_COMPATIBLE\": \"whatever\"})\n    # Any pother value should auto-detect\n    assert console.is_terminal\n    # Should have auto-detected\n    assert console.file.called_isatty\n\n    # TTY_COMPATIBLE should override file.isattry\n    console = Console(file=FakeTTY(), _environ={\"TTY_COMPATIBLE\": \"0\"})\n    # Should report that it is *not* a terminal\n    assert not console.is_terminal\n    # Should not have auto-detected\n    assert not console.file.called_isatty\n",
      "code_after": "import datetime\nimport io\nimport os\nimport subprocess\nimport sys\nimport tempfile\nfrom typing import Optional, Tuple, Type, Union\nfrom unittest import mock\n\nimport pytest\n\nfrom rich import errors\nfrom rich._null_file import NullFile\nfrom rich.color import ColorSystem\nfrom rich.console import (\n    CaptureError,\n    Console,\n    ConsoleDimensions,\n    ConsoleOptions,\n    ScreenUpdate,\n    group,\n)\nfrom rich.control import Control\nfrom rich.measure import measure_renderables\nfrom rich.padding import Padding\nfrom rich.pager import SystemPager\nfrom rich.panel import Panel\nfrom rich.region import Region\nfrom rich.segment import Segment\nfrom rich.status import Status\nfrom rich.style import Style\nfrom rich.text import Text\n\nos.get_terminal_size\n\n\ndef test_dumb_terminal() -> None:\n    console = Console(force_terminal=True, _environ={})\n    assert console.color_system is not None\n\n    console = Console(force_terminal=True, _environ={\"TERM\": \"dumb\"})\n    assert console.color_system is None\n    width, height = console.size\n    assert width == 80\n    assert height == 25\n\n\ndef test_soft_wrap() -> None:\n    console = Console(file=io.StringIO(), width=20, soft_wrap=True)\n    console.print(\"foo \" * 10)\n    assert console.file.getvalue() == \"foo \" * 20\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_16color_terminal() -> None:\n    console = Console(\n        force_terminal=True, _environ={\"TERM\": \"xterm-16color\"}, legacy_windows=False\n    )\n    assert console.color_system == \"standard\"\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_truecolor_terminal() -> None:\n    console = Console(\n        force_terminal=True,\n        legacy_windows=False,\n        _environ={\"COLORTERM\": \"truecolor\", \"TERM\": \"xterm-16color\"},\n    )\n    assert console.color_system == \"truecolor\"\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_kitty_terminal() -> None:\n    console = Console(\n        force_terminal=True,\n        legacy_windows=False,\n        _environ={\"TERM\": \"xterm-kitty\"},\n    )\n    assert console.color_system == \"256\"\n\n\ndef test_console_options_update() -> None:\n    options = ConsoleOptions(\n        ConsoleDimensions(80, 25),\n        max_height=25,\n        legacy_windows=False,\n        min_width=10,\n        max_width=20,\n        is_terminal=False,\n        encoding=\"utf-8\",\n    )\n    options1 = options.update(width=15)\n    assert options1.min_width == 15 and options1.max_width == 15\n\n    options2 = options.update(min_width=5, max_width=15, justify=\"right\")\n    assert (\n        options2.min_width == 5\n        and options2.max_width == 15\n        and options2.justify == \"right\"\n    )\n\n    options_copy = options.update()\n    assert options_copy == options and options_copy is not options\n\n\ndef test_console_options_update_height() -> None:\n    options = ConsoleOptions(\n        ConsoleDimensions(80, 25),\n        max_height=25,\n        legacy_windows=False,\n        min_width=10,\n        max_width=20,\n        is_terminal=False,\n        encoding=\"utf-8\",\n    )\n    assert options.height is None\n    render_options = options.update_height(12)\n    assert options.height is None\n    assert render_options.height == 12\n    assert render_options.max_height == 12\n\n\ndef test_init() -> None:\n    console = Console(color_system=None)\n    assert console._color_system == None\n    console = Console(color_system=\"standard\")\n    assert console._color_system == ColorSystem.STANDARD\n    console = Console(color_system=\"auto\")\n\n\ndef test_size() -> None:\n    console = Console()\n    w, h = console.size\n    assert console.width == w\n\n    console = Console(width=99, height=101, legacy_windows=False)\n    w, h = console.size\n    assert w == 99 and h == 101\n\n\n@pytest.mark.parametrize(\n    \"is_windows,no_descriptor_size,stdin_size,stdout_size,stderr_size,expected_size\",\n    [\n        # on Windows we'll use `os.get_terminal_size()` without arguments...\n        (True, (133, 24), ValueError, ValueError, ValueError, (80, 25)),\n        (False, (133, 24), ValueError, ValueError, ValueError, (80, 25)),\n        # ...while on other OS we'll try to pass stdin, then stdout, then stderr to it:\n        (False, ValueError, (133, 24), ValueError, ValueError, (133, 24)),\n        (False, ValueError, ValueError, (133, 24), ValueError, (133, 24)),\n        (False, ValueError, ValueError, ValueError, (133, 24), (133, 24)),\n        (False, ValueError, ValueError, ValueError, ValueError, (80, 25)),\n    ],\n)\n@mock.patch(\"rich.console.os.get_terminal_size\")\ndef test_size_can_fall_back_to_std_descriptors(\n    get_terminal_size_mock: mock.MagicMock,\n    is_windows: bool,\n    no_descriptor_size: Union[Tuple[int, int], Type[ValueError]],\n    stdin_size: Union[Tuple[int, int], Type[ValueError]],\n    stdout_size: Union[Tuple[int, int], Type[ValueError]],\n    stderr_size: Union[Tuple[int, int], Type[ValueError]],\n    expected_size: Tuple[int, int],\n) -> None:\n    def get_terminal_size_mock_impl(fileno: int = None) -> Tuple[int, int]:\n        value = {\n            None: no_descriptor_size,\n            sys.__stdin__.fileno(): stdin_size,\n            sys.__stdout__.fileno(): stdout_size,\n            sys.__stderr__.fileno(): stderr_size,\n        }[fileno]\n        if value is ValueError:\n            raise value\n        return value\n\n    get_terminal_size_mock.side_effect = get_terminal_size_mock_impl\n\n    console = Console(legacy_windows=False)\n    with mock.patch(\"rich.console.WINDOWS\", new=is_windows):\n        w, h = console.size\n    assert (w, h) == expected_size\n\n\ndef test_repr() -> None:\n    console = Console()\n    assert isinstance(repr(console), str)\n    assert isinstance(str(console), str)\n\n\ndef test_print() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"foo\")\n    assert console.file.getvalue() == \"foo\\n\"\n\n\ndef test_print_multiple() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"foo\", \"bar\")\n    assert console.file.getvalue() == \"foo bar\\n\"\n\n\ndef test_print_text() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(Text(\"foo\", style=\"bold\"))\n    assert console.file.getvalue() == \"\\x1b[1mfoo\\x1b[0m\\n\"\n\n\ndef test_print_text_multiple() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(Text(\"foo\", style=\"bold\"), Text(\"bar\"), \"baz\")\n    assert console.file.getvalue() == \"\\x1b[1mfoo\\x1b[0m bar baz\\n\"\n\n\ndef test_print_json() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json('[false, true, null, \"foo\"]', indent=4)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m[\\x1b[0m\\n    \\x1b[3;91mfalse\\x1b[0m,\\n    \\x1b[3;92mtrue\\x1b[0m,\\n    \\x1b[3;35mnull\\x1b[0m,\\n    \\x1b[32m\"foo\"\\x1b[0m\\n\\x1b[1m]\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_error() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    with pytest.raises(TypeError):\n        console.print_json([\"foo\"], indent=4)\n\n\ndef test_print_json_data() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json(data=[False, True, None, \"foo\"], indent=4)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m[\\x1b[0m\\n    \\x1b[3;91mfalse\\x1b[0m,\\n    \\x1b[3;92mtrue\\x1b[0m,\\n    \\x1b[3;35mnull\\x1b[0m,\\n    \\x1b[32m\"foo\"\\x1b[0m\\n\\x1b[1m]\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_ensure_ascii() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json(data={\"foo\": \"\ud83d\udca9\"}, ensure_ascii=False)\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m{\\x1b[0m\\n  \\x1b[1;34m\"foo\"\\x1b[0m: \\x1b[32m\"\ud83d\udca9\"\\x1b[0m\\n\\x1b[1m}\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_with_default_ensure_ascii() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print_json(data={\"foo\": \"\ud83d\udca9\"})\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = '\\x1b[1m{\\x1b[0m\\n  \\x1b[1;34m\"foo\"\\x1b[0m: \\x1b[32m\"\ud83d\udca9\"\\x1b[0m\\n\\x1b[1m}\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_print_json_indent_none() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    data = {\"name\": \"apple\", \"count\": 1}\n    console.print_json(data=data, indent=None)\n    result = console.file.getvalue()\n    expected = '\\x1b[1m{\\x1b[0m\\x1b[1;34m\"name\"\\x1b[0m: \\x1b[32m\"apple\"\\x1b[0m, \\x1b[1;34m\"count\"\\x1b[0m: \\x1b[1;36m1\\x1b[0m\\x1b[1m}\\x1b[0m\\n'\n    assert result == expected\n\n\ndef test_console_null_file(monkeypatch) -> None:\n    # When stdout and stderr are null, Console.file should be replaced with NullFile\n    monkeypatch.setattr(\"sys.stdout\", None)\n    monkeypatch.setattr(\"sys.stderr\", None)\n\n    console = Console()\n    assert isinstance(console.file, NullFile)\n\n\ndef test_log() -> None:\n    console = Console(\n        file=io.StringIO(),\n        width=80,\n        color_system=\"truecolor\",\n        log_time_format=\"TIME\",\n        log_path=False,\n        _environ={},\n    )\n    console.log(\"foo\", style=\"red\")\n    expected = \"\\x1b[2;36mTIME\\x1b[0m\\x1b[2;36m \\x1b[0m\\x1b[31mfoo                                                                        \\x1b[0m\\n\"\n    result = console.file.getvalue()\n    print(repr(result))\n    assert result == expected\n\n\ndef test_log_milliseconds() -> None:\n    def time_formatter(timestamp: datetime) -> Text:\n        return Text(\"TIME\")\n\n    console = Console(\n        file=io.StringIO(), width=40, log_time_format=time_formatter, log_path=False\n    )\n    console.log(\"foo\")\n    result = console.file.getvalue()\n    assert result == \"TIME foo                                \\n\"\n\n\ndef test_print_empty() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print()\n    assert console.file.getvalue() == \"\\n\"\n\n\ndef test_markup_highlight() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"'[bold]foo[/bold]'\")\n    assert (\n        console.file.getvalue()\n        == \"\\x1b[32m'\\x1b[0m\\x1b[1;32mfoo\\x1b[0m\\x1b[32m'\\x1b[0m\\n\"\n    )\n\n\ndef test_print_style() -> None:\n    console = Console(file=io.StringIO(), color_system=\"truecolor\")\n    console.print(\"foo\", style=\"bold\")\n    assert console.file.getvalue() == \"\\x1b[1mfoo\\x1b[0m\\n\"\n\n\ndef test_show_cursor() -> None:\n    console = Console(\n        file=io.StringIO(), force_terminal=True, legacy_windows=False, _environ={}\n    )\n    console.show_cursor(False)\n    console.print(\"foo\")\n    console.show_cursor(True)\n    assert console.file.getvalue() == \"\\x1b[?25lfoo\\n\\x1b[?25h\"\n\n\ndef test_clear() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, _environ={})\n    console.clear()\n    console.clear(home=False)\n    assert console.file.getvalue() == \"\\033[2J\\033[H\" + \"\\033[2J\"\n\n\ndef test_clear_no_terminal() -> None:\n    console = Console(file=io.StringIO())\n    console.clear()\n    console.clear(home=False)\n    assert console.file.getvalue() == \"\"\n\n\ndef test_get_style() -> None:\n    console = Console()\n    console.get_style(\"repr.brace\") == Style(bold=True)\n\n\ndef test_get_style_default() -> None:\n    console = Console()\n    console.get_style(\"foobar\", default=\"red\") == Style(color=\"red\")\n\n\ndef test_get_style_error() -> None:\n    console = Console()\n    with pytest.raises(errors.MissingStyle):\n        console.get_style(\"nosuchstyle\")\n    with pytest.raises(errors.MissingStyle):\n        console.get_style(\"foo bar\")\n\n\ndef test_render_error() -> None:\n    console = Console()\n    with pytest.raises(errors.NotRenderableError):\n        list(console.render([], console.options))\n\n\ndef test_control() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, _environ={})\n    console.control(Control.clear())\n    console.print(\"BAR\")\n    assert console.file.getvalue() == \"\\x1b[2JBAR\\n\"\n\n\ndef test_capture() -> None:\n    console = Console()\n    with console.capture() as capture:\n        with pytest.raises(CaptureError):\n            capture.get()\n        console.print(\"Hello\")\n    assert capture.get() == \"Hello\\n\"\n\n\ndef test_input(monkeypatch, capsys) -> None:\n    def fake_input(prompt=\"\"):\n        console.file.write(prompt)\n        return \"bar\"\n\n    monkeypatch.setattr(\"builtins.input\", fake_input)\n    console = Console()\n    user_input = console.input(prompt=\"foo:\")\n    assert capsys.readouterr().out == \"foo:\"\n    assert user_input == \"bar\"\n\n\ndef test_input_password(monkeypatch, capsys) -> None:\n    def fake_input(prompt, stream=None):\n        console.file.write(prompt)\n        return \"bar\"\n\n    import rich.console\n\n    monkeypatch.setattr(rich.console, \"getpass\", fake_input)\n    console = Console()\n    user_input = console.input(prompt=\"foo:\", password=True)\n    assert capsys.readouterr().out == \"foo:\"\n    assert user_input == \"bar\"\n\n\ndef test_status() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20)\n    status = console.status(\"foo\")\n    assert isinstance(status, Status)\n\n\ndef test_justify_none() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20)\n    console.print(\"FOO\", justify=None)\n    assert console.file.getvalue() == \"FOO\\n\"\n\n\ndef test_justify_left() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20, _environ={})\n    console.print(\"FOO\", justify=\"left\")\n    assert console.file.getvalue() == \"FOO                 \\n\"\n\n\ndef test_justify_center() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20, _environ={})\n    console.print(\"FOO\", justify=\"center\")\n    assert console.file.getvalue() == \"        FOO         \\n\"\n\n\ndef test_justify_right() -> None:\n    console = Console(file=io.StringIO(), force_terminal=True, width=20, _environ={})\n    console.print(\"FOO\", justify=\"right\")\n    assert console.file.getvalue() == \"                 FOO\\n\"\n\n\ndef test_justify_renderable_none() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=20,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=None)\n    assert console.file.getvalue() == \"\u256d\u2500\u2500\u2500\u256e\\n\u2502FOO\u2502\\n\u2570\u2500\u2500\u2500\u256f\\n\"\n\n\ndef test_justify_renderable_left() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=10,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=\"left\")\n    assert console.file.getvalue() == \"\u256d\u2500\u2500\u2500\u256e     \\n\u2502FOO\u2502     \\n\u2570\u2500\u2500\u2500\u256f     \\n\"\n\n\ndef test_justify_renderable_center() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=10,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=\"center\")\n    assert console.file.getvalue() == \"  \u256d\u2500\u2500\u2500\u256e   \\n  \u2502FOO\u2502   \\n  \u2570\u2500\u2500\u2500\u256f   \\n\"\n\n\ndef test_justify_renderable_right() -> None:\n    console = Console(\n        file=io.StringIO(),\n        force_terminal=True,\n        width=20,\n        legacy_windows=False,\n        _environ={},\n    )\n    console.print(Panel(\"FOO\", expand=False, padding=0), justify=\"right\")\n    assert (\n        console.file.getvalue()\n        == \"               \u256d\u2500\u2500\u2500\u256e\\n               \u2502FOO\u2502\\n               \u2570\u2500\u2500\u2500\u256f\\n\"\n    )\n\n\nclass BrokenRenderable:\n    def __rich_console__(self, console, options):\n        pass\n\n\ndef test_render_broken_renderable() -> None:\n    console = Console()\n    broken = BrokenRenderable()\n    with pytest.raises(errors.NotRenderableError):\n        list(console.render(broken, console.options))\n\n\ndef test_export_text() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"[b]foo\")\n    text = console.export_text()\n    expected = \"foo\\n\"\n    assert text == expected\n\n\ndef test_export_html() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"[b]foo <script> 'test' [link=https://example.org]Click[/link]\")\n    html = console.export_html()\n    print(repr(html))\n    expected = '<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n<style>\\n.r1 {font-weight: bold}\\n.r2 {color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold}\\n.r3 {color: #008000; text-decoration-color: #008000; font-weight: bold}\\nbody {\\n    color: #000000;\\n    background-color: #ffffff;\\n}\\n</style>\\n</head>\\n<body>\\n    <pre style=\"font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><code style=\"font-family:inherit\"><span class=\"r1\">foo &lt;</span><span class=\"r2\">script</span><span class=\"r1\">&gt; </span><span class=\"r3\">&#x27;test&#x27;</span><span class=\"r1\"> </span><a class=\"r1\" href=\"https://example.org\">Click</a>\\n</code></pre>\\n</body>\\n</html>\\n'\n    assert html == expected\n\n\ndef test_export_html_inline() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"[b]foo [link=https://example.org]Click[/link]\")\n    html = console.export_html(inline_styles=True)\n    print(repr(html))\n    expected = '<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n<style>\\n\\nbody {\\n    color: #000000;\\n    background-color: #ffffff;\\n}\\n</style>\\n</head>\\n<body>\\n    <pre style=\"font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><code style=\"font-family:inherit\"><span style=\"font-weight: bold\">foo </span><span style=\"font-weight: bold\"><a href=\"https://example.org\">Click</a></span>\\n</code></pre>\\n</body>\\n</html>\\n'\n    assert html == expected\n\n\nEXPECTED_SVG = '<svg class=\"rich-terminal\" viewBox=\"0 0 1238 74.4\" xmlns=\"http://www.w3.org/2000/svg\">\\n    <!-- Generated with Rich https://www.textualize.io -->\\n    <style>\\n\\n    @font-face {\\n        font-family: \"Fira Code\";\\n        src: local(\"FiraCode-Regular\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Regular.woff2\") format(\"woff2\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Regular.woff\") format(\"woff\");\\n        font-style: normal;\\n        font-weight: 400;\\n    }\\n    @font-face {\\n        font-family: \"Fira Code\";\\n        src: local(\"FiraCode-Bold\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff2/FiraCode-Bold.woff2\") format(\"woff2\"),\\n                url(\"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/woff/FiraCode-Bold.woff\") format(\"woff\");\\n        font-style: bold;\\n        font-weight: 700;\\n    }\\n\\n    .terminal-3526644552-matrix {\\n        font-family: Fira Code, monospace;\\n        font-size: 20px;\\n        line-height: 24.4px;\\n        font-variant-east-asian: full-width;\\n    }\\n\\n    .terminal-3526644552-title {\\n        font-size: 18px;\\n        font-weight: bold;\\n        font-family: arial;\\n    }\\n\\n    .terminal-3526644552-r1 { fill: #608ab1;font-weight: bold }\\n.terminal-3526644552-r2 { fill: #c5c8c6 }\\n    </style>\\n\\n    <defs>\\n    <clipPath id=\"terminal-3526644552-clip-terminal\">\\n      <rect x=\"0\" y=\"0\" width=\"1219.0\" height=\"23.4\" />\\n    </clipPath>\\n    \\n    </defs>\\n\\n    <rect fill=\"#292929\" stroke=\"rgba(255,255,255,0.35)\" stroke-width=\"1\" x=\"1\" y=\"1\" width=\"1236\" height=\"72.4\" rx=\"8\"/><text class=\"terminal-3526644552-title\" fill=\"#c5c8c6\" text-anchor=\"middle\" x=\"618\" y=\"27\">Rich</text>\\n            <g transform=\"translate(26,22)\">\\n            <circle cx=\"0\" cy=\"0\" r=\"7\" fill=\"#ff5f57\"/>\\n            <circle cx=\"22\" cy=\"0\" r=\"7\" fill=\"#febc2e\"/>\\n            <circle cx=\"44\" cy=\"0\" r=\"7\" fill=\"#28c840\"/>\\n            </g>\\n        \\n    <g transform=\"translate(9, 41)\" clip-path=\"url(#terminal-3526644552-clip-terminal)\">\\n    <rect fill=\"#cc555a\" x=\"0\" y=\"1.5\" width=\"36.6\" height=\"24.65\" shape-rendering=\"crispEdges\"/>\\n    <g class=\"terminal-3526644552-matrix\">\\n    <text class=\"terminal-3526644552-r1\" x=\"0\" y=\"20\" textLength=\"36.6\" clip-path=\"url(#terminal-3526644552-line-0)\">foo</text><text class=\"terminal-3526644552-r2\" x=\"48.8\" y=\"20\" textLength=\"61\" clip-path=\"url(#terminal-3526644552-line-0)\">Click</text><text class=\"terminal-3526644552-r2\" x=\"1220\" y=\"20\" textLength=\"12.2\" clip-path=\"url(#terminal-3526644552-line-0)\">\\n</text>\\n    </g>\\n    </g>\\n</svg>\\n'\n\n\ndef test_export_svg() -> None:\n    console = Console(record=True, width=100)\n    console.print(\n        \"[b red on blue reverse]foo[/] [blink][link=https://example.org]Click[/link]\"\n    )\n    svg = console.export_svg()\n    print(repr(svg))\n\n    assert svg == EXPECTED_SVG\n\n\ndef test_export_svg_specified_unique_id() -> None:\n    expected_svg = EXPECTED_SVG.replace(\"terminal-3526644552\", \"given-id\")\n    console = Console(record=True, width=100)\n    console.print(\n        \"[b red on blue reverse]foo[/] [blink][link=https://example.org]Click[/link]\"\n    )\n    svg = console.export_svg(unique_id=\"given-id\")\n    print(repr(svg))\n\n    assert svg == expected_svg\n\n\ndef test_save_svg() -> None:\n    console = Console(record=True, width=100)\n    console.print(\n        \"[b red on blue reverse]foo[/] [blink][link=https://example.org]Click[/link]\"\n    )\n    with tempfile.TemporaryDirectory() as path:\n        export_path = os.path.join(path, \"example.svg\")\n        console.save_svg(export_path)\n        with open(export_path, \"rt\", encoding=\"utf-8\") as svg_file:\n            assert svg_file.read() == EXPECTED_SVG\n\n\ndef test_save_text() -> None:\n    console = Console(record=True, width=100)\n    console.print(\"foo\")\n    with tempfile.TemporaryDirectory() as path:\n        export_path = os.path.join(path, \"rich.txt\")\n        console.save_text(export_path)\n        with open(export_path, \"rt\") as text_file:\n            assert text_file.read() == \"foo\\n\"\n\n\ndef test_save_html() -> None:\n    expected = '<!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset=\"UTF-8\">\\n<style>\\n\\nbody {\\n    color: #000000;\\n    background-color: #ffffff;\\n}\\n</style>\\n</head>\\n<body>\\n    <pre style=\"font-family:Menlo,\\'DejaVu Sans Mono\\',consolas,\\'Courier New\\',monospace\"><code style=\"font-family:inherit\">foo\\n</code></pre>\\n</body>\\n</html>\\n'\n    console = Console(record=True, width=100)\n    console.print(\"foo\")\n    with tempfile.TemporaryDirectory() as path:\n        export_path = os.path.join(path, \"example.html\")\n        console.save_html(export_path)\n        with open(export_path, \"rt\") as html_file:\n            html = html_file.read()\n            print(repr(html))\n            assert html == expected\n\n\ndef test_no_wrap() -> None:\n    console = Console(width=10, file=io.StringIO())\n    console.print(\"foo bar baz egg\", no_wrap=True)\n    assert console.file.getvalue() == \"foo bar ba\\n\"\n\n\ndef test_soft_wrap() -> None:\n    console = Console(width=10, file=io.StringIO())\n    console.print(\"foo bar baz egg\", soft_wrap=True)\n    assert console.file.getvalue() == \"foo bar baz egg\\n\"\n\n\ndef test_unicode_error() -> None:\n    try:\n        with tempfile.TemporaryFile(\"wt\", encoding=\"ascii\") as tmpfile:\n            console = Console(file=tmpfile)\n            console.print(\":vampire:\")\n    except UnicodeEncodeError as error:\n        assert \"PYTHONIOENCODING\" in str(error)\n    else:\n        assert False, \"didn't raise UnicodeEncodeError\"\n\n\ndef test_bell() -> None:\n    console = Console(force_terminal=True, _environ={})\n    console.begin_capture()\n    console.bell()\n    assert console.end_capture() == \"\\x07\"\n\n\ndef test_pager() -> None:\n    console = Console(_environ={})\n\n    pager_content: Optional[str] = None\n\n    def mock_pager(content: str) -> None:\n        nonlocal pager_content\n        pager_content = content\n\n    pager = SystemPager()\n    pager._pager = mock_pager\n\n    with console.pager(pager):\n        console.print(\"[bold]Hello World\")\n    assert pager_content == \"Hello World\\n\"\n\n    with console.pager(pager, styles=True, links=False):\n        console.print(\"[bold link https:/example.org]Hello World\")\n\n    assert pager_content == \"Hello World\\n\"\n\n\ndef test_out() -> None:\n    console = Console(width=10)\n    console.begin_capture()\n    console.out(*([\"foo bar\"] * 5), sep=\".\", end=\"X\")\n    assert console.end_capture() == \"foo bar.foo bar.foo bar.foo bar.foo barX\"\n\n\ndef test_render_group() -> None:\n    @group(fit=False)\n    def renderable():\n        yield \"one\"\n        yield \"two\"\n        yield \"three\"  # <- largest width of 5\n        yield \"four\"\n\n    renderables = [renderable() for _ in range(4)]\n    console = Console(width=42)\n    min_width, _ = measure_renderables(console, console.options, renderables)\n    assert min_width == 42\n\n\ndef test_render_group_fit() -> None:\n    @group()\n    def renderable():\n        yield \"one\"\n        yield \"two\"\n        yield \"three\"  # <- largest width of 5\n        yield \"four\"\n\n    renderables = [renderable() for _ in range(4)]\n\n    console = Console(width=42)\n\n    min_width, _ = measure_renderables(console, console.options, renderables)\n    assert min_width == 5\n\n\ndef test_get_time() -> None:\n    console = Console(\n        get_time=lambda: 99, get_datetime=lambda: datetime.datetime(1974, 7, 5)\n    )\n    assert console.get_time() == 99\n    assert console.get_datetime() == datetime.datetime(1974, 7, 5)\n\n\ndef test_console_style() -> None:\n    console = Console(\n        file=io.StringIO(), color_system=\"truecolor\", force_terminal=True, style=\"red\"\n    )\n    console.print(\"foo\")\n    expected = \"\\x1b[31mfoo\\x1b[0m\\n\"\n    result = console.file.getvalue()\n    assert result == expected\n\n\ndef test_no_color() -> None:\n    console = Console(\n        file=io.StringIO(), color_system=\"truecolor\", force_terminal=True, no_color=True\n    )\n    console.print(\"[bold magenta on red]FOO\")\n    expected = \"\\x1b[1mFOO\\x1b[0m\\n\"\n    result = console.file.getvalue()\n    print(repr(result))\n    assert result == expected\n\n\ndef test_quiet() -> None:\n    console = Console(file=io.StringIO(), quiet=True)\n    console.print(\"Hello, World!\")\n    assert console.file.getvalue() == \"\"\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_screen() -> None:\n    console = Console(\n        color_system=None, force_terminal=True, force_interactive=True, _environ={}\n    )\n    with console.capture() as capture:\n        with console.screen():\n            console.print(\"Don't panic\")\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25lDon't panic\\n\\x1b[?1049l\\x1b[?25h\"\n    result = capture.get()\n    print(repr(result))\n    assert result == expected\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_screen_update() -> None:\n    console = Console(\n        width=20, height=4, color_system=\"truecolor\", force_terminal=True, _environ={}\n    )\n    with console.capture() as capture:\n        with console.screen() as screen:\n            screen.update(\"foo\", style=\"blue\")\n            screen.update(\"bar\")\n            screen.update()\n    result = capture.get()\n    print(repr(result))\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25l\\x1b[34mfoo\\x1b[0m\\x1b[34m                 \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\x1b[34mbar\\x1b[0m\\x1b[34m                 \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\x1b[34mbar\\x1b[0m\\x1b[34m                 \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\n\\x1b[34m                    \\x1b[0m\\x1b[?1049l\\x1b[?25h\"\n    assert result == expected\n\n\ndef test_height() -> None:\n    console = Console(width=80, height=46)\n    assert console.height == 46\n\n\ndef test_columns_env() -> None:\n    console = Console(_environ={\"COLUMNS\": \"314\"}, legacy_windows=False)\n    assert console.width == 314\n    # width take precedence\n    console = Console(width=40, _environ={\"COLUMNS\": \"314\"}, legacy_windows=False)\n    assert console.width == 40\n    # Should not fail\n    console = Console(width=40, _environ={\"COLUMNS\": \"broken\"}, legacy_windows=False)\n\n\ndef test_lines_env() -> None:\n    console = Console(_environ={\"LINES\": \"220\"})\n    assert console.height == 220\n    # height take precedence\n    console = Console(height=40, _environ={\"LINES\": \"220\"})\n    assert console.height == 40\n    # Should not fail\n    console = Console(width=40, _environ={\"LINES\": \"broken\"})\n\n\ndef test_screen_update_class() -> None:\n    screen_update = ScreenUpdate([[Segment(\"foo\")], [Segment(\"bar\")]], 5, 10)\n    assert screen_update.x == 5\n    assert screen_update.y == 10\n\n    console = Console(force_terminal=True)\n    console.begin_capture()\n    console.print(screen_update)\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"\\x1b[11;6Hfoo\\x1b[12;6Hbar\"\n    assert result == expected\n\n\ndef test_is_alt_screen() -> None:\n    console = Console(force_terminal=True)\n    if console.legacy_windows:\n        return\n    assert not console.is_alt_screen\n    with console.screen():\n        assert console.is_alt_screen\n    assert not console.is_alt_screen\n\n\ndef test_set_console_title() -> None:\n    console = Console(force_terminal=True, _environ={})\n    if console.legacy_windows:\n        return\n\n    with console.capture() as captured:\n        console.set_window_title(\"hello\")\n\n    result = captured.get()\n    assert result == \"\\x1b]0;hello\\x07\"\n\n\ndef test_update_screen() -> None:\n    console = Console(force_terminal=True, width=20, height=5, _environ={})\n    if console.legacy_windows:\n        return\n    with pytest.raises(errors.NoAltScreen):\n        console.update_screen(\"foo\")\n    console.begin_capture()\n    with console.screen():\n        console.update_screen(\"foo\")\n        console.update_screen(\"bar\", region=Region(2, 3, 8, 4))\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25l\\x1b[1;1Hfoo                 \\x1b[2;1H                    \\x1b[3;1H                    \\x1b[4;1H                    \\x1b[5;1H                    \\x1b[4;3Hbar     \\x1b[5;3H        \\x1b[6;3H        \\x1b[7;3H        \\x1b[?1049l\\x1b[?25h\"\n    assert result == expected\n\n\ndef test_update_screen_lines() -> None:\n    console = Console(force_terminal=True, width=20, height=5)\n    if console.legacy_windows:\n        return\n    with pytest.raises(errors.NoAltScreen):\n        console.update_screen_lines([])\n\n\ndef test_update_options_markup() -> None:\n    console = Console()\n    options = console.options\n    assert options.update(markup=False).markup == False\n    assert options.update(markup=True).markup == True\n\n\ndef test_print_width_zero() -> None:\n    console = Console()\n    with console.capture() as capture:\n        console.print(\"Hello\", width=0)\n    assert capture.get() == \"\"\n\n\ndef test_size_properties() -> None:\n    console = Console(width=80, height=25, legacy_windows=False)\n    assert console.size == ConsoleDimensions(80, 25)\n    console.size = (10, 20)\n    assert console.size == ConsoleDimensions(10, 20)\n    console.width = 5\n    assert console.size == ConsoleDimensions(5, 20)\n    console.height = 10\n    assert console.size == ConsoleDimensions(5, 10)\n\n\ndef test_print_newline_start() -> None:\n    console = Console(width=80, height=25)\n    console.begin_capture()\n    console.print(\"Foo\", new_line_start=True)\n    console.print(\"Foo\\nbar\\n\", new_line_start=True)\n    result = console.end_capture()\n\n    assert result == \"Foo\\n\\nFoo\\nbar\\n\\n\"\n\n\ndef test_is_terminal_broken_file() -> None:\n    console = Console()\n\n    def _mock_isatty():\n        raise ValueError()\n\n    console.file.isatty = _mock_isatty\n\n    assert console.is_terminal == False\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"not relevant on Windows\")\ndef test_detect_color_system() -> None:\n    console = Console(_environ={\"TERM\": \"rxvt-unicode-256color\"}, force_terminal=True)\n    assert console._detect_color_system() == ColorSystem.EIGHT_BIT\n\n\ndef test_reset_height() -> None:\n    \"\"\"Test height is reset when rendering complex renderables.\"\"\"\n\n    # https://github.com/Textualize/rich/issues/2042\n    class Panels:\n        def __rich_console__(self, console, options):\n            yield Panel(\"foo\")\n            yield Panel(\"bar\")\n\n    console = Console(\n        force_terminal=True,\n        color_system=\"truecolor\",\n        width=20,\n        height=40,\n        legacy_windows=False,\n    )\n\n    with console.capture() as capture:\n        console.print(Panel(Panels()), height=12)\n    result = capture.get()\n    print(repr(result))\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\\n\u2502 \u2502 foo          \u2502 \u2502\\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\\n\u2502 \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502\\n\u2502 \u2502 bar          \u2502 \u2502\\n\u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2502\\n\u2502                  \u2502\\n\u2502                  \u2502\\n\u2502                  \u2502\\n\u2502                  \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n\n    assert result == expected\n\n\ndef test_render_lines_height_minus_vertical_pad_is_negative() -> None:\n    # https://github.com/Textualize/textual/issues/389\n    console = Console(\n        force_terminal=True,\n        color_system=\"truecolor\",\n        width=20,\n        height=40,\n        legacy_windows=False,\n    )\n    options = console.options.update_height(1)\n\n    # Ensuring that no exception is raised...\n    console.render_lines(Padding(\"hello\", pad=(1, 0)), options=options)\n\n\ndef test_recording_no_stdout_and_no_stderr_files(monkeypatch) -> None:\n    # Rich should work even if there's no file available to write to.\n    # For example, pythonw nullifies output streams.\n    # Built-in print silently no-ops in pythonw.\n    # Related: https://github.com/Textualize/rich/issues/2400\n    monkeypatch.setattr(\"sys.stdout\", None)\n    monkeypatch.setattr(\"sys.stderr\", None)\n    console = Console(record=True)\n    console.print(\"hello world\")\n    text = console.export_text()\n    assert text == \"hello world\\n\"\n\n\ndef test_capturing_no_stdout_and_no_stderr_files(monkeypatch) -> None:\n    monkeypatch.setattr(\"sys.stdout\", None)\n    monkeypatch.setattr(\"sys.stderr\", None)\n    console = Console()\n    with console.capture() as capture:\n        console.print(\"hello world\")\n    assert capture.get() == \"hello world\\n\"\n\n\n@pytest.mark.parametrize(\"env_value\", [\"\", \"something\", \"0\"])\ndef test_force_color(env_value) -> None:\n    # Even though we use a non-tty file, the presence of FORCE_COLOR env var\n    # means is_terminal returns True.\n    console = Console(file=io.StringIO(), _environ={\"FORCE_COLOR\": env_value})\n    assert console.is_terminal\n\n\ndef test_force_color_jupyter() -> None:\n    # FORCE_COLOR above doesn't happen in a Jupyter kernel\n    console = Console(\n        file=io.StringIO(), _environ={\"FORCE_COLOR\": \"1\"}, force_jupyter=True\n    )\n    assert not console.is_terminal\n\n\ndef test_force_color() -> None:\n    console = Console(\n        file=io.StringIO(),\n        _environ={\n            \"FORCE_COLOR\": \"1\",\n            \"TERM\": \"xterm-256color\",\n            \"COLORTERM\": \"truecolor\",\n        },\n    )\n    assert console.color_system in (\"truecolor\", \"windows\")\n\n\ndef test_reenable_highlighting() -> None:\n    \"\"\"Check that when highlighting is disabled, it can be reenabled in print()\"\"\"\n    console = Console(\n        file=io.StringIO(),\n        _environ={\n            \"FORCE_COLOR\": \"1\",\n            \"TERM\": \"xterm-256color\",\n            \"COLORTERM\": \"truecolor\",\n        },\n        highlight=False,\n    )\n    console.print(\"[1, 2, 3]\")\n    console.print(\"[1, 2, 3]\", highlight=True)\n    output = console.file.getvalue()\n    lines = output.splitlines()\n    print(repr(lines))\n    # First line not highlighted\n    assert lines[0] == \"[1, 2, 3]\"\n    # Second line highlighted\n\n    assert (\n        lines[1]\n        == \"\\x1b[1m[\\x1b[0m\\x1b[1;36m1\\x1b[0m, \\x1b[1;36m2\\x1b[0m, \\x1b[1;36m3\\x1b[0m\\x1b[1m]\\x1b[0m\"\n    )\n\n\n@pytest.mark.skipif(sys.platform == \"win32\", reason=\"does not run on windows\")\ndef test_brokenpipeerror() -> None:\n    \"\"\"Test BrokenPipe works as expected.\"\"\"\n    which_py, which_head = ([\"which\", cmd] for cmd in (\"python\", \"head\"))\n    rich_cmd = \"python -m rich\".split()\n    for cmd in [which_py, which_head, rich_cmd]:\n        check = subprocess.run(cmd).returncode\n        if check != 0:\n            return  # Only test on suitable Unix platforms\n    head_cmd = \"head -1\".split()\n    proc1 = subprocess.Popen(rich_cmd, stdout=subprocess.PIPE)\n    proc2 = subprocess.Popen(head_cmd, stdin=proc1.stdout, stdout=subprocess.PIPE)\n    proc1.stdout.close()\n    output, _ = proc2.communicate()\n    proc1.wait()\n    proc2.wait()\n    assert proc1.returncode == 1\n    assert proc2.returncode == 0\n\n\ndef test_capture_and_record() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/2563\"\"\"\n\n    console = Console(record=True)\n    print(\"Before Capture started:\")\n    console.print(\"[blue underline]Print 0\")\n    with console.capture() as capture:\n        console.print(\"[blue underline]Print 1\")\n        console.print(\"[blue underline]Print 2\")\n        console.print(\"[blue underline]Print 3\")\n        console.print(\"[blue underline]Print 4\")\n\n    capture_content = capture.get()\n    print(repr(capture_content))\n    assert capture_content == \"Print 1\\nPrint 2\\nPrint 3\\nPrint 4\\n\"\n\n    recorded_content = console.export_text()\n    print(repr(recorded_content))\n    assert recorded_content == \"Print 0\\n\"\n\n\ndef test_tty_compatible() -> None:\n    \"\"\"Check TTY_COMPATIBLE environment var.\"\"\"\n\n    class FakeTTY:\n        \"\"\"An file file-like which reports it is a TTY.\"\"\"\n\n        def __init__(self) -> None:\n            self.called_isatty = False\n\n        def isatty(self) -> bool:\n            self.called_isatty = True\n            return True\n\n    class FakeFile:\n        \"\"\"A file object that reports False for isatty\"\"\"\n\n        def __init__(self) -> None:\n            self.called_isatty = False\n\n        def isatty(self) -> bool:\n            self.called_isatty = True\n            return False\n\n    # Console file is not a TTY\n    console = Console(file=FakeFile())\n    # Not a TTY, so is_terminal should be False\n    assert not console.is_terminal\n    # Should have called isatty to auto-detect tty support\n    assert console.file.called_isatty\n\n    # Not a terminal\n    console = Console(file=FakeFile(), _environ={\"TTY_COMPATIBLE\": \"1\"})\n    # env TTY_COMPATIBLE=1 should report that it is a terminal\n    assert console.is_terminal\n    # Should not have called file.isattry\n    assert not console.file.called_isatty\n\n    # File is a fake TTY\n    console = Console(file=FakeTTY())\n    # Should report True\n    assert console.is_terminal\n    # SHould have auto-detected\n    assert console.file.called_isatty\n\n    # File is a fake TTY\n    console = Console(file=FakeTTY(), _environ={\"TTY_COMPATIBLE\": \"\"})\n    # Blank TTY_COMPATIBLE should auto-detect, so is_terminal is True\n    assert console.is_terminal\n    # Should have auto-detected\n    assert console.file.called_isatty\n\n    # File is a fake TTY\n    console = Console(file=FakeTTY(), _environ={\"TTY_COMPATIBLE\": \"whatever\"})\n    # Any pother value should auto-detect\n    assert console.is_terminal\n    # Should have auto-detected\n    assert console.file.called_isatty\n\n    # TTY_COMPATIBLE should override file.isattry\n    console = Console(file=FakeTTY(), _environ={\"TTY_COMPATIBLE\": \"0\"})\n    # Should report that it is *not* a terminal\n    assert not console.is_terminal\n    # Should not have auto-detected\n    assert not console.file.called_isatty\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "051c7bfab79e",
      "repo": "rich",
      "commit_hash": "82afcb4",
      "commit_message": "test fixes",
      "file_path": "tests/test_live.py",
      "language": "python",
      "code_before": "# encoding=utf-8\nimport time\nfrom typing import Optional\n\n# import pytest\nfrom rich.console import Console\nfrom rich.live import Live\nfrom rich.text import Text\n\n\ndef create_capture_console(\n    *, width: int = 60, height: int = 80, force_terminal: Optional[bool] = True\n) -> Console:\n    return Console(\n        width=width,\n        height=height,\n        force_terminal=force_terminal,\n        legacy_windows=False,\n        color_system=None,  # use no color system to reduce complexity of output,\n        _environ={},\n    )\n\n\ndef test_live_state() -> None:\n    with Live(\"\") as live:\n        assert live._started\n        live.start()\n\n        assert live.renderable == \"\"\n\n        assert live._started\n        live.stop()\n        assert not live._started\n\n    assert not live._started\n\n\ndef test_growing_display() -> None:\n    console = create_capture_console()\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    print(repr(output))\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_transient() -> None:\n    console = create_capture_console()\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False, transient=True) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\\r\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\"\n    )\n\n\ndef test_growing_display_overflow_ellipsis() -> None:\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(\n        console=console, auto_refresh=False, vertical_overflow=\"ellipsis\"\n    ) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_overflow_crop() -> None:\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False, vertical_overflow=\"crop\") as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_overflow_visible() -> None:\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False, vertical_overflow=\"visible\") as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_autorefresh() -> None:\n    \"\"\"Test generating a table but using auto-refresh from threading\"\"\"\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=True, vertical_overflow=\"visible\") as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display)\n            time.sleep(0.2)\n\n    # no way to truly test w/ multithreading, just make sure it doesn't crash\n\n\ndef test_growing_display_console_redirect() -> None:\n    console = create_capture_console()\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False) as live:\n        display = \"\"\n        for step in range(10):\n            console.print(f\"Running step {step}\")\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lRunning step 0\\n\\r\\x1b[2KStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KRunning step 1\\nStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 2\\nStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 3\\nStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 4\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 5\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 6\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 7\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 8\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 9\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_file_console() -> None:\n    console = create_capture_console(force_terminal=False)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"Step 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\"\n    )\n\n\ndef test_live_screen() -> None:\n    console = create_capture_console(width=20, height=5)\n    console.begin_capture()\n    with Live(Text(\"foo\"), screen=True, console=console, auto_refresh=False) as live:\n        live.refresh()\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25l\\x1b[Hfoo                 \\n                    \\n                    \\n                    \\n                    \\x1b[Hfoo                 \\n                    \\n                    \\n                    \\n                    \\x1b[?25h\\x1b[?1049l\"\n    assert result == expected\n",
      "code_after": "# encoding=utf-8\nimport time\nfrom typing import Optional\n\n# import pytest\nfrom rich.console import Console\nfrom rich.live import Live\nfrom rich.text import Text\n\n\ndef create_capture_console(\n    *, width: int = 60, height: int = 80, force_terminal: Optional[bool] = True\n) -> Console:\n    return Console(\n        width=width,\n        height=height,\n        force_terminal=force_terminal,\n        legacy_windows=False,\n        color_system=None,  # use no color system to reduce complexity of output,\n        _environ={},\n    )\n\n\ndef test_live_state() -> None:\n    with Live(\"\") as live:\n        assert live._started\n        live.start()\n\n        assert live.get_renderable() == \"\"\n\n        assert live._started\n        live.stop()\n        assert not live._started\n\n    assert not live._started\n\n\ndef test_growing_display() -> None:\n    console = create_capture_console()\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    print(repr(output))\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_transient() -> None:\n    console = create_capture_console()\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False, transient=True) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\\r\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\"\n    )\n\n\ndef test_growing_display_overflow_ellipsis() -> None:\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(\n        console=console, auto_refresh=False, vertical_overflow=\"ellipsis\"\n    ) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n                            ...                             \\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_overflow_crop() -> None:\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False, vertical_overflow=\"crop\") as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_overflow_visible() -> None:\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False, vertical_overflow=\"visible\") as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_autorefresh() -> None:\n    \"\"\"Test generating a table but using auto-refresh from threading\"\"\"\n    console = create_capture_console(height=5)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=True, vertical_overflow=\"visible\") as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display)\n            time.sleep(0.2)\n\n    # no way to truly test w/ multithreading, just make sure it doesn't crash\n\n\ndef test_growing_display_console_redirect() -> None:\n    console = create_capture_console()\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False) as live:\n        display = \"\"\n        for step in range(10):\n            console.print(f\"Running step {step}\")\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"\\x1b[?25lRunning step 0\\n\\r\\x1b[2KStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KRunning step 1\\nStep 0\\n\\r\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 2\\nStep 0\\nStep 1\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 3\\nStep 0\\nStep 1\\nStep 2\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 4\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 5\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 6\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 7\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 8\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KRunning step 9\\nStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\r\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2K\\x1b[1A\\x1b[2KStep 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\\n\\x1b[?25h\"\n    )\n\n\ndef test_growing_display_file_console() -> None:\n    console = create_capture_console(force_terminal=False)\n    console.begin_capture()\n    with Live(console=console, auto_refresh=False) as live:\n        display = \"\"\n        for step in range(10):\n            display += f\"Step {step}\\n\"\n            live.update(display, refresh=True)\n    output = console.end_capture()\n    assert (\n        output\n        == \"Step 0\\nStep 1\\nStep 2\\nStep 3\\nStep 4\\nStep 5\\nStep 6\\nStep 7\\nStep 8\\nStep 9\\n\"\n    )\n\n\ndef test_live_screen() -> None:\n    console = create_capture_console(width=20, height=5)\n    console.begin_capture()\n    with Live(Text(\"foo\"), screen=True, console=console, auto_refresh=False) as live:\n        live.refresh()\n    result = console.end_capture()\n    print(repr(result))\n    expected = \"\\x1b[?1049h\\x1b[H\\x1b[?25l\\x1b[Hfoo                 \\n                    \\n                    \\n                    \\n                    \\x1b[Hfoo                 \\n                    \\n                    \\n                    \\n                    \\x1b[?25h\\x1b[?1049l\"\n    assert result == expected\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "6824d4df23b0",
      "repo": "rich",
      "commit_hash": "82afcb4",
      "commit_message": "test fixes",
      "file_path": "tests/test_markdown.py",
      "language": "python",
      "code_before": "# coding=utf-8\n\nMARKDOWN = \"\"\"Heading\n=======\n\nSub-heading\n-----------\n\n### Heading\n\n#### H4 Heading\n\n##### H5 Heading\n\n###### H6 Heading\n\n\nParagraphs are separated\nby a blank line.\n\nTwo spaces at the end of a line\nproduces a line break.\n\nText attributes _italic_,\n**bold**, `monospace`.\n\nHorizontal rule:\n\n---\n\nBullet list:\n\n  * apples\n  * oranges\n  * pears\n\nNumbered list:\n\n  1. lather\n  2. rinse\n  3. repeat\n\nAn [example](http://example.com).\n\n> Markdown uses email-style > characters for blockquoting.\n>\n> Lorem ipsum\n\n![progress](https://github.com/textualize/rich/raw/master/imgs/progress.gif)\n\n\n```\na=1\n```\n\n```python\nimport this\n```\n\n```somelang\nfoobar\n```\n\n    import this\n\n\n1. List item\n\n       Code block\n\"\"\"\n\nimport io\nimport re\n\nfrom rich.console import Console, RenderableType\nfrom rich.markdown import Markdown\n\nre_link_ids = re.compile(r\"id=[\\d\\.\\-]*?;.*?\\x1b\")\n\n\ndef replace_link_ids(render: str) -> str:\n    \"\"\"Link IDs have a random ID and system path which is a problem for\n    reproducible tests.\n\n    \"\"\"\n    return re_link_ids.sub(\"id=0;foo\\x1b\", render)\n\n\ndef render(renderable: RenderableType) -> str:\n    console = Console(\n        width=100, file=io.StringIO(), color_system=\"truecolor\", legacy_windows=False\n    )\n    console.print(renderable)\n    output = replace_link_ids(console.file.getvalue())\n    print(repr(output))\n    return output\n\n\ndef test_markdown_render():\n    markdown = Markdown(MARKDOWN)\n    rendered_markdown = render(markdown)\n    expected = \"\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\\n\u2503                                             \\x1b[1mHeading\\x1b[0m                                              \u2503\\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\\n\\n\\n                                            \\x1b[1;4mSub-heading\\x1b[0m                                             \\n\\n                                              \\x1b[1mHeading\\x1b[0m                                               \\n\\n                                             \\x1b[1;2mH4 Heading\\x1b[0m                                             \\n\\n                                             \\x1b[4mH5 Heading\\x1b[0m                                             \\n\\n                                             \\x1b[3mH6 Heading\\x1b[0m                                             \\n\\nParagraphs are separated by a blank line.                                                           \\n\\nTwo spaces at the end of a line produces a line break.                                              \\n\\nText attributes \\x1b[3mitalic\\x1b[0m, \\x1b[1mbold\\x1b[0m, \\x1b[1;36;40mmonospace\\x1b[0m.                                                            \\n\\nHorizontal rule:                                                                                    \\n\\n\\x1b[33m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\nBullet list:                                                                                        \\n\\n\\x1b[1;33m \u2022 \\x1b[0mapples                                                                                           \\n\\x1b[1;33m \u2022 \\x1b[0moranges                                                                                          \\n\\x1b[1;33m \u2022 \\x1b[0mpears                                                                                            \\n\\nNumbered list:                                                                                      \\n\\n\\x1b[1;33m 1 \\x1b[0mlather                                                                                           \\n\\x1b[1;33m 2 \\x1b[0mrinse                                                                                            \\n\\x1b[1;33m 3 \\x1b[0mrepeat                                                                                           \\n\\nAn \\x1b]8;id=0;foo\\x1b\\\\\\x1b[4;34mexample\\x1b[0m\\x1b]8;;\\x1b\\\\.                                                                                         \\n\\n\\x1b[35m\u258c \\x1b[0m\\x1b[35mMarkdown uses email-style > characters for blockquoting.\\x1b[0m\\x1b[35m                                        \\x1b[0m\\n\\x1b[35m\u258c \\x1b[0m\\x1b[35mLorem ipsum\\x1b[0m\\x1b[35m                                                                                     \\x1b[0m\\n\\n\ud83c\udf06 \\x1b]8;id=0;foo\\x1b\\\\progress\\x1b]8;;\\x1b\\\\                                                                                         \\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34ma=1\\x1b[0m\\x1b[48;2;39;40;34m                                                                                               \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34mimport\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mthis\\x1b[0m\\x1b[48;2;39;40;34m                                                                                       \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfoobar\\x1b[0m\\x1b[48;2;39;40;34m                                                                                            \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mimport this\\x1b[0m\\x1b[48;2;39;40;34m                                                                                       \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[1;33m 1 \\x1b[0mList item                                                                                        \\n\\x1b[1;33m   \\x1b[0m\\x1b[48;2;39;40;34m                                                                                                 \\x1b[0m\\n\\x1b[1;33m   \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mCode block\\x1b[0m\\x1b[48;2;39;40;34m                                                                                     \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[1;33m   \\x1b[0m\\x1b[48;2;39;40;34m                                                                                                 \\x1b[0m\\n\"\n    assert rendered_markdown == expected\n\n\ndef test_inline_code():\n    markdown = Markdown(\n        \"inline `import this` code\",\n        inline_code_lexer=\"python\",\n        inline_code_theme=\"emacs\",\n    )\n    result = render(markdown)\n    expected = \"inline \\x1b[1;38;2;170;34;255;48;2;248;248;248mimport\\x1b[0m\\x1b[38;2;0;0;0;48;2;248;248;248m \\x1b[0m\\x1b[1;38;2;0;0;255;48;2;248;248;248mthis\\x1b[0m code                                                                             \\n\"\n    print(result)\n    print(repr(result))\n    assert result == expected\n\n\ndef test_markdown_table():\n    markdown = Markdown(\n        \"\"\"\\\n| Year |                      Title                       | Director          |  Box Office (USD) |\n|------|:------------------------------------------------:|:------------------|------------------:|\n| 1982 |            *E.T. the Extra-Terrestrial*          | Steven Spielberg  |    $792.9 million |\n| 1980 |  Star Wars: Episode V \u2013 The Empire Strikes Back  | Irvin Kershner    |    $538.4 million |\n| 1983 |    Star Wars: Episode VI \u2013 Return of the Jedi    | Richard Marquand  |    $475.1 million |\n| 1981 |             Raiders of the Lost Ark              | Steven Spielberg  |    $389.9 million |\n| 1984 |       Indiana Jones and the Temple of Doom       | Steven Spielberg  |    $333.1 million |\n\"\"\"\n    )\n    result = render(markdown)\n    expected = \"\\n                                                                                               \\n \\x1b[1m \\x1b[0m\\x1b[1mYear\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1m                    Title                     \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mDirector        \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mBox Office (USD)\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n  1982             \\x1b[3mE.T. the Extra-Terrestrial\\x1b[0m             Steven Spielberg     $792.9 million  \\n  1980   Star Wars: Episode V \u2013 The Empire Strikes Back   Irvin Kershner       $538.4 million  \\n  1983     Star Wars: Episode VI \u2013 Return of the Jedi     Richard Marquand     $475.1 million  \\n  1981              Raiders of the Lost Ark               Steven Spielberg     $389.9 million  \\n  1984        Indiana Jones and the Temple of Doom        Steven Spielberg     $333.1 million  \\n                                                                                               \\n\"\n    assert result == expected\n\n\ndef test_inline_styles_in_table():\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3115\"\"\"\n    markdown = Markdown(\n        \"\"\"\\\n| Year | This **column** displays _the_ movie _title_ ~~description~~ | Director          |  Box Office (USD) |\n|------|:----------------------------------------------------------:|:------------------|------------------:|\n| 1982 | *E.T. the Extra-Terrestrial* ([Wikipedia article](https://en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial)) | Steven Spielberg  |    $792.9 million |\n| 1980 |  Star Wars: Episode V \u2013 The *Empire* **Strikes** ~~Back~~  | Irvin Kershner    |    $538.4 million |\n\"\"\"\n    )\n    result = render(markdown)\n    expected = \"\\n                                                                                                 \\n \\x1b[1m \\x1b[0m\\x1b[1mYear\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mThis \\x1b[0m\\x1b[1mcolumn\\x1b[0m\\x1b[1m displays \\x1b[0m\\x1b[1;3mthe\\x1b[0m\\x1b[1m movie \\x1b[0m\\x1b[1;3mtitle\\x1b[0m\\x1b[1m \\x1b[0m\\x1b[1;9mdescription\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mDirector        \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mBox Office (USD)\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n  1982    \\x1b[3mE.T. the Extra-Terrestrial\\x1b[0m (\\x1b]8;id=0;foo\\x1b\\\\\\x1b[4;34mWikipedia article\\x1b[0m\\x1b]8;;\\x1b\\\\)    Steven Spielberg     $792.9 million  \\n  1980    Star Wars: Episode V \u2013 The \\x1b[3mEmpire\\x1b[0m \\x1b[1mStrikes\\x1b[0m \\x1b[9mBack\\x1b[0m    Irvin Kershner       $538.4 million  \\n                                                                                                 \\n\"\n    assert result == expected\n\n\ndef test_inline_styles_with_justification():\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3115\n\n    In particular, this tests the interaction between the change that was made to fix\n    #3115 and column text justification.\n    \"\"\"\n    markdown = Markdown(\n        \"\"\"\\\n| left | center | right |\n| :- | :-: | -: |\n| This is a long row | because it contains | a fairly long sentence. |\n| a*b* _c_ ~~d~~ e | a*b* _c_ ~~d~~ e | a*b* _c_ ~~d~~ e |\"\"\"\n    )\n    result = render(markdown)\n    expected = \"\\n                                                                      \\n \\x1b[1m \\x1b[0m\\x1b[1mleft              \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1m      center       \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1m                  right\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n  This is a long row   because it contains   a fairly long sentence.  \\n  a\\x1b[3mb\\x1b[0m \\x1b[3mc\\x1b[0m \\x1b[9md\\x1b[0m e                  a\\x1b[3mb\\x1b[0m \\x1b[3mc\\x1b[0m \\x1b[9md\\x1b[0m e                        a\\x1b[3mb\\x1b[0m \\x1b[3mc\\x1b[0m \\x1b[9md\\x1b[0m e  \\n                                                                      \\n\"\n    assert result == expected\n\n\ndef test_partial_table():\n    markdown = Markdown(\"| Simple | Table |\\n| ------ | ----- \")\n    result = render(markdown)\n    print(repr(result))\n    expected = \"\\n                  \\n \\x1b[1m \\x1b[0m\\x1b[1mSimple\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mTable\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n                  \\n\"\n    assert result == expected\n\n\ndef test_table_with_empty_cells() -> None:\n    \"\"\"Test a table with empty cells is rendered without extra newlines above.\n    Regression test for #3027 https://github.com/Textualize/rich/issues/3027\n    \"\"\"\n    complete_table = Markdown(\n        \"\"\"\\\n| First Header  | Second Header |\n| ------------- | ------------- |\n| Content Cell  | Content Cell  |\n| Content Cell  | Content Cell  |\n\"\"\"\n    )\n    table_with_empty_cells = Markdown(\n        \"\"\"\\\n| First Header  |               |\n| ------------- | ------------- |\n| Content Cell  | Content Cell  |\n|               | Content Cell  |\n\"\"\"\n    )\n    result = len(render(table_with_empty_cells).splitlines())\n    expected = len(render(complete_table).splitlines())\n    assert result == expected\n\n\nif __name__ == \"__main__\":\n    markdown = Markdown(MARKDOWN)\n    rendered = render(markdown)\n    print(rendered)\n    print(repr(rendered))\n",
      "code_after": "# coding=utf-8\n\nMARKDOWN = \"\"\"Heading\n=======\n\nSub-heading\n-----------\n\n### Heading\n\n#### H4 Heading\n\n##### H5 Heading\n\n###### H6 Heading\n\n\nParagraphs are separated\nby a blank line.\n\nTwo spaces at the end of a line\nproduces a line break.\n\nText attributes _italic_,\n**bold**, `monospace`.\n\nHorizontal rule:\n\n---\n\nBullet list:\n\n  * apples\n  * oranges\n  * pears\n\nNumbered list:\n\n  1. lather\n  2. rinse\n  3. repeat\n\nAn [example](http://example.com).\n\n> Markdown uses email-style > characters for blockquoting.\n>\n> Lorem ipsum\n\n![progress](https://github.com/textualize/rich/raw/master/imgs/progress.gif)\n\n\n```\na=1\n```\n\n```python\nimport this\n```\n\n```somelang\nfoobar\n```\n\n    import this\n\n\n1. List item\n\n       Code block\n\"\"\"\n\nimport io\nimport re\n\nfrom rich.console import Console, RenderableType\nfrom rich.markdown import Markdown\n\nre_link_ids = re.compile(r\"id=[\\d\\.\\-]*?;.*?\\x1b\")\n\n\ndef replace_link_ids(render: str) -> str:\n    \"\"\"Link IDs have a random ID and system path which is a problem for\n    reproducible tests.\n\n    \"\"\"\n    return re_link_ids.sub(\"id=0;foo\\x1b\", render)\n\n\ndef render(renderable: RenderableType) -> str:\n    console = Console(\n        width=100, file=io.StringIO(), color_system=\"truecolor\", legacy_windows=False\n    )\n    console.print(renderable)\n    output = replace_link_ids(console.file.getvalue())\n    print(repr(output))\n    return output\n\n\ndef test_markdown_render():\n    markdown = Markdown(MARKDOWN)\n    rendered_markdown = render(markdown)\n    expected = \"\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\\n\u2503                                             \\x1b[1mHeading\\x1b[0m                                              \u2503\\n\u2517\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u251b\\n\\n\\n                                            \\x1b[1;4mSub-heading\\x1b[0m                                             \\n\\n                                              \\x1b[1mHeading\\x1b[0m                                               \\n\\n                                             \\x1b[1;2mH4 Heading\\x1b[0m                                             \\n\\n                                             \\x1b[4mH5 Heading\\x1b[0m                                             \\n\\n                                             \\x1b[3mH6 Heading\\x1b[0m                                             \\n\\nParagraphs are separated by a blank line.                                                           \\n\\nTwo spaces at the end of a line produces a line break.                                              \\n\\nText attributes \\x1b[3mitalic\\x1b[0m, \\x1b[1mbold\\x1b[0m, \\x1b[1;36;40mmonospace\\x1b[0m.                                                            \\n\\nHorizontal rule:                                                                                    \\n\\n\\x1b[33m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\nBullet list:                                                                                        \\n\\n\\x1b[1;33m \u2022 \\x1b[0mapples                                                                                           \\n\\x1b[1;33m \u2022 \\x1b[0moranges                                                                                          \\n\\x1b[1;33m \u2022 \\x1b[0mpears                                                                                            \\n\\nNumbered list:                                                                                      \\n\\n\\x1b[1;33m 1 \\x1b[0mlather                                                                                           \\n\\x1b[1;33m 2 \\x1b[0mrinse                                                                                            \\n\\x1b[1;33m 3 \\x1b[0mrepeat                                                                                           \\n\\nAn \\x1b]8;id=0;foo\\x1b\\\\\\x1b[4;34mexample\\x1b[0m\\x1b]8;;\\x1b\\\\.                                                                                         \\n\\n\\x1b[35m\u258c \\x1b[0m\\x1b[35mMarkdown uses email-style > characters for blockquoting.\\x1b[0m\\x1b[35m                                        \\x1b[0m\\n\\x1b[35m\u258c \\x1b[0m\\x1b[35mLorem ipsum\\x1b[0m\\x1b[35m                                                                                     \\x1b[0m\\n\\n\ud83c\udf06 \\x1b]8;id=0;foo\\x1b\\\\progress\\x1b]8;;\\x1b\\\\                                                                                         \\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34ma=1\\x1b[0m\\x1b[48;2;39;40;34m                                                                                               \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34mimport\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mthis\\x1b[0m\\x1b[48;2;39;40;34m                                                                                       \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfoobar\\x1b[0m\\x1b[48;2;39;40;34m                                                                                            \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mimport this\\x1b[0m\\x1b[48;2;39;40;34m                                                                                       \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[48;2;39;40;34m                                                                                                    \\x1b[0m\\n\\n\\x1b[1;33m 1 \\x1b[0mList item                                                                                        \\n\\x1b[1;33m   \\x1b[0m\\x1b[48;2;39;40;34m                                                                                                 \\x1b[0m\\n\\x1b[1;33m   \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mCode block\\x1b[0m\\x1b[48;2;39;40;34m                                                                                     \\x1b[0m\\x1b[48;2;39;40;34m \\x1b[0m\\n\\x1b[1;33m   \\x1b[0m\\x1b[48;2;39;40;34m                                                                                                 \\x1b[0m\\n\"\n    assert rendered_markdown == expected\n\n\ndef test_inline_code():\n    markdown = Markdown(\n        \"inline `import this` code\",\n        inline_code_lexer=\"python\",\n        inline_code_theme=\"emacs\",\n    )\n    result = render(markdown)\n    expected = \"inline \\x1b[1;38;2;170;34;255;48;2;248;248;248mimport\\x1b[0m\\x1b[38;2;187;187;187;48;2;248;248;248m \\x1b[0m\\x1b[1;38;2;0;0;255;48;2;248;248;248mthis\\x1b[0m code                                                                             \\n\"\n    print(result)\n    print(repr(result))\n    assert result == expected\n\n\ndef test_markdown_table():\n    markdown = Markdown(\n        \"\"\"\\\n| Year |                      Title                       | Director          |  Box Office (USD) |\n|------|:------------------------------------------------:|:------------------|------------------:|\n| 1982 |            *E.T. the Extra-Terrestrial*          | Steven Spielberg  |    $792.9 million |\n| 1980 |  Star Wars: Episode V \u2013 The Empire Strikes Back  | Irvin Kershner    |    $538.4 million |\n| 1983 |    Star Wars: Episode VI \u2013 Return of the Jedi    | Richard Marquand  |    $475.1 million |\n| 1981 |             Raiders of the Lost Ark              | Steven Spielberg  |    $389.9 million |\n| 1984 |       Indiana Jones and the Temple of Doom       | Steven Spielberg  |    $333.1 million |\n\"\"\"\n    )\n    result = render(markdown)\n    expected = \"\\n                                                                                               \\n \\x1b[1m \\x1b[0m\\x1b[1mYear\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1m                    Title                     \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mDirector        \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mBox Office (USD)\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n  1982             \\x1b[3mE.T. the Extra-Terrestrial\\x1b[0m             Steven Spielberg     $792.9 million  \\n  1980   Star Wars: Episode V \u2013 The Empire Strikes Back   Irvin Kershner       $538.4 million  \\n  1983     Star Wars: Episode VI \u2013 Return of the Jedi     Richard Marquand     $475.1 million  \\n  1981              Raiders of the Lost Ark               Steven Spielberg     $389.9 million  \\n  1984        Indiana Jones and the Temple of Doom        Steven Spielberg     $333.1 million  \\n                                                                                               \\n\"\n    assert result == expected\n\n\ndef test_inline_styles_in_table():\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3115\"\"\"\n    markdown = Markdown(\n        \"\"\"\\\n| Year | This **column** displays _the_ movie _title_ ~~description~~ | Director          |  Box Office (USD) |\n|------|:----------------------------------------------------------:|:------------------|------------------:|\n| 1982 | *E.T. the Extra-Terrestrial* ([Wikipedia article](https://en.wikipedia.org/wiki/E.T._the_Extra-Terrestrial)) | Steven Spielberg  |    $792.9 million |\n| 1980 |  Star Wars: Episode V \u2013 The *Empire* **Strikes** ~~Back~~  | Irvin Kershner    |    $538.4 million |\n\"\"\"\n    )\n    result = render(markdown)\n    expected = \"\\n                                                                                                 \\n \\x1b[1m \\x1b[0m\\x1b[1mYear\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mThis \\x1b[0m\\x1b[1mcolumn\\x1b[0m\\x1b[1m displays \\x1b[0m\\x1b[1;3mthe\\x1b[0m\\x1b[1m movie \\x1b[0m\\x1b[1;3mtitle\\x1b[0m\\x1b[1m \\x1b[0m\\x1b[1;9mdescription\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mDirector        \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mBox Office (USD)\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n  1982    \\x1b[3mE.T. the Extra-Terrestrial\\x1b[0m (\\x1b]8;id=0;foo\\x1b\\\\\\x1b[4;34mWikipedia article\\x1b[0m\\x1b]8;;\\x1b\\\\)    Steven Spielberg     $792.9 million  \\n  1980    Star Wars: Episode V \u2013 The \\x1b[3mEmpire\\x1b[0m \\x1b[1mStrikes\\x1b[0m \\x1b[9mBack\\x1b[0m    Irvin Kershner       $538.4 million  \\n                                                                                                 \\n\"\n    assert result == expected\n\n\ndef test_inline_styles_with_justification():\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3115\n\n    In particular, this tests the interaction between the change that was made to fix\n    #3115 and column text justification.\n    \"\"\"\n    markdown = Markdown(\n        \"\"\"\\\n| left | center | right |\n| :- | :-: | -: |\n| This is a long row | because it contains | a fairly long sentence. |\n| a*b* _c_ ~~d~~ e | a*b* _c_ ~~d~~ e | a*b* _c_ ~~d~~ e |\"\"\"\n    )\n    result = render(markdown)\n    expected = \"\\n                                                                      \\n \\x1b[1m \\x1b[0m\\x1b[1mleft              \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1m      center       \\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1m                  right\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n  This is a long row   because it contains   a fairly long sentence.  \\n  a\\x1b[3mb\\x1b[0m \\x1b[3mc\\x1b[0m \\x1b[9md\\x1b[0m e                  a\\x1b[3mb\\x1b[0m \\x1b[3mc\\x1b[0m \\x1b[9md\\x1b[0m e                        a\\x1b[3mb\\x1b[0m \\x1b[3mc\\x1b[0m \\x1b[9md\\x1b[0m e  \\n                                                                      \\n\"\n    assert result == expected\n\n\ndef test_partial_table():\n    markdown = Markdown(\"| Simple | Table |\\n| ------ | ----- \")\n    result = render(markdown)\n    print(repr(result))\n    expected = \"\\n                  \\n \\x1b[1m \\x1b[0m\\x1b[1mSimple\\x1b[0m\\x1b[1m \\x1b[0m \\x1b[1m \\x1b[0m\\x1b[1mTable\\x1b[0m\\x1b[1m \\x1b[0m \\n \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 \\n                  \\n\"\n    assert result == expected\n\n\ndef test_table_with_empty_cells() -> None:\n    \"\"\"Test a table with empty cells is rendered without extra newlines above.\n    Regression test for #3027 https://github.com/Textualize/rich/issues/3027\n    \"\"\"\n    complete_table = Markdown(\n        \"\"\"\\\n| First Header  | Second Header |\n| ------------- | ------------- |\n| Content Cell  | Content Cell  |\n| Content Cell  | Content Cell  |\n\"\"\"\n    )\n    table_with_empty_cells = Markdown(\n        \"\"\"\\\n| First Header  |               |\n| ------------- | ------------- |\n| Content Cell  | Content Cell  |\n|               | Content Cell  |\n\"\"\"\n    )\n    result = len(render(table_with_empty_cells).splitlines())\n    expected = len(render(complete_table).splitlines())\n    assert result == expected\n\n\nif __name__ == \"__main__\":\n    markdown = Markdown(MARKDOWN)\n    rendered = render(markdown)\n    print(rendered)\n    print(repr(rendered))\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "951e1f4c2669",
      "repo": "rich",
      "commit_hash": "82afcb4",
      "commit_message": "test fixes",
      "file_path": "tests/test_syntax.py",
      "language": "python",
      "code_before": "import io\nimport os\nimport sys\nimport tempfile\n\nimport pytest\nfrom pygments.lexers import PythonLexer\n\nfrom rich.measure import Measurement\nfrom rich.panel import Panel\nfrom rich.style import Style\nfrom rich.syntax import (\n    ANSISyntaxTheme,\n    Color,\n    Console,\n    PygmentsSyntaxTheme,\n    Syntax,\n    _SyntaxHighlightRange,\n)\n\nfrom .render import render\n\nif sys.version_info >= (3, 8):\n    from importlib.metadata import Distribution\nelse:\n    from importlib_metadata import Distribution\n\nPYGMENTS_VERSION = Distribution.from_name(\"pygments\").version\nOLD_PYGMENTS = PYGMENTS_VERSION == \"2.13.0\"\n\nCODE = '''\\\ndef loop_first_last(values: Iterable[T]) -> Iterable[Tuple[bool, bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    first = True\n    for value in iter_values:\n        yield first, False, previous_value\n        first = False\n        previous_value = value\n    yield first, True, previous_value'''\n\n\ndef test_blank_lines():\n    code = \"\\n\\nimport this\\n\\n\"\n    syntax = Syntax(\n        code, lexer=\"python\", theme=\"ascii_light\", code_width=30, line_numbers=True\n    )\n    result = render(syntax)\n    print(repr(result))\n    assert (\n        result\n        == \"\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m1 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m2 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m3 \\x1b[0m\\x1b[1;38;2;0;128;0;48;2;248;248;248mimport\\x1b[0m\\x1b[38;2;0;0;0;48;2;248;248;248m \\x1b[0m\\x1b[1;38;2;0;0;255;48;2;248;248;248mthis\\x1b[0m\\x1b[48;2;248;248;248m                   \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m4 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m5 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\"\n    )\n\n\ndef test_python_render():\n    syntax = Panel.fit(\n        Syntax(\n            CODE,\n            lexer=\"python\",\n            line_numbers=True,\n            line_range=(2, 10),\n            theme=\"monokai\",\n            code_width=60,\n            word_wrap=True,\n        ),\n        padding=0,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 2 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first \\x1b[0m\\x1b[48;2;39;40;34m  \\x1b[0m\u2502\\n\u2502\\x1b[48;2;39;40;34m     \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34mand last value.\"\"\"\\x1b[0m\\x1b[48;2;39;40;34m                                          \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 3 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 4 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 5 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 6 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 7 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 8 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 9 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m10 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n'\n    assert rendered_syntax == expected\n\n\ndef test_python_render_simple():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=False,\n        theme=\"monokai\",\n        code_width=60,\n        word_wrap=False,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[38;2;102;217;239;48;2;39;40;34mdef\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mloop_first_last\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m-\\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m>\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mTuple\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mb\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[48;2;39;40;34m                                       \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                       \\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\ndef test_python_render_simple_passing_lexer_instance():\n    syntax = Syntax(\n        CODE,\n        lexer=PythonLexer(),\n        line_numbers=False,\n        theme=\"monokai\",\n        code_width=60,\n        word_wrap=False,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[38;2;102;217;239;48;2;39;40;34mdef\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mloop_first_last\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m-\\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m>\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mTuple\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mb\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[48;2;39;40;34m                                       \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                       \\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\n@pytest.mark.skipif(OLD_PYGMENTS, reason=\"Pygments changed their tokenizer\")\ndef test_python_render_simple_indent_guides():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=False,\n        theme=\"ansi_light\",\n        code_width=60,\n        word_wrap=False,\n        indent_guides=True,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[34mdef\\x1b[0m \\x1b[32mloop_first_last\\x1b[0m(values: Iterable[T]) -> Iterable[Tuple[\\x1b[36mb\\x1b[0m\\n\\x1b[2;37m\u2502   \\x1b[0m\\x1b[33m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0miter_values = \\x1b[36miter\\x1b[0m(values)\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34mtry\\x1b[0m:\\n\\x1b[2m\u2502   \u2502   \\x1b[0mprevious_value = \\x1b[36mnext\\x1b[0m(iter_values)\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34mexcept\\x1b[0m \\x1b[36mStopIteration\\x1b[0m:\\n\\x1b[2m\u2502   \u2502   \\x1b[0m\\x1b[34mreturn\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0mfirst = \\x1b[34mTrue\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34mfor\\x1b[0m value \\x1b[35min\\x1b[0m iter_values:\\n\\x1b[2m\u2502   \u2502   \\x1b[0m\\x1b[34myield\\x1b[0m first, \\x1b[34mFalse\\x1b[0m, previous_value\\n\\x1b[2m\u2502   \u2502   \\x1b[0mfirst = \\x1b[34mFalse\\x1b[0m\\n\\x1b[2m\u2502   \u2502   \\x1b[0mprevious_value = value\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34myield\\x1b[0m first, \\x1b[34mTrue\\x1b[0m, previous_value\\n'\n    assert rendered_syntax == expected\n\n\n@pytest.mark.skipif(OLD_PYGMENTS, reason=\"Pygments changed their tokenizer\")\ndef test_python_render_line_range_indent_guides():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=False,\n        theme=\"ansi_light\",\n        code_width=60,\n        word_wrap=False,\n        line_range=(2, 3),\n        indent_guides=True,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[2;37m\u2502   \\x1b[0m\\x1b[33m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0miter_values = \\x1b[36miter\\x1b[0m(values)\\n'\n    assert rendered_syntax == expected\n\n\ndef test_python_render_indent_guides():\n    syntax = Panel.fit(\n        Syntax(\n            CODE,\n            lexer=\"python\",\n            line_numbers=True,\n            line_range=(2, 10),\n            theme=\"monokai\",\n            code_width=60,\n            word_wrap=True,\n            indent_guides=True,\n        ),\n        padding=0,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 2 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first \\x1b[0m\\x1b[48;2;39;40;34m  \\x1b[0m\u2502\\n\u2502\\x1b[48;2;39;40;34m     \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34mand last value.\"\"\"\\x1b[0m\\x1b[48;2;39;40;34m                                          \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 3 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 4 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 5 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \u2502   \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 6 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 7 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 8 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 9 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m10 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n'\n    assert rendered_syntax == expected\n\n\ndef test_pygments_syntax_theme_non_str():\n    from pygments.style import Style as PygmentsStyle\n\n    style = PygmentsSyntaxTheme(PygmentsStyle())\n    assert style.get_background_style().bgcolor == Color.parse(\"#ffffff\")\n\n\ndef test_pygments_syntax_theme():\n    style = PygmentsSyntaxTheme(\"default\")\n    assert style.get_style_for_token(\"abc\") == Style.parse(\"none\")\n\n\ndef test_get_line_color_none():\n    style = PygmentsSyntaxTheme(\"default\")\n    style._background_style = Style(bgcolor=None)\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        theme=style,\n        code_width=60,\n        word_wrap=True,\n        background_color=\"red\",\n    )\n    assert syntax._get_line_numbers_color() == Color.default()\n\n\ndef test_highlight_background_color():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        theme=\"foo\",\n        code_width=60,\n        word_wrap=True,\n        background_color=\"red\",\n    )\n    assert syntax.highlight(CODE).style == Style.parse(\"on red\")\n\n\ndef test_get_number_styles():\n    syntax = Syntax(CODE, \"python\", theme=\"monokai\", line_numbers=True)\n    console = Console(color_system=\"windows\")\n    assert syntax._get_number_styles(console=console) == (\n        Style.parse(\"on #272822\"),\n        Style.parse(\"dim on #272822\"),\n        Style.parse(\"not dim on #272822\"),\n    )\n\n\ndef test_get_style_for_token():\n    # from pygments.style import Style as PygmentsStyle\n    # pygments_style = PygmentsStyle()\n    from pygments.style import Token\n\n    style = PygmentsSyntaxTheme(\"default\")\n    style_dict = {Token.Text: Style(color=None)}\n    style._style_cache = style_dict\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        theme=style,\n        code_width=60,\n        word_wrap=True,\n        background_color=\"red\",\n    )\n    assert syntax._get_line_numbers_color() == Color.default()\n\n\ndef test_option_no_wrap():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        code_width=60,\n        word_wrap=False,\n        background_color=\"red\",\n    )\n\n    rendered_syntax = render(syntax, True)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 2 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;230;219;116;41m\"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 3 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;248;248;242;41miter_values\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41miter\\x1b[0m\\x1b[38;2;248;248;242;41m(\\x1b[0m\\x1b[38;2;248;248;242;41mvalues\\x1b[0m\\x1b[38;2;248;248;242;41m)\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 4 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;102;217;239;41mtry\\x1b[0m\\x1b[38;2;248;248;242;41m:\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 5 \\x1b[0m\\x1b[38;2;248;248;242;41m        \\x1b[0m\\x1b[38;2;248;248;242;41mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mnext\\x1b[0m\\x1b[38;2;248;248;242;41m(\\x1b[0m\\x1b[38;2;248;248;242;41miter_values\\x1b[0m\\x1b[38;2;248;248;242;41m)\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 6 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;102;217;239;41mexcept\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;166;226;46;41mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;41m:\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 7 \\x1b[0m\\x1b[38;2;248;248;242;41m        \\x1b[0m\\x1b[38;2;102;217;239;41mreturn\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 8 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;248;248;242;41mfirst\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;102;217;239;41mTrue\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 9 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;102;217;239;41mfor\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mvalue\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41min\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41miter_values\\x1b[0m\\x1b[38;2;248;248;242;41m:\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m10 \\x1b[0m\\x1b[38;2;248;248;242;41m        \\x1b[0m\\x1b[38;2;102;217;239;41myield\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mfirst\\x1b[0m\\x1b[38;2;248;248;242;41m,\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;102;217;239;41mFalse\\x1b[0m\\x1b[38;2;248;248;242;41m,\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mprevious_value\\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\ndef test_syntax_highlight_ranges():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        word_wrap=False,\n    )\n    stylized_ranges = [\n        _SyntaxHighlightRange(\n            # overline the 2nd char of the 1st line:\n            start=(1, 1),\n            end=(1, 2),\n            style=Style(overline=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(1, len(\"def loop_\")),\n            end=(1, len(\"def loop_first_last\")),\n            style=Style(underline=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(1, len(\"def loop_first\")),\n            end=(3, len(\"    iter_values = iter\")),\n            style=Style(bold=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(9, len(\"    for \")),\n            end=(9, len(\"    for value in\")),\n            style=Style(strike=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(6, len(\"    except \")),\n            end=(6, len(\"    except StopIteration\")),\n            style=Style(reverse=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(10, len(\"       yield first,\")),\n            # `column_index` is out of range: should be clamped to the line length:\n            end=(10, 300),\n            style=Style(bold=True),\n        ),\n        # For this one the end `line_number` is out of range, so it should have no impact:\n        _SyntaxHighlightRange(\n            start=(1, 1),\n            end=(30, 2),\n            style=Style(bold=True),\n        ),\n    ]\n    for range_ in stylized_ranges:\n        syntax.stylize_range(range_.style, range_.start, range_.end)\n    rendered_syntax = render(syntax, True)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 1 \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34md\\x1b[0m\\x1b[53;38;2;102;217;239;48;2;39;40;34me\\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mf\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mloop_\\x1b[0m\\x1b[4;38;2;166;226;46;48;2;39;40;34mfirst\\x1b[0m\\x1b[1;4;38;2;166;226;46;48;2;39;40;34m_last\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;255;70;137;48;2;39;40;34m-\\x1b[0m\\x1b[1;38;2;255;70;137;48;2;39;40;34m>\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mTuple\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mbool\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mbool\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 2 \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[1;38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 3 \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 4 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 5 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 6 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[7;38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 7 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 8 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 9 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[9;38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[9;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[9;38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m10 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m11 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m12 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m13 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\ndef test_ansi_theme():\n    style = Style(color=\"red\")\n    theme = ANSISyntaxTheme({(\"foo\", \"bar\"): style})\n    assert theme.get_style_for_token((\"foo\", \"bar\", \"baz\")) == style\n    assert theme.get_background_style() == Style()\n\n\nskip_windows_permission_error = pytest.mark.skipif(\n    sys.platform == \"win32\", reason=\"permissions error on Windows\"\n)\n\n\n@skip_windows_permission_error\ndef test_from_path():\n    fh, path = tempfile.mkstemp(\"example.py\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path)\n        assert syntax.lexer\n        assert syntax.lexer.name == \"Python\"\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\n@skip_windows_permission_error\ndef test_from_path_unknown_lexer():\n    fh, path = tempfile.mkstemp(\"example.nosuchtype\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path)\n        assert syntax.lexer is None\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\n@skip_windows_permission_error\ndef test_from_path_lexer_override():\n    fh, path = tempfile.mkstemp(\"example.nosuchtype\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path, lexer=\"rust\")\n        assert syntax.lexer.name == \"Rust\"\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\n@skip_windows_permission_error\ndef test_from_path_lexer_override_invalid_lexer():\n    fh, path = tempfile.mkstemp(\"example.nosuchtype\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path, lexer=\"blah\")\n        assert syntax.lexer is None\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\ndef test_syntax_guess_lexer():\n    assert Syntax.guess_lexer(\"banana.py\") == \"python\"\n    assert Syntax.guess_lexer(\"banana.py\", \"import this\") == \"python\"\n    assert Syntax.guess_lexer(\"banana.html\", \"<a href='#'>hello</a>\") == \"html\"\n    assert Syntax.guess_lexer(\"banana.html\", \"<%= @foo %>\") == \"rhtml\"\n    assert Syntax.guess_lexer(\"banana.html\", \"{{something|filter:3}}\") == \"html+django\"\n\n\ndef test_syntax_padding():\n    syntax = Syntax(\"x = 1\", lexer=\"python\", padding=(1, 3))\n    console = Console(\n        width=20,\n        file=io.StringIO(),\n        color_system=\"truecolor\",\n        legacy_windows=False,\n        record=True,\n    )\n    console.print(syntax)\n    output = console.export_text()\n    assert (\n        output == \"                    \\n   x = 1            \\n                    \\n\"\n    )\n\n\ndef test_syntax_measure():\n    console = Console()\n    code = Syntax(\"Hello, World\", \"python\")\n    assert code.__rich_measure__(console, console.options) == Measurement(0, 12)\n\n    code = Syntax(\"Hello, World\", \"python\", line_numbers=True)\n    assert code.__rich_measure__(console, console.options) == Measurement(3, 16)\n\n    code = Syntax(\"Hello, World\", \"python\", code_width=20, line_numbers=True)\n    assert code.__rich_measure__(console, console.options) == Measurement(3, 24)\n\n    code = Syntax(\"\", \"python\", code_width=20, line_numbers=True)\n    assert code.__rich_measure__(console, console.options) == Measurement(3, 24)\n\n\ndef test_background_color_override_includes_padding():\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3295\"\"\"\n\n    syntax = Syntax(\n        \"x = 1\",\n        lexer=\"python\",\n        padding=(1, 3),\n        background_color=\"red\",\n    )\n    result = render(syntax)\n    print(repr(result))\n    assert (\n        result\n        == \"\\x1b[41m                                                                                                    \\x1b[0m\\n\\x1b[41m   \\x1b[0m\\x1b[38;2;248;248;242;41mx\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;174;129;255;41m1\\x1b[0m\\x1b[41m                                                                                         \\x1b[0m\\x1b[41m   \\x1b[0m\\n\\x1b[41m                                                                                                    \\x1b[0m\\n\"\n    )\n\n\nif __name__ == \"__main__\":\n    syntax = Panel.fit(\n        Syntax(\n            CODE,\n            lexer=\"python\",\n            line_numbers=True,\n            line_range=(2, 10),\n            theme=\"foo\",\n            code_width=60,\n            word_wrap=True,\n        ),\n        padding=0,\n    )\n    rendered = render(markdown)\n    print(rendered)\n    print(repr(rendered))\n",
      "code_after": "import io\nimport os\nimport sys\nimport tempfile\n\nimport pytest\nfrom pygments.lexers import PythonLexer\n\nfrom rich.measure import Measurement\nfrom rich.panel import Panel\nfrom rich.style import Style\nfrom rich.syntax import (\n    ANSISyntaxTheme,\n    Color,\n    Console,\n    PygmentsSyntaxTheme,\n    Syntax,\n    _SyntaxHighlightRange,\n)\n\nfrom .render import render\n\nif sys.version_info >= (3, 8):\n    from importlib.metadata import Distribution\nelse:\n    from importlib_metadata import Distribution\n\nPYGMENTS_VERSION = Distribution.from_name(\"pygments\").version\nOLD_PYGMENTS = PYGMENTS_VERSION == \"2.13.0\"\n\nCODE = '''\\\ndef loop_first_last(values: Iterable[T]) -> Iterable[Tuple[bool, bool, T]]:\n    \"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\n    iter_values = iter(values)\n    try:\n        previous_value = next(iter_values)\n    except StopIteration:\n        return\n    first = True\n    for value in iter_values:\n        yield first, False, previous_value\n        first = False\n        previous_value = value\n    yield first, True, previous_value'''\n\n\ndef test_blank_lines():\n    code = \"\\n\\nimport this\\n\\n\"\n    syntax = Syntax(\n        code, lexer=\"python\", theme=\"ascii_light\", code_width=30, line_numbers=True\n    )\n    result = render(syntax)\n    print(repr(result))\n    assert (\n        result\n        == \"\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m1 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m2 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m3 \\x1b[0m\\x1b[1;38;2;0;128;0;48;2;248;248;248mimport\\x1b[0m\\x1b[38;2;187;187;187;48;2;248;248;248m \\x1b[0m\\x1b[1;38;2;0;0;255;48;2;248;248;248mthis\\x1b[0m\\x1b[48;2;248;248;248m                   \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m4 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\\x1b[1;38;2;24;24;24;48;2;248;248;248m  \\x1b[0m\\x1b[38;2;173;173;173;48;2;248;248;248m5 \\x1b[0m\\x1b[48;2;248;248;248m                              \\x1b[0m\\n\"\n    )\n\n\ndef test_python_render():\n    syntax = Panel.fit(\n        Syntax(\n            CODE,\n            lexer=\"python\",\n            line_numbers=True,\n            line_range=(2, 10),\n            theme=\"monokai\",\n            code_width=60,\n            word_wrap=True,\n        ),\n        padding=0,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 2 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first \\x1b[0m\\x1b[48;2;39;40;34m  \\x1b[0m\u2502\\n\u2502\\x1b[48;2;39;40;34m     \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34mand last value.\"\"\"\\x1b[0m\\x1b[48;2;39;40;34m                                          \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 3 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 4 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 5 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 6 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 7 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 8 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 9 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m10 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n'\n    assert rendered_syntax == expected\n\n\ndef test_python_render_simple():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=False,\n        theme=\"monokai\",\n        code_width=60,\n        word_wrap=False,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[38;2;102;217;239;48;2;39;40;34mdef\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mloop_first_last\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m-\\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m>\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mTuple\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mb\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[48;2;39;40;34m                                       \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                       \\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\ndef test_python_render_simple_passing_lexer_instance():\n    syntax = Syntax(\n        CODE,\n        lexer=PythonLexer(),\n        line_numbers=False,\n        theme=\"monokai\",\n        code_width=60,\n        word_wrap=False,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[38;2;102;217;239;48;2;39;40;34mdef\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mloop_first_last\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m-\\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m>\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mTuple\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mb\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[48;2;39;40;34m                                       \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\\n\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                       \\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\n@pytest.mark.skipif(OLD_PYGMENTS, reason=\"Pygments changed their tokenizer\")\ndef test_python_render_simple_indent_guides():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=False,\n        theme=\"ansi_light\",\n        code_width=60,\n        word_wrap=False,\n        indent_guides=True,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[34mdef\\x1b[0m\\x1b[37m \\x1b[0m\\x1b[32mloop_first_last\\x1b[0m(values: Iterable[T]) -> Iterable[Tuple[\\x1b[36mb\\x1b[0m\\n\\x1b[2;37m\u2502   \\x1b[0m\\x1b[33m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0miter_values = \\x1b[36miter\\x1b[0m(values)\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34mtry\\x1b[0m:\\n\\x1b[2m\u2502   \u2502   \\x1b[0mprevious_value = \\x1b[36mnext\\x1b[0m(iter_values)\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34mexcept\\x1b[0m \\x1b[36mStopIteration\\x1b[0m:\\n\\x1b[2m\u2502   \u2502   \\x1b[0m\\x1b[34mreturn\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0mfirst = \\x1b[34mTrue\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34mfor\\x1b[0m value \\x1b[35min\\x1b[0m iter_values:\\n\\x1b[2m\u2502   \u2502   \\x1b[0m\\x1b[34myield\\x1b[0m first, \\x1b[34mFalse\\x1b[0m, previous_value\\n\\x1b[2m\u2502   \u2502   \\x1b[0mfirst = \\x1b[34mFalse\\x1b[0m\\n\\x1b[2m\u2502   \u2502   \\x1b[0mprevious_value = value\\n\\x1b[2m\u2502   \\x1b[0m\\x1b[34myield\\x1b[0m first, \\x1b[34mTrue\\x1b[0m, previous_value\\n'\n    assert rendered_syntax == expected\n\n\n@pytest.mark.skipif(OLD_PYGMENTS, reason=\"Pygments changed their tokenizer\")\ndef test_python_render_line_range_indent_guides():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=False,\n        theme=\"ansi_light\",\n        code_width=60,\n        word_wrap=False,\n        line_range=(2, 3),\n        indent_guides=True,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[2;37m\u2502   \\x1b[0m\\x1b[33m\"\"\"Iterate and generate a tuple with a flag for first an\\x1b[0m\\n\\x1b[2m\u2502   \\x1b[0miter_values = \\x1b[36miter\\x1b[0m(values)\\n'\n    assert rendered_syntax == expected\n\n\ndef test_python_render_indent_guides():\n    syntax = Panel.fit(\n        Syntax(\n            CODE,\n            lexer=\"python\",\n            line_numbers=True,\n            line_range=(2, 10),\n            theme=\"monokai\",\n            code_width=60,\n            word_wrap=True,\n            indent_guides=True,\n        ),\n        padding=0,\n    )\n    rendered_syntax = render(syntax)\n    print(repr(rendered_syntax))\n    expected = '\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 2 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first \\x1b[0m\\x1b[48;2;39;40;34m  \\x1b[0m\u2502\\n\u2502\\x1b[48;2;39;40;34m     \\x1b[0m\\x1b[38;2;230;219;116;48;2;39;40;34mand last value.\"\"\"\\x1b[0m\\x1b[48;2;39;40;34m                                          \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 3 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 4 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                                    \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 5 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \u2502   \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 6 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                                   \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 7 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\x1b[48;2;39;40;34m                                              \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 8 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[48;2;39;40;34m                                            \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 9 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[48;2;39;40;34m                               \\x1b[0m\u2502\\n\u2502\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m10 \\x1b[0m\\x1b[2;38;2;149;144;119;48;2;39;40;34m\u2502   \u2502   \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[48;2;39;40;34m                  \\x1b[0m\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n'\n    assert rendered_syntax == expected\n\n\ndef test_pygments_syntax_theme_non_str():\n    from pygments.style import Style as PygmentsStyle\n\n    style = PygmentsSyntaxTheme(PygmentsStyle())\n    assert style.get_background_style().bgcolor == Color.parse(\"#ffffff\")\n\n\ndef test_pygments_syntax_theme():\n    style = PygmentsSyntaxTheme(\"default\")\n    assert style.get_style_for_token(\"abc\") == Style.parse(\"none\")\n\n\ndef test_get_line_color_none():\n    style = PygmentsSyntaxTheme(\"default\")\n    style._background_style = Style(bgcolor=None)\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        theme=style,\n        code_width=60,\n        word_wrap=True,\n        background_color=\"red\",\n    )\n    assert syntax._get_line_numbers_color() == Color.default()\n\n\ndef test_highlight_background_color():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        theme=\"foo\",\n        code_width=60,\n        word_wrap=True,\n        background_color=\"red\",\n    )\n    assert syntax.highlight(CODE).style == Style.parse(\"on red\")\n\n\ndef test_get_number_styles():\n    syntax = Syntax(CODE, \"python\", theme=\"monokai\", line_numbers=True)\n    console = Console(color_system=\"windows\")\n    assert syntax._get_number_styles(console=console) == (\n        Style.parse(\"on #272822\"),\n        Style.parse(\"dim on #272822\"),\n        Style.parse(\"not dim on #272822\"),\n    )\n\n\ndef test_get_style_for_token():\n    # from pygments.style import Style as PygmentsStyle\n    # pygments_style = PygmentsStyle()\n    from pygments.style import Token\n\n    style = PygmentsSyntaxTheme(\"default\")\n    style_dict = {Token.Text: Style(color=None)}\n    style._style_cache = style_dict\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        theme=style,\n        code_width=60,\n        word_wrap=True,\n        background_color=\"red\",\n    )\n    assert syntax._get_line_numbers_color() == Color.default()\n\n\ndef test_option_no_wrap():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        line_range=(2, 10),\n        code_width=60,\n        word_wrap=False,\n        background_color=\"red\",\n    )\n\n    rendered_syntax = render(syntax, True)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 2 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;230;219;116;41m\"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 3 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;248;248;242;41miter_values\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41miter\\x1b[0m\\x1b[38;2;248;248;242;41m(\\x1b[0m\\x1b[38;2;248;248;242;41mvalues\\x1b[0m\\x1b[38;2;248;248;242;41m)\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 4 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;102;217;239;41mtry\\x1b[0m\\x1b[38;2;248;248;242;41m:\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 5 \\x1b[0m\\x1b[38;2;248;248;242;41m        \\x1b[0m\\x1b[38;2;248;248;242;41mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mnext\\x1b[0m\\x1b[38;2;248;248;242;41m(\\x1b[0m\\x1b[38;2;248;248;242;41miter_values\\x1b[0m\\x1b[38;2;248;248;242;41m)\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 6 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;102;217;239;41mexcept\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;166;226;46;41mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;41m:\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 7 \\x1b[0m\\x1b[38;2;248;248;242;41m        \\x1b[0m\\x1b[38;2;102;217;239;41mreturn\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 8 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;248;248;242;41mfirst\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;102;217;239;41mTrue\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m 9 \\x1b[0m\\x1b[38;2;248;248;242;41m    \\x1b[0m\\x1b[38;2;102;217;239;41mfor\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mvalue\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41min\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41miter_values\\x1b[0m\\x1b[38;2;248;248;242;41m:\\x1b[0m\\n\\x1b[1;39;41m  \\x1b[0m\\x1b[39;41m10 \\x1b[0m\\x1b[38;2;248;248;242;41m        \\x1b[0m\\x1b[38;2;102;217;239;41myield\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mfirst\\x1b[0m\\x1b[38;2;248;248;242;41m,\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;102;217;239;41mFalse\\x1b[0m\\x1b[38;2;248;248;242;41m,\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;248;248;242;41mprevious_value\\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\ndef test_syntax_highlight_ranges():\n    syntax = Syntax(\n        CODE,\n        lexer=\"python\",\n        line_numbers=True,\n        word_wrap=False,\n    )\n    stylized_ranges = [\n        _SyntaxHighlightRange(\n            # overline the 2nd char of the 1st line:\n            start=(1, 1),\n            end=(1, 2),\n            style=Style(overline=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(1, len(\"def loop_\")),\n            end=(1, len(\"def loop_first_last\")),\n            style=Style(underline=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(1, len(\"def loop_first\")),\n            end=(3, len(\"    iter_values = iter\")),\n            style=Style(bold=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(9, len(\"    for \")),\n            end=(9, len(\"    for value in\")),\n            style=Style(strike=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(6, len(\"    except \")),\n            end=(6, len(\"    except StopIteration\")),\n            style=Style(reverse=True),\n        ),\n        _SyntaxHighlightRange(\n            start=(10, len(\"       yield first,\")),\n            # `column_index` is out of range: should be clamped to the line length:\n            end=(10, 300),\n            style=Style(bold=True),\n        ),\n        # For this one the end `line_number` is out of range, so it should have no impact:\n        _SyntaxHighlightRange(\n            start=(1, 1),\n            end=(30, 2),\n            style=Style(bold=True),\n        ),\n    ]\n    for range_ in stylized_ranges:\n        syntax.stylize_range(range_.style, range_.start, range_.end)\n    rendered_syntax = render(syntax, True)\n    print(repr(rendered_syntax))\n    expected = '\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 1 \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34md\\x1b[0m\\x1b[53;38;2;102;217;239;48;2;39;40;34me\\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mf\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;166;226;46;48;2;39;40;34mloop_\\x1b[0m\\x1b[4;38;2;166;226;46;48;2;39;40;34mfirst\\x1b[0m\\x1b[1;4;38;2;166;226;46;48;2;39;40;34m_last\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;255;70;137;48;2;39;40;34m-\\x1b[0m\\x1b[1;38;2;255;70;137;48;2;39;40;34m>\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mIterable\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mTuple\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m[\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mbool\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mbool\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mT\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m]\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 2 \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[1;38;2;230;219;116;48;2;39;40;34m\"\"\"Iterate and generate a tuple with a flag for first and last value.\"\"\"\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 3 \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34miter\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalues\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 4 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mtry\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 5 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mnext\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m(\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m)\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 6 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mexcept\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[7;38;2;166;226;46;48;2;39;40;34mStopIteration\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 7 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mreturn\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 8 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m 9 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mfor\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[9;38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\x1b[9;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[9;38;2;255;70;137;48;2;39;40;34min\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34miter_values\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m:\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m10 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[1;38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m11 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mFalse\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m12 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m        \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;255;70;137;48;2;39;40;34m=\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mvalue\\x1b[0m\\n\\x1b[1;38;2;227;227;221;48;2;39;40;34m  \\x1b[0m\\x1b[38;2;101;102;96;48;2;39;40;34m13 \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m    \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34myield\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mfirst\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;102;217;239;48;2;39;40;34mTrue\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m,\\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34m \\x1b[0m\\x1b[38;2;248;248;242;48;2;39;40;34mprevious_value\\x1b[0m\\n'\n    assert rendered_syntax == expected\n\n\ndef test_ansi_theme():\n    style = Style(color=\"red\")\n    theme = ANSISyntaxTheme({(\"foo\", \"bar\"): style})\n    assert theme.get_style_for_token((\"foo\", \"bar\", \"baz\")) == style\n    assert theme.get_background_style() == Style()\n\n\nskip_windows_permission_error = pytest.mark.skipif(\n    sys.platform == \"win32\", reason=\"permissions error on Windows\"\n)\n\n\n@skip_windows_permission_error\ndef test_from_path():\n    fh, path = tempfile.mkstemp(\"example.py\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path)\n        assert syntax.lexer\n        assert syntax.lexer.name == \"Python\"\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\n@skip_windows_permission_error\ndef test_from_path_unknown_lexer():\n    fh, path = tempfile.mkstemp(\"example.nosuchtype\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path)\n        assert syntax.lexer is None\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\n@skip_windows_permission_error\ndef test_from_path_lexer_override():\n    fh, path = tempfile.mkstemp(\"example.nosuchtype\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path, lexer=\"rust\")\n        assert syntax.lexer.name == \"Rust\"\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\n@skip_windows_permission_error\ndef test_from_path_lexer_override_invalid_lexer():\n    fh, path = tempfile.mkstemp(\"example.nosuchtype\")\n    try:\n        os.write(fh, b\"import this\\n\")\n        syntax = Syntax.from_path(path, lexer=\"blah\")\n        assert syntax.lexer is None\n        assert syntax.code == \"import this\\n\"\n    finally:\n        os.remove(path)\n\n\ndef test_syntax_guess_lexer():\n    assert Syntax.guess_lexer(\"banana.py\") == \"python\"\n    assert Syntax.guess_lexer(\"banana.py\", \"import this\") == \"python\"\n    assert Syntax.guess_lexer(\"banana.html\", \"<a href='#'>hello</a>\") == \"html\"\n    assert Syntax.guess_lexer(\"banana.html\", \"<%= @foo %>\") == \"rhtml\"\n    assert Syntax.guess_lexer(\"banana.html\", \"{{something|filter:3}}\") == \"html+django\"\n\n\ndef test_syntax_padding():\n    syntax = Syntax(\"x = 1\", lexer=\"python\", padding=(1, 3))\n    console = Console(\n        width=20,\n        file=io.StringIO(),\n        color_system=\"truecolor\",\n        legacy_windows=False,\n        record=True,\n    )\n    console.print(syntax)\n    output = console.export_text()\n    assert (\n        output == \"                    \\n   x = 1            \\n                    \\n\"\n    )\n\n\ndef test_syntax_measure():\n    console = Console()\n    code = Syntax(\"Hello, World\", \"python\")\n    assert code.__rich_measure__(console, console.options) == Measurement(0, 12)\n\n    code = Syntax(\"Hello, World\", \"python\", line_numbers=True)\n    assert code.__rich_measure__(console, console.options) == Measurement(3, 16)\n\n    code = Syntax(\"Hello, World\", \"python\", code_width=20, line_numbers=True)\n    assert code.__rich_measure__(console, console.options) == Measurement(3, 24)\n\n    code = Syntax(\"\", \"python\", code_width=20, line_numbers=True)\n    assert code.__rich_measure__(console, console.options) == Measurement(3, 24)\n\n\ndef test_background_color_override_includes_padding():\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3295\"\"\"\n\n    syntax = Syntax(\n        \"x = 1\",\n        lexer=\"python\",\n        padding=(1, 3),\n        background_color=\"red\",\n    )\n    result = render(syntax)\n    print(repr(result))\n    assert (\n        result\n        == \"\\x1b[41m                                                                                                    \\x1b[0m\\n\\x1b[41m   \\x1b[0m\\x1b[38;2;248;248;242;41mx\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;255;70;137;41m=\\x1b[0m\\x1b[38;2;248;248;242;41m \\x1b[0m\\x1b[38;2;174;129;255;41m1\\x1b[0m\\x1b[41m                                                                                         \\x1b[0m\\x1b[41m   \\x1b[0m\\n\\x1b[41m                                                                                                    \\x1b[0m\\n\"\n    )\n\n\nif __name__ == \"__main__\":\n    syntax = Panel.fit(\n        Syntax(\n            CODE,\n            lexer=\"python\",\n            line_numbers=True,\n            line_range=(2, 10),\n            theme=\"foo\",\n            code_width=60,\n            word_wrap=True,\n        ),\n        padding=0,\n    )\n    rendered = render(markdown)\n    print(rendered)\n    print(repr(rendered))\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "2c7d08e26ef7",
      "repo": "rich",
      "commit_hash": "f0626d3",
      "commit_message": "fix(logging): fix tracebacks_code_width type hint",
      "file_path": "rich/logging.py",
      "language": "python",
      "code_before": "import logging\nfrom datetime import datetime\nfrom logging import Handler, LogRecord\nfrom pathlib import Path\nfrom types import ModuleType\nfrom typing import ClassVar, Iterable, List, Optional, Type, Union\n\nfrom rich._null_file import NullFile\n\nfrom . import get_console\nfrom ._log_render import FormatTimeCallable, LogRender\nfrom .console import Console, ConsoleRenderable\nfrom .highlighter import Highlighter, ReprHighlighter\nfrom .text import Text\nfrom .traceback import Traceback\n\n\nclass RichHandler(Handler):\n    \"\"\"A logging handler that renders output with Rich. The time / level / message and file are displayed in columns.\n    The level is color coded, and the message is syntax highlighted.\n\n    Note:\n        Be careful when enabling console markup in log messages if you have configured logging for libraries not\n        under your control. If a dependency writes messages containing square brackets, it may not produce the intended output.\n\n    Args:\n        level (Union[int, str], optional): Log level. Defaults to logging.NOTSET.\n        console (:class:`~rich.console.Console`, optional): Optional console instance to write logs.\n            Default will use a global console instance writing to stdout.\n        show_time (bool, optional): Show a column for the time. Defaults to True.\n        omit_repeated_times (bool, optional): Omit repetition of the same time. Defaults to True.\n        show_level (bool, optional): Show a column for the level. Defaults to True.\n        show_path (bool, optional): Show the path to the original log call. Defaults to True.\n        enable_link_path (bool, optional): Enable terminal link of path column to file. Defaults to True.\n        highlighter (Highlighter, optional): Highlighter to style log messages, or None to use ReprHighlighter. Defaults to None.\n        markup (bool, optional): Enable console markup in log messages. Defaults to False.\n        rich_tracebacks (bool, optional): Enable rich tracebacks with syntax highlighting and formatting. Defaults to False.\n        tracebacks_width (Optional[int], optional): Number of characters used to render tracebacks, or None for full width. Defaults to None.\n        tracebacks_code_width (int, optional): Number of code characters used to render tracebacks, or None for full width. Defaults to 88.\n        tracebacks_extra_lines (int, optional): Additional lines of code to render tracebacks, or None for full width. Defaults to None.\n        tracebacks_theme (str, optional): Override pygments theme used in traceback.\n        tracebacks_word_wrap (bool, optional): Enable word wrapping of long tracebacks lines. Defaults to True.\n        tracebacks_show_locals (bool, optional): Enable display of locals in tracebacks. Defaults to False.\n        tracebacks_suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        tracebacks_max_frames (int, optional): Optional maximum number of frames returned by traceback.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to \"[%x %X] \".\n        keywords (List[str], optional): List of words to highlight instead of ``RichHandler.KEYWORDS``.\n    \"\"\"\n\n    KEYWORDS: ClassVar[Optional[List[str]]] = [\n        \"GET\",\n        \"POST\",\n        \"HEAD\",\n        \"PUT\",\n        \"DELETE\",\n        \"OPTIONS\",\n        \"TRACE\",\n        \"PATCH\",\n    ]\n    HIGHLIGHTER_CLASS: ClassVar[Type[Highlighter]] = ReprHighlighter\n\n    def __init__(\n        self,\n        level: Union[int, str] = logging.NOTSET,\n        console: Optional[Console] = None,\n        *,\n        show_time: bool = True,\n        omit_repeated_times: bool = True,\n        show_level: bool = True,\n        show_path: bool = True,\n        enable_link_path: bool = True,\n        highlighter: Optional[Highlighter] = None,\n        markup: bool = False,\n        rich_tracebacks: bool = False,\n        tracebacks_width: Optional[int] = None,\n        tracebacks_code_width: int = 88,\n        tracebacks_extra_lines: int = 3,\n        tracebacks_theme: Optional[str] = None,\n        tracebacks_word_wrap: bool = True,\n        tracebacks_show_locals: bool = False,\n        tracebacks_suppress: Iterable[Union[str, ModuleType]] = (),\n        tracebacks_max_frames: int = 100,\n        locals_max_length: int = 10,\n        locals_max_string: int = 80,\n        log_time_format: Union[str, FormatTimeCallable] = \"[%x %X]\",\n        keywords: Optional[List[str]] = None,\n    ) -> None:\n        super().__init__(level=level)\n        self.console = console or get_console()\n        self.highlighter = highlighter or self.HIGHLIGHTER_CLASS()\n        self._log_render = LogRender(\n            show_time=show_time,\n            show_level=show_level,\n            show_path=show_path,\n            time_format=log_time_format,\n            omit_repeated_times=omit_repeated_times,\n            level_width=None,\n        )\n        self.enable_link_path = enable_link_path\n        self.markup = markup\n        self.rich_tracebacks = rich_tracebacks\n        self.tracebacks_width = tracebacks_width\n        self.tracebacks_extra_lines = tracebacks_extra_lines\n        self.tracebacks_theme = tracebacks_theme\n        self.tracebacks_word_wrap = tracebacks_word_wrap\n        self.tracebacks_show_locals = tracebacks_show_locals\n        self.tracebacks_suppress = tracebacks_suppress\n        self.tracebacks_max_frames = tracebacks_max_frames\n        self.tracebacks_code_width = tracebacks_code_width\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.keywords = keywords\n\n    def get_level_text(self, record: LogRecord) -> Text:\n        \"\"\"Get the level name from the record.\n\n        Args:\n            record (LogRecord): LogRecord instance.\n\n        Returns:\n            Text: A tuple of the style and level name.\n        \"\"\"\n        level_name = record.levelname\n        level_text = Text.styled(\n            level_name.ljust(8), f\"logging.level.{level_name.lower()}\"\n        )\n        return level_text\n\n    def emit(self, record: LogRecord) -> None:\n        \"\"\"Invoked by logging.\"\"\"\n        message = self.format(record)\n        traceback = None\n        if (\n            self.rich_tracebacks\n            and record.exc_info\n            and record.exc_info != (None, None, None)\n        ):\n            exc_type, exc_value, exc_traceback = record.exc_info\n            assert exc_type is not None\n            assert exc_value is not None\n            traceback = Traceback.from_exception(\n                exc_type,\n                exc_value,\n                exc_traceback,\n                width=self.tracebacks_width,\n                code_width=self.tracebacks_code_width,\n                extra_lines=self.tracebacks_extra_lines,\n                theme=self.tracebacks_theme,\n                word_wrap=self.tracebacks_word_wrap,\n                show_locals=self.tracebacks_show_locals,\n                locals_max_length=self.locals_max_length,\n                locals_max_string=self.locals_max_string,\n                suppress=self.tracebacks_suppress,\n                max_frames=self.tracebacks_max_frames,\n            )\n            message = record.getMessage()\n            if self.formatter:\n                record.message = record.getMessage()\n                formatter = self.formatter\n                if hasattr(formatter, \"usesTime\") and formatter.usesTime():\n                    record.asctime = formatter.formatTime(record, formatter.datefmt)\n                message = formatter.formatMessage(record)\n\n        message_renderable = self.render_message(record, message)\n        log_renderable = self.render(\n            record=record, traceback=traceback, message_renderable=message_renderable\n        )\n        if isinstance(self.console.file, NullFile):\n            # Handles pythonw, where stdout/stderr are null, and we return NullFile\n            # instance from Console.file. In this case, we still want to make a log record\n            # even though we won't be writing anything to a file.\n            self.handleError(record)\n        else:\n            try:\n                self.console.print(log_renderable)\n            except Exception:\n                self.handleError(record)\n\n    def render_message(self, record: LogRecord, message: str) -> \"ConsoleRenderable\":\n        \"\"\"Render message text in to Text.\n\n        Args:\n            record (LogRecord): logging Record.\n            message (str): String containing log message.\n\n        Returns:\n            ConsoleRenderable: Renderable to display log message.\n        \"\"\"\n        use_markup = getattr(record, \"markup\", self.markup)\n        message_text = Text.from_markup(message) if use_markup else Text(message)\n\n        highlighter = getattr(record, \"highlighter\", self.highlighter)\n        if highlighter:\n            message_text = highlighter(message_text)\n\n        if self.keywords is None:\n            self.keywords = self.KEYWORDS\n\n        if self.keywords:\n            message_text.highlight_words(self.keywords, \"logging.keyword\")\n\n        return message_text\n\n    def render(\n        self,\n        *,\n        record: LogRecord,\n        traceback: Optional[Traceback],\n        message_renderable: \"ConsoleRenderable\",\n    ) -> \"ConsoleRenderable\":\n        \"\"\"Render log for display.\n\n        Args:\n            record (LogRecord): logging Record.\n            traceback (Optional[Traceback]): Traceback instance or None for no Traceback.\n            message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.\n\n        Returns:\n            ConsoleRenderable: Renderable to display log.\n        \"\"\"\n        path = Path(record.pathname).name\n        level = self.get_level_text(record)\n        time_format = None if self.formatter is None else self.formatter.datefmt\n        log_time = datetime.fromtimestamp(record.created)\n\n        log_renderable = self._log_render(\n            self.console,\n            [message_renderable] if not traceback else [message_renderable, traceback],\n            log_time=log_time,\n            time_format=time_format,\n            level=level,\n            path=path,\n            line_no=record.lineno,\n            link_path=record.pathname if self.enable_link_path else None,\n        )\n        return log_renderable\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from time import sleep\n\n    FORMAT = \"%(message)s\"\n    # FORMAT = \"%(asctime)-15s - %(levelname)s - %(message)s\"\n    logging.basicConfig(\n        level=\"NOTSET\",\n        format=FORMAT,\n        datefmt=\"[%X]\",\n        handlers=[RichHandler(rich_tracebacks=True, tracebacks_show_locals=True)],\n    )\n    log = logging.getLogger(\"rich\")\n\n    log.info(\"Server starting...\")\n    log.info(\"Listening on http://127.0.0.1:8080\")\n    sleep(1)\n\n    log.info(\"GET /index.html 200 1298\")\n    log.info(\"GET /imgs/backgrounds/back1.jpg 200 54386\")\n    log.info(\"GET /css/styles.css 200 54386\")\n    log.warning(\"GET /favicon.ico 404 242\")\n    sleep(1)\n\n    log.debug(\n        \"JSONRPC request\\n--> %r\\n<-- %r\",\n        {\n            \"version\": \"1.1\",\n            \"method\": \"confirmFruitPurchase\",\n            \"params\": [[\"apple\", \"orange\", \"mangoes\", \"pomelo\"], 1.123],\n            \"id\": \"194521489\",\n        },\n        {\"version\": \"1.1\", \"result\": True, \"error\": None, \"id\": \"194521489\"},\n    )\n    log.debug(\n        \"Loading configuration file /adasd/asdasd/qeqwe/qwrqwrqwr/sdgsdgsdg/werwerwer/dfgerert/ertertert/ertetert/werwerwer\"\n    )\n    log.error(\"Unable to find 'pomelo' in database!\")\n    log.info(\"POST /jsonrpc/ 200 65532\")\n    log.info(\"POST /admin/ 401 42234\")\n    log.warning(\"password was rejected for admin site.\")\n\n    def divide() -> None:\n        number = 1\n        divisor = 0\n        foos = [\"foo\"] * 100\n        log.debug(\"in divide\")\n        try:\n            number / divisor\n        except:\n            log.exception(\"An error of some kind occurred!\")\n\n    divide()\n    sleep(1)\n    log.critical(\"Out of memory!\")\n    log.info(\"Server exited with code=-1\")\n    log.info(\"[bold]EXITING...[/bold]\", extra=dict(markup=True))\n",
      "code_after": "import logging\nfrom datetime import datetime\nfrom logging import Handler, LogRecord\nfrom pathlib import Path\nfrom types import ModuleType\nfrom typing import ClassVar, Iterable, List, Optional, Type, Union\n\nfrom rich._null_file import NullFile\n\nfrom . import get_console\nfrom ._log_render import FormatTimeCallable, LogRender\nfrom .console import Console, ConsoleRenderable\nfrom .highlighter import Highlighter, ReprHighlighter\nfrom .text import Text\nfrom .traceback import Traceback\n\n\nclass RichHandler(Handler):\n    \"\"\"A logging handler that renders output with Rich. The time / level / message and file are displayed in columns.\n    The level is color coded, and the message is syntax highlighted.\n\n    Note:\n        Be careful when enabling console markup in log messages if you have configured logging for libraries not\n        under your control. If a dependency writes messages containing square brackets, it may not produce the intended output.\n\n    Args:\n        level (Union[int, str], optional): Log level. Defaults to logging.NOTSET.\n        console (:class:`~rich.console.Console`, optional): Optional console instance to write logs.\n            Default will use a global console instance writing to stdout.\n        show_time (bool, optional): Show a column for the time. Defaults to True.\n        omit_repeated_times (bool, optional): Omit repetition of the same time. Defaults to True.\n        show_level (bool, optional): Show a column for the level. Defaults to True.\n        show_path (bool, optional): Show the path to the original log call. Defaults to True.\n        enable_link_path (bool, optional): Enable terminal link of path column to file. Defaults to True.\n        highlighter (Highlighter, optional): Highlighter to style log messages, or None to use ReprHighlighter. Defaults to None.\n        markup (bool, optional): Enable console markup in log messages. Defaults to False.\n        rich_tracebacks (bool, optional): Enable rich tracebacks with syntax highlighting and formatting. Defaults to False.\n        tracebacks_width (Optional[int], optional): Number of characters used to render tracebacks, or None for full width. Defaults to None.\n        tracebacks_code_width (int, optional): Number of code characters used to render tracebacks, or None for full width. Defaults to 88.\n        tracebacks_extra_lines (int, optional): Additional lines of code to render tracebacks, or None for full width. Defaults to None.\n        tracebacks_theme (str, optional): Override pygments theme used in traceback.\n        tracebacks_word_wrap (bool, optional): Enable word wrapping of long tracebacks lines. Defaults to True.\n        tracebacks_show_locals (bool, optional): Enable display of locals in tracebacks. Defaults to False.\n        tracebacks_suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        tracebacks_max_frames (int, optional): Optional maximum number of frames returned by traceback.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        log_time_format (Union[str, TimeFormatterCallable], optional): If ``log_time`` is enabled, either string for strftime or callable that formats the time. Defaults to \"[%x %X] \".\n        keywords (List[str], optional): List of words to highlight instead of ``RichHandler.KEYWORDS``.\n    \"\"\"\n\n    KEYWORDS: ClassVar[Optional[List[str]]] = [\n        \"GET\",\n        \"POST\",\n        \"HEAD\",\n        \"PUT\",\n        \"DELETE\",\n        \"OPTIONS\",\n        \"TRACE\",\n        \"PATCH\",\n    ]\n    HIGHLIGHTER_CLASS: ClassVar[Type[Highlighter]] = ReprHighlighter\n\n    def __init__(\n        self,\n        level: Union[int, str] = logging.NOTSET,\n        console: Optional[Console] = None,\n        *,\n        show_time: bool = True,\n        omit_repeated_times: bool = True,\n        show_level: bool = True,\n        show_path: bool = True,\n        enable_link_path: bool = True,\n        highlighter: Optional[Highlighter] = None,\n        markup: bool = False,\n        rich_tracebacks: bool = False,\n        tracebacks_width: Optional[int] = None,\n        tracebacks_code_width: Optional[int] = 88,\n        tracebacks_extra_lines: int = 3,\n        tracebacks_theme: Optional[str] = None,\n        tracebacks_word_wrap: bool = True,\n        tracebacks_show_locals: bool = False,\n        tracebacks_suppress: Iterable[Union[str, ModuleType]] = (),\n        tracebacks_max_frames: int = 100,\n        locals_max_length: int = 10,\n        locals_max_string: int = 80,\n        log_time_format: Union[str, FormatTimeCallable] = \"[%x %X]\",\n        keywords: Optional[List[str]] = None,\n    ) -> None:\n        super().__init__(level=level)\n        self.console = console or get_console()\n        self.highlighter = highlighter or self.HIGHLIGHTER_CLASS()\n        self._log_render = LogRender(\n            show_time=show_time,\n            show_level=show_level,\n            show_path=show_path,\n            time_format=log_time_format,\n            omit_repeated_times=omit_repeated_times,\n            level_width=None,\n        )\n        self.enable_link_path = enable_link_path\n        self.markup = markup\n        self.rich_tracebacks = rich_tracebacks\n        self.tracebacks_width = tracebacks_width\n        self.tracebacks_extra_lines = tracebacks_extra_lines\n        self.tracebacks_theme = tracebacks_theme\n        self.tracebacks_word_wrap = tracebacks_word_wrap\n        self.tracebacks_show_locals = tracebacks_show_locals\n        self.tracebacks_suppress = tracebacks_suppress\n        self.tracebacks_max_frames = tracebacks_max_frames\n        self.tracebacks_code_width = tracebacks_code_width\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.keywords = keywords\n\n    def get_level_text(self, record: LogRecord) -> Text:\n        \"\"\"Get the level name from the record.\n\n        Args:\n            record (LogRecord): LogRecord instance.\n\n        Returns:\n            Text: A tuple of the style and level name.\n        \"\"\"\n        level_name = record.levelname\n        level_text = Text.styled(\n            level_name.ljust(8), f\"logging.level.{level_name.lower()}\"\n        )\n        return level_text\n\n    def emit(self, record: LogRecord) -> None:\n        \"\"\"Invoked by logging.\"\"\"\n        message = self.format(record)\n        traceback = None\n        if (\n            self.rich_tracebacks\n            and record.exc_info\n            and record.exc_info != (None, None, None)\n        ):\n            exc_type, exc_value, exc_traceback = record.exc_info\n            assert exc_type is not None\n            assert exc_value is not None\n            traceback = Traceback.from_exception(\n                exc_type,\n                exc_value,\n                exc_traceback,\n                width=self.tracebacks_width,\n                code_width=self.tracebacks_code_width,\n                extra_lines=self.tracebacks_extra_lines,\n                theme=self.tracebacks_theme,\n                word_wrap=self.tracebacks_word_wrap,\n                show_locals=self.tracebacks_show_locals,\n                locals_max_length=self.locals_max_length,\n                locals_max_string=self.locals_max_string,\n                suppress=self.tracebacks_suppress,\n                max_frames=self.tracebacks_max_frames,\n            )\n            message = record.getMessage()\n            if self.formatter:\n                record.message = record.getMessage()\n                formatter = self.formatter\n                if hasattr(formatter, \"usesTime\") and formatter.usesTime():\n                    record.asctime = formatter.formatTime(record, formatter.datefmt)\n                message = formatter.formatMessage(record)\n\n        message_renderable = self.render_message(record, message)\n        log_renderable = self.render(\n            record=record, traceback=traceback, message_renderable=message_renderable\n        )\n        if isinstance(self.console.file, NullFile):\n            # Handles pythonw, where stdout/stderr are null, and we return NullFile\n            # instance from Console.file. In this case, we still want to make a log record\n            # even though we won't be writing anything to a file.\n            self.handleError(record)\n        else:\n            try:\n                self.console.print(log_renderable)\n            except Exception:\n                self.handleError(record)\n\n    def render_message(self, record: LogRecord, message: str) -> \"ConsoleRenderable\":\n        \"\"\"Render message text in to Text.\n\n        Args:\n            record (LogRecord): logging Record.\n            message (str): String containing log message.\n\n        Returns:\n            ConsoleRenderable: Renderable to display log message.\n        \"\"\"\n        use_markup = getattr(record, \"markup\", self.markup)\n        message_text = Text.from_markup(message) if use_markup else Text(message)\n\n        highlighter = getattr(record, \"highlighter\", self.highlighter)\n        if highlighter:\n            message_text = highlighter(message_text)\n\n        if self.keywords is None:\n            self.keywords = self.KEYWORDS\n\n        if self.keywords:\n            message_text.highlight_words(self.keywords, \"logging.keyword\")\n\n        return message_text\n\n    def render(\n        self,\n        *,\n        record: LogRecord,\n        traceback: Optional[Traceback],\n        message_renderable: \"ConsoleRenderable\",\n    ) -> \"ConsoleRenderable\":\n        \"\"\"Render log for display.\n\n        Args:\n            record (LogRecord): logging Record.\n            traceback (Optional[Traceback]): Traceback instance or None for no Traceback.\n            message_renderable (ConsoleRenderable): Renderable (typically Text) containing log message contents.\n\n        Returns:\n            ConsoleRenderable: Renderable to display log.\n        \"\"\"\n        path = Path(record.pathname).name\n        level = self.get_level_text(record)\n        time_format = None if self.formatter is None else self.formatter.datefmt\n        log_time = datetime.fromtimestamp(record.created)\n\n        log_renderable = self._log_render(\n            self.console,\n            [message_renderable] if not traceback else [message_renderable, traceback],\n            log_time=log_time,\n            time_format=time_format,\n            level=level,\n            path=path,\n            line_no=record.lineno,\n            link_path=record.pathname if self.enable_link_path else None,\n        )\n        return log_renderable\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from time import sleep\n\n    FORMAT = \"%(message)s\"\n    # FORMAT = \"%(asctime)-15s - %(levelname)s - %(message)s\"\n    logging.basicConfig(\n        level=\"NOTSET\",\n        format=FORMAT,\n        datefmt=\"[%X]\",\n        handlers=[RichHandler(rich_tracebacks=True, tracebacks_show_locals=True)],\n    )\n    log = logging.getLogger(\"rich\")\n\n    log.info(\"Server starting...\")\n    log.info(\"Listening on http://127.0.0.1:8080\")\n    sleep(1)\n\n    log.info(\"GET /index.html 200 1298\")\n    log.info(\"GET /imgs/backgrounds/back1.jpg 200 54386\")\n    log.info(\"GET /css/styles.css 200 54386\")\n    log.warning(\"GET /favicon.ico 404 242\")\n    sleep(1)\n\n    log.debug(\n        \"JSONRPC request\\n--> %r\\n<-- %r\",\n        {\n            \"version\": \"1.1\",\n            \"method\": \"confirmFruitPurchase\",\n            \"params\": [[\"apple\", \"orange\", \"mangoes\", \"pomelo\"], 1.123],\n            \"id\": \"194521489\",\n        },\n        {\"version\": \"1.1\", \"result\": True, \"error\": None, \"id\": \"194521489\"},\n    )\n    log.debug(\n        \"Loading configuration file /adasd/asdasd/qeqwe/qwrqwrqwr/sdgsdgsdg/werwerwer/dfgerert/ertertert/ertetert/werwerwer\"\n    )\n    log.error(\"Unable to find 'pomelo' in database!\")\n    log.info(\"POST /jsonrpc/ 200 65532\")\n    log.info(\"POST /admin/ 401 42234\")\n    log.warning(\"password was rejected for admin site.\")\n\n    def divide() -> None:\n        number = 1\n        divisor = 0\n        foos = [\"foo\"] * 100\n        log.debug(\"in divide\")\n        try:\n            number / divisor\n        except:\n            log.exception(\"An error of some kind occurred!\")\n\n    divide()\n    sleep(1)\n    log.critical(\"Out of memory!\")\n    log.info(\"Server exited with code=-1\")\n    log.info(\"[bold]EXITING...[/bold]\", extra=dict(markup=True))\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "b5a4935b5235",
      "repo": "rich",
      "commit_hash": "30e5ed6",
      "commit_message": "fix(panel): fix title missing panel background",
      "file_path": "rich/panel.py",
      "language": "python",
      "code_before": "from typing import TYPE_CHECKING, Optional\n\nfrom .align import AlignMethod\nfrom .box import ROUNDED, Box\nfrom .cells import cell_len\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement, measure_renderables\nfrom .padding import Padding, PaddingDimensions\nfrom .segment import Segment\nfrom .style import Style, StyleType\nfrom .text import Text, TextType\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n\n\nclass Panel(JupyterMixin):\n    \"\"\"A console renderable that draws a border around its contents.\n\n    Example:\n        >>> console.print(Panel(\"Hello, World!\"))\n\n    Args:\n        renderable (RenderableType): A console renderable object.\n        box (Box): A Box instance that defines the look of the border (see :ref:`appendix_box`. Defaults to box.ROUNDED.\n        title (Optional[TextType], optional): Optional title displayed in panel header. Defaults to None.\n        title_align (AlignMethod, optional): Alignment of title. Defaults to \"center\".\n        subtitle (Optional[TextType], optional): Optional subtitle displayed in panel footer. Defaults to None.\n        subtitle_align (AlignMethod, optional): Alignment of subtitle. Defaults to \"center\".\n        safe_box (bool, optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.\n        expand (bool, optional): If True the panel will stretch to fill the console width, otherwise it will be sized to fit the contents. Defaults to True.\n        style (str, optional): The style of the panel (border and contents). Defaults to \"none\".\n        border_style (str, optional): The style of the border. Defaults to \"none\".\n        width (Optional[int], optional): Optional width of panel. Defaults to None to auto-detect.\n        height (Optional[int], optional): Optional height of panel. Defaults to None to auto-detect.\n        padding (Optional[PaddingDimensions]): Optional padding around renderable. Defaults to 0.\n        highlight (bool, optional): Enable automatic highlighting of panel title (if str). Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: \"RenderableType\",\n        box: Box = ROUNDED,\n        *,\n        title: Optional[TextType] = None,\n        title_align: AlignMethod = \"center\",\n        subtitle: Optional[TextType] = None,\n        subtitle_align: AlignMethod = \"center\",\n        safe_box: Optional[bool] = None,\n        expand: bool = True,\n        style: StyleType = \"none\",\n        border_style: StyleType = \"none\",\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n        padding: PaddingDimensions = (0, 1),\n        highlight: bool = False,\n    ) -> None:\n        self.renderable = renderable\n        self.box = box\n        self.title = title\n        self.title_align: AlignMethod = title_align\n        self.subtitle = subtitle\n        self.subtitle_align = subtitle_align\n        self.safe_box = safe_box\n        self.expand = expand\n        self.style = style\n        self.border_style = border_style\n        self.width = width\n        self.height = height\n        self.padding = padding\n        self.highlight = highlight\n\n    @classmethod\n    def fit(\n        cls,\n        renderable: \"RenderableType\",\n        box: Box = ROUNDED,\n        *,\n        title: Optional[TextType] = None,\n        title_align: AlignMethod = \"center\",\n        subtitle: Optional[TextType] = None,\n        subtitle_align: AlignMethod = \"center\",\n        safe_box: Optional[bool] = None,\n        style: StyleType = \"none\",\n        border_style: StyleType = \"none\",\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n        padding: PaddingDimensions = (0, 1),\n        highlight: bool = False,\n    ) -> \"Panel\":\n        \"\"\"An alternative constructor that sets expand=False.\"\"\"\n        return cls(\n            renderable,\n            box,\n            title=title,\n            title_align=title_align,\n            subtitle=subtitle,\n            subtitle_align=subtitle_align,\n            safe_box=safe_box,\n            style=style,\n            border_style=border_style,\n            width=width,\n            height=height,\n            padding=padding,\n            highlight=highlight,\n            expand=False,\n        )\n\n    @property\n    def _title(self) -> Optional[Text]:\n        if self.title:\n            title_text = (\n                Text.from_markup(self.title)\n                if isinstance(self.title, str)\n                else self.title.copy()\n            )\n            title_text.end = \"\"\n            title_text.plain = title_text.plain.replace(\"\\n\", \" \")\n            title_text.no_wrap = True\n            title_text.expand_tabs()\n            title_text.pad(1)\n            return title_text\n        return None\n\n    @property\n    def _subtitle(self) -> Optional[Text]:\n        if self.subtitle:\n            subtitle_text = (\n                Text.from_markup(self.subtitle)\n                if isinstance(self.subtitle, str)\n                else self.subtitle.copy()\n            )\n            subtitle_text.end = \"\"\n            subtitle_text.plain = subtitle_text.plain.replace(\"\\n\", \" \")\n            subtitle_text.no_wrap = True\n            subtitle_text.expand_tabs()\n            subtitle_text.pad(1)\n            return subtitle_text\n        return None\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        _padding = Padding.unpack(self.padding)\n        renderable = (\n            Padding(self.renderable, _padding) if any(_padding) else self.renderable\n        )\n        style = console.get_style(self.style)\n        partial_border_style = console.get_style(self.border_style)\n        border_style = style + partial_border_style\n        width = (\n            options.max_width\n            if self.width is None\n            else min(options.max_width, self.width)\n        )\n\n        safe_box: bool = console.safe_box if self.safe_box is None else self.safe_box\n        box = self.box.substitute(options, safe=safe_box)\n\n        def align_text(\n            text: Text, width: int, align: str, character: str, style: Style\n        ) -> Text:\n            \"\"\"Gets new aligned text.\n\n            Args:\n                text (Text): Title or subtitle text.\n                width (int): Desired width.\n                align (str): Alignment.\n                character (str): Character for alignment.\n                style (Style): Border style\n\n            Returns:\n                Text: New text instance\n            \"\"\"\n            text = text.copy()\n            text.truncate(width)\n            excess_space = width - cell_len(text.plain)\n            if text.style:\n                text.stylize(console.get_style(text.style))\n\n            if excess_space:\n                if align == \"left\":\n                    return Text.assemble(\n                        text,\n                        (character * excess_space, style),\n                        no_wrap=True,\n                        end=\"\",\n                    )\n                elif align == \"center\":\n                    left = excess_space // 2\n                    return Text.assemble(\n                        (character * left, style),\n                        text,\n                        (character * (excess_space - left), style),\n                        no_wrap=True,\n                        end=\"\",\n                    )\n                else:\n                    return Text.assemble(\n                        (character * excess_space, style),\n                        text,\n                        no_wrap=True,\n                        end=\"\",\n                    )\n            return text\n\n        title_text = self._title\n        if title_text is not None:\n            title_text.stylize_before(partial_border_style)\n\n        child_width = (\n            width - 2\n            if self.expand\n            else console.measure(\n                renderable, options=options.update_width(width - 2)\n            ).maximum\n        )\n        child_height = self.height or options.height or None\n        if child_height:\n            child_height -= 2\n        if title_text is not None:\n            child_width = min(\n                options.max_width - 2, max(child_width, title_text.cell_len + 2)\n            )\n\n        width = child_width + 2\n        child_options = options.update(\n            width=child_width, height=child_height, highlight=self.highlight\n        )\n        lines = console.render_lines(renderable, child_options, style=style)\n\n        line_start = Segment(box.mid_left, border_style)\n        line_end = Segment(f\"{box.mid_right}\", border_style)\n        new_line = Segment.line()\n        if title_text is None or width <= 4:\n            yield Segment(box.get_top([width - 2]), border_style)\n        else:\n            title_text = align_text(\n                title_text,\n                width - 4,\n                self.title_align,\n                box.top,\n                border_style,\n            )\n            yield Segment(box.top_left + box.top, border_style)\n            yield from console.render(title_text, child_options.update_width(width - 4))\n            yield Segment(box.top + box.top_right, border_style)\n\n        yield new_line\n        for line in lines:\n            yield line_start\n            yield from line\n            yield line_end\n            yield new_line\n\n        subtitle_text = self._subtitle\n        if subtitle_text is not None:\n            subtitle_text.stylize_before(partial_border_style)\n\n        if subtitle_text is None or width <= 4:\n            yield Segment(box.get_bottom([width - 2]), border_style)\n        else:\n            subtitle_text = align_text(\n                subtitle_text,\n                width - 4,\n                self.subtitle_align,\n                box.bottom,\n                border_style,\n            )\n            yield Segment(box.bottom_left + box.bottom, border_style)\n            yield from console.render(\n                subtitle_text, child_options.update_width(width - 4)\n            )\n            yield Segment(box.bottom + box.bottom_right, border_style)\n\n        yield new_line\n\n    def __rich_measure__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"Measurement\":\n        _title = self._title\n        _, right, _, left = Padding.unpack(self.padding)\n        padding = left + right\n        renderables = [self.renderable, _title] if _title else [self.renderable]\n\n        if self.width is None:\n            width = (\n                measure_renderables(\n                    console,\n                    options.update_width(options.max_width - padding - 2),\n                    renderables,\n                ).maximum\n                + padding\n                + 2\n            )\n        else:\n            width = self.width\n        return Measurement(width, width)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from .console import Console\n\n    c = Console()\n\n    from .box import DOUBLE, ROUNDED\n    from .padding import Padding\n\n    p = Panel(\n        \"Hello, World!\",\n        title=\"rich.Panel\",\n        style=\"white on blue\",\n        box=DOUBLE,\n        padding=1,\n    )\n\n    c.print()\n    c.print(p)\n",
      "code_after": "from typing import TYPE_CHECKING, Optional\n\nfrom .align import AlignMethod\nfrom .box import ROUNDED, Box\nfrom .cells import cell_len\nfrom .jupyter import JupyterMixin\nfrom .measure import Measurement, measure_renderables\nfrom .padding import Padding, PaddingDimensions\nfrom .segment import Segment\nfrom .style import Style, StyleType\nfrom .text import Text, TextType\n\nif TYPE_CHECKING:\n    from .console import Console, ConsoleOptions, RenderableType, RenderResult\n\n\nclass Panel(JupyterMixin):\n    \"\"\"A console renderable that draws a border around its contents.\n\n    Example:\n        >>> console.print(Panel(\"Hello, World!\"))\n\n    Args:\n        renderable (RenderableType): A console renderable object.\n        box (Box): A Box instance that defines the look of the border (see :ref:`appendix_box`. Defaults to box.ROUNDED.\n        title (Optional[TextType], optional): Optional title displayed in panel header. Defaults to None.\n        title_align (AlignMethod, optional): Alignment of title. Defaults to \"center\".\n        subtitle (Optional[TextType], optional): Optional subtitle displayed in panel footer. Defaults to None.\n        subtitle_align (AlignMethod, optional): Alignment of subtitle. Defaults to \"center\".\n        safe_box (bool, optional): Disable box characters that don't display on windows legacy terminal with *raster* fonts. Defaults to True.\n        expand (bool, optional): If True the panel will stretch to fill the console width, otherwise it will be sized to fit the contents. Defaults to True.\n        style (str, optional): The style of the panel (border and contents). Defaults to \"none\".\n        border_style (str, optional): The style of the border. Defaults to \"none\".\n        width (Optional[int], optional): Optional width of panel. Defaults to None to auto-detect.\n        height (Optional[int], optional): Optional height of panel. Defaults to None to auto-detect.\n        padding (Optional[PaddingDimensions]): Optional padding around renderable. Defaults to 0.\n        highlight (bool, optional): Enable automatic highlighting of panel title (if str). Defaults to False.\n    \"\"\"\n\n    def __init__(\n        self,\n        renderable: \"RenderableType\",\n        box: Box = ROUNDED,\n        *,\n        title: Optional[TextType] = None,\n        title_align: AlignMethod = \"center\",\n        subtitle: Optional[TextType] = None,\n        subtitle_align: AlignMethod = \"center\",\n        safe_box: Optional[bool] = None,\n        expand: bool = True,\n        style: StyleType = \"none\",\n        border_style: StyleType = \"none\",\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n        padding: PaddingDimensions = (0, 1),\n        highlight: bool = False,\n    ) -> None:\n        self.renderable = renderable\n        self.box = box\n        self.title = title\n        self.title_align: AlignMethod = title_align\n        self.subtitle = subtitle\n        self.subtitle_align = subtitle_align\n        self.safe_box = safe_box\n        self.expand = expand\n        self.style = style\n        self.border_style = border_style\n        self.width = width\n        self.height = height\n        self.padding = padding\n        self.highlight = highlight\n\n    @classmethod\n    def fit(\n        cls,\n        renderable: \"RenderableType\",\n        box: Box = ROUNDED,\n        *,\n        title: Optional[TextType] = None,\n        title_align: AlignMethod = \"center\",\n        subtitle: Optional[TextType] = None,\n        subtitle_align: AlignMethod = \"center\",\n        safe_box: Optional[bool] = None,\n        style: StyleType = \"none\",\n        border_style: StyleType = \"none\",\n        width: Optional[int] = None,\n        height: Optional[int] = None,\n        padding: PaddingDimensions = (0, 1),\n        highlight: bool = False,\n    ) -> \"Panel\":\n        \"\"\"An alternative constructor that sets expand=False.\"\"\"\n        return cls(\n            renderable,\n            box,\n            title=title,\n            title_align=title_align,\n            subtitle=subtitle,\n            subtitle_align=subtitle_align,\n            safe_box=safe_box,\n            style=style,\n            border_style=border_style,\n            width=width,\n            height=height,\n            padding=padding,\n            highlight=highlight,\n            expand=False,\n        )\n\n    @property\n    def _title(self) -> Optional[Text]:\n        if self.title:\n            title_text = (\n                Text.from_markup(self.title)\n                if isinstance(self.title, str)\n                else self.title.copy()\n            )\n            title_text.end = \"\"\n            title_text.plain = title_text.plain.replace(\"\\n\", \" \")\n            title_text.no_wrap = True\n            title_text.expand_tabs()\n            title_text.pad(1)\n            return title_text\n        return None\n\n    @property\n    def _subtitle(self) -> Optional[Text]:\n        if self.subtitle:\n            subtitle_text = (\n                Text.from_markup(self.subtitle)\n                if isinstance(self.subtitle, str)\n                else self.subtitle.copy()\n            )\n            subtitle_text.end = \"\"\n            subtitle_text.plain = subtitle_text.plain.replace(\"\\n\", \" \")\n            subtitle_text.no_wrap = True\n            subtitle_text.expand_tabs()\n            subtitle_text.pad(1)\n            return subtitle_text\n        return None\n\n    def __rich_console__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"RenderResult\":\n        _padding = Padding.unpack(self.padding)\n        renderable = (\n            Padding(self.renderable, _padding) if any(_padding) else self.renderable\n        )\n        style = console.get_style(self.style)\n        border_style = style + console.get_style(self.border_style)\n        width = (\n            options.max_width\n            if self.width is None\n            else min(options.max_width, self.width)\n        )\n\n        safe_box: bool = console.safe_box if self.safe_box is None else self.safe_box\n        box = self.box.substitute(options, safe=safe_box)\n\n        def align_text(\n            text: Text, width: int, align: str, character: str, style: Style\n        ) -> Text:\n            \"\"\"Gets new aligned text.\n\n            Args:\n                text (Text): Title or subtitle text.\n                width (int): Desired width.\n                align (str): Alignment.\n                character (str): Character for alignment.\n                style (Style): Border style\n\n            Returns:\n                Text: New text instance\n            \"\"\"\n            text = text.copy()\n            text.truncate(width)\n            excess_space = width - cell_len(text.plain)\n            if text.style:\n                text.stylize(console.get_style(text.style))\n\n            if excess_space:\n                if align == \"left\":\n                    return Text.assemble(\n                        text,\n                        (character * excess_space, style),\n                        no_wrap=True,\n                        end=\"\",\n                    )\n                elif align == \"center\":\n                    left = excess_space // 2\n                    return Text.assemble(\n                        (character * left, style),\n                        text,\n                        (character * (excess_space - left), style),\n                        no_wrap=True,\n                        end=\"\",\n                    )\n                else:\n                    return Text.assemble(\n                        (character * excess_space, style),\n                        text,\n                        no_wrap=True,\n                        end=\"\",\n                    )\n            return text\n\n        title_text = self._title\n        if title_text is not None:\n            title_text.stylize_before(border_style)\n\n        child_width = (\n            width - 2\n            if self.expand\n            else console.measure(\n                renderable, options=options.update_width(width - 2)\n            ).maximum\n        )\n        child_height = self.height or options.height or None\n        if child_height:\n            child_height -= 2\n        if title_text is not None:\n            child_width = min(\n                options.max_width - 2, max(child_width, title_text.cell_len + 2)\n            )\n\n        width = child_width + 2\n        child_options = options.update(\n            width=child_width, height=child_height, highlight=self.highlight\n        )\n        lines = console.render_lines(renderable, child_options, style=style)\n\n        line_start = Segment(box.mid_left, border_style)\n        line_end = Segment(f\"{box.mid_right}\", border_style)\n        new_line = Segment.line()\n        if title_text is None or width <= 4:\n            yield Segment(box.get_top([width - 2]), border_style)\n        else:\n            title_text = align_text(\n                title_text,\n                width - 4,\n                self.title_align,\n                box.top,\n                border_style,\n            )\n            yield Segment(box.top_left + box.top, border_style)\n            yield from console.render(title_text, child_options.update_width(width - 4))\n            yield Segment(box.top + box.top_right, border_style)\n\n        yield new_line\n        for line in lines:\n            yield line_start\n            yield from line\n            yield line_end\n            yield new_line\n\n        subtitle_text = self._subtitle\n        if subtitle_text is not None:\n            subtitle_text.stylize_before(border_style)\n\n        if subtitle_text is None or width <= 4:\n            yield Segment(box.get_bottom([width - 2]), border_style)\n        else:\n            subtitle_text = align_text(\n                subtitle_text,\n                width - 4,\n                self.subtitle_align,\n                box.bottom,\n                border_style,\n            )\n            yield Segment(box.bottom_left + box.bottom, border_style)\n            yield from console.render(\n                subtitle_text, child_options.update_width(width - 4)\n            )\n            yield Segment(box.bottom + box.bottom_right, border_style)\n\n        yield new_line\n\n    def __rich_measure__(\n        self, console: \"Console\", options: \"ConsoleOptions\"\n    ) -> \"Measurement\":\n        _title = self._title\n        _, right, _, left = Padding.unpack(self.padding)\n        padding = left + right\n        renderables = [self.renderable, _title] if _title else [self.renderable]\n\n        if self.width is None:\n            width = (\n                measure_renderables(\n                    console,\n                    options.update_width(options.max_width - padding - 2),\n                    renderables,\n                ).maximum\n                + padding\n                + 2\n            )\n        else:\n            width = self.width\n        return Measurement(width, width)\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    from .console import Console\n\n    c = Console()\n\n    from .box import DOUBLE, ROUNDED\n    from .padding import Padding\n\n    p = Panel(\n        \"Hello, World!\",\n        title=\"rich.Panel\",\n        style=\"white on blue\",\n        box=DOUBLE,\n        padding=1,\n    )\n\n    c.print()\n    c.print(p)\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "a6571254c024",
      "repo": "rich",
      "commit_hash": "30e5ed6",
      "commit_message": "fix(panel): fix title missing panel background",
      "file_path": "tests/test_panel.py",
      "language": "python",
      "code_before": "import io\n\nimport pytest\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.segment import Segment\nfrom rich.style import Style\nfrom rich.text import Text\n\ntests = [\n    Panel(\"Hello, World\", padding=0),\n    Panel(\"Hello, World\", expand=False, padding=0),\n    Panel.fit(\"Hello, World\", padding=0),\n    Panel(\"Hello, World\", width=8, padding=0),\n    Panel(Panel(\"Hello, World\", padding=0), padding=0),\n    Panel(\"Hello, World\", title=\"FOO\", padding=0),\n    Panel(\"Hello, World\", subtitle=\"FOO\", padding=0),\n]\n\nexpected = [\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World                                    \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello,\u2502\\n\u2502World \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502\\n\u2502\u2502Hello, World                                  \u2502\u2502\\n\u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 FOO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World                                    \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World                                    \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 FOO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n]\n\n\ndef render(panel, width=50) -> str:\n    console = Console(file=io.StringIO(), width=50, legacy_windows=False)\n    console.print(panel)\n    result = console.file.getvalue()\n    print(result)\n    return result\n\n\n@pytest.mark.parametrize(\"panel,expected\", zip(tests, expected))\ndef test_render_panel(panel, expected) -> None:\n    assert render(panel) == expected\n\n\ndef test_console_width() -> None:\n    console = Console(file=io.StringIO(), width=50, legacy_windows=False)\n    panel = Panel(\"Hello, World\", expand=False)\n    min_width, max_width = panel.__rich_measure__(console, console.options)\n    assert min_width == 16\n    assert max_width == 16\n\n\ndef test_fixed_width() -> None:\n    console = Console(file=io.StringIO(), width=50, legacy_windows=False)\n    panel = Panel(\"Hello World\", width=20)\n    min_width, max_width = panel.__rich_measure__(console, console.options)\n    assert min_width == 20\n    assert max_width == 20\n\n\ndef test_render_size() -> None:\n    console = Console(width=63, height=46, legacy_windows=False)\n    options = console.options.update_dimensions(80, 4)\n    lines = console.render_lines(Panel(\"foo\", title=\"Hello\"), options=options)\n    print(repr(lines))\n    expected = [\n        [\n            Segment(\"\u256d\u2500\", Style()),\n            Segment(\n                \"\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Hello \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\"\n            ),\n            Segment(\"\u2500\u256e\", Style()),\n        ],\n        [\n            Segment(\"\u2502\", Style()),\n            Segment(\" \", Style()),\n            Segment(\"foo\"),\n            Segment(\n                \"                                                                         \",\n                Style(),\n            ),\n            Segment(\" \", Style()),\n            Segment(\"\u2502\", Style()),\n        ],\n        [\n            Segment(\"\u2502\", Style()),\n            Segment(\" \", Style()),\n            Segment(\n                \"                                                                            \",\n                Style(),\n            ),\n            Segment(\" \", Style()),\n            Segment(\"\u2502\", Style()),\n        ],\n        [\n            Segment(\n                \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\",\n                Style(),\n            )\n        ],\n    ]\n    assert lines == expected\n\n\ndef test_title_text() -> None:\n    panel = Panel(\n        \"Hello, World\",\n        title=Text(\"title\", style=\"red\"),\n        subtitle=Text(\"subtitle\", style=\"magenta bold\"),\n    )\n    console = Console(\n        file=io.StringIO(),\n        width=50,\n        height=20,\n        legacy_windows=False,\n        force_terminal=True,\n        color_system=\"truecolor\",\n    )\n    console.print(panel)\n\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[31m title \\x1b[0m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 Hello, World                                   \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[1;35m subtitle \\x1b[0m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    assert result == expected\n\n\ndef test_title_text_with_border_color() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/2745\"\"\"\n    panel = Panel(\n        \"Hello, World\",\n        border_style=\"blue\",\n        title=Text(\"title\", style=\"red\"),\n        subtitle=Text(\"subtitle\", style=\"magenta bold\"),\n    )\n    console = Console(\n        file=io.StringIO(),\n        width=50,\n        height=20,\n        legacy_windows=False,\n        force_terminal=True,\n        color_system=\"truecolor\",\n    )\n    console.print(panel)\n\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\\x1b[34m\u256d\u2500\\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[31m title \\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[34m\u2500\u256e\\x1b[0m\\n\\x1b[34m\u2502\\x1b[0m Hello, World                                   \\x1b[34m\u2502\\x1b[0m\\n\\x1b[34m\u2570\u2500\\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[1;35m subtitle \\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[34m\u2500\u256f\\x1b[0m\\n\"\n    assert result == expected\n\n\nif __name__ == \"__main__\":\n    expected = []\n    for panel in tests:\n        result = render(panel)\n        print(result)\n        expected.append(result)\n    print(\"--\")\n    print()\n    print(f\"expected={repr(expected)}\")\n",
      "code_after": "import io\n\nimport pytest\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.segment import Segment\nfrom rich.style import Style\nfrom rich.text import Text\n\ntests = [\n    Panel(\"Hello, World\", padding=0),\n    Panel(\"Hello, World\", expand=False, padding=0),\n    Panel.fit(\"Hello, World\", padding=0),\n    Panel(\"Hello, World\", width=8, padding=0),\n    Panel(Panel(\"Hello, World\", padding=0), padding=0),\n    Panel(\"Hello, World\", title=\"FOO\", padding=0),\n    Panel(\"Hello, World\", subtitle=\"FOO\", padding=0),\n]\n\nexpected = [\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World                                    \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello,\u2502\\n\u2502World \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\u2502\\n\u2502\u2502Hello, World                                  \u2502\u2502\\n\u2502\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 FOO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World                                    \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n    \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502Hello, World                                    \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 FOO \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\",\n]\n\n\ndef render(panel, width=50) -> str:\n    console = Console(file=io.StringIO(), width=50, legacy_windows=False)\n    console.print(panel)\n    result = console.file.getvalue()\n    print(result)\n    return result\n\n\n@pytest.mark.parametrize(\"panel,expected\", zip(tests, expected))\ndef test_render_panel(panel, expected) -> None:\n    assert render(panel) == expected\n\n\ndef test_console_width() -> None:\n    console = Console(file=io.StringIO(), width=50, legacy_windows=False)\n    panel = Panel(\"Hello, World\", expand=False)\n    min_width, max_width = panel.__rich_measure__(console, console.options)\n    assert min_width == 16\n    assert max_width == 16\n\n\ndef test_fixed_width() -> None:\n    console = Console(file=io.StringIO(), width=50, legacy_windows=False)\n    panel = Panel(\"Hello World\", width=20)\n    min_width, max_width = panel.__rich_measure__(console, console.options)\n    assert min_width == 20\n    assert max_width == 20\n\n\ndef test_render_size() -> None:\n    console = Console(width=63, height=46, legacy_windows=False)\n    options = console.options.update_dimensions(80, 4)\n    lines = console.render_lines(Panel(\"foo\", title=\"Hello\"), options=options)\n    print(repr(lines))\n    expected = [\n        [\n            Segment(\"\u256d\u2500\", Style()),\n            Segment(\n                \"\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Hello \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\"\n            ),\n            Segment(\"\u2500\u256e\", Style()),\n        ],\n        [\n            Segment(\"\u2502\", Style()),\n            Segment(\" \", Style()),\n            Segment(\"foo\"),\n            Segment(\n                \"                                                                         \",\n                Style(),\n            ),\n            Segment(\" \", Style()),\n            Segment(\"\u2502\", Style()),\n        ],\n        [\n            Segment(\"\u2502\", Style()),\n            Segment(\" \", Style()),\n            Segment(\n                \"                                                                            \",\n                Style(),\n            ),\n            Segment(\" \", Style()),\n            Segment(\"\u2502\", Style()),\n        ],\n        [\n            Segment(\n                \"\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\",\n                Style(),\n            )\n        ],\n    ]\n    assert lines == expected\n\n\ndef test_title_text() -> None:\n    panel = Panel(\n        \"Hello, World\",\n        title=Text(\"title\", style=\"red\"),\n        subtitle=Text(\"subtitle\", style=\"magenta bold\"),\n    )\n    console = Console(\n        file=io.StringIO(),\n        width=50,\n        height=20,\n        legacy_windows=False,\n        force_terminal=True,\n        color_system=\"truecolor\",\n    )\n    console.print(panel)\n\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[31m title \\x1b[0m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\\n\u2502 Hello, World                                   \u2502\\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[1;35m subtitle \\x1b[0m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\\n\"\n    assert result == expected\n\n\ndef test_title_text_with_border_color() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/2745\"\"\"\n    panel = Panel(\n        \"Hello, World\",\n        border_style=\"blue\",\n        title=Text(\"title\", style=\"red\"),\n        subtitle=Text(\"subtitle\", style=\"magenta bold\"),\n    )\n    console = Console(\n        file=io.StringIO(),\n        width=50,\n        height=20,\n        legacy_windows=False,\n        force_terminal=True,\n        color_system=\"truecolor\",\n    )\n    console.print(panel)\n\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\\x1b[34m\u256d\u2500\\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[31m title \\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[34m\u2500\u256e\\x1b[0m\\n\\x1b[34m\u2502\\x1b[0m Hello, World                                   \\x1b[34m\u2502\\x1b[0m\\n\\x1b[34m\u2570\u2500\\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[1;35m subtitle \\x1b[0m\\x1b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[34m\u2500\u256f\\x1b[0m\\n\"\n    assert result == expected\n\n\ndef test_title_text_with_panel_background() -> None:\n    \"\"\"Regression test for https://github.com/Textualize/rich/issues/3569\"\"\"\n    panel = Panel(\n        \"Hello, World\",\n        style=\"on blue\",\n        title=Text(\"title\", style=\"red\"),\n        subtitle=Text(\"subtitle\", style=\"magenta bold\"),\n    )\n    console = Console(\n        file=io.StringIO(),\n        width=50,\n        height=20,\n        legacy_windows=False,\n        force_terminal=True,\n        color_system=\"truecolor\",\n    )\n    console.print(panel)\n\n    result = console.file.getvalue()\n    print(repr(result))\n    expected = \"\\x1b[44m\u256d\u2500\\x1b[0m\\x1b[44m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[31;44m title \\x1b[0m\\x1b[44m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[44m\u2500\u256e\\x1b[0m\\n\\x1b[44m\u2502\\x1b[0m\\x1b[44m \\x1b[0m\\x1b[44mHello, World\\x1b[0m\\x1b[44m                                  \\x1b[0m\\x1b[44m \\x1b[0m\\x1b[44m\u2502\\x1b[0m\\n\\x1b[44m\u2570\u2500\\x1b[0m\\x1b[44m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[1;35;44m subtitle \\x1b[0m\\x1b[44m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\\x1b[0m\\x1b[44m\u2500\u256f\\x1b[0m\\n\"\n    assert result == expected\n\n\nif __name__ == \"__main__\":\n    expected = []\n    for panel in tests:\n        result = render(panel)\n        print(result)\n        expected.append(result)\n    print(\"--\")\n    print()\n    print(f\"expected={repr(expected)}\")\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "c1021230e6e1",
      "repo": "rich",
      "commit_hash": "a648cdc",
      "commit_message": "docs: fix search not working",
      "file_path": "docs/source/conf.py",
      "language": "python",
      "code_before": "# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n\n\n# -- Project information -----------------------------------------------------\n\nimport sys\n\nimport sphinx_rtd_theme\n\nif sys.version_info >= (3, 8):\n    from importlib.metadata import Distribution\nelse:\n    from importlib_metadata import Distribution\n\nhtml_theme = \"sphinx_rtd_theme\"\n\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\nproject = \"Rich\"\ncopyright = \"Will McGugan\"\nauthor = \"Will McGugan\"\n\n# The full version, including alpha/beta/rc tags\nrelease = Distribution.from_name(\"rich\").version\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.autosectionlabel\",\n    \"sphinx_copybutton\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n# html_theme = \"alabaster\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\nintersphinx_mapping = {\"python\": (\"http://docs.python.org/3\", None)}\n\nautodoc_typehints = \"description\"\n\nhtml_css_files = [\n    \"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/fira_code.min.css\"\n]\n",
      "code_after": "# Configuration file for the Sphinx documentation builder.\n#\n# This file only contains a selection of the most common options. For a full\n# list see the documentation:\n# https://www.sphinx-doc.org/en/master/usage/configuration.html\n\n# -- Path setup --------------------------------------------------------------\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n#\n# import os\n# import sys\n# sys.path.insert(0, os.path.abspath('.'))\n\n\n# -- Project information -----------------------------------------------------\n\nimport sys\n\nimport sphinx_rtd_theme\n\nif sys.version_info >= (3, 8):\n    from importlib.metadata import Distribution\nelse:\n    from importlib_metadata import Distribution\n\nhtml_theme = \"sphinx_rtd_theme\"\n\nhtml_theme_path = [sphinx_rtd_theme.get_html_theme_path()]\n\nproject = \"Rich\"\ncopyright = \"Will McGugan\"\nauthor = \"Will McGugan\"\n\n# The full version, including alpha/beta/rc tags\nrelease = Distribution.from_name(\"rich\").version\n\n\n# -- General configuration ---------------------------------------------------\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.viewcode\",\n    \"sphinx.ext.napoleon\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.autosectionlabel\",\n    \"sphinx_copybutton\",\n    \"sphinx_rtd_theme\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\n# This pattern also affects html_static_path and html_extra_path.\nexclude_patterns = []\n\n\n# -- Options for HTML output -------------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\n#\n# html_theme = \"alabaster\"\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\nintersphinx_mapping = {\"python\": (\"http://docs.python.org/3\", None)}\n\nautodoc_typehints = \"description\"\n\nhtml_css_files = [\n    \"https://cdnjs.cloudflare.com/ajax/libs/firacode/6.2.0/fira_code.min.css\"\n]\n",
      "bug_category": "readability",
      "error_type": "readability",
      "confidence": 0.2
    },
    {
      "bug_id": "74620ccc8612",
      "repo": "rich",
      "commit_hash": "a34914b",
      "commit_message": "fix for null tb_offset",
      "file_path": "rich/traceback.py",
      "language": "python",
      "code_before": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            cause = getattr(exc_value, \"__cause__\", None)\n            if cause:\n                exc_type = cause.__class__\n                exc_value = cause\n                # __traceback__ can be None, e.g. for exceptions raised by the\n                # 'multiprocessing' module\n                traceback = cause.__traceback__\n                is_cause = True\n                continue\n\n            cause = exc_value.__context__\n            if cause and not getattr(exc_value, \"__suppress_context__\", False):\n                exc_type = cause.__class__\n                exc_value = cause\n                traceback = cause.__traceback__\n                is_cause = False\n                continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield \"\"\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code_lines = linecache.getlines(frame.filename)\n                    code = \"\".join(code_lines)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n\n                        # Stylize a line at a time\n                        # So that indentation isn't underlined (which looks bad)\n                        for line1, column1, column2 in _iter_syntax_lines(start, end):\n                            try:\n                                if column1 == 0:\n                                    line = code_lines[line1 - 1]\n                                    column1 = len(line) - len(line.lstrip())\n                                if column2 == -1:\n                                    column2 = len(code_lines[line1 - 1])\n                            except IndexError:\n                                # Being defensive here\n                                # If last_instruction reports a line out-of-bounds, we don't want to crash\n                                continue\n\n                            syntax.stylize_range(\n                                style=\"traceback.error_range\",\n                                start=(line1, column1),\n                                end=(line1, column2),\n                            )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "code_after": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_first_last, loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax, SyntaxPosition\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef _iter_syntax_lines(\n    start: SyntaxPosition, end: SyntaxPosition\n) -> Iterable[Tuple[int, int, int]]:\n    \"\"\"Yield start and end positions per line.\n\n    Args:\n        start: Start position.\n        end: End position.\n\n    Returns:\n        Iterable of (LINE, COLUMN1, COLUMN2).\n    \"\"\"\n\n    line1, column1 = start\n    line2, column2 = end\n\n    if line1 == line2:\n        yield line1, column1, column2\n    else:\n        for first, last, line_no in loop_first_last(range(line1, line2 + 1)):\n            if first:\n                yield line_no, column1, -1\n            elif last:\n                yield line_no, 0, column2\n            else:\n                yield line_no, 0, -1\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\")\n            if tb_offset is None:\n                tb_offset = 1 if compiled else 0\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            cause = getattr(exc_value, \"__cause__\", None)\n            if cause:\n                exc_type = cause.__class__\n                exc_value = cause\n                # __traceback__ can be None, e.g. for exceptions raised by the\n                # 'multiprocessing' module\n                traceback = cause.__traceback__\n                is_cause = True\n                continue\n\n            cause = exc_value.__context__\n            if cause and not getattr(exc_value, \"__suppress_context__\", False):\n                exc_type = cause.__class__\n                exc_value = cause\n                traceback = cause.__traceback__\n                is_cause = False\n                continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield \"\"\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code_lines = linecache.getlines(frame.filename)\n                    code = \"\".join(code_lines)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n\n                        # Stylize a line at a time\n                        # So that indentation isn't underlined (which looks bad)\n                        for line1, column1, column2 in _iter_syntax_lines(start, end):\n                            try:\n                                if column1 == 0:\n                                    line = code_lines[line1 - 1]\n                                    column1 = len(line) - len(line.lstrip())\n                                if column2 == -1:\n                                    column2 = len(code_lines[line1 - 1])\n                            except IndexError:\n                                # Being defensive here\n                                # If last_instruction reports a line out-of-bounds, we don't want to crash\n                                continue\n\n                            syntax.stylize_range(\n                                style=\"traceback.error_range\",\n                                start=(line1, column1),\n                                end=(line1, column2),\n                            )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "1933ae0d08da",
      "repo": "rich",
      "commit_hash": "c8e9222",
      "commit_message": "typing fix",
      "file_path": "rich/traceback.py",
      "language": "python",
      "code_before": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n        # REMOVE THIS LINE\n        traceback_console.print(exception_traceback.trace)\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            cause = getattr(exc_value, \"__cause__\", None)\n            if cause:\n                exc_type = cause.__class__\n                exc_value = cause\n                # __traceback__ can be None, e.g. for exceptions raised by the\n                # 'multiprocessing' module\n                traceback = cause.__traceback__\n                is_cause = True\n                continue\n\n            cause = exc_value.__context__\n            if cause and not getattr(exc_value, \"__suppress_context__\", False):\n                exc_type = cause.__class__\n                exc_value = cause\n                traceback = cause.__traceback__\n                is_cause = False\n                continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: list[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            style=background_style,\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def read_code(filename: str) -> str:\n            \"\"\"Read files, and cache results on filename.\n\n            Args:\n                filename (str): Filename to read\n\n            Returns:\n                str: Contents of file\n            \"\"\"\n            return \"\".join(linecache.getlines(filename))\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code = read_code(frame.filename)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n                        syntax.stylize_range(\n                            style=\"traceback.error_range\",\n                            start=start,\n                            end=end,\n                            style_before=True,\n                        )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "code_after": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_last\nfrom .columns import Columns\nfrom .console import (\n    Console,\n    ConsoleOptions,\n    ConsoleRenderable,\n    Group,\n    RenderResult,\n    group,\n)\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        exception_traceback = Traceback.from_exception(\n            type_,\n            value,\n            traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=bool(locals_hide_sunder),\n            indent_guides=indent_guides,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n        # REMOVE THIS LINE\n        traceback_console.print(exception_traceback.trace)\n        traceback_console.print(exception_traceback)\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n    is_group: bool = False\n    exceptions: List[\"Trace\"] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if sys.version_info >= (3, 11):\n                if isinstance(exc_value, (BaseExceptionGroup, ExceptionGroup)):\n                    stack.is_group = True\n                    for exception in exc_value.exceptions:\n                        stack.exceptions.append(\n                            Traceback.extract(\n                                type(exception),\n                                exception,\n                                exception.__traceback__,\n                                show_locals=show_locals,\n                                locals_max_length=locals_max_length,\n                                locals_hide_dunder=locals_hide_dunder,\n                                locals_hide_sunder=locals_hide_sunder,\n                            )\n                        )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            cause = getattr(exc_value, \"__cause__\", None)\n            if cause:\n                exc_type = cause.__class__\n                exc_value = cause\n                # __traceback__ can be None, e.g. for exceptions raised by the\n                # 'multiprocessing' module\n                traceback = cause.__traceback__\n                is_cause = True\n                continue\n\n            cause = exc_value.__context__\n            if cause and not getattr(exc_value, \"__suppress_context__\", False):\n                exc_type = cause.__class__\n                exc_value = cause\n                traceback = cause.__traceback__\n                is_cause = False\n                continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n\n        @group()\n        def render_stack(stack: Stack, last: bool) -> RenderResult:\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if stack.is_group:\n                for group_no, group_exception in enumerate(stack.exceptions, 1):\n                    grouped_exceptions: List[Group] = []\n                    for group_last, group_stack in loop_last(group_exception.stacks):\n                        grouped_exceptions.append(render_stack(group_stack, group_last))\n                    yield Constrain(\n                        Panel(\n                            Group(*grouped_exceptions),\n                            style=background_style,\n                            title=f\"Sub-exception #{group_no}\",\n                            border_style=\"traceback.group.border\",\n                        ),\n                        self.width,\n                    )\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            yield render_stack(stack, last)\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def read_code(filename: str) -> str:\n            \"\"\"Read files, and cache results on filename.\n\n            Args:\n                filename (str): Filename to read\n\n            Returns:\n                str: Contents of file\n            \"\"\"\n            return \"\".join(linecache.getlines(filename))\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code = read_code(frame.filename)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n                        syntax.stylize_range(\n                            style=\"traceback.error_range\",\n                            start=start,\n                            end=end,\n                            style_before=True,\n                        )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "c35903ed36f7",
      "repo": "rich",
      "commit_hash": "d09e63a",
      "commit_message": "fix typing",
      "file_path": "rich/traceback.py",
      "language": "python",
      "code_before": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_last\nfrom .columns import Columns\nfrom .console import Console, ConsoleOptions, ConsoleRenderable, RenderResult, group\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        traceback_console.print(\n            Traceback.from_exception(\n                type_,\n                value,\n                traceback,\n                width=width,\n                code_width=code_width,\n                extra_lines=extra_lines,\n                theme=theme,\n                word_wrap=word_wrap,\n                show_locals=show_locals,\n                locals_max_length=locals_max_length,\n                locals_max_string=locals_max_string,\n                locals_hide_dunder=locals_hide_dunder,\n                locals_hide_sunder=bool(locals_hide_sunder),\n                indent_guides=indent_guides,\n                suppress=suppress,\n                max_frames=max_frames,\n            )\n        )\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: list[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            cause = getattr(exc_value, \"__cause__\", None)\n            if cause:\n                exc_type = cause.__class__\n                exc_value = cause\n                # __traceback__ can be None, e.g. for exceptions raised by the\n                # 'multiprocessing' module\n                traceback = cause.__traceback__\n                is_cause = True\n                continue\n\n            cause = exc_value.__context__\n            if cause and not getattr(exc_value, \"__suppress_context__\", False):\n                exc_type = cause.__class__\n                exc_value = cause\n                traceback = cause.__traceback__\n                is_cause = False\n                continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def read_code(filename: str) -> str:\n            \"\"\"Read files, and cache results on filename.\n\n            Args:\n                filename (str): Filename to read\n\n            Returns:\n                str: Contents of file\n            \"\"\"\n            return \"\".join(linecache.getlines(filename))\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code = read_code(frame.filename)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n                        syntax.stylize_range(\n                            style=\"traceback.error_range\",\n                            start=start,\n                            end=end,\n                            style_before=True,\n                        )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "code_after": "import inspect\nimport linecache\nimport os\nimport sys\nfrom dataclasses import dataclass, field\nfrom itertools import islice\nfrom traceback import walk_tb\nfrom types import ModuleType, TracebackType\nfrom typing import (\n    Any,\n    Callable,\n    Dict,\n    Iterable,\n    List,\n    Optional,\n    Sequence,\n    Tuple,\n    Type,\n    Union,\n)\n\nfrom pygments.lexers import guess_lexer_for_filename\nfrom pygments.token import Comment, Keyword, Name, Number, Operator, String\nfrom pygments.token import Text as TextToken\nfrom pygments.token import Token\nfrom pygments.util import ClassNotFound\n\nfrom . import pretty\nfrom ._loop import loop_last\nfrom .columns import Columns\nfrom .console import Console, ConsoleOptions, ConsoleRenderable, RenderResult, group\nfrom .constrain import Constrain\nfrom .highlighter import RegexHighlighter, ReprHighlighter\nfrom .panel import Panel\nfrom .scope import render_scope\nfrom .style import Style\nfrom .syntax import Syntax\nfrom .text import Text\nfrom .theme import Theme\n\nWINDOWS = sys.platform == \"win32\"\n\nLOCALS_MAX_LENGTH = 10\nLOCALS_MAX_STRING = 80\n\n\ndef install(\n    *,\n    console: Optional[Console] = None,\n    width: Optional[int] = 100,\n    code_width: Optional[int] = 88,\n    extra_lines: int = 3,\n    theme: Optional[str] = None,\n    word_wrap: bool = False,\n    show_locals: bool = False,\n    locals_max_length: int = LOCALS_MAX_LENGTH,\n    locals_max_string: int = LOCALS_MAX_STRING,\n    locals_hide_dunder: bool = True,\n    locals_hide_sunder: Optional[bool] = None,\n    indent_guides: bool = True,\n    suppress: Iterable[Union[str, ModuleType]] = (),\n    max_frames: int = 100,\n) -> Callable[[Type[BaseException], BaseException, Optional[TracebackType]], Any]:\n    \"\"\"Install a rich traceback handler.\n\n    Once installed, any tracebacks will be printed with syntax highlighting and rich formatting.\n\n\n    Args:\n        console (Optional[Console], optional): Console to write exception to. Default uses internal Console instance.\n        width (Optional[int], optional): Width (in characters) of traceback. Defaults to 100.\n        code_width (Optional[int], optional): Code width (in characters) of traceback. Defaults to 88.\n        extra_lines (int, optional): Extra lines of code. Defaults to 3.\n        theme (Optional[str], optional): Pygments theme to use in traceback. Defaults to ``None`` which will pick\n            a theme appropriate for the platform.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n\n    Returns:\n        Callable: The previous exception handler that was replaced.\n\n    \"\"\"\n    traceback_console = Console(stderr=True) if console is None else console\n\n    locals_hide_sunder = (\n        True\n        if (traceback_console.is_jupyter and locals_hide_sunder is None)\n        else locals_hide_sunder\n    )\n\n    def excepthook(\n        type_: Type[BaseException],\n        value: BaseException,\n        traceback: Optional[TracebackType],\n    ) -> None:\n        traceback_console.print(\n            Traceback.from_exception(\n                type_,\n                value,\n                traceback,\n                width=width,\n                code_width=code_width,\n                extra_lines=extra_lines,\n                theme=theme,\n                word_wrap=word_wrap,\n                show_locals=show_locals,\n                locals_max_length=locals_max_length,\n                locals_max_string=locals_max_string,\n                locals_hide_dunder=locals_hide_dunder,\n                locals_hide_sunder=bool(locals_hide_sunder),\n                indent_guides=indent_guides,\n                suppress=suppress,\n                max_frames=max_frames,\n            )\n        )\n\n    def ipy_excepthook_closure(ip: Any) -> None:  # pragma: no cover\n        tb_data = {}  # store information about showtraceback call\n        default_showtraceback = ip.showtraceback  # keep reference of default traceback\n\n        def ipy_show_traceback(*args: Any, **kwargs: Any) -> None:\n            \"\"\"wrap the default ip.showtraceback to store info for ip._showtraceback\"\"\"\n            nonlocal tb_data\n            tb_data = kwargs\n            default_showtraceback(*args, **kwargs)\n\n        def ipy_display_traceback(\n            *args: Any, is_syntax: bool = False, **kwargs: Any\n        ) -> None:\n            \"\"\"Internally called traceback from ip._showtraceback\"\"\"\n            nonlocal tb_data\n            exc_tuple = ip._get_exc_info()\n\n            # do not display trace on syntax error\n            tb: Optional[TracebackType] = None if is_syntax else exc_tuple[2]\n\n            # determine correct tb_offset\n            compiled = tb_data.get(\"running_compiled_code\", False)\n            tb_offset = tb_data.get(\"tb_offset\", 1 if compiled else 0)\n            # remove ipython internal frames from trace with tb_offset\n            for _ in range(tb_offset):\n                if tb is None:\n                    break\n                tb = tb.tb_next\n\n            excepthook(exc_tuple[0], exc_tuple[1], tb)\n            tb_data = {}  # clear data upon usage\n\n        # replace _showtraceback instead of showtraceback to allow ipython features such as debugging to work\n        # this is also what the ipython docs recommends to modify when subclassing InteractiveShell\n        ip._showtraceback = ipy_display_traceback\n        # add wrapper to capture tb_data\n        ip.showtraceback = ipy_show_traceback\n        ip.showsyntaxerror = lambda *args, **kwargs: ipy_display_traceback(\n            *args, is_syntax=True, **kwargs\n        )\n\n    try:  # pragma: no cover\n        # if within ipython, use customized traceback\n        ip = get_ipython()  # type: ignore[name-defined]\n        ipy_excepthook_closure(ip)\n        return sys.excepthook\n    except Exception:\n        # otherwise use default system hook\n        old_excepthook = sys.excepthook\n        sys.excepthook = excepthook\n        return old_excepthook\n\n\n@dataclass\nclass Frame:\n    filename: str\n    lineno: int\n    name: str\n    line: str = \"\"\n    locals: Optional[Dict[str, pretty.Node]] = None\n    last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]] = None\n\n\n@dataclass\nclass _SyntaxError:\n    offset: int\n    filename: str\n    line: str\n    lineno: int\n    msg: str\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Stack:\n    exc_type: str\n    exc_value: str\n    syntax_error: Optional[_SyntaxError] = None\n    is_cause: bool = False\n    frames: List[Frame] = field(default_factory=list)\n    notes: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass Trace:\n    stacks: List[Stack]\n\n\nclass PathHighlighter(RegexHighlighter):\n    highlights = [r\"(?P<dim>.*/)(?P<bold>.+)\"]\n\n\nclass Traceback:\n    \"\"\"A Console renderable that renders a traceback.\n\n    Args:\n        trace (Trace, optional): A `Trace` object produced from `extract`. Defaults to None, which uses\n            the last exception.\n        width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n        code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n        extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n        theme (str, optional): Override pygments theme used in traceback.\n        word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n        show_locals (bool, optional): Enable display of local variables. Defaults to False.\n        indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n        locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n            Defaults to 10.\n        locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n        locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n        locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n        suppress (Sequence[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n        max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n    \"\"\"\n\n    LEXERS = {\n        \"\": \"text\",\n        \".py\": \"python\",\n        \".pxd\": \"cython\",\n        \".pyx\": \"cython\",\n        \".pxi\": \"pyrex\",\n    }\n\n    def __init__(\n        self,\n        trace: Optional[Trace] = None,\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ):\n        if trace is None:\n            exc_type, exc_value, traceback = sys.exc_info()\n            if exc_type is None or exc_value is None or traceback is None:\n                raise ValueError(\n                    \"Value for 'trace' required if not called in except: block\"\n                )\n            trace = self.extract(\n                exc_type, exc_value, traceback, show_locals=show_locals\n            )\n        self.trace = trace\n        self.width = width\n        self.code_width = code_width\n        self.extra_lines = extra_lines\n        self.theme = Syntax.get_theme(theme or \"ansi_dark\")\n        self.word_wrap = word_wrap\n        self.show_locals = show_locals\n        self.indent_guides = indent_guides\n        self.locals_max_length = locals_max_length\n        self.locals_max_string = locals_max_string\n        self.locals_hide_dunder = locals_hide_dunder\n        self.locals_hide_sunder = locals_hide_sunder\n\n        self.suppress: Sequence[str] = []\n        for suppress_entity in suppress:\n            if not isinstance(suppress_entity, str):\n                assert (\n                    suppress_entity.__file__ is not None\n                ), f\"{suppress_entity!r} must be a module with '__file__' attribute\"\n                path = os.path.dirname(suppress_entity.__file__)\n            else:\n                path = suppress_entity\n            path = os.path.normpath(os.path.abspath(path))\n            self.suppress.append(path)\n        self.max_frames = max(4, max_frames) if max_frames > 0 else 0\n\n    @classmethod\n    def from_exception(\n        cls,\n        exc_type: Type[Any],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        width: Optional[int] = 100,\n        code_width: Optional[int] = 88,\n        extra_lines: int = 3,\n        theme: Optional[str] = None,\n        word_wrap: bool = False,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n        indent_guides: bool = True,\n        suppress: Iterable[Union[str, ModuleType]] = (),\n        max_frames: int = 100,\n    ) -> \"Traceback\":\n        \"\"\"Create a traceback from exception info\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            width (Optional[int], optional): Number of characters used to traceback. Defaults to 100.\n            code_width (Optional[int], optional): Number of code characters used to traceback. Defaults to 88.\n            extra_lines (int, optional): Additional lines of code to render. Defaults to 3.\n            theme (str, optional): Override pygments theme used in traceback.\n            word_wrap (bool, optional): Enable word wrapping of long lines. Defaults to False.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            indent_guides (bool, optional): Enable indent guides in code and locals. Defaults to True.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n            suppress (Iterable[Union[str, ModuleType]]): Optional sequence of modules or paths to exclude from traceback.\n            max_frames (int): Maximum number of frames to show in a traceback, 0 for no maximum. Defaults to 100.\n\n        Returns:\n            Traceback: A Traceback instance that may be printed.\n        \"\"\"\n        rich_traceback = cls.extract(\n            exc_type,\n            exc_value,\n            traceback,\n            show_locals=show_locals,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n        )\n\n        return cls(\n            rich_traceback,\n            width=width,\n            code_width=code_width,\n            extra_lines=extra_lines,\n            theme=theme,\n            word_wrap=word_wrap,\n            show_locals=show_locals,\n            indent_guides=indent_guides,\n            locals_max_length=locals_max_length,\n            locals_max_string=locals_max_string,\n            locals_hide_dunder=locals_hide_dunder,\n            locals_hide_sunder=locals_hide_sunder,\n            suppress=suppress,\n            max_frames=max_frames,\n        )\n\n    @classmethod\n    def extract(\n        cls,\n        exc_type: Type[BaseException],\n        exc_value: BaseException,\n        traceback: Optional[TracebackType],\n        *,\n        show_locals: bool = False,\n        locals_max_length: int = LOCALS_MAX_LENGTH,\n        locals_max_string: int = LOCALS_MAX_STRING,\n        locals_hide_dunder: bool = True,\n        locals_hide_sunder: bool = False,\n    ) -> Trace:\n        \"\"\"Extract traceback information.\n\n        Args:\n            exc_type (Type[BaseException]): Exception type.\n            exc_value (BaseException): Exception value.\n            traceback (TracebackType): Python Traceback object.\n            show_locals (bool, optional): Enable display of local variables. Defaults to False.\n            locals_max_length (int, optional): Maximum length of containers before abbreviating, or None for no abbreviation.\n                Defaults to 10.\n            locals_max_string (int, optional): Maximum length of string before truncating, or None to disable. Defaults to 80.\n            locals_hide_dunder (bool, optional): Hide locals prefixed with double underscore. Defaults to True.\n            locals_hide_sunder (bool, optional): Hide locals prefixed with single underscore. Defaults to False.\n\n        Returns:\n            Trace: A Trace instance which you can use to construct a `Traceback`.\n        \"\"\"\n\n        stacks: List[Stack] = []\n        is_cause = False\n\n        from rich import _IMPORT_CWD\n\n        notes: List[str] = getattr(exc_value, \"__notes__\", None) or []\n\n        def safe_str(_object: Any) -> str:\n            \"\"\"Don't allow exceptions from __str__ to propagate.\"\"\"\n            try:\n                return str(_object)\n            except Exception:\n                return \"<exception str() failed>\"\n\n        while True:\n            stack = Stack(\n                exc_type=safe_str(exc_type.__name__),\n                exc_value=safe_str(exc_value),\n                is_cause=is_cause,\n                notes=notes,\n            )\n\n            if isinstance(exc_value, SyntaxError):\n                stack.syntax_error = _SyntaxError(\n                    offset=exc_value.offset or 0,\n                    filename=exc_value.filename or \"?\",\n                    lineno=exc_value.lineno or 0,\n                    line=exc_value.text or \"\",\n                    msg=exc_value.msg,\n                    notes=notes,\n                )\n\n            stacks.append(stack)\n            append = stack.frames.append\n\n            def get_locals(\n                iter_locals: Iterable[Tuple[str, object]],\n            ) -> Iterable[Tuple[str, object]]:\n                \"\"\"Extract locals from an iterator of key pairs.\"\"\"\n                if not (locals_hide_dunder or locals_hide_sunder):\n                    yield from iter_locals\n                    return\n                for key, value in iter_locals:\n                    if locals_hide_dunder and key.startswith(\"__\"):\n                        continue\n                    if locals_hide_sunder and key.startswith(\"_\"):\n                        continue\n                    yield key, value\n\n            for frame_summary, line_no in walk_tb(traceback):\n                filename = frame_summary.f_code.co_filename\n\n                last_instruction: Optional[Tuple[Tuple[int, int], Tuple[int, int]]]\n                last_instruction = None\n                if sys.version_info >= (3, 11):\n                    instruction_index = frame_summary.f_lasti // 2\n                    instruction_position = next(\n                        islice(\n                            frame_summary.f_code.co_positions(),\n                            instruction_index,\n                            instruction_index + 1,\n                        )\n                    )\n                    (\n                        start_line,\n                        end_line,\n                        start_column,\n                        end_column,\n                    ) = instruction_position\n                    if (\n                        start_line is not None\n                        and end_line is not None\n                        and start_column is not None\n                        and end_column is not None\n                    ):\n                        last_instruction = (\n                            (start_line, start_column),\n                            (end_line, end_column),\n                        )\n\n                if filename and not filename.startswith(\"<\"):\n                    if not os.path.isabs(filename):\n                        filename = os.path.join(_IMPORT_CWD, filename)\n                if frame_summary.f_locals.get(\"_rich_traceback_omit\", False):\n                    continue\n\n                frame = Frame(\n                    filename=filename or \"?\",\n                    lineno=line_no,\n                    name=frame_summary.f_code.co_name,\n                    locals=(\n                        {\n                            key: pretty.traverse(\n                                value,\n                                max_length=locals_max_length,\n                                max_string=locals_max_string,\n                            )\n                            for key, value in get_locals(frame_summary.f_locals.items())\n                            if not (inspect.isfunction(value) or inspect.isclass(value))\n                        }\n                        if show_locals\n                        else None\n                    ),\n                    last_instruction=last_instruction,\n                )\n                append(frame)\n                if frame_summary.f_locals.get(\"_rich_traceback_guard\", False):\n                    del stack.frames[:]\n\n            cause = getattr(exc_value, \"__cause__\", None)\n            if cause:\n                exc_type = cause.__class__\n                exc_value = cause\n                # __traceback__ can be None, e.g. for exceptions raised by the\n                # 'multiprocessing' module\n                traceback = cause.__traceback__\n                is_cause = True\n                continue\n\n            cause = exc_value.__context__\n            if cause and not getattr(exc_value, \"__suppress_context__\", False):\n                exc_type = cause.__class__\n                exc_value = cause\n                traceback = cause.__traceback__\n                is_cause = False\n                continue\n            # No cover, code is reached but coverage doesn't recognize it.\n            break  # pragma: no cover\n\n        trace = Trace(stacks=stacks)\n        return trace\n\n    def __rich_console__(\n        self, console: Console, options: ConsoleOptions\n    ) -> RenderResult:\n        theme = self.theme\n        background_style = theme.get_background_style()\n        token_style = theme.get_style_for_token\n\n        traceback_theme = Theme(\n            {\n                \"pretty\": token_style(TextToken),\n                \"pygments.text\": token_style(Token),\n                \"pygments.string\": token_style(String),\n                \"pygments.function\": token_style(Name.Function),\n                \"pygments.number\": token_style(Number),\n                \"repr.indent\": token_style(Comment) + Style(dim=True),\n                \"repr.str\": token_style(String),\n                \"repr.brace\": token_style(TextToken) + Style(bold=True),\n                \"repr.number\": token_style(Number),\n                \"repr.bool_true\": token_style(Keyword.Constant),\n                \"repr.bool_false\": token_style(Keyword.Constant),\n                \"repr.none\": token_style(Keyword.Constant),\n                \"scope.border\": token_style(String.Delimiter),\n                \"scope.equals\": token_style(Operator),\n                \"scope.key\": token_style(Name),\n                \"scope.key.special\": token_style(Name.Constant) + Style(dim=True),\n            },\n            inherit=False,\n        )\n\n        highlighter = ReprHighlighter()\n        for last, stack in loop_last(reversed(self.trace.stacks)):\n            if stack.frames:\n                stack_renderable: ConsoleRenderable = Panel(\n                    self._render_stack(stack),\n                    title=\"[traceback.title]Traceback [dim](most recent call last)\",\n                    style=background_style,\n                    border_style=\"traceback.border\",\n                    expand=True,\n                    padding=(0, 1),\n                )\n                stack_renderable = Constrain(stack_renderable, self.width)\n                with console.use_theme(traceback_theme):\n                    yield stack_renderable\n\n            if stack.syntax_error is not None:\n                with console.use_theme(traceback_theme):\n                    yield Constrain(\n                        Panel(\n                            self._render_syntax_error(stack.syntax_error),\n                            style=background_style,\n                            border_style=\"traceback.border.syntax_error\",\n                            expand=True,\n                            padding=(0, 1),\n                            width=self.width,\n                        ),\n                        self.width,\n                    )\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.syntax_error.msg),\n                )\n            elif stack.exc_value:\n                yield Text.assemble(\n                    (f\"{stack.exc_type}: \", \"traceback.exc_type\"),\n                    highlighter(stack.exc_value),\n                )\n            else:\n                yield Text.assemble((f\"{stack.exc_type}\", \"traceback.exc_type\"))\n\n            for note in stack.notes:\n                yield Text.assemble((\"[NOTE] \", \"traceback.note\"), highlighter(note))\n\n            if not last:\n                if stack.is_cause:\n                    yield Text.from_markup(\n                        \"\\n[i]The above exception was the direct cause of the following exception:\\n\",\n                    )\n                else:\n                    yield Text.from_markup(\n                        \"\\n[i]During handling of the above exception, another exception occurred:\\n\",\n                    )\n\n    @group()\n    def _render_syntax_error(self, syntax_error: _SyntaxError) -> RenderResult:\n        highlighter = ReprHighlighter()\n        path_highlighter = PathHighlighter()\n        if syntax_error.filename != \"<stdin>\":\n            if os.path.exists(syntax_error.filename):\n                text = Text.assemble(\n                    (f\" {syntax_error.filename}\", \"pygments.string\"),\n                    (\":\", \"pygments.text\"),\n                    (str(syntax_error.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n                yield path_highlighter(text)\n        syntax_error_text = highlighter(syntax_error.line.rstrip())\n        syntax_error_text.no_wrap = True\n        offset = min(syntax_error.offset - 1, len(syntax_error_text))\n        syntax_error_text.stylize(\"bold underline\", offset, offset)\n        syntax_error_text += Text.from_markup(\n            \"\\n\" + \" \" * offset + \"[traceback.offset]\u25b2[/]\",\n            style=\"pygments.text\",\n        )\n        yield syntax_error_text\n\n    @classmethod\n    def _guess_lexer(cls, filename: str, code: str) -> str:\n        ext = os.path.splitext(filename)[-1]\n        if not ext:\n            # No extension, look at first line to see if it is a hashbang\n            # Note, this is an educated guess and not a guarantee\n            # If it fails, the only downside is that the code is highlighted strangely\n            new_line_index = code.index(\"\\n\")\n            first_line = code[:new_line_index] if new_line_index != -1 else code\n            if first_line.startswith(\"#!\") and \"python\" in first_line.lower():\n                return \"python\"\n        try:\n            return cls.LEXERS.get(ext) or guess_lexer_for_filename(filename, code).name\n        except ClassNotFound:\n            return \"text\"\n\n    @group()\n    def _render_stack(self, stack: Stack) -> RenderResult:\n        path_highlighter = PathHighlighter()\n        theme = self.theme\n\n        def read_code(filename: str) -> str:\n            \"\"\"Read files, and cache results on filename.\n\n            Args:\n                filename (str): Filename to read\n\n            Returns:\n                str: Contents of file\n            \"\"\"\n            return \"\".join(linecache.getlines(filename))\n\n        def render_locals(frame: Frame) -> Iterable[ConsoleRenderable]:\n            if frame.locals:\n                yield render_scope(\n                    frame.locals,\n                    title=\"locals\",\n                    indent_guides=self.indent_guides,\n                    max_length=self.locals_max_length,\n                    max_string=self.locals_max_string,\n                )\n\n        exclude_frames: Optional[range] = None\n        if self.max_frames != 0:\n            exclude_frames = range(\n                self.max_frames // 2,\n                len(stack.frames) - self.max_frames // 2,\n            )\n\n        excluded = False\n        for frame_index, frame in enumerate(stack.frames):\n            if exclude_frames and frame_index in exclude_frames:\n                excluded = True\n                continue\n\n            if excluded:\n                assert exclude_frames is not None\n                yield Text(\n                    f\"\\n... {len(exclude_frames)} frames hidden ...\",\n                    justify=\"center\",\n                    style=\"traceback.error\",\n                )\n                excluded = False\n\n            first = frame_index == 0\n            frame_filename = frame.filename\n            suppressed = any(frame_filename.startswith(path) for path in self.suppress)\n\n            if os.path.exists(frame.filename):\n                text = Text.assemble(\n                    path_highlighter(Text(frame.filename, style=\"pygments.string\")),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    \" in \",\n                    (frame.name, \"pygments.function\"),\n                    style=\"pygments.text\",\n                )\n            else:\n                text = Text.assemble(\n                    \"in \",\n                    (frame.name, \"pygments.function\"),\n                    (\":\", \"pygments.text\"),\n                    (str(frame.lineno), \"pygments.number\"),\n                    style=\"pygments.text\",\n                )\n            if not frame.filename.startswith(\"<\") and not first:\n                yield \"\"\n            yield text\n            if frame.filename.startswith(\"<\"):\n                yield from render_locals(frame)\n                continue\n            if not suppressed:\n                try:\n                    code = read_code(frame.filename)\n                    if not code:\n                        # code may be an empty string if the file doesn't exist, OR\n                        # if the traceback filename is generated dynamically\n                        continue\n                    lexer_name = self._guess_lexer(frame.filename, code)\n                    syntax = Syntax(\n                        code,\n                        lexer_name,\n                        theme=theme,\n                        line_numbers=True,\n                        line_range=(\n                            frame.lineno - self.extra_lines,\n                            frame.lineno + self.extra_lines,\n                        ),\n                        highlight_lines={frame.lineno},\n                        word_wrap=self.word_wrap,\n                        code_width=self.code_width,\n                        indent_guides=self.indent_guides,\n                        dedent=False,\n                    )\n                    yield \"\"\n                except Exception as error:\n                    yield Text.assemble(\n                        (f\"\\n{error}\", \"traceback.error\"),\n                    )\n                else:\n                    if frame.last_instruction is not None:\n                        start, end = frame.last_instruction\n                        syntax.stylize_range(\n                            style=\"traceback.error_range\",\n                            start=start,\n                            end=end,\n                            style_before=True,\n                        )\n                    yield (\n                        Columns(\n                            [\n                                syntax,\n                                *render_locals(frame),\n                            ],\n                            padding=1,\n                        )\n                        if frame.locals\n                        else syntax\n                    )\n\n\nif __name__ == \"__main__\":  # pragma: no cover\n    install(show_locals=True)\n    import sys\n\n    def bar(\n        a: Any,\n    ) -> None:  # \u8fd9\u662f\u5bf9\u4e9a\u6d32\u8bed\u8a00\u652f\u6301\u7684\u6d4b\u8bd5\u3002\u9762\u5bf9\u6a21\u68f1\u4e24\u53ef\u7684\u60f3\u6cd5\uff0c\u62d2\u7edd\u731c\u6d4b\u7684\u8bf1\u60d1\n        one = 1\n        print(one / a)\n\n    def foo(a: Any) -> None:\n        _rich_traceback_guard = True\n        zed = {\n            \"characters\": {\n                \"Paul Atreides\",\n                \"Vladimir Harkonnen\",\n                \"Thufir Hawat\",\n                \"Duncan Idaho\",\n            },\n            \"atomic_types\": (None, False, True),\n        }\n        bar(a)\n\n    def error() -> None:\n        foo(0)\n\n    error()\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.4
    },
    {
      "bug_id": "00922f240948",
      "repo": "click",
      "commit_hash": "b9e4052",
      "commit_message": "[pre-commit.ci lite] apply automatic fixes",
      "file_path": "src/click/_termui_impl.py",
      "language": "python",
      "code_before": "\"\"\"\nThis module contains implementations for the termui module. To keep the\nimport time of Click down, some infrequently used functionality is\nplaced in this module and only imported as needed.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport contextlib\nimport math\nimport os\nimport shlex\nimport sys\nimport time\nimport typing as t\nfrom gettext import gettext as _\nfrom io import StringIO\nfrom pathlib import Path\nfrom types import TracebackType\n\nfrom ._compat import _default_text_stdout\nfrom ._compat import CYGWIN\nfrom ._compat import get_best_encoding\nfrom ._compat import isatty\nfrom ._compat import open_stream\nfrom ._compat import strip_ansi\nfrom ._compat import term_len\nfrom ._compat import WIN\nfrom .exceptions import ClickException\nfrom .utils import echo\n\nV = t.TypeVar(\"V\")\n\nif os.name == \"nt\":\n    BEFORE_BAR = \"\\r\"\n    AFTER_BAR = \"\\n\"\nelse:\n    BEFORE_BAR = \"\\r\\033[?25l\"\n    AFTER_BAR = \"\\033[?25h\\n\"\n\n\nclass ProgressBar(t.Generic[V]):\n    def __init__(\n        self,\n        iterable: cabc.Iterable[V] | None,\n        length: int | None = None,\n        fill_char: str = \"#\",\n        empty_char: str = \" \",\n        bar_template: str = \"%(bar)s\",\n        info_sep: str = \"  \",\n        hidden: bool = False,\n        show_eta: bool = True,\n        show_percent: bool | None = None,\n        show_pos: bool = False,\n        item_show_func: t.Callable[[V | None], str | None] | None = None,\n        label: str | None = None,\n        file: t.TextIO | None = None,\n        color: bool | None = None,\n        update_min_steps: int = 1,\n        width: int = 30,\n    ) -> None:\n        self.fill_char = fill_char\n        self.empty_char = empty_char\n        self.bar_template = bar_template\n        self.info_sep = info_sep\n        self.hidden = hidden\n        self.show_eta = show_eta\n        self.show_percent = show_percent\n        self.show_pos = show_pos\n        self.item_show_func = item_show_func\n        self.label: str = label or \"\"\n\n        if file is None:\n            file = _default_text_stdout()\n\n            # There are no standard streams attached to write to. For example,\n            # pythonw on Windows.\n            if file is None:\n                file = StringIO()\n\n        self.file = file\n        self.color = color\n        self.update_min_steps = update_min_steps\n        self._completed_intervals = 0\n        self.width: int = width\n        self.autowidth: bool = width == 0\n\n        if length is None:\n            from operator import length_hint\n\n            length = length_hint(iterable, -1)\n\n            if length == -1:\n                length = None\n        if iterable is None:\n            if length is None:\n                raise TypeError(\"iterable or length is required\")\n            iterable = t.cast(\"cabc.Iterable[V]\", range(length))\n        self.iter: cabc.Iterable[V] = iter(iterable)\n        self.length = length\n        self.pos: int = 0\n        self.avg: list[float] = []\n        self.last_eta: float\n        self.start: float\n        self.start = self.last_eta = time.time()\n        self.eta_known: bool = False\n        self.finished: bool = False\n        self.max_width: int | None = None\n        self.entered: bool = False\n        self.current_item: V | None = None\n        self._is_atty = isatty(self.file)\n        self._last_line: str | None = None\n\n    def __enter__(self) -> ProgressBar[V]:\n        self.entered = True\n        self.render_progress()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.render_finish()\n\n    def __iter__(self) -> cabc.Iterator[V]:\n        if not self.entered:\n            raise RuntimeError(\"You need to use progress bars in a with block.\")\n        self.render_progress()\n        return self.generator()\n\n    def __next__(self) -> V:\n        # Iteration is defined in terms of a generator function,\n        # returned by iter(self); use that to define next(). This works\n        # because `self.iter` is an iterable consumed by that generator,\n        # so it is re-entry safe. Calling `next(self.generator())`\n        # twice works and does \"what you want\".\n        return next(iter(self))\n\n    def render_finish(self) -> None:\n        if self.hidden or not self._is_atty:\n            return\n        self.file.write(AFTER_BAR)\n        self.file.flush()\n\n    @property\n    def pct(self) -> float:\n        if self.finished:\n            return 1.0\n        return min(self.pos / (float(self.length or 1) or 1), 1.0)\n\n    @property\n    def time_per_iteration(self) -> float:\n        if not self.avg:\n            return 0.0\n        return sum(self.avg) / float(len(self.avg))\n\n    @property\n    def eta(self) -> float:\n        if self.length is not None and not self.finished:\n            return self.time_per_iteration * (self.length - self.pos)\n        return 0.0\n\n    def format_eta(self) -> str:\n        if self.eta_known:\n            t = int(self.eta)\n            seconds = t % 60\n            t //= 60\n            minutes = t % 60\n            t //= 60\n            hours = t % 24\n            t //= 24\n            if t > 0:\n                return f\"{t}d {hours:02}:{minutes:02}:{seconds:02}\"\n            else:\n                return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n        return \"\"\n\n    def format_pos(self) -> str:\n        pos = str(self.pos)\n        if self.length is not None:\n            pos += f\"/{self.length}\"\n        return pos\n\n    def format_pct(self) -> str:\n        return f\"{int(self.pct * 100): 4}%\"[1:]\n\n    def format_bar(self) -> str:\n        if self.length is not None:\n            bar_length = int(self.pct * self.width)\n            bar = self.fill_char * bar_length\n            bar += self.empty_char * (self.width - bar_length)\n        elif self.finished:\n            bar = self.fill_char * self.width\n        else:\n            chars = list(self.empty_char * (self.width or 1))\n            if self.time_per_iteration != 0:\n                chars[\n                    int(\n                        (math.cos(self.pos * self.time_per_iteration) / 2.0 + 0.5)\n                        * self.width\n                    )\n                ] = self.fill_char\n            bar = \"\".join(chars)\n        return bar\n\n    def format_progress_line(self) -> str:\n        show_percent = self.show_percent\n\n        info_bits = []\n        if self.length is not None and show_percent is None:\n            show_percent = not self.show_pos\n\n        if self.show_pos:\n            info_bits.append(self.format_pos())\n        if show_percent:\n            info_bits.append(self.format_pct())\n        if self.show_eta and self.eta_known and not self.finished:\n            info_bits.append(self.format_eta())\n        if self.item_show_func is not None:\n            item_info = self.item_show_func(self.current_item)\n            if item_info is not None:\n                info_bits.append(item_info)\n\n        return (\n            self.bar_template\n            % {\n                \"label\": self.label,\n                \"bar\": self.format_bar(),\n                \"info\": self.info_sep.join(info_bits),\n            }\n        ).rstrip()\n\n    def render_progress(self) -> None:\n        if self.hidden:\n            return\n\n        if not self._is_atty:\n            # Only output the label once if the output is not a TTY.\n            if self._last_line != self.label:\n                self._last_line = self.label\n                echo(self.label, file=self.file, color=self.color)\n            return\n\n        buf = []\n        # Update width in case the terminal has been resized\n        if self.autowidth:\n            import shutil\n\n            old_width = self.width\n            self.width = 0\n            clutter_length = term_len(self.format_progress_line())\n            new_width = max(0, shutil.get_terminal_size().columns - clutter_length)\n            if new_width < old_width and self.max_width is not None:\n                buf.append(BEFORE_BAR)\n                buf.append(\" \" * self.max_width)\n                self.max_width = new_width\n            self.width = new_width\n\n        clear_width = self.width\n        if self.max_width is not None:\n            clear_width = self.max_width\n\n        buf.append(BEFORE_BAR)\n        line = self.format_progress_line()\n        line_len = term_len(line)\n        if self.max_width is None or self.max_width < line_len:\n            self.max_width = line_len\n\n        buf.append(line)\n        buf.append(\" \" * (clear_width - line_len))\n        line = \"\".join(buf)\n        # Render the line only if it changed.\n\n        if line != self._last_line:\n            self._last_line = line\n            echo(line, file=self.file, color=self.color, nl=False)\n            self.file.flush()\n\n    def make_step(self, n_steps: int) -> None:\n        self.pos += n_steps\n        if self.length is not None and self.pos >= self.length:\n            self.finished = True\n\n        if (time.time() - self.last_eta) < 1.0:\n            return\n\n        self.last_eta = time.time()\n\n        # self.avg is a rolling list of length <= 7 of steps where steps are\n        # defined as time elapsed divided by the total progress through\n        # self.length.\n        if self.pos:\n            step = (time.time() - self.start) / self.pos\n        else:\n            step = time.time() - self.start\n\n        self.avg = self.avg[-6:] + [step]\n\n        self.eta_known = self.length is not None\n\n    def update(self, n_steps: int, current_item: V | None = None) -> None:\n        \"\"\"Update the progress bar by advancing a specified number of\n        steps, and optionally set the ``current_item`` for this new\n        position.\n\n        :param n_steps: Number of steps to advance.\n        :param current_item: Optional item to set as ``current_item``\n            for the updated position.\n\n        .. versionchanged:: 8.0\n            Added the ``current_item`` optional parameter.\n\n        .. versionchanged:: 8.0\n            Only render when the number of steps meets the\n            ``update_min_steps`` threshold.\n        \"\"\"\n        if current_item is not None:\n            self.current_item = current_item\n\n        self._completed_intervals += n_steps\n\n        if self._completed_intervals >= self.update_min_steps:\n            self.make_step(self._completed_intervals)\n            self.render_progress()\n            self._completed_intervals = 0\n\n    def finish(self) -> None:\n        self.eta_known = False\n        self.current_item = None\n        self.finished = True\n\n    def generator(self) -> cabc.Iterator[V]:\n        \"\"\"Return a generator which yields the items added to the bar\n        during construction, and updates the progress bar *after* the\n        yielded block returns.\n        \"\"\"\n        # WARNING: the iterator interface for `ProgressBar` relies on\n        # this and only works because this is a simple generator which\n        # doesn't create or manage additional state. If this function\n        # changes, the impact should be evaluated both against\n        # `iter(bar)` and `next(bar)`. `next()` in particular may call\n        # `self.generator()` repeatedly, and this must remain safe in\n        # order for that interface to work.\n        if not self.entered:\n            raise RuntimeError(\"You need to use progress bars in a with block.\")\n\n        if not self._is_atty:\n            yield from self.iter\n        else:\n            for rv in self.iter:\n                self.current_item = rv\n\n                # This allows show_item_func to be updated before the\n                # item is processed. Only trigger at the beginning of\n                # the update interval.\n                if self._completed_intervals == 0:\n                    self.render_progress()\n\n                yield rv\n                self.update(1)\n\n            self.finish()\n            self.render_progress()\n\n\ndef pager(generator: cabc.Iterable[str], color: bool | None = None) -> None:\n    \"\"\"Decide what method to use for paging through text.\"\"\"\n    stdout = _default_text_stdout()\n\n    # There are no standard streams attached to write to. For example,\n    # pythonw on Windows.\n    if stdout is None:\n        stdout = StringIO()\n\n    if not isatty(sys.stdin) or not isatty(stdout):\n        return _nullpager(stdout, generator, color)\n\n    # Split and normalize the pager command into parts.\n    pager_cmd_parts = shlex.split(os.environ.get(\"PAGER\", \"\"), posix=False)\n    if pager_cmd_parts:\n        if WIN:\n            if _tempfilepager(generator, pager_cmd_parts, color):\n                return\n        elif _pipepager(generator, pager_cmd_parts, color):\n            return\n\n    if os.environ.get(\"TERM\") in (\"dumb\", \"emacs\"):\n        return _nullpager(stdout, generator, color)\n    if (WIN or sys.platform.startswith(\"os2\")) and _tempfilepager(\n        generator, [\"more\"], color\n    ):\n        return\n    if _pipepager(generator, [\"less\"], color):\n        return\n\n    import tempfile\n\n    fd, filename = tempfile.mkstemp()\n    os.close(fd)\n    try:\n        if _pipepager(generator, [\"more\"], color):\n            return\n        return _nullpager(stdout, generator, color)\n    finally:\n        os.unlink(filename)\n\n\ndef _pipepager(\n    generator: cabc.Iterable[str], cmd_parts: list[str], color: bool | None\n) -> bool:\n    \"\"\"Page through text by feeding it to another program. Invoking a\n    pager through this might support colors.\n\n    Returns `True` if the command was found, `False` otherwise and thus another\n    pager should be attempted.\n    \"\"\"\n    # Split the command into the invoked CLI and its parameters.\n    if not cmd_parts:\n        return False\n    \n    import shutil\n\n    cmd = cmd_parts[0]\n    cmd_params = cmd_parts[1:]\n\n    cmd_filepath = shutil.which(cmd)\n    if not cmd_filepath:\n        return False\n    # Resolves symlinks and produces a normalized absolute path string.\n    cmd_path = Path(cmd_filepath).resolve()\n    cmd_name = cmd_path.name\n\n    import subprocess\n\n    # Make a local copy of the environment to not affect the global one.\n    env = dict(os.environ)\n\n    # If we're piping to less and the user hasn't decided on colors, we enable\n    # them by default we find the -R flag in the command line arguments.\n    if color is None and cmd_name == \"less\":\n        less_flags = f\"{os.environ.get('LESS', '')}{' '.join(cmd_params)}\"\n        if not less_flags:\n            env[\"LESS\"] = \"-R\"\n            color = True\n        elif \"r\" in less_flags or \"R\" in less_flags:\n            color = True\n\n    c = subprocess.Popen(\n        [str(cmd_path)] + cmd_params,\n        shell=True,\n        stdin=subprocess.PIPE,\n        env=env,\n        errors=\"replace\",\n        text=True,\n    )\n    assert c.stdin is not None\n    try:\n        for text in generator:\n            if not color:\n                text = strip_ansi(text)\n\n            c.stdin.write(text)\n    except BrokenPipeError:\n        # In case the pager exited unexpectedly, ignore the broken pipe error.\n        pass\n    except Exception as e:\n        # In case there is an exception we want to close the pager immediately\n        # and let the caller handle it.\n        # Otherwise the pager will keep running, and the user may not notice\n        # the error message, or worse yet it may leave the terminal in a broken state.\n        c.terminate()\n        raise e\n    finally:\n        # We must close stdin and wait for the pager to exit before we continue\n        try:\n            c.stdin.close()\n        # Close implies flush, so it might throw a BrokenPipeError if the pager\n        # process exited already.\n        except BrokenPipeError:\n            pass\n\n        # Less doesn't respect ^C, but catches it for its own UI purposes (aborting\n        # search or other commands inside less).\n        #\n        # That means when the user hits ^C, the parent process (click) terminates,\n        # but less is still alive, paging the output and messing up the terminal.\n        #\n        # If the user wants to make the pager exit on ^C, they should set\n        # `LESS='-K'`. It's not our decision to make.\n        while True:\n            try:\n                c.wait()\n            except KeyboardInterrupt:\n                pass\n            else:\n                break\n\n    return True\n\n\ndef _tempfilepager(\n    generator: cabc.Iterable[str], cmd_parts: list[str], color: bool | None\n) -> bool:\n    \"\"\"Page through text by invoking a program on a temporary file.\n\n    Returns `True` if the command was found, `False` otherwise and thus another\n    pager should be attempted.\n    \"\"\"\n    # Split the command into the invoked CLI and its parameters.\n    if not cmd_parts:\n        return False\n\n    import shutil\n\n    cmd = cmd_parts[0]\n\n    cmd_filepath = shutil.which(cmd)\n    if not cmd_filepath:\n        return False\n    # Resolves symlinks and produces a normalized absolute path string.\n    cmd_path = Path(cmd_filepath).resolve()\n\n    import subprocess\n    import tempfile\n\n    fd, filename = tempfile.mkstemp()\n    # TODO: This never terminates if the passed generator never terminates.\n    text = \"\".join(generator)\n    if not color:\n        text = strip_ansi(text)\n    encoding = get_best_encoding(sys.stdout)\n    with open_stream(filename, \"wb\")[0] as f:\n        f.write(text.encode(encoding))\n    try:\n        subprocess.call([str(cmd_path), filename])\n    except OSError:\n        # Command not found\n        pass\n    finally:\n        os.close(fd)\n        os.unlink(filename)\n\n    return True\n\n\ndef _nullpager(\n    stream: t.TextIO, generator: cabc.Iterable[str], color: bool | None\n) -> None:\n    \"\"\"Simply print unformatted text.  This is the ultimate fallback.\"\"\"\n    for text in generator:\n        if not color:\n            text = strip_ansi(text)\n        stream.write(text)\n\n\nclass Editor:\n    def __init__(\n        self,\n        editor: str | None = None,\n        env: cabc.Mapping[str, str] | None = None,\n        require_save: bool = True,\n        extension: str = \".txt\",\n    ) -> None:\n        self.editor = editor\n        self.env = env\n        self.require_save = require_save\n        self.extension = extension\n\n    def get_editor(self) -> str:\n        if self.editor is not None:\n            return self.editor\n        for key in \"VISUAL\", \"EDITOR\":\n            rv = os.environ.get(key)\n            if rv:\n                return rv\n        if WIN:\n            return \"notepad\"\n\n        from shutil import which\n\n        for editor in \"sensible-editor\", \"vim\", \"nano\":\n            if which(editor) is not None:\n                return editor\n        return \"vi\"\n\n    def edit_files(self, filenames: cabc.Iterable[str]) -> None:\n        import subprocess\n\n        editor = self.get_editor()\n        environ: dict[str, str] | None = None\n\n        if self.env:\n            environ = os.environ.copy()\n            environ.update(self.env)\n\n        exc_filename = \" \".join(f'\"{filename}\"' for filename in filenames)\n\n        try:\n            c = subprocess.Popen(\n                args=f\"{editor} {exc_filename}\", env=environ, shell=True\n            )\n            exit_code = c.wait()\n            if exit_code != 0:\n                raise ClickException(\n                    _(\"{editor}: Editing failed\").format(editor=editor)\n                )\n        except OSError as e:\n            raise ClickException(\n                _(\"{editor}: Editing failed: {e}\").format(editor=editor, e=e)\n            ) from e\n\n    @t.overload\n    def edit(self, text: bytes | bytearray) -> bytes | None: ...\n\n    # We cannot know whether or not the type expected is str or bytes when None\n    # is passed, so str is returned as that was what was done before.\n    @t.overload\n    def edit(self, text: str | None) -> str | None: ...\n\n    def edit(self, text: str | bytes | bytearray | None) -> str | bytes | None:\n        import tempfile\n\n        if text is None:\n            data: bytes | bytearray = b\"\"\n        elif isinstance(text, (bytes, bytearray)):\n            data = text\n        else:\n            if text and not text.endswith(\"\\n\"):\n                text += \"\\n\"\n\n            if WIN:\n                data = text.replace(\"\\n\", \"\\r\\n\").encode(\"utf-8-sig\")\n            else:\n                data = text.encode(\"utf-8\")\n\n        fd, name = tempfile.mkstemp(prefix=\"editor-\", suffix=self.extension)\n        f: t.BinaryIO\n\n        try:\n            with os.fdopen(fd, \"wb\") as f:\n                f.write(data)\n\n            # If the filesystem resolution is 1 second, like Mac OS\n            # 10.12 Extended, or 2 seconds, like FAT32, and the editor\n            # closes very fast, require_save can fail. Set the modified\n            # time to be 2 seconds in the past to work around this.\n            os.utime(name, (os.path.getatime(name), os.path.getmtime(name) - 2))\n            # Depending on the resolution, the exact value might not be\n            # recorded, so get the new recorded value.\n            timestamp = os.path.getmtime(name)\n\n            self.edit_files((name,))\n\n            if self.require_save and os.path.getmtime(name) == timestamp:\n                return None\n\n            with open(name, \"rb\") as f:\n                rv = f.read()\n\n            if isinstance(text, (bytes, bytearray)):\n                return rv\n\n            return rv.decode(\"utf-8-sig\").replace(\"\\r\\n\", \"\\n\")\n        finally:\n            os.unlink(name)\n\n\ndef open_url(url: str, wait: bool = False, locate: bool = False) -> int:\n    import subprocess\n\n    def _unquote_file(url: str) -> str:\n        from urllib.parse import unquote\n\n        if url.startswith(\"file://\"):\n            url = unquote(url[7:])\n\n        return url\n\n    if sys.platform == \"darwin\":\n        args = [\"open\"]\n        if wait:\n            args.append(\"-W\")\n        if locate:\n            args.append(\"-R\")\n        args.append(_unquote_file(url))\n        null = open(\"/dev/null\", \"w\")\n        try:\n            return subprocess.Popen(args, stderr=null).wait()\n        finally:\n            null.close()\n    elif WIN:\n        if locate:\n            url = _unquote_file(url)\n            args = [\"explorer\", f\"/select,{url}\"]\n        else:\n            args = [\"start\"]\n            if wait:\n                args.append(\"/WAIT\")\n            args.append(\"\")\n            args.append(url)\n        try:\n            return subprocess.call(args)\n        except OSError:\n            # Command not found\n            return 127\n    elif CYGWIN:\n        if locate:\n            url = _unquote_file(url)\n            args = [\"cygstart\", os.path.dirname(url)]\n        else:\n            args = [\"cygstart\"]\n            if wait:\n                args.append(\"-w\")\n            args.append(url)\n        try:\n            return subprocess.call(args)\n        except OSError:\n            # Command not found\n            return 127\n\n    try:\n        if locate:\n            url = os.path.dirname(_unquote_file(url)) or \".\"\n        else:\n            url = _unquote_file(url)\n        c = subprocess.Popen([\"xdg-open\", url])\n        if wait:\n            return c.wait()\n        return 0\n    except OSError:\n        if url.startswith((\"http://\", \"https://\")) and not locate and not wait:\n            import webbrowser\n\n            webbrowser.open(url)\n            return 0\n        return 1\n\n\ndef _translate_ch_to_exc(ch: str) -> None:\n    if ch == \"\\x03\":\n        raise KeyboardInterrupt()\n\n    if ch == \"\\x04\" and not WIN:  # Unix-like, Ctrl+D\n        raise EOFError()\n\n    if ch == \"\\x1a\" and WIN:  # Windows, Ctrl+Z\n        raise EOFError()\n\n    return None\n\n\nif sys.platform == \"win32\":\n    import msvcrt\n\n    @contextlib.contextmanager\n    def raw_terminal() -> cabc.Iterator[int]:\n        yield -1\n\n    def getchar(echo: bool) -> str:\n        # The function `getch` will return a bytes object corresponding to\n        # the pressed character. Since Windows 10 build 1803, it will also\n        # return \\x00 when called a second time after pressing a regular key.\n        #\n        # `getwch` does not share this probably-bugged behavior. Moreover, it\n        # returns a Unicode object by default, which is what we want.\n        #\n        # Either of these functions will return \\x00 or \\xe0 to indicate\n        # a special key, and you need to call the same function again to get\n        # the \"rest\" of the code. The fun part is that \\u00e0 is\n        # \"latin small letter a with grave\", so if you type that on a French\n        # keyboard, you _also_ get a \\xe0.\n        # E.g., consider the Up arrow. This returns \\xe0 and then \\x48. The\n        # resulting Unicode string reads as \"a with grave\" + \"capital H\".\n        # This is indistinguishable from when the user actually types\n        # \"a with grave\" and then \"capital H\".\n        #\n        # When \\xe0 is returned, we assume it's part of a special-key sequence\n        # and call `getwch` again, but that means that when the user types\n        # the \\u00e0 character, `getchar` doesn't return until a second\n        # character is typed.\n        # The alternative is returning immediately, but that would mess up\n        # cross-platform handling of arrow keys and others that start with\n        # \\xe0. Another option is using `getch`, but then we can't reliably\n        # read non-ASCII characters, because return values of `getch` are\n        # limited to the current 8-bit codepage.\n        #\n        # Anyway, Click doesn't claim to do this Right(tm), and using `getwch`\n        # is doing the right thing in more situations than with `getch`.\n\n        if echo:\n            func = t.cast(t.Callable[[], str], msvcrt.getwche)\n        else:\n            func = t.cast(t.Callable[[], str], msvcrt.getwch)\n\n        rv = func()\n\n        if rv in (\"\\x00\", \"\\xe0\"):\n            # \\x00 and \\xe0 are control characters that indicate special key,\n            # see above.\n            rv += func()\n\n        _translate_ch_to_exc(rv)\n        return rv\n\nelse:\n    import termios\n    import tty\n\n    @contextlib.contextmanager\n    def raw_terminal() -> cabc.Iterator[int]:\n        f: t.TextIO | None\n        fd: int\n\n        if not isatty(sys.stdin):\n            f = open(\"/dev/tty\")\n            fd = f.fileno()\n        else:\n            fd = sys.stdin.fileno()\n            f = None\n\n        try:\n            old_settings = termios.tcgetattr(fd)\n\n            try:\n                tty.setraw(fd)\n                yield fd\n            finally:\n                termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n                sys.stdout.flush()\n\n                if f is not None:\n                    f.close()\n        except termios.error:\n            pass\n\n    def getchar(echo: bool) -> str:\n        with raw_terminal() as fd:\n            ch = os.read(fd, 32).decode(get_best_encoding(sys.stdin), \"replace\")\n\n            if echo and isatty(sys.stdout):\n                sys.stdout.write(ch)\n\n            _translate_ch_to_exc(ch)\n            return ch\n",
      "code_after": "\"\"\"\nThis module contains implementations for the termui module. To keep the\nimport time of Click down, some infrequently used functionality is\nplaced in this module and only imported as needed.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport contextlib\nimport math\nimport os\nimport shlex\nimport sys\nimport time\nimport typing as t\nfrom gettext import gettext as _\nfrom io import StringIO\nfrom pathlib import Path\nfrom types import TracebackType\n\nfrom ._compat import _default_text_stdout\nfrom ._compat import CYGWIN\nfrom ._compat import get_best_encoding\nfrom ._compat import isatty\nfrom ._compat import open_stream\nfrom ._compat import strip_ansi\nfrom ._compat import term_len\nfrom ._compat import WIN\nfrom .exceptions import ClickException\nfrom .utils import echo\n\nV = t.TypeVar(\"V\")\n\nif os.name == \"nt\":\n    BEFORE_BAR = \"\\r\"\n    AFTER_BAR = \"\\n\"\nelse:\n    BEFORE_BAR = \"\\r\\033[?25l\"\n    AFTER_BAR = \"\\033[?25h\\n\"\n\n\nclass ProgressBar(t.Generic[V]):\n    def __init__(\n        self,\n        iterable: cabc.Iterable[V] | None,\n        length: int | None = None,\n        fill_char: str = \"#\",\n        empty_char: str = \" \",\n        bar_template: str = \"%(bar)s\",\n        info_sep: str = \"  \",\n        hidden: bool = False,\n        show_eta: bool = True,\n        show_percent: bool | None = None,\n        show_pos: bool = False,\n        item_show_func: t.Callable[[V | None], str | None] | None = None,\n        label: str | None = None,\n        file: t.TextIO | None = None,\n        color: bool | None = None,\n        update_min_steps: int = 1,\n        width: int = 30,\n    ) -> None:\n        self.fill_char = fill_char\n        self.empty_char = empty_char\n        self.bar_template = bar_template\n        self.info_sep = info_sep\n        self.hidden = hidden\n        self.show_eta = show_eta\n        self.show_percent = show_percent\n        self.show_pos = show_pos\n        self.item_show_func = item_show_func\n        self.label: str = label or \"\"\n\n        if file is None:\n            file = _default_text_stdout()\n\n            # There are no standard streams attached to write to. For example,\n            # pythonw on Windows.\n            if file is None:\n                file = StringIO()\n\n        self.file = file\n        self.color = color\n        self.update_min_steps = update_min_steps\n        self._completed_intervals = 0\n        self.width: int = width\n        self.autowidth: bool = width == 0\n\n        if length is None:\n            from operator import length_hint\n\n            length = length_hint(iterable, -1)\n\n            if length == -1:\n                length = None\n        if iterable is None:\n            if length is None:\n                raise TypeError(\"iterable or length is required\")\n            iterable = t.cast(\"cabc.Iterable[V]\", range(length))\n        self.iter: cabc.Iterable[V] = iter(iterable)\n        self.length = length\n        self.pos: int = 0\n        self.avg: list[float] = []\n        self.last_eta: float\n        self.start: float\n        self.start = self.last_eta = time.time()\n        self.eta_known: bool = False\n        self.finished: bool = False\n        self.max_width: int | None = None\n        self.entered: bool = False\n        self.current_item: V | None = None\n        self._is_atty = isatty(self.file)\n        self._last_line: str | None = None\n\n    def __enter__(self) -> ProgressBar[V]:\n        self.entered = True\n        self.render_progress()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_value: BaseException | None,\n        tb: TracebackType | None,\n    ) -> None:\n        self.render_finish()\n\n    def __iter__(self) -> cabc.Iterator[V]:\n        if not self.entered:\n            raise RuntimeError(\"You need to use progress bars in a with block.\")\n        self.render_progress()\n        return self.generator()\n\n    def __next__(self) -> V:\n        # Iteration is defined in terms of a generator function,\n        # returned by iter(self); use that to define next(). This works\n        # because `self.iter` is an iterable consumed by that generator,\n        # so it is re-entry safe. Calling `next(self.generator())`\n        # twice works and does \"what you want\".\n        return next(iter(self))\n\n    def render_finish(self) -> None:\n        if self.hidden or not self._is_atty:\n            return\n        self.file.write(AFTER_BAR)\n        self.file.flush()\n\n    @property\n    def pct(self) -> float:\n        if self.finished:\n            return 1.0\n        return min(self.pos / (float(self.length or 1) or 1), 1.0)\n\n    @property\n    def time_per_iteration(self) -> float:\n        if not self.avg:\n            return 0.0\n        return sum(self.avg) / float(len(self.avg))\n\n    @property\n    def eta(self) -> float:\n        if self.length is not None and not self.finished:\n            return self.time_per_iteration * (self.length - self.pos)\n        return 0.0\n\n    def format_eta(self) -> str:\n        if self.eta_known:\n            t = int(self.eta)\n            seconds = t % 60\n            t //= 60\n            minutes = t % 60\n            t //= 60\n            hours = t % 24\n            t //= 24\n            if t > 0:\n                return f\"{t}d {hours:02}:{minutes:02}:{seconds:02}\"\n            else:\n                return f\"{hours:02}:{minutes:02}:{seconds:02}\"\n        return \"\"\n\n    def format_pos(self) -> str:\n        pos = str(self.pos)\n        if self.length is not None:\n            pos += f\"/{self.length}\"\n        return pos\n\n    def format_pct(self) -> str:\n        return f\"{int(self.pct * 100): 4}%\"[1:]\n\n    def format_bar(self) -> str:\n        if self.length is not None:\n            bar_length = int(self.pct * self.width)\n            bar = self.fill_char * bar_length\n            bar += self.empty_char * (self.width - bar_length)\n        elif self.finished:\n            bar = self.fill_char * self.width\n        else:\n            chars = list(self.empty_char * (self.width or 1))\n            if self.time_per_iteration != 0:\n                chars[\n                    int(\n                        (math.cos(self.pos * self.time_per_iteration) / 2.0 + 0.5)\n                        * self.width\n                    )\n                ] = self.fill_char\n            bar = \"\".join(chars)\n        return bar\n\n    def format_progress_line(self) -> str:\n        show_percent = self.show_percent\n\n        info_bits = []\n        if self.length is not None and show_percent is None:\n            show_percent = not self.show_pos\n\n        if self.show_pos:\n            info_bits.append(self.format_pos())\n        if show_percent:\n            info_bits.append(self.format_pct())\n        if self.show_eta and self.eta_known and not self.finished:\n            info_bits.append(self.format_eta())\n        if self.item_show_func is not None:\n            item_info = self.item_show_func(self.current_item)\n            if item_info is not None:\n                info_bits.append(item_info)\n\n        return (\n            self.bar_template\n            % {\n                \"label\": self.label,\n                \"bar\": self.format_bar(),\n                \"info\": self.info_sep.join(info_bits),\n            }\n        ).rstrip()\n\n    def render_progress(self) -> None:\n        if self.hidden:\n            return\n\n        if not self._is_atty:\n            # Only output the label once if the output is not a TTY.\n            if self._last_line != self.label:\n                self._last_line = self.label\n                echo(self.label, file=self.file, color=self.color)\n            return\n\n        buf = []\n        # Update width in case the terminal has been resized\n        if self.autowidth:\n            import shutil\n\n            old_width = self.width\n            self.width = 0\n            clutter_length = term_len(self.format_progress_line())\n            new_width = max(0, shutil.get_terminal_size().columns - clutter_length)\n            if new_width < old_width and self.max_width is not None:\n                buf.append(BEFORE_BAR)\n                buf.append(\" \" * self.max_width)\n                self.max_width = new_width\n            self.width = new_width\n\n        clear_width = self.width\n        if self.max_width is not None:\n            clear_width = self.max_width\n\n        buf.append(BEFORE_BAR)\n        line = self.format_progress_line()\n        line_len = term_len(line)\n        if self.max_width is None or self.max_width < line_len:\n            self.max_width = line_len\n\n        buf.append(line)\n        buf.append(\" \" * (clear_width - line_len))\n        line = \"\".join(buf)\n        # Render the line only if it changed.\n\n        if line != self._last_line:\n            self._last_line = line\n            echo(line, file=self.file, color=self.color, nl=False)\n            self.file.flush()\n\n    def make_step(self, n_steps: int) -> None:\n        self.pos += n_steps\n        if self.length is not None and self.pos >= self.length:\n            self.finished = True\n\n        if (time.time() - self.last_eta) < 1.0:\n            return\n\n        self.last_eta = time.time()\n\n        # self.avg is a rolling list of length <= 7 of steps where steps are\n        # defined as time elapsed divided by the total progress through\n        # self.length.\n        if self.pos:\n            step = (time.time() - self.start) / self.pos\n        else:\n            step = time.time() - self.start\n\n        self.avg = self.avg[-6:] + [step]\n\n        self.eta_known = self.length is not None\n\n    def update(self, n_steps: int, current_item: V | None = None) -> None:\n        \"\"\"Update the progress bar by advancing a specified number of\n        steps, and optionally set the ``current_item`` for this new\n        position.\n\n        :param n_steps: Number of steps to advance.\n        :param current_item: Optional item to set as ``current_item``\n            for the updated position.\n\n        .. versionchanged:: 8.0\n            Added the ``current_item`` optional parameter.\n\n        .. versionchanged:: 8.0\n            Only render when the number of steps meets the\n            ``update_min_steps`` threshold.\n        \"\"\"\n        if current_item is not None:\n            self.current_item = current_item\n\n        self._completed_intervals += n_steps\n\n        if self._completed_intervals >= self.update_min_steps:\n            self.make_step(self._completed_intervals)\n            self.render_progress()\n            self._completed_intervals = 0\n\n    def finish(self) -> None:\n        self.eta_known = False\n        self.current_item = None\n        self.finished = True\n\n    def generator(self) -> cabc.Iterator[V]:\n        \"\"\"Return a generator which yields the items added to the bar\n        during construction, and updates the progress bar *after* the\n        yielded block returns.\n        \"\"\"\n        # WARNING: the iterator interface for `ProgressBar` relies on\n        # this and only works because this is a simple generator which\n        # doesn't create or manage additional state. If this function\n        # changes, the impact should be evaluated both against\n        # `iter(bar)` and `next(bar)`. `next()` in particular may call\n        # `self.generator()` repeatedly, and this must remain safe in\n        # order for that interface to work.\n        if not self.entered:\n            raise RuntimeError(\"You need to use progress bars in a with block.\")\n\n        if not self._is_atty:\n            yield from self.iter\n        else:\n            for rv in self.iter:\n                self.current_item = rv\n\n                # This allows show_item_func to be updated before the\n                # item is processed. Only trigger at the beginning of\n                # the update interval.\n                if self._completed_intervals == 0:\n                    self.render_progress()\n\n                yield rv\n                self.update(1)\n\n            self.finish()\n            self.render_progress()\n\n\ndef pager(generator: cabc.Iterable[str], color: bool | None = None) -> None:\n    \"\"\"Decide what method to use for paging through text.\"\"\"\n    stdout = _default_text_stdout()\n\n    # There are no standard streams attached to write to. For example,\n    # pythonw on Windows.\n    if stdout is None:\n        stdout = StringIO()\n\n    if not isatty(sys.stdin) or not isatty(stdout):\n        return _nullpager(stdout, generator, color)\n\n    # Split and normalize the pager command into parts.\n    pager_cmd_parts = shlex.split(os.environ.get(\"PAGER\", \"\"), posix=False)\n    if pager_cmd_parts:\n        if WIN:\n            if _tempfilepager(generator, pager_cmd_parts, color):\n                return\n        elif _pipepager(generator, pager_cmd_parts, color):\n            return\n\n    if os.environ.get(\"TERM\") in (\"dumb\", \"emacs\"):\n        return _nullpager(stdout, generator, color)\n    if (WIN or sys.platform.startswith(\"os2\")) and _tempfilepager(\n        generator, [\"more\"], color\n    ):\n        return\n    if _pipepager(generator, [\"less\"], color):\n        return\n\n    import tempfile\n\n    fd, filename = tempfile.mkstemp()\n    os.close(fd)\n    try:\n        if _pipepager(generator, [\"more\"], color):\n            return\n        return _nullpager(stdout, generator, color)\n    finally:\n        os.unlink(filename)\n\n\ndef _pipepager(\n    generator: cabc.Iterable[str], cmd_parts: list[str], color: bool | None\n) -> bool:\n    \"\"\"Page through text by feeding it to another program. Invoking a\n    pager through this might support colors.\n\n    Returns `True` if the command was found, `False` otherwise and thus another\n    pager should be attempted.\n    \"\"\"\n    # Split the command into the invoked CLI and its parameters.\n    if not cmd_parts:\n        return False\n\n    import shutil\n\n    cmd = cmd_parts[0]\n    cmd_params = cmd_parts[1:]\n\n    cmd_filepath = shutil.which(cmd)\n    if not cmd_filepath:\n        return False\n    # Resolves symlinks and produces a normalized absolute path string.\n    cmd_path = Path(cmd_filepath).resolve()\n    cmd_name = cmd_path.name\n\n    import subprocess\n\n    # Make a local copy of the environment to not affect the global one.\n    env = dict(os.environ)\n\n    # If we're piping to less and the user hasn't decided on colors, we enable\n    # them by default we find the -R flag in the command line arguments.\n    if color is None and cmd_name == \"less\":\n        less_flags = f\"{os.environ.get('LESS', '')}{' '.join(cmd_params)}\"\n        if not less_flags:\n            env[\"LESS\"] = \"-R\"\n            color = True\n        elif \"r\" in less_flags or \"R\" in less_flags:\n            color = True\n\n    c = subprocess.Popen(\n        [str(cmd_path)] + cmd_params,\n        shell=True,\n        stdin=subprocess.PIPE,\n        env=env,\n        errors=\"replace\",\n        text=True,\n    )\n    assert c.stdin is not None\n    try:\n        for text in generator:\n            if not color:\n                text = strip_ansi(text)\n\n            c.stdin.write(text)\n    except BrokenPipeError:\n        # In case the pager exited unexpectedly, ignore the broken pipe error.\n        pass\n    except Exception as e:\n        # In case there is an exception we want to close the pager immediately\n        # and let the caller handle it.\n        # Otherwise the pager will keep running, and the user may not notice\n        # the error message, or worse yet it may leave the terminal in a broken state.\n        c.terminate()\n        raise e\n    finally:\n        # We must close stdin and wait for the pager to exit before we continue\n        try:\n            c.stdin.close()\n        # Close implies flush, so it might throw a BrokenPipeError if the pager\n        # process exited already.\n        except BrokenPipeError:\n            pass\n\n        # Less doesn't respect ^C, but catches it for its own UI purposes (aborting\n        # search or other commands inside less).\n        #\n        # That means when the user hits ^C, the parent process (click) terminates,\n        # but less is still alive, paging the output and messing up the terminal.\n        #\n        # If the user wants to make the pager exit on ^C, they should set\n        # `LESS='-K'`. It's not our decision to make.\n        while True:\n            try:\n                c.wait()\n            except KeyboardInterrupt:\n                pass\n            else:\n                break\n\n    return True\n\n\ndef _tempfilepager(\n    generator: cabc.Iterable[str], cmd_parts: list[str], color: bool | None\n) -> bool:\n    \"\"\"Page through text by invoking a program on a temporary file.\n\n    Returns `True` if the command was found, `False` otherwise and thus another\n    pager should be attempted.\n    \"\"\"\n    # Split the command into the invoked CLI and its parameters.\n    if not cmd_parts:\n        return False\n\n    import shutil\n\n    cmd = cmd_parts[0]\n\n    cmd_filepath = shutil.which(cmd)\n    if not cmd_filepath:\n        return False\n    # Resolves symlinks and produces a normalized absolute path string.\n    cmd_path = Path(cmd_filepath).resolve()\n\n    import subprocess\n    import tempfile\n\n    fd, filename = tempfile.mkstemp()\n    # TODO: This never terminates if the passed generator never terminates.\n    text = \"\".join(generator)\n    if not color:\n        text = strip_ansi(text)\n    encoding = get_best_encoding(sys.stdout)\n    with open_stream(filename, \"wb\")[0] as f:\n        f.write(text.encode(encoding))\n    try:\n        subprocess.call([str(cmd_path), filename])\n    except OSError:\n        # Command not found\n        pass\n    finally:\n        os.close(fd)\n        os.unlink(filename)\n\n    return True\n\n\ndef _nullpager(\n    stream: t.TextIO, generator: cabc.Iterable[str], color: bool | None\n) -> None:\n    \"\"\"Simply print unformatted text.  This is the ultimate fallback.\"\"\"\n    for text in generator:\n        if not color:\n            text = strip_ansi(text)\n        stream.write(text)\n\n\nclass Editor:\n    def __init__(\n        self,\n        editor: str | None = None,\n        env: cabc.Mapping[str, str] | None = None,\n        require_save: bool = True,\n        extension: str = \".txt\",\n    ) -> None:\n        self.editor = editor\n        self.env = env\n        self.require_save = require_save\n        self.extension = extension\n\n    def get_editor(self) -> str:\n        if self.editor is not None:\n            return self.editor\n        for key in \"VISUAL\", \"EDITOR\":\n            rv = os.environ.get(key)\n            if rv:\n                return rv\n        if WIN:\n            return \"notepad\"\n\n        from shutil import which\n\n        for editor in \"sensible-editor\", \"vim\", \"nano\":\n            if which(editor) is not None:\n                return editor\n        return \"vi\"\n\n    def edit_files(self, filenames: cabc.Iterable[str]) -> None:\n        import subprocess\n\n        editor = self.get_editor()\n        environ: dict[str, str] | None = None\n\n        if self.env:\n            environ = os.environ.copy()\n            environ.update(self.env)\n\n        exc_filename = \" \".join(f'\"{filename}\"' for filename in filenames)\n\n        try:\n            c = subprocess.Popen(\n                args=f\"{editor} {exc_filename}\", env=environ, shell=True\n            )\n            exit_code = c.wait()\n            if exit_code != 0:\n                raise ClickException(\n                    _(\"{editor}: Editing failed\").format(editor=editor)\n                )\n        except OSError as e:\n            raise ClickException(\n                _(\"{editor}: Editing failed: {e}\").format(editor=editor, e=e)\n            ) from e\n\n    @t.overload\n    def edit(self, text: bytes | bytearray) -> bytes | None: ...\n\n    # We cannot know whether or not the type expected is str or bytes when None\n    # is passed, so str is returned as that was what was done before.\n    @t.overload\n    def edit(self, text: str | None) -> str | None: ...\n\n    def edit(self, text: str | bytes | bytearray | None) -> str | bytes | None:\n        import tempfile\n\n        if text is None:\n            data: bytes | bytearray = b\"\"\n        elif isinstance(text, (bytes, bytearray)):\n            data = text\n        else:\n            if text and not text.endswith(\"\\n\"):\n                text += \"\\n\"\n\n            if WIN:\n                data = text.replace(\"\\n\", \"\\r\\n\").encode(\"utf-8-sig\")\n            else:\n                data = text.encode(\"utf-8\")\n\n        fd, name = tempfile.mkstemp(prefix=\"editor-\", suffix=self.extension)\n        f: t.BinaryIO\n\n        try:\n            with os.fdopen(fd, \"wb\") as f:\n                f.write(data)\n\n            # If the filesystem resolution is 1 second, like Mac OS\n            # 10.12 Extended, or 2 seconds, like FAT32, and the editor\n            # closes very fast, require_save can fail. Set the modified\n            # time to be 2 seconds in the past to work around this.\n            os.utime(name, (os.path.getatime(name), os.path.getmtime(name) - 2))\n            # Depending on the resolution, the exact value might not be\n            # recorded, so get the new recorded value.\n            timestamp = os.path.getmtime(name)\n\n            self.edit_files((name,))\n\n            if self.require_save and os.path.getmtime(name) == timestamp:\n                return None\n\n            with open(name, \"rb\") as f:\n                rv = f.read()\n\n            if isinstance(text, (bytes, bytearray)):\n                return rv\n\n            return rv.decode(\"utf-8-sig\").replace(\"\\r\\n\", \"\\n\")\n        finally:\n            os.unlink(name)\n\n\ndef open_url(url: str, wait: bool = False, locate: bool = False) -> int:\n    import subprocess\n\n    def _unquote_file(url: str) -> str:\n        from urllib.parse import unquote\n\n        if url.startswith(\"file://\"):\n            url = unquote(url[7:])\n\n        return url\n\n    if sys.platform == \"darwin\":\n        args = [\"open\"]\n        if wait:\n            args.append(\"-W\")\n        if locate:\n            args.append(\"-R\")\n        args.append(_unquote_file(url))\n        null = open(\"/dev/null\", \"w\")\n        try:\n            return subprocess.Popen(args, stderr=null).wait()\n        finally:\n            null.close()\n    elif WIN:\n        if locate:\n            url = _unquote_file(url)\n            args = [\"explorer\", f\"/select,{url}\"]\n        else:\n            args = [\"start\"]\n            if wait:\n                args.append(\"/WAIT\")\n            args.append(\"\")\n            args.append(url)\n        try:\n            return subprocess.call(args)\n        except OSError:\n            # Command not found\n            return 127\n    elif CYGWIN:\n        if locate:\n            url = _unquote_file(url)\n            args = [\"cygstart\", os.path.dirname(url)]\n        else:\n            args = [\"cygstart\"]\n            if wait:\n                args.append(\"-w\")\n            args.append(url)\n        try:\n            return subprocess.call(args)\n        except OSError:\n            # Command not found\n            return 127\n\n    try:\n        if locate:\n            url = os.path.dirname(_unquote_file(url)) or \".\"\n        else:\n            url = _unquote_file(url)\n        c = subprocess.Popen([\"xdg-open\", url])\n        if wait:\n            return c.wait()\n        return 0\n    except OSError:\n        if url.startswith((\"http://\", \"https://\")) and not locate and not wait:\n            import webbrowser\n\n            webbrowser.open(url)\n            return 0\n        return 1\n\n\ndef _translate_ch_to_exc(ch: str) -> None:\n    if ch == \"\\x03\":\n        raise KeyboardInterrupt()\n\n    if ch == \"\\x04\" and not WIN:  # Unix-like, Ctrl+D\n        raise EOFError()\n\n    if ch == \"\\x1a\" and WIN:  # Windows, Ctrl+Z\n        raise EOFError()\n\n    return None\n\n\nif sys.platform == \"win32\":\n    import msvcrt\n\n    @contextlib.contextmanager\n    def raw_terminal() -> cabc.Iterator[int]:\n        yield -1\n\n    def getchar(echo: bool) -> str:\n        # The function `getch` will return a bytes object corresponding to\n        # the pressed character. Since Windows 10 build 1803, it will also\n        # return \\x00 when called a second time after pressing a regular key.\n        #\n        # `getwch` does not share this probably-bugged behavior. Moreover, it\n        # returns a Unicode object by default, which is what we want.\n        #\n        # Either of these functions will return \\x00 or \\xe0 to indicate\n        # a special key, and you need to call the same function again to get\n        # the \"rest\" of the code. The fun part is that \\u00e0 is\n        # \"latin small letter a with grave\", so if you type that on a French\n        # keyboard, you _also_ get a \\xe0.\n        # E.g., consider the Up arrow. This returns \\xe0 and then \\x48. The\n        # resulting Unicode string reads as \"a with grave\" + \"capital H\".\n        # This is indistinguishable from when the user actually types\n        # \"a with grave\" and then \"capital H\".\n        #\n        # When \\xe0 is returned, we assume it's part of a special-key sequence\n        # and call `getwch` again, but that means that when the user types\n        # the \\u00e0 character, `getchar` doesn't return until a second\n        # character is typed.\n        # The alternative is returning immediately, but that would mess up\n        # cross-platform handling of arrow keys and others that start with\n        # \\xe0. Another option is using `getch`, but then we can't reliably\n        # read non-ASCII characters, because return values of `getch` are\n        # limited to the current 8-bit codepage.\n        #\n        # Anyway, Click doesn't claim to do this Right(tm), and using `getwch`\n        # is doing the right thing in more situations than with `getch`.\n\n        if echo:\n            func = t.cast(t.Callable[[], str], msvcrt.getwche)\n        else:\n            func = t.cast(t.Callable[[], str], msvcrt.getwch)\n\n        rv = func()\n\n        if rv in (\"\\x00\", \"\\xe0\"):\n            # \\x00 and \\xe0 are control characters that indicate special key,\n            # see above.\n            rv += func()\n\n        _translate_ch_to_exc(rv)\n        return rv\n\nelse:\n    import termios\n    import tty\n\n    @contextlib.contextmanager\n    def raw_terminal() -> cabc.Iterator[int]:\n        f: t.TextIO | None\n        fd: int\n\n        if not isatty(sys.stdin):\n            f = open(\"/dev/tty\")\n            fd = f.fileno()\n        else:\n            fd = sys.stdin.fileno()\n            f = None\n\n        try:\n            old_settings = termios.tcgetattr(fd)\n\n            try:\n                tty.setraw(fd)\n                yield fd\n            finally:\n                termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)\n                sys.stdout.flush()\n\n                if f is not None:\n                    f.close()\n        except termios.error:\n            pass\n\n    def getchar(echo: bool) -> str:\n        with raw_terminal() as fd:\n            ch = os.read(fd, 32).decode(get_best_encoding(sys.stdin), \"replace\")\n\n            if echo and isatty(sys.stdout):\n                sys.stdout.write(ch)\n\n            _translate_ch_to_exc(ch)\n            return ch\n",
      "bug_category": "modularity",
      "error_type": "modularity",
      "confidence": 0.2
    },
    {
      "bug_id": "7cb537ea62dc",
      "repo": "click",
      "commit_hash": "812b800",
      "commit_message": "Fix rendering when `prompt_suffix` is empty",
      "file_path": "src/click/termui.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport inspect\nimport io\nimport itertools\nimport sys\nimport typing as t\nfrom contextlib import AbstractContextManager\nfrom gettext import gettext as _\n\nfrom ._compat import isatty\nfrom ._compat import strip_ansi\nfrom .exceptions import Abort\nfrom .exceptions import UsageError\nfrom .globals import resolve_color_default\nfrom .types import Choice\nfrom .types import convert_type\nfrom .types import ParamType\nfrom .utils import echo\nfrom .utils import LazyFile\n\nif t.TYPE_CHECKING:\n    from ._termui_impl import ProgressBar\n\nV = t.TypeVar(\"V\")\n\n# The prompt functions to use.  The doc tools currently override these\n# functions to customize how they work.\nvisible_prompt_func: t.Callable[[str], str] = input\n\n_ansi_colors = {\n    \"black\": 30,\n    \"red\": 31,\n    \"green\": 32,\n    \"yellow\": 33,\n    \"blue\": 34,\n    \"magenta\": 35,\n    \"cyan\": 36,\n    \"white\": 37,\n    \"reset\": 39,\n    \"bright_black\": 90,\n    \"bright_red\": 91,\n    \"bright_green\": 92,\n    \"bright_yellow\": 93,\n    \"bright_blue\": 94,\n    \"bright_magenta\": 95,\n    \"bright_cyan\": 96,\n    \"bright_white\": 97,\n}\n_ansi_reset_all = \"\\033[0m\"\n\n\ndef hidden_prompt_func(prompt: str) -> str:\n    import getpass\n\n    return getpass.getpass(prompt)\n\n\ndef _build_prompt(\n    text: str,\n    suffix: str,\n    show_default: bool = False,\n    default: t.Any | None = None,\n    show_choices: bool = True,\n    type: ParamType | None = None,\n) -> str:\n    prompt = text\n    if type is not None and show_choices and isinstance(type, Choice):\n        prompt += f\" ({', '.join(map(str, type.choices))})\"\n    if default is not None and show_default:\n        prompt = f\"{prompt} [{_format_default(default)}]\"\n    return f\"{prompt}{suffix}\"\n\n\ndef _format_default(default: t.Any) -> t.Any:\n    if isinstance(default, (io.IOBase, LazyFile)) and hasattr(default, \"name\"):\n        return default.name\n\n    return default\n\n\ndef prompt(\n    text: str,\n    default: t.Any | None = None,\n    hide_input: bool = False,\n    confirmation_prompt: bool | str = False,\n    type: ParamType | t.Any | None = None,\n    value_proc: t.Callable[[str], t.Any] | None = None,\n    prompt_suffix: str = \": \",\n    show_default: bool = True,\n    err: bool = False,\n    show_choices: bool = True,\n) -> t.Any:\n    \"\"\"Prompts a user for input.  This is a convenience function that can\n    be used to prompt a user for input later.\n\n    If the user aborts the input by sending an interrupt signal, this\n    function will catch it and raise a :exc:`Abort` exception.\n\n    :param text: the text to show for the prompt.\n    :param default: the default value to use if no input happens.  If this\n                    is not given it will prompt until it's aborted.\n    :param hide_input: if this is set to true then the input value will\n                       be hidden.\n    :param confirmation_prompt: Prompt a second time to confirm the\n        value. Can be set to a string instead of ``True`` to customize\n        the message.\n    :param type: the type to use to check the value against.\n    :param value_proc: if this parameter is provided it's a function that\n                       is invoked instead of the type conversion to\n                       convert a value.\n    :param prompt_suffix: a suffix that should be added to the prompt.\n    :param show_default: shows or hides the default value in the prompt.\n    :param err: if set to true the file defaults to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n    :param show_choices: Show or hide choices if the passed type is a Choice.\n                         For example if type is a Choice of either day or week,\n                         show_choices is true and text is \"Group by\" then the\n                         prompt will be \"Group by (day, week): \".\n\n    .. versionadded:: 8.0\n        ``confirmation_prompt`` can be a custom string.\n\n    .. versionadded:: 7.0\n        Added the ``show_choices`` parameter.\n\n    .. versionadded:: 6.0\n        Added unicode support for cmd.exe on Windows.\n\n    .. versionadded:: 4.0\n        Added the `err` parameter.\n\n    \"\"\"\n\n    def prompt_func(text: str) -> str:\n        f = hidden_prompt_func if hide_input else visible_prompt_func\n        try:\n            # Write the prompt separately so that we get nice\n            # coloring through colorama on Windows\n            echo(text.rstrip(\" \"), nl=False, err=err)\n            # Echo a space to stdout to work around an issue where\n            # readline causes backspace to clear the whole line.\n            return f(\" \")\n        except (KeyboardInterrupt, EOFError):\n            # getpass doesn't print a newline if the user aborts input with ^C.\n            # Allegedly this behavior is inherited from getpass(3).\n            # A doc bug has been filed at https://bugs.python.org/issue24711\n            if hide_input:\n                echo(None, err=err)\n            raise Abort() from None\n\n    if value_proc is None:\n        value_proc = convert_type(type, default)\n\n    prompt = _build_prompt(\n        text, prompt_suffix, show_default, default, show_choices, type\n    )\n\n    if confirmation_prompt:\n        if confirmation_prompt is True:\n            confirmation_prompt = _(\"Repeat for confirmation\")\n\n        confirmation_prompt = _build_prompt(confirmation_prompt, prompt_suffix)\n\n    while True:\n        while True:\n            value = prompt_func(prompt)\n            if value:\n                break\n            elif default is not None:\n                value = default\n                break\n        try:\n            result = value_proc(value)\n        except UsageError as e:\n            if hide_input:\n                echo(_(\"Error: The value you entered was invalid.\"), err=err)\n            else:\n                echo(_(\"Error: {e.message}\").format(e=e), err=err)\n            continue\n        if not confirmation_prompt:\n            return result\n        while True:\n            value2 = prompt_func(confirmation_prompt)\n            is_empty = not value and not value2\n            if value2 or is_empty:\n                break\n        if value == value2:\n            return result\n        echo(_(\"Error: The two entered values do not match.\"), err=err)\n\n\ndef confirm(\n    text: str,\n    default: bool | None = False,\n    abort: bool = False,\n    prompt_suffix: str = \": \",\n    show_default: bool = True,\n    err: bool = False,\n) -> bool:\n    \"\"\"Prompts for confirmation (yes/no question).\n\n    If the user aborts the input by sending a interrupt signal this\n    function will catch it and raise a :exc:`Abort` exception.\n\n    :param text: the question to ask.\n    :param default: The default value to use when no input is given. If\n        ``None``, repeat until input is given.\n    :param abort: if this is set to `True` a negative answer aborts the\n                  exception by raising :exc:`Abort`.\n    :param prompt_suffix: a suffix that should be added to the prompt.\n    :param show_default: shows or hides the default value in the prompt.\n    :param err: if set to true the file defaults to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n\n    .. versionchanged:: 8.0\n        Repeat until input is given if ``default`` is ``None``.\n\n    .. versionadded:: 4.0\n        Added the ``err`` parameter.\n    \"\"\"\n    prompt = _build_prompt(\n        text,\n        prompt_suffix,\n        show_default,\n        \"y/n\" if default is None else (\"Y/n\" if default else \"y/N\"),\n    )\n\n    while True:\n        try:\n            # Write the prompt separately so that we get nice\n            # coloring through colorama on Windows\n            echo(prompt.rstrip(\" \"), nl=False, err=err)\n            # Echo a space to stdout to work around an issue where\n            # readline causes backspace to clear the whole line.\n            value = visible_prompt_func(\" \").lower().strip()\n        except (KeyboardInterrupt, EOFError):\n            raise Abort() from None\n        if value in (\"y\", \"yes\"):\n            rv = True\n        elif value in (\"n\", \"no\"):\n            rv = False\n        elif default is not None and value == \"\":\n            rv = default\n        else:\n            echo(_(\"Error: invalid input\"), err=err)\n            continue\n        break\n    if abort and not rv:\n        raise Abort()\n    return rv\n\n\ndef echo_via_pager(\n    text_or_generator: cabc.Iterable[str] | t.Callable[[], cabc.Iterable[str]] | str,\n    color: bool | None = None,\n) -> None:\n    \"\"\"This function takes a text and shows it via an environment specific\n    pager on stdout.\n\n    .. versionchanged:: 3.0\n       Added the `color` flag.\n\n    :param text_or_generator: the text to page, or alternatively, a\n                              generator emitting the text to page.\n    :param color: controls if the pager supports ANSI colors or not.  The\n                  default is autodetection.\n    \"\"\"\n    color = resolve_color_default(color)\n\n    if inspect.isgeneratorfunction(text_or_generator):\n        i = t.cast(\"t.Callable[[], cabc.Iterable[str]]\", text_or_generator)()\n    elif isinstance(text_or_generator, str):\n        i = [text_or_generator]\n    else:\n        i = iter(t.cast(\"cabc.Iterable[str]\", text_or_generator))\n\n    # convert every element of i to a text type if necessary\n    text_generator = (el if isinstance(el, str) else str(el) for el in i)\n\n    from ._termui_impl import pager\n\n    return pager(itertools.chain(text_generator, \"\\n\"), color)\n\n\n@t.overload\ndef progressbar(\n    *,\n    length: int,\n    label: str | None = None,\n    hidden: bool = False,\n    show_eta: bool = True,\n    show_percent: bool | None = None,\n    show_pos: bool = False,\n    fill_char: str = \"#\",\n    empty_char: str = \"-\",\n    bar_template: str = \"%(label)s  [%(bar)s]  %(info)s\",\n    info_sep: str = \"  \",\n    width: int = 36,\n    file: t.TextIO | None = None,\n    color: bool | None = None,\n    update_min_steps: int = 1,\n) -> ProgressBar[int]: ...\n\n\n@t.overload\ndef progressbar(\n    iterable: cabc.Iterable[V] | None = None,\n    length: int | None = None,\n    label: str | None = None,\n    hidden: bool = False,\n    show_eta: bool = True,\n    show_percent: bool | None = None,\n    show_pos: bool = False,\n    item_show_func: t.Callable[[V | None], str | None] | None = None,\n    fill_char: str = \"#\",\n    empty_char: str = \"-\",\n    bar_template: str = \"%(label)s  [%(bar)s]  %(info)s\",\n    info_sep: str = \"  \",\n    width: int = 36,\n    file: t.TextIO | None = None,\n    color: bool | None = None,\n    update_min_steps: int = 1,\n) -> ProgressBar[V]: ...\n\n\ndef progressbar(\n    iterable: cabc.Iterable[V] | None = None,\n    length: int | None = None,\n    label: str | None = None,\n    hidden: bool = False,\n    show_eta: bool = True,\n    show_percent: bool | None = None,\n    show_pos: bool = False,\n    item_show_func: t.Callable[[V | None], str | None] | None = None,\n    fill_char: str = \"#\",\n    empty_char: str = \"-\",\n    bar_template: str = \"%(label)s  [%(bar)s]  %(info)s\",\n    info_sep: str = \"  \",\n    width: int = 36,\n    file: t.TextIO | None = None,\n    color: bool | None = None,\n    update_min_steps: int = 1,\n) -> ProgressBar[V]:\n    \"\"\"This function creates an iterable context manager that can be used\n    to iterate over something while showing a progress bar.  It will\n    either iterate over the `iterable` or `length` items (that are counted\n    up).  While iteration happens, this function will print a rendered\n    progress bar to the given `file` (defaults to stdout) and will attempt\n    to calculate remaining time and more.  By default, this progress bar\n    will not be rendered if the file is not a terminal.\n\n    The context manager creates the progress bar.  When the context\n    manager is entered the progress bar is already created.  With every\n    iteration over the progress bar, the iterable passed to the bar is\n    advanced and the bar is updated.  When the context manager exits,\n    a newline is printed and the progress bar is finalized on screen.\n\n    Note: The progress bar is currently designed for use cases where the\n    total progress can be expected to take at least several seconds.\n    Because of this, the ProgressBar class object won't display\n    progress that is considered too fast, and progress where the time\n    between steps is less than a second.\n\n    No printing must happen or the progress bar will be unintentionally\n    destroyed.\n\n    Example usage::\n\n        with progressbar(items) as bar:\n            for item in bar:\n                do_something_with(item)\n\n    Alternatively, if no iterable is specified, one can manually update the\n    progress bar through the `update()` method instead of directly\n    iterating over the progress bar.  The update method accepts the number\n    of steps to increment the bar with::\n\n        with progressbar(length=chunks.total_bytes) as bar:\n            for chunk in chunks:\n                process_chunk(chunk)\n                bar.update(chunks.bytes)\n\n    The ``update()`` method also takes an optional value specifying the\n    ``current_item`` at the new position. This is useful when used\n    together with ``item_show_func`` to customize the output for each\n    manual step::\n\n        with click.progressbar(\n            length=total_size,\n            label='Unzipping archive',\n            item_show_func=lambda a: a.filename\n        ) as bar:\n            for archive in zip_file:\n                archive.extract()\n                bar.update(archive.size, archive)\n\n    :param iterable: an iterable to iterate over.  If not provided the length\n                     is required.\n    :param length: the number of items to iterate over.  By default the\n                   progressbar will attempt to ask the iterator about its\n                   length, which might or might not work.  If an iterable is\n                   also provided this parameter can be used to override the\n                   length.  If an iterable is not provided the progress bar\n                   will iterate over a range of that length.\n    :param label: the label to show next to the progress bar.\n    :param hidden: hide the progressbar. Defaults to ``False``. When no tty is\n        detected, it will only print the progressbar label. Setting this to\n        ``False`` also disables that.\n    :param show_eta: enables or disables the estimated time display.  This is\n                     automatically disabled if the length cannot be\n                     determined.\n    :param show_percent: enables or disables the percentage display.  The\n                         default is `True` if the iterable has a length or\n                         `False` if not.\n    :param show_pos: enables or disables the absolute position display.  The\n                     default is `False`.\n    :param item_show_func: A function called with the current item which\n        can return a string to show next to the progress bar. If the\n        function returns ``None`` nothing is shown. The current item can\n        be ``None``, such as when entering and exiting the bar.\n    :param fill_char: the character to use to show the filled part of the\n                      progress bar.\n    :param empty_char: the character to use to show the non-filled part of\n                       the progress bar.\n    :param bar_template: the format string to use as template for the bar.\n                         The parameters in it are ``label`` for the label,\n                         ``bar`` for the progress bar and ``info`` for the\n                         info section.\n    :param info_sep: the separator between multiple info items (eta etc.)\n    :param width: the width of the progress bar in characters, 0 means full\n                  terminal width\n    :param file: The file to write to. If this is not a terminal then\n        only the label is printed.\n    :param color: controls if the terminal supports ANSI colors or not.  The\n                  default is autodetection.  This is only needed if ANSI\n                  codes are included anywhere in the progress bar output\n                  which is not the case by default.\n    :param update_min_steps: Render only when this many updates have\n        completed. This allows tuning for very fast iterators.\n\n    .. versionadded:: 8.2\n        The ``hidden`` argument.\n\n    .. versionchanged:: 8.0\n        Output is shown even if execution time is less than 0.5 seconds.\n\n    .. versionchanged:: 8.0\n        ``item_show_func`` shows the current item, not the previous one.\n\n    .. versionchanged:: 8.0\n        Labels are echoed if the output is not a TTY. Reverts a change\n        in 7.0 that removed all output.\n\n    .. versionadded:: 8.0\n       The ``update_min_steps`` parameter.\n\n    .. versionadded:: 4.0\n        The ``color`` parameter and ``update`` method.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    from ._termui_impl import ProgressBar\n\n    color = resolve_color_default(color)\n    return ProgressBar(\n        iterable=iterable,\n        length=length,\n        hidden=hidden,\n        show_eta=show_eta,\n        show_percent=show_percent,\n        show_pos=show_pos,\n        item_show_func=item_show_func,\n        fill_char=fill_char,\n        empty_char=empty_char,\n        bar_template=bar_template,\n        info_sep=info_sep,\n        file=file,\n        label=label,\n        width=width,\n        color=color,\n        update_min_steps=update_min_steps,\n    )\n\n\ndef clear() -> None:\n    \"\"\"Clears the terminal screen.  This will have the effect of clearing\n    the whole visible space of the terminal and moving the cursor to the\n    top left.  This does not do anything if not connected to a terminal.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    if not isatty(sys.stdout):\n        return\n\n    # ANSI escape \\033[2J clears the screen, \\033[1;1H moves the cursor\n    echo(\"\\033[2J\\033[1;1H\", nl=False)\n\n\ndef _interpret_color(color: int | tuple[int, int, int] | str, offset: int = 0) -> str:\n    if isinstance(color, int):\n        return f\"{38 + offset};5;{color:d}\"\n\n    if isinstance(color, (tuple, list)):\n        r, g, b = color\n        return f\"{38 + offset};2;{r:d};{g:d};{b:d}\"\n\n    return str(_ansi_colors[color] + offset)\n\n\ndef style(\n    text: t.Any,\n    fg: int | tuple[int, int, int] | str | None = None,\n    bg: int | tuple[int, int, int] | str | None = None,\n    bold: bool | None = None,\n    dim: bool | None = None,\n    underline: bool | None = None,\n    overline: bool | None = None,\n    italic: bool | None = None,\n    blink: bool | None = None,\n    reverse: bool | None = None,\n    strikethrough: bool | None = None,\n    reset: bool = True,\n) -> str:\n    \"\"\"Styles a text with ANSI styles and returns the new string.  By\n    default the styling is self contained which means that at the end\n    of the string a reset code is issued.  This can be prevented by\n    passing ``reset=False``.\n\n    Examples::\n\n        click.echo(click.style('Hello World!', fg='green'))\n        click.echo(click.style('ATTENTION!', blink=True))\n        click.echo(click.style('Some things', reverse=True, fg='cyan'))\n        click.echo(click.style('More colors', fg=(255, 12, 128), bg=117))\n\n    Supported color names:\n\n    * ``black`` (might be a gray)\n    * ``red``\n    * ``green``\n    * ``yellow`` (might be an orange)\n    * ``blue``\n    * ``magenta``\n    * ``cyan``\n    * ``white`` (might be light gray)\n    * ``bright_black``\n    * ``bright_red``\n    * ``bright_green``\n    * ``bright_yellow``\n    * ``bright_blue``\n    * ``bright_magenta``\n    * ``bright_cyan``\n    * ``bright_white``\n    * ``reset`` (reset the color code only)\n\n    If the terminal supports it, color may also be specified as:\n\n    -   An integer in the interval [0, 255]. The terminal must support\n        8-bit/256-color mode.\n    -   An RGB tuple of three integers in [0, 255]. The terminal must\n        support 24-bit/true-color mode.\n\n    See https://en.wikipedia.org/wiki/ANSI_color and\n    https://gist.github.com/XVilka/8346728 for more information.\n\n    :param text: the string to style with ansi codes.\n    :param fg: if provided this will become the foreground color.\n    :param bg: if provided this will become the background color.\n    :param bold: if provided this will enable or disable bold mode.\n    :param dim: if provided this will enable or disable dim mode.  This is\n                badly supported.\n    :param underline: if provided this will enable or disable underline.\n    :param overline: if provided this will enable or disable overline.\n    :param italic: if provided this will enable or disable italic.\n    :param blink: if provided this will enable or disable blinking.\n    :param reverse: if provided this will enable or disable inverse\n                    rendering (foreground becomes background and the\n                    other way round).\n    :param strikethrough: if provided this will enable or disable\n        striking through text.\n    :param reset: by default a reset-all code is added at the end of the\n                  string which means that styles do not carry over.  This\n                  can be disabled to compose styles.\n\n    .. versionchanged:: 8.0\n        A non-string ``message`` is converted to a string.\n\n    .. versionchanged:: 8.0\n       Added support for 256 and RGB color codes.\n\n    .. versionchanged:: 8.0\n        Added the ``strikethrough``, ``italic``, and ``overline``\n        parameters.\n\n    .. versionchanged:: 7.0\n        Added support for bright colors.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    if not isinstance(text, str):\n        text = str(text)\n\n    bits = []\n\n    if fg:\n        try:\n            bits.append(f\"\\033[{_interpret_color(fg)}m\")\n        except KeyError:\n            raise TypeError(f\"Unknown color {fg!r}\") from None\n\n    if bg:\n        try:\n            bits.append(f\"\\033[{_interpret_color(bg, 10)}m\")\n        except KeyError:\n            raise TypeError(f\"Unknown color {bg!r}\") from None\n\n    if bold is not None:\n        bits.append(f\"\\033[{1 if bold else 22}m\")\n    if dim is not None:\n        bits.append(f\"\\033[{2 if dim else 22}m\")\n    if underline is not None:\n        bits.append(f\"\\033[{4 if underline else 24}m\")\n    if overline is not None:\n        bits.append(f\"\\033[{53 if overline else 55}m\")\n    if italic is not None:\n        bits.append(f\"\\033[{3 if italic else 23}m\")\n    if blink is not None:\n        bits.append(f\"\\033[{5 if blink else 25}m\")\n    if reverse is not None:\n        bits.append(f\"\\033[{7 if reverse else 27}m\")\n    if strikethrough is not None:\n        bits.append(f\"\\033[{9 if strikethrough else 29}m\")\n    bits.append(text)\n    if reset:\n        bits.append(_ansi_reset_all)\n    return \"\".join(bits)\n\n\ndef unstyle(text: str) -> str:\n    \"\"\"Removes ANSI styling information from a string.  Usually it's not\n    necessary to use this function as Click's echo function will\n    automatically remove styling if necessary.\n\n    .. versionadded:: 2.0\n\n    :param text: the text to remove style information from.\n    \"\"\"\n    return strip_ansi(text)\n\n\ndef secho(\n    message: t.Any | None = None,\n    file: t.IO[t.AnyStr] | None = None,\n    nl: bool = True,\n    err: bool = False,\n    color: bool | None = None,\n    **styles: t.Any,\n) -> None:\n    \"\"\"This function combines :func:`echo` and :func:`style` into one\n    call.  As such the following two calls are the same::\n\n        click.secho('Hello World!', fg='green')\n        click.echo(click.style('Hello World!', fg='green'))\n\n    All keyword arguments are forwarded to the underlying functions\n    depending on which one they go with.\n\n    Non-string types will be converted to :class:`str`. However,\n    :class:`bytes` are passed directly to :meth:`echo` without applying\n    style. If you want to style bytes that represent text, call\n    :meth:`bytes.decode` first.\n\n    .. versionchanged:: 8.0\n        A non-string ``message`` is converted to a string. Bytes are\n        passed through without style applied.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    if message is not None and not isinstance(message, (bytes, bytearray)):\n        message = style(message, **styles)\n\n    return echo(message, file=file, nl=nl, err=err, color=color)\n\n\n@t.overload\ndef edit(\n    text: bytes | bytearray,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = False,\n    extension: str = \".txt\",\n) -> bytes | None: ...\n\n\n@t.overload\ndef edit(\n    text: str,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = True,\n    extension: str = \".txt\",\n) -> str | None: ...\n\n\n@t.overload\ndef edit(\n    text: None = None,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = True,\n    extension: str = \".txt\",\n    filename: str | cabc.Iterable[str] | None = None,\n) -> None: ...\n\n\ndef edit(\n    text: str | bytes | bytearray | None = None,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = True,\n    extension: str = \".txt\",\n    filename: str | cabc.Iterable[str] | None = None,\n) -> str | bytes | bytearray | None:\n    r\"\"\"Edits the given text in the defined editor.  If an editor is given\n    (should be the full path to the executable but the regular operating\n    system search path is used for finding the executable) it overrides\n    the detected editor.  Optionally, some environment variables can be\n    used.  If the editor is closed without changes, `None` is returned.  In\n    case a file is edited directly the return value is always `None` and\n    `require_save` and `extension` are ignored.\n\n    If the editor cannot be opened a :exc:`UsageError` is raised.\n\n    Note for Windows: to simplify cross-platform usage, the newlines are\n    automatically converted from POSIX to Windows and vice versa.  As such,\n    the message here will have ``\\n`` as newline markers.\n\n    :param text: the text to edit.\n    :param editor: optionally the editor to use.  Defaults to automatic\n                   detection.\n    :param env: environment variables to forward to the editor.\n    :param require_save: if this is true, then not saving in the editor\n                         will make the return value become `None`.\n    :param extension: the extension to tell the editor about.  This defaults\n                      to `.txt` but changing this might change syntax\n                      highlighting.\n    :param filename: if provided it will edit this file instead of the\n                     provided text contents.  It will not use a temporary\n                     file as an indirection in that case. If the editor supports\n                     editing multiple files at once, a sequence of files may be\n                     passed as well. Invoke `click.file` once per file instead\n                     if multiple files cannot be managed at once or editing the\n                     files serially is desired.\n\n    .. versionchanged:: 8.2.0\n        ``filename`` now accepts any ``Iterable[str]`` in addition to a ``str``\n        if the ``editor`` supports editing multiple files at once.\n\n    \"\"\"\n    from ._termui_impl import Editor\n\n    ed = Editor(editor=editor, env=env, require_save=require_save, extension=extension)\n\n    if filename is None:\n        return ed.edit(text)\n\n    if isinstance(filename, str):\n        filename = (filename,)\n\n    ed.edit_files(filenames=filename)\n    return None\n\n\ndef launch(url: str, wait: bool = False, locate: bool = False) -> int:\n    \"\"\"This function launches the given URL (or filename) in the default\n    viewer application for this file type.  If this is an executable, it\n    might launch the executable in a new session.  The return value is\n    the exit code of the launched application.  Usually, ``0`` indicates\n    success.\n\n    Examples::\n\n        click.launch('https://click.palletsprojects.com/')\n        click.launch('/my/downloaded/file', locate=True)\n\n    .. versionadded:: 2.0\n\n    :param url: URL or filename of the thing to launch.\n    :param wait: Wait for the program to exit before returning. This\n        only works if the launched program blocks. In particular,\n        ``xdg-open`` on Linux does not block.\n    :param locate: if this is set to `True` then instead of launching the\n                   application associated with the URL it will attempt to\n                   launch a file manager with the file located.  This\n                   might have weird effects if the URL does not point to\n                   the filesystem.\n    \"\"\"\n    from ._termui_impl import open_url\n\n    return open_url(url, wait=wait, locate=locate)\n\n\n# If this is provided, getchar() calls into this instead.  This is used\n# for unittesting purposes.\n_getchar: t.Callable[[bool], str] | None = None\n\n\ndef getchar(echo: bool = False) -> str:\n    \"\"\"Fetches a single character from the terminal and returns it.  This\n    will always return a unicode character and under certain rare\n    circumstances this might return more than one character.  The\n    situations which more than one character is returned is when for\n    whatever reason multiple characters end up in the terminal buffer or\n    standard input was not actually a terminal.\n\n    Note that this will always read from the terminal, even if something\n    is piped into the standard input.\n\n    Note for Windows: in rare cases when typing non-ASCII characters, this\n    function might wait for a second character and then return both at once.\n    This is because certain Unicode characters look like special-key markers.\n\n    .. versionadded:: 2.0\n\n    :param echo: if set to `True`, the character read will also show up on\n                 the terminal.  The default is to not show it.\n    \"\"\"\n    global _getchar\n\n    if _getchar is None:\n        from ._termui_impl import getchar as f\n\n        _getchar = f\n\n    return _getchar(echo)\n\n\ndef raw_terminal() -> AbstractContextManager[int]:\n    from ._termui_impl import raw_terminal as f\n\n    return f()\n\n\ndef pause(info: str | None = None, err: bool = False) -> None:\n    \"\"\"This command stops execution and waits for the user to press any\n    key to continue.  This is similar to the Windows batch \"pause\"\n    command.  If the program is not run through a terminal, this command\n    will instead do nothing.\n\n    .. versionadded:: 2.0\n\n    .. versionadded:: 4.0\n       Added the `err` parameter.\n\n    :param info: The message to print before pausing. Defaults to\n        ``\"Press any key to continue...\"``.\n    :param err: if set to message goes to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n    \"\"\"\n    if not isatty(sys.stdin) or not isatty(sys.stdout):\n        return\n\n    if info is None:\n        info = _(\"Press any key to continue...\")\n\n    try:\n        if info:\n            echo(info, nl=False, err=err)\n        try:\n            getchar()\n        except (KeyboardInterrupt, EOFError):\n            pass\n    finally:\n        if info:\n            echo(err=err)\n",
      "code_after": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport inspect\nimport io\nimport itertools\nimport sys\nimport typing as t\nfrom contextlib import AbstractContextManager\nfrom gettext import gettext as _\n\nfrom ._compat import isatty\nfrom ._compat import strip_ansi\nfrom .exceptions import Abort\nfrom .exceptions import UsageError\nfrom .globals import resolve_color_default\nfrom .types import Choice\nfrom .types import convert_type\nfrom .types import ParamType\nfrom .utils import echo\nfrom .utils import LazyFile\n\nif t.TYPE_CHECKING:\n    from ._termui_impl import ProgressBar\n\nV = t.TypeVar(\"V\")\n\n# The prompt functions to use.  The doc tools currently override these\n# functions to customize how they work.\nvisible_prompt_func: t.Callable[[str], str] = input\n\n_ansi_colors = {\n    \"black\": 30,\n    \"red\": 31,\n    \"green\": 32,\n    \"yellow\": 33,\n    \"blue\": 34,\n    \"magenta\": 35,\n    \"cyan\": 36,\n    \"white\": 37,\n    \"reset\": 39,\n    \"bright_black\": 90,\n    \"bright_red\": 91,\n    \"bright_green\": 92,\n    \"bright_yellow\": 93,\n    \"bright_blue\": 94,\n    \"bright_magenta\": 95,\n    \"bright_cyan\": 96,\n    \"bright_white\": 97,\n}\n_ansi_reset_all = \"\\033[0m\"\n\n\ndef hidden_prompt_func(prompt: str) -> str:\n    import getpass\n\n    return getpass.getpass(prompt)\n\n\ndef _build_prompt(\n    text: str,\n    suffix: str,\n    show_default: bool = False,\n    default: t.Any | None = None,\n    show_choices: bool = True,\n    type: ParamType | None = None,\n) -> str:\n    prompt = text\n    if type is not None and show_choices and isinstance(type, Choice):\n        prompt += f\" ({', '.join(map(str, type.choices))})\"\n    if default is not None and show_default:\n        prompt = f\"{prompt} [{_format_default(default)}]\"\n    return f\"{prompt}{suffix}\"\n\n\ndef _format_default(default: t.Any) -> t.Any:\n    if isinstance(default, (io.IOBase, LazyFile)) and hasattr(default, \"name\"):\n        return default.name\n\n    return default\n\n\ndef prompt(\n    text: str,\n    default: t.Any | None = None,\n    hide_input: bool = False,\n    confirmation_prompt: bool | str = False,\n    type: ParamType | t.Any | None = None,\n    value_proc: t.Callable[[str], t.Any] | None = None,\n    prompt_suffix: str = \": \",\n    show_default: bool = True,\n    err: bool = False,\n    show_choices: bool = True,\n) -> t.Any:\n    \"\"\"Prompts a user for input.  This is a convenience function that can\n    be used to prompt a user for input later.\n\n    If the user aborts the input by sending an interrupt signal, this\n    function will catch it and raise a :exc:`Abort` exception.\n\n    :param text: the text to show for the prompt.\n    :param default: the default value to use if no input happens.  If this\n                    is not given it will prompt until it's aborted.\n    :param hide_input: if this is set to true then the input value will\n                       be hidden.\n    :param confirmation_prompt: Prompt a second time to confirm the\n        value. Can be set to a string instead of ``True`` to customize\n        the message.\n    :param type: the type to use to check the value against.\n    :param value_proc: if this parameter is provided it's a function that\n                       is invoked instead of the type conversion to\n                       convert a value.\n    :param prompt_suffix: a suffix that should be added to the prompt.\n    :param show_default: shows or hides the default value in the prompt.\n    :param err: if set to true the file defaults to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n    :param show_choices: Show or hide choices if the passed type is a Choice.\n                         For example if type is a Choice of either day or week,\n                         show_choices is true and text is \"Group by\" then the\n                         prompt will be \"Group by (day, week): \".\n\n    .. versionadded:: 8.0\n        ``confirmation_prompt`` can be a custom string.\n\n    .. versionadded:: 7.0\n        Added the ``show_choices`` parameter.\n\n    .. versionadded:: 6.0\n        Added unicode support for cmd.exe on Windows.\n\n    .. versionadded:: 4.0\n        Added the `err` parameter.\n\n    \"\"\"\n\n    def prompt_func(text: str) -> str:\n        f = hidden_prompt_func if hide_input else visible_prompt_func\n        try:\n            # Write the prompt separately so that we get nice\n            # coloring through colorama on Windows\n            echo(text[:-1], nl=False, err=err)\n            # Echo the last character to stdout to work around an issue where\n            # readline causes backspace to clear the whole line.\n            return f(text[-1:])\n        except (KeyboardInterrupt, EOFError):\n            # getpass doesn't print a newline if the user aborts input with ^C.\n            # Allegedly this behavior is inherited from getpass(3).\n            # A doc bug has been filed at https://bugs.python.org/issue24711\n            if hide_input:\n                echo(None, err=err)\n            raise Abort() from None\n\n    if value_proc is None:\n        value_proc = convert_type(type, default)\n\n    prompt = _build_prompt(\n        text, prompt_suffix, show_default, default, show_choices, type\n    )\n\n    if confirmation_prompt:\n        if confirmation_prompt is True:\n            confirmation_prompt = _(\"Repeat for confirmation\")\n\n        confirmation_prompt = _build_prompt(confirmation_prompt, prompt_suffix)\n\n    while True:\n        while True:\n            value = prompt_func(prompt)\n            if value:\n                break\n            elif default is not None:\n                value = default\n                break\n        try:\n            result = value_proc(value)\n        except UsageError as e:\n            if hide_input:\n                echo(_(\"Error: The value you entered was invalid.\"), err=err)\n            else:\n                echo(_(\"Error: {e.message}\").format(e=e), err=err)\n            continue\n        if not confirmation_prompt:\n            return result\n        while True:\n            value2 = prompt_func(confirmation_prompt)\n            is_empty = not value and not value2\n            if value2 or is_empty:\n                break\n        if value == value2:\n            return result\n        echo(_(\"Error: The two entered values do not match.\"), err=err)\n\n\ndef confirm(\n    text: str,\n    default: bool | None = False,\n    abort: bool = False,\n    prompt_suffix: str = \": \",\n    show_default: bool = True,\n    err: bool = False,\n) -> bool:\n    \"\"\"Prompts for confirmation (yes/no question).\n\n    If the user aborts the input by sending a interrupt signal this\n    function will catch it and raise a :exc:`Abort` exception.\n\n    :param text: the question to ask.\n    :param default: The default value to use when no input is given. If\n        ``None``, repeat until input is given.\n    :param abort: if this is set to `True` a negative answer aborts the\n                  exception by raising :exc:`Abort`.\n    :param prompt_suffix: a suffix that should be added to the prompt.\n    :param show_default: shows or hides the default value in the prompt.\n    :param err: if set to true the file defaults to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n\n    .. versionchanged:: 8.0\n        Repeat until input is given if ``default`` is ``None``.\n\n    .. versionadded:: 4.0\n        Added the ``err`` parameter.\n    \"\"\"\n    prompt = _build_prompt(\n        text,\n        prompt_suffix,\n        show_default,\n        \"y/n\" if default is None else (\"Y/n\" if default else \"y/N\"),\n    )\n\n    while True:\n        try:\n            # Write the prompt separately so that we get nice\n            # coloring through colorama on Windows\n            echo(prompt[:-1], nl=False, err=err)\n            # Echo the last character to stdout to work around an issue where\n            # readline causes backspace to clear the whole line.\n            value = visible_prompt_func(prompt[-1:]).lower().strip()\n        except (KeyboardInterrupt, EOFError):\n            raise Abort() from None\n        if value in (\"y\", \"yes\"):\n            rv = True\n        elif value in (\"n\", \"no\"):\n            rv = False\n        elif default is not None and value == \"\":\n            rv = default\n        else:\n            echo(_(\"Error: invalid input\"), err=err)\n            continue\n        break\n    if abort and not rv:\n        raise Abort()\n    return rv\n\n\ndef echo_via_pager(\n    text_or_generator: cabc.Iterable[str] | t.Callable[[], cabc.Iterable[str]] | str,\n    color: bool | None = None,\n) -> None:\n    \"\"\"This function takes a text and shows it via an environment specific\n    pager on stdout.\n\n    .. versionchanged:: 3.0\n       Added the `color` flag.\n\n    :param text_or_generator: the text to page, or alternatively, a\n                              generator emitting the text to page.\n    :param color: controls if the pager supports ANSI colors or not.  The\n                  default is autodetection.\n    \"\"\"\n    color = resolve_color_default(color)\n\n    if inspect.isgeneratorfunction(text_or_generator):\n        i = t.cast(\"t.Callable[[], cabc.Iterable[str]]\", text_or_generator)()\n    elif isinstance(text_or_generator, str):\n        i = [text_or_generator]\n    else:\n        i = iter(t.cast(\"cabc.Iterable[str]\", text_or_generator))\n\n    # convert every element of i to a text type if necessary\n    text_generator = (el if isinstance(el, str) else str(el) for el in i)\n\n    from ._termui_impl import pager\n\n    return pager(itertools.chain(text_generator, \"\\n\"), color)\n\n\n@t.overload\ndef progressbar(\n    *,\n    length: int,\n    label: str | None = None,\n    hidden: bool = False,\n    show_eta: bool = True,\n    show_percent: bool | None = None,\n    show_pos: bool = False,\n    fill_char: str = \"#\",\n    empty_char: str = \"-\",\n    bar_template: str = \"%(label)s  [%(bar)s]  %(info)s\",\n    info_sep: str = \"  \",\n    width: int = 36,\n    file: t.TextIO | None = None,\n    color: bool | None = None,\n    update_min_steps: int = 1,\n) -> ProgressBar[int]: ...\n\n\n@t.overload\ndef progressbar(\n    iterable: cabc.Iterable[V] | None = None,\n    length: int | None = None,\n    label: str | None = None,\n    hidden: bool = False,\n    show_eta: bool = True,\n    show_percent: bool | None = None,\n    show_pos: bool = False,\n    item_show_func: t.Callable[[V | None], str | None] | None = None,\n    fill_char: str = \"#\",\n    empty_char: str = \"-\",\n    bar_template: str = \"%(label)s  [%(bar)s]  %(info)s\",\n    info_sep: str = \"  \",\n    width: int = 36,\n    file: t.TextIO | None = None,\n    color: bool | None = None,\n    update_min_steps: int = 1,\n) -> ProgressBar[V]: ...\n\n\ndef progressbar(\n    iterable: cabc.Iterable[V] | None = None,\n    length: int | None = None,\n    label: str | None = None,\n    hidden: bool = False,\n    show_eta: bool = True,\n    show_percent: bool | None = None,\n    show_pos: bool = False,\n    item_show_func: t.Callable[[V | None], str | None] | None = None,\n    fill_char: str = \"#\",\n    empty_char: str = \"-\",\n    bar_template: str = \"%(label)s  [%(bar)s]  %(info)s\",\n    info_sep: str = \"  \",\n    width: int = 36,\n    file: t.TextIO | None = None,\n    color: bool | None = None,\n    update_min_steps: int = 1,\n) -> ProgressBar[V]:\n    \"\"\"This function creates an iterable context manager that can be used\n    to iterate over something while showing a progress bar.  It will\n    either iterate over the `iterable` or `length` items (that are counted\n    up).  While iteration happens, this function will print a rendered\n    progress bar to the given `file` (defaults to stdout) and will attempt\n    to calculate remaining time and more.  By default, this progress bar\n    will not be rendered if the file is not a terminal.\n\n    The context manager creates the progress bar.  When the context\n    manager is entered the progress bar is already created.  With every\n    iteration over the progress bar, the iterable passed to the bar is\n    advanced and the bar is updated.  When the context manager exits,\n    a newline is printed and the progress bar is finalized on screen.\n\n    Note: The progress bar is currently designed for use cases where the\n    total progress can be expected to take at least several seconds.\n    Because of this, the ProgressBar class object won't display\n    progress that is considered too fast, and progress where the time\n    between steps is less than a second.\n\n    No printing must happen or the progress bar will be unintentionally\n    destroyed.\n\n    Example usage::\n\n        with progressbar(items) as bar:\n            for item in bar:\n                do_something_with(item)\n\n    Alternatively, if no iterable is specified, one can manually update the\n    progress bar through the `update()` method instead of directly\n    iterating over the progress bar.  The update method accepts the number\n    of steps to increment the bar with::\n\n        with progressbar(length=chunks.total_bytes) as bar:\n            for chunk in chunks:\n                process_chunk(chunk)\n                bar.update(chunks.bytes)\n\n    The ``update()`` method also takes an optional value specifying the\n    ``current_item`` at the new position. This is useful when used\n    together with ``item_show_func`` to customize the output for each\n    manual step::\n\n        with click.progressbar(\n            length=total_size,\n            label='Unzipping archive',\n            item_show_func=lambda a: a.filename\n        ) as bar:\n            for archive in zip_file:\n                archive.extract()\n                bar.update(archive.size, archive)\n\n    :param iterable: an iterable to iterate over.  If not provided the length\n                     is required.\n    :param length: the number of items to iterate over.  By default the\n                   progressbar will attempt to ask the iterator about its\n                   length, which might or might not work.  If an iterable is\n                   also provided this parameter can be used to override the\n                   length.  If an iterable is not provided the progress bar\n                   will iterate over a range of that length.\n    :param label: the label to show next to the progress bar.\n    :param hidden: hide the progressbar. Defaults to ``False``. When no tty is\n        detected, it will only print the progressbar label. Setting this to\n        ``False`` also disables that.\n    :param show_eta: enables or disables the estimated time display.  This is\n                     automatically disabled if the length cannot be\n                     determined.\n    :param show_percent: enables or disables the percentage display.  The\n                         default is `True` if the iterable has a length or\n                         `False` if not.\n    :param show_pos: enables or disables the absolute position display.  The\n                     default is `False`.\n    :param item_show_func: A function called with the current item which\n        can return a string to show next to the progress bar. If the\n        function returns ``None`` nothing is shown. The current item can\n        be ``None``, such as when entering and exiting the bar.\n    :param fill_char: the character to use to show the filled part of the\n                      progress bar.\n    :param empty_char: the character to use to show the non-filled part of\n                       the progress bar.\n    :param bar_template: the format string to use as template for the bar.\n                         The parameters in it are ``label`` for the label,\n                         ``bar`` for the progress bar and ``info`` for the\n                         info section.\n    :param info_sep: the separator between multiple info items (eta etc.)\n    :param width: the width of the progress bar in characters, 0 means full\n                  terminal width\n    :param file: The file to write to. If this is not a terminal then\n        only the label is printed.\n    :param color: controls if the terminal supports ANSI colors or not.  The\n                  default is autodetection.  This is only needed if ANSI\n                  codes are included anywhere in the progress bar output\n                  which is not the case by default.\n    :param update_min_steps: Render only when this many updates have\n        completed. This allows tuning for very fast iterators.\n\n    .. versionadded:: 8.2\n        The ``hidden`` argument.\n\n    .. versionchanged:: 8.0\n        Output is shown even if execution time is less than 0.5 seconds.\n\n    .. versionchanged:: 8.0\n        ``item_show_func`` shows the current item, not the previous one.\n\n    .. versionchanged:: 8.0\n        Labels are echoed if the output is not a TTY. Reverts a change\n        in 7.0 that removed all output.\n\n    .. versionadded:: 8.0\n       The ``update_min_steps`` parameter.\n\n    .. versionadded:: 4.0\n        The ``color`` parameter and ``update`` method.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    from ._termui_impl import ProgressBar\n\n    color = resolve_color_default(color)\n    return ProgressBar(\n        iterable=iterable,\n        length=length,\n        hidden=hidden,\n        show_eta=show_eta,\n        show_percent=show_percent,\n        show_pos=show_pos,\n        item_show_func=item_show_func,\n        fill_char=fill_char,\n        empty_char=empty_char,\n        bar_template=bar_template,\n        info_sep=info_sep,\n        file=file,\n        label=label,\n        width=width,\n        color=color,\n        update_min_steps=update_min_steps,\n    )\n\n\ndef clear() -> None:\n    \"\"\"Clears the terminal screen.  This will have the effect of clearing\n    the whole visible space of the terminal and moving the cursor to the\n    top left.  This does not do anything if not connected to a terminal.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    if not isatty(sys.stdout):\n        return\n\n    # ANSI escape \\033[2J clears the screen, \\033[1;1H moves the cursor\n    echo(\"\\033[2J\\033[1;1H\", nl=False)\n\n\ndef _interpret_color(color: int | tuple[int, int, int] | str, offset: int = 0) -> str:\n    if isinstance(color, int):\n        return f\"{38 + offset};5;{color:d}\"\n\n    if isinstance(color, (tuple, list)):\n        r, g, b = color\n        return f\"{38 + offset};2;{r:d};{g:d};{b:d}\"\n\n    return str(_ansi_colors[color] + offset)\n\n\ndef style(\n    text: t.Any,\n    fg: int | tuple[int, int, int] | str | None = None,\n    bg: int | tuple[int, int, int] | str | None = None,\n    bold: bool | None = None,\n    dim: bool | None = None,\n    underline: bool | None = None,\n    overline: bool | None = None,\n    italic: bool | None = None,\n    blink: bool | None = None,\n    reverse: bool | None = None,\n    strikethrough: bool | None = None,\n    reset: bool = True,\n) -> str:\n    \"\"\"Styles a text with ANSI styles and returns the new string.  By\n    default the styling is self contained which means that at the end\n    of the string a reset code is issued.  This can be prevented by\n    passing ``reset=False``.\n\n    Examples::\n\n        click.echo(click.style('Hello World!', fg='green'))\n        click.echo(click.style('ATTENTION!', blink=True))\n        click.echo(click.style('Some things', reverse=True, fg='cyan'))\n        click.echo(click.style('More colors', fg=(255, 12, 128), bg=117))\n\n    Supported color names:\n\n    * ``black`` (might be a gray)\n    * ``red``\n    * ``green``\n    * ``yellow`` (might be an orange)\n    * ``blue``\n    * ``magenta``\n    * ``cyan``\n    * ``white`` (might be light gray)\n    * ``bright_black``\n    * ``bright_red``\n    * ``bright_green``\n    * ``bright_yellow``\n    * ``bright_blue``\n    * ``bright_magenta``\n    * ``bright_cyan``\n    * ``bright_white``\n    * ``reset`` (reset the color code only)\n\n    If the terminal supports it, color may also be specified as:\n\n    -   An integer in the interval [0, 255]. The terminal must support\n        8-bit/256-color mode.\n    -   An RGB tuple of three integers in [0, 255]. The terminal must\n        support 24-bit/true-color mode.\n\n    See https://en.wikipedia.org/wiki/ANSI_color and\n    https://gist.github.com/XVilka/8346728 for more information.\n\n    :param text: the string to style with ansi codes.\n    :param fg: if provided this will become the foreground color.\n    :param bg: if provided this will become the background color.\n    :param bold: if provided this will enable or disable bold mode.\n    :param dim: if provided this will enable or disable dim mode.  This is\n                badly supported.\n    :param underline: if provided this will enable or disable underline.\n    :param overline: if provided this will enable or disable overline.\n    :param italic: if provided this will enable or disable italic.\n    :param blink: if provided this will enable or disable blinking.\n    :param reverse: if provided this will enable or disable inverse\n                    rendering (foreground becomes background and the\n                    other way round).\n    :param strikethrough: if provided this will enable or disable\n        striking through text.\n    :param reset: by default a reset-all code is added at the end of the\n                  string which means that styles do not carry over.  This\n                  can be disabled to compose styles.\n\n    .. versionchanged:: 8.0\n        A non-string ``message`` is converted to a string.\n\n    .. versionchanged:: 8.0\n       Added support for 256 and RGB color codes.\n\n    .. versionchanged:: 8.0\n        Added the ``strikethrough``, ``italic``, and ``overline``\n        parameters.\n\n    .. versionchanged:: 7.0\n        Added support for bright colors.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    if not isinstance(text, str):\n        text = str(text)\n\n    bits = []\n\n    if fg:\n        try:\n            bits.append(f\"\\033[{_interpret_color(fg)}m\")\n        except KeyError:\n            raise TypeError(f\"Unknown color {fg!r}\") from None\n\n    if bg:\n        try:\n            bits.append(f\"\\033[{_interpret_color(bg, 10)}m\")\n        except KeyError:\n            raise TypeError(f\"Unknown color {bg!r}\") from None\n\n    if bold is not None:\n        bits.append(f\"\\033[{1 if bold else 22}m\")\n    if dim is not None:\n        bits.append(f\"\\033[{2 if dim else 22}m\")\n    if underline is not None:\n        bits.append(f\"\\033[{4 if underline else 24}m\")\n    if overline is not None:\n        bits.append(f\"\\033[{53 if overline else 55}m\")\n    if italic is not None:\n        bits.append(f\"\\033[{3 if italic else 23}m\")\n    if blink is not None:\n        bits.append(f\"\\033[{5 if blink else 25}m\")\n    if reverse is not None:\n        bits.append(f\"\\033[{7 if reverse else 27}m\")\n    if strikethrough is not None:\n        bits.append(f\"\\033[{9 if strikethrough else 29}m\")\n    bits.append(text)\n    if reset:\n        bits.append(_ansi_reset_all)\n    return \"\".join(bits)\n\n\ndef unstyle(text: str) -> str:\n    \"\"\"Removes ANSI styling information from a string.  Usually it's not\n    necessary to use this function as Click's echo function will\n    automatically remove styling if necessary.\n\n    .. versionadded:: 2.0\n\n    :param text: the text to remove style information from.\n    \"\"\"\n    return strip_ansi(text)\n\n\ndef secho(\n    message: t.Any | None = None,\n    file: t.IO[t.AnyStr] | None = None,\n    nl: bool = True,\n    err: bool = False,\n    color: bool | None = None,\n    **styles: t.Any,\n) -> None:\n    \"\"\"This function combines :func:`echo` and :func:`style` into one\n    call.  As such the following two calls are the same::\n\n        click.secho('Hello World!', fg='green')\n        click.echo(click.style('Hello World!', fg='green'))\n\n    All keyword arguments are forwarded to the underlying functions\n    depending on which one they go with.\n\n    Non-string types will be converted to :class:`str`. However,\n    :class:`bytes` are passed directly to :meth:`echo` without applying\n    style. If you want to style bytes that represent text, call\n    :meth:`bytes.decode` first.\n\n    .. versionchanged:: 8.0\n        A non-string ``message`` is converted to a string. Bytes are\n        passed through without style applied.\n\n    .. versionadded:: 2.0\n    \"\"\"\n    if message is not None and not isinstance(message, (bytes, bytearray)):\n        message = style(message, **styles)\n\n    return echo(message, file=file, nl=nl, err=err, color=color)\n\n\n@t.overload\ndef edit(\n    text: bytes | bytearray,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = False,\n    extension: str = \".txt\",\n) -> bytes | None: ...\n\n\n@t.overload\ndef edit(\n    text: str,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = True,\n    extension: str = \".txt\",\n) -> str | None: ...\n\n\n@t.overload\ndef edit(\n    text: None = None,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = True,\n    extension: str = \".txt\",\n    filename: str | cabc.Iterable[str] | None = None,\n) -> None: ...\n\n\ndef edit(\n    text: str | bytes | bytearray | None = None,\n    editor: str | None = None,\n    env: cabc.Mapping[str, str] | None = None,\n    require_save: bool = True,\n    extension: str = \".txt\",\n    filename: str | cabc.Iterable[str] | None = None,\n) -> str | bytes | bytearray | None:\n    r\"\"\"Edits the given text in the defined editor.  If an editor is given\n    (should be the full path to the executable but the regular operating\n    system search path is used for finding the executable) it overrides\n    the detected editor.  Optionally, some environment variables can be\n    used.  If the editor is closed without changes, `None` is returned.  In\n    case a file is edited directly the return value is always `None` and\n    `require_save` and `extension` are ignored.\n\n    If the editor cannot be opened a :exc:`UsageError` is raised.\n\n    Note for Windows: to simplify cross-platform usage, the newlines are\n    automatically converted from POSIX to Windows and vice versa.  As such,\n    the message here will have ``\\n`` as newline markers.\n\n    :param text: the text to edit.\n    :param editor: optionally the editor to use.  Defaults to automatic\n                   detection.\n    :param env: environment variables to forward to the editor.\n    :param require_save: if this is true, then not saving in the editor\n                         will make the return value become `None`.\n    :param extension: the extension to tell the editor about.  This defaults\n                      to `.txt` but changing this might change syntax\n                      highlighting.\n    :param filename: if provided it will edit this file instead of the\n                     provided text contents.  It will not use a temporary\n                     file as an indirection in that case. If the editor supports\n                     editing multiple files at once, a sequence of files may be\n                     passed as well. Invoke `click.file` once per file instead\n                     if multiple files cannot be managed at once or editing the\n                     files serially is desired.\n\n    .. versionchanged:: 8.2.0\n        ``filename`` now accepts any ``Iterable[str]`` in addition to a ``str``\n        if the ``editor`` supports editing multiple files at once.\n\n    \"\"\"\n    from ._termui_impl import Editor\n\n    ed = Editor(editor=editor, env=env, require_save=require_save, extension=extension)\n\n    if filename is None:\n        return ed.edit(text)\n\n    if isinstance(filename, str):\n        filename = (filename,)\n\n    ed.edit_files(filenames=filename)\n    return None\n\n\ndef launch(url: str, wait: bool = False, locate: bool = False) -> int:\n    \"\"\"This function launches the given URL (or filename) in the default\n    viewer application for this file type.  If this is an executable, it\n    might launch the executable in a new session.  The return value is\n    the exit code of the launched application.  Usually, ``0`` indicates\n    success.\n\n    Examples::\n\n        click.launch('https://click.palletsprojects.com/')\n        click.launch('/my/downloaded/file', locate=True)\n\n    .. versionadded:: 2.0\n\n    :param url: URL or filename of the thing to launch.\n    :param wait: Wait for the program to exit before returning. This\n        only works if the launched program blocks. In particular,\n        ``xdg-open`` on Linux does not block.\n    :param locate: if this is set to `True` then instead of launching the\n                   application associated with the URL it will attempt to\n                   launch a file manager with the file located.  This\n                   might have weird effects if the URL does not point to\n                   the filesystem.\n    \"\"\"\n    from ._termui_impl import open_url\n\n    return open_url(url, wait=wait, locate=locate)\n\n\n# If this is provided, getchar() calls into this instead.  This is used\n# for unittesting purposes.\n_getchar: t.Callable[[bool], str] | None = None\n\n\ndef getchar(echo: bool = False) -> str:\n    \"\"\"Fetches a single character from the terminal and returns it.  This\n    will always return a unicode character and under certain rare\n    circumstances this might return more than one character.  The\n    situations which more than one character is returned is when for\n    whatever reason multiple characters end up in the terminal buffer or\n    standard input was not actually a terminal.\n\n    Note that this will always read from the terminal, even if something\n    is piped into the standard input.\n\n    Note for Windows: in rare cases when typing non-ASCII characters, this\n    function might wait for a second character and then return both at once.\n    This is because certain Unicode characters look like special-key markers.\n\n    .. versionadded:: 2.0\n\n    :param echo: if set to `True`, the character read will also show up on\n                 the terminal.  The default is to not show it.\n    \"\"\"\n    global _getchar\n\n    if _getchar is None:\n        from ._termui_impl import getchar as f\n\n        _getchar = f\n\n    return _getchar(echo)\n\n\ndef raw_terminal() -> AbstractContextManager[int]:\n    from ._termui_impl import raw_terminal as f\n\n    return f()\n\n\ndef pause(info: str | None = None, err: bool = False) -> None:\n    \"\"\"This command stops execution and waits for the user to press any\n    key to continue.  This is similar to the Windows batch \"pause\"\n    command.  If the program is not run through a terminal, this command\n    will instead do nothing.\n\n    .. versionadded:: 2.0\n\n    .. versionadded:: 4.0\n       Added the `err` parameter.\n\n    :param info: The message to print before pausing. Defaults to\n        ``\"Press any key to continue...\"``.\n    :param err: if set to message goes to ``stderr`` instead of\n                ``stdout``, the same as with echo.\n    \"\"\"\n    if not isatty(sys.stdin) or not isatty(sys.stdout):\n        return\n\n    if info is None:\n        info = _(\"Press any key to continue...\")\n\n    try:\n        if info:\n            echo(info, nl=False, err=err)\n        try:\n            getchar()\n        except (KeyboardInterrupt, EOFError):\n            pass\n    finally:\n        if info:\n            echo(err=err)\n",
      "bug_category": "key",
      "error_type": "key_error",
      "confidence": 0.4
    },
    {
      "bug_id": "0b484b538911",
      "repo": "click",
      "commit_hash": "812b800",
      "commit_message": "Fix rendering when `prompt_suffix` is empty",
      "file_path": "tests/test_utils.py",
      "language": "python",
      "code_before": "import os\nimport pathlib\nimport stat\nimport subprocess\nimport sys\nfrom collections import namedtuple\nfrom contextlib import nullcontext\nfrom functools import partial\nfrom io import StringIO\nfrom pathlib import Path\nfrom tempfile import tempdir\nfrom unittest.mock import patch\n\nimport pytest\n\nimport click._termui_impl\nimport click.utils\nfrom click._compat import WIN\n\n\ndef test_echo(runner):\n    with runner.isolation() as outstreams:\n        click.echo(\"\\N{SNOWMAN}\")\n        click.echo(b\"\\x44\\x44\")\n        click.echo(42, nl=False)\n        click.echo(b\"a\", nl=False)\n        click.echo(\"\\x1b[31mx\\x1b[39m\", nl=False)\n        bytes = outstreams[0].getvalue().replace(b\"\\r\\n\", b\"\\n\")\n        assert bytes == b\"\\xe2\\x98\\x83\\nDD\\n42ax\"\n\n    # if wrapped, we expect bytes to survive.\n    @click.command()\n    def cli():\n        click.echo(b\"\\xf6\")\n\n    result = runner.invoke(cli, [])\n    assert result.stdout_bytes == b\"\\xf6\\n\"\n\n    # Ensure we do not strip for bytes.\n    with runner.isolation() as outstreams:\n        click.echo(bytearray(b\"\\x1b[31mx\\x1b[39m\"), nl=False)\n        assert outstreams[0].getvalue() == b\"\\x1b[31mx\\x1b[39m\"\n\n\ndef test_echo_custom_file():\n    f = StringIO()\n    click.echo(\"hello\", file=f)\n    assert f.getvalue() == \"hello\\n\"\n\n\ndef test_echo_no_streams(monkeypatch, runner):\n    \"\"\"echo should not fail when stdout and stderr are None with pythonw on Windows.\"\"\"\n    with runner.isolation():\n        sys.stdout = None\n        sys.stderr = None\n        click.echo(\"test\")\n        click.echo(\"test\", err=True)\n\n\n@pytest.mark.parametrize(\n    (\"styles\", \"ref\"),\n    [\n        ({\"fg\": \"black\"}, \"\\x1b[30mx y\\x1b[0m\"),\n        ({\"fg\": \"red\"}, \"\\x1b[31mx y\\x1b[0m\"),\n        ({\"fg\": \"green\"}, \"\\x1b[32mx y\\x1b[0m\"),\n        ({\"fg\": \"yellow\"}, \"\\x1b[33mx y\\x1b[0m\"),\n        ({\"fg\": \"blue\"}, \"\\x1b[34mx y\\x1b[0m\"),\n        ({\"fg\": \"magenta\"}, \"\\x1b[35mx y\\x1b[0m\"),\n        ({\"fg\": \"cyan\"}, \"\\x1b[36mx y\\x1b[0m\"),\n        ({\"fg\": \"white\"}, \"\\x1b[37mx y\\x1b[0m\"),\n        ({\"bg\": \"black\"}, \"\\x1b[40mx y\\x1b[0m\"),\n        ({\"bg\": \"red\"}, \"\\x1b[41mx y\\x1b[0m\"),\n        ({\"bg\": \"green\"}, \"\\x1b[42mx y\\x1b[0m\"),\n        ({\"bg\": \"yellow\"}, \"\\x1b[43mx y\\x1b[0m\"),\n        ({\"bg\": \"blue\"}, \"\\x1b[44mx y\\x1b[0m\"),\n        ({\"bg\": \"magenta\"}, \"\\x1b[45mx y\\x1b[0m\"),\n        ({\"bg\": \"cyan\"}, \"\\x1b[46mx y\\x1b[0m\"),\n        ({\"bg\": \"white\"}, \"\\x1b[47mx y\\x1b[0m\"),\n        ({\"bg\": 91}, \"\\x1b[48;5;91mx y\\x1b[0m\"),\n        ({\"bg\": (135, 0, 175)}, \"\\x1b[48;2;135;0;175mx y\\x1b[0m\"),\n        ({\"bold\": True}, \"\\x1b[1mx y\\x1b[0m\"),\n        ({\"dim\": True}, \"\\x1b[2mx y\\x1b[0m\"),\n        ({\"underline\": True}, \"\\x1b[4mx y\\x1b[0m\"),\n        ({\"overline\": True}, \"\\x1b[53mx y\\x1b[0m\"),\n        ({\"italic\": True}, \"\\x1b[3mx y\\x1b[0m\"),\n        ({\"blink\": True}, \"\\x1b[5mx y\\x1b[0m\"),\n        ({\"reverse\": True}, \"\\x1b[7mx y\\x1b[0m\"),\n        ({\"strikethrough\": True}, \"\\x1b[9mx y\\x1b[0m\"),\n        ({\"bold\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"dim\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"underline\": False}, \"\\x1b[24mx y\\x1b[0m\"),\n        ({\"overline\": False}, \"\\x1b[55mx y\\x1b[0m\"),\n        ({\"italic\": False}, \"\\x1b[23mx y\\x1b[0m\"),\n        ({\"blink\": False}, \"\\x1b[25mx y\\x1b[0m\"),\n        ({\"reverse\": False}, \"\\x1b[27mx y\\x1b[0m\"),\n        ({\"strikethrough\": False}, \"\\x1b[29mx y\\x1b[0m\"),\n        ({\"fg\": \"black\", \"reset\": False}, \"\\x1b[30mx y\"),\n    ],\n)\ndef test_styling(styles, ref):\n    assert click.style(\"x y\", **styles) == ref\n    assert click.unstyle(ref) == \"x y\"\n\n\n@pytest.mark.parametrize((\"text\", \"expect\"), [(\"\\x1b[?25lx y\\x1b[?25h\", \"x y\")])\ndef test_unstyle_other_ansi(text, expect):\n    assert click.unstyle(text) == expect\n\n\ndef test_filename_formatting():\n    assert click.format_filename(b\"foo.txt\") == \"foo.txt\"\n    assert click.format_filename(b\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\", shorten=True) == \"foo.txt\"\n    assert click.format_filename(\"/x/\\ufffd.txt\", shorten=True) == \"\ufffd.txt\"\n\n\ndef test_prompts(runner):\n    @click.command()\n    def test():\n        if click.confirm(\"Foo\"):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: y\\nyes!\\n\"\n\n    result = runner.invoke(test, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: \\nno :(\\n\"\n\n    result = runner.invoke(test, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: n\\nno :(\\n\"\n\n    @click.command()\n    def test_no():\n        if click.confirm(\"Foo\", default=True):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test_no, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: y\\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: \\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: n\\nno :(\\n\"\n\n\ndef test_confirm_repeat(runner):\n    cli = click.Command(\n        \"cli\", params=[click.Option([\"--a/--no-a\"], default=None, prompt=True)]\n    )\n    result = runner.invoke(cli, input=\"\\ny\\n\")\n    assert result.output == \"A [y/n]: \\nError: invalid input\\nA [y/n]: y\\n\"\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\ndef test_prompts_abort(monkeypatch, capsys):\n    def f(_):\n        raise KeyboardInterrupt()\n\n    monkeypatch.setattr(\"click.termui.hidden_prompt_func\", f)\n\n    try:\n        click.prompt(\"Password\", hide_input=True)\n    except click.Abort:\n        click.echo(\"interrupted\")\n\n    out, err = capsys.readouterr()\n    assert out == \"Password:\\ninterrupted\\n\"\n\n\ndef test_prompts_eof(runner):\n    \"\"\"If too few lines of input are given, prompt should exit, not hang.\"\"\"\n\n    @click.command\n    def echo():\n        for _ in range(3):\n            click.echo(click.prompt(\"\", type=int))\n\n    # only provide two lines of input for three prompts\n    result = runner.invoke(echo, input=\"1\\n2\\n\")\n    assert result.exit_code == 1\n\n\ndef _test_gen_func():\n    yield \"a\"\n    yield \"b\"\n    yield \"c\"\n    yield \"abc\"\n\n\ndef _test_gen_func_fails():\n    yield \"test\"\n    raise RuntimeError(\"This is a test.\")\n\n\ndef _test_gen_func_echo(file=None):\n    yield \"test\"\n    click.echo(\"hello\", file=file)\n    yield \"test\"\n\n\ndef _test_simulate_keyboard_interrupt(file=None):\n    yield \"output_before_keyboard_interrupt\"\n    raise KeyboardInterrupt()\n\n\nEchoViaPagerTest = namedtuple(\n    \"EchoViaPagerTest\",\n    (\n        \"description\",\n        \"test_input\",\n        \"expected_pager\",\n        \"expected_stdout\",\n        \"expected_stderr\",\n        \"expected_error\",\n    ),\n)\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\n@pytest.mark.parametrize(\n    \"pager_cmd\", [\"cat\", \"cat \", \" cat \", \"less\", \" less\", \" less \"]\n)\n@pytest.mark.parametrize(\n    \"test\",\n    [\n        # We need to pass a parameter function instead of a plain param\n        # as pytest.mark.parametrize will reuse the parameters causing the\n        # generators to be used up so they will not yield anymore\n        EchoViaPagerTest(\n            description=\"Plain string argument\",\n            test_input=lambda: \"just text\",\n            expected_pager=\"just text\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Iterable argument\",\n            test_input=lambda: [\"itera\", \"ble\"],\n            expected_pager=\"iterable\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Generator function argument\",\n            test_input=lambda: _test_gen_func,\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"String generator argument\",\n            test_input=lambda: _test_gen_func(),\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Number generator expression argument\",\n            test_input=lambda: (c for c in range(6)),\n            expected_pager=\"012345\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator function argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have\n            # a chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have a\n            # chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Keyboard interrupt should not terminate the pager\",\n            test_input=lambda: _test_simulate_keyboard_interrupt(),\n            # Due to the keyboard interrupt during pager execution, click program\n            # should abort, but the pager should stay open.\n            # This allows users to cancel the program and search in the pager\n            # output, before they decide to terminate the pager.\n            expected_pager=\"output_before_keyboard_interrupt\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=KeyboardInterrupt,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stdout during generator execution\",\n            test_input=lambda: _test_gen_func_echo(),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"hello\\n\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stderr during generator execution\",\n            test_input=lambda: _test_gen_func_echo(file=sys.stderr),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"hello\\n\",\n            expected_error=None,\n        ),\n    ],\n)\ndef test_echo_via_pager(monkeypatch, capfd, pager_cmd, test):\n    monkeypatch.setitem(os.environ, \"PAGER\", pager_cmd)\n    monkeypatch.setattr(click._termui_impl, \"isatty\", lambda x: True)\n\n    test_input = test.test_input()\n    expected_pager = test.expected_pager\n    expected_stdout = test.expected_stdout\n    expected_stderr = test.expected_stderr\n    expected_error = test.expected_error\n\n    check_raise = pytest.raises(expected_error) if expected_error else nullcontext()\n\n    pager_out_tmp = Path(tempdir) / \"pager_out.txt\"\n    pager_out_tmp.unlink(missing_ok=True)\n    with pager_out_tmp.open(\"w\") as f:\n        force_subprocess_stdout = patch.object(\n            subprocess,\n            \"Popen\",\n            partial(subprocess.Popen, stdout=f),\n        )\n        with force_subprocess_stdout:\n            with check_raise:\n                click.echo_via_pager(test_input)\n\n    out, err = capfd.readouterr()\n\n    pager = pager_out_tmp.read_text()\n\n    assert pager == expected_pager, (\n        f\"Unexpected pager output in test case '{test.description}'\"\n    )\n    assert out == expected_stdout, (\n        f\"Unexpected stdout in test case '{test.description}'\"\n    )\n    assert err == expected_stderr, (\n        f\"Unexpected stderr in test case '{test.description}'\"\n    )\n\n\ndef test_echo_color_flag(monkeypatch, capfd):\n    isatty = True\n    monkeypatch.setattr(click._compat, \"isatty\", lambda x: isatty)\n\n    text = \"foo\"\n    styled_text = click.style(text, fg=\"red\")\n    assert styled_text == \"\\x1b[31mfoo\\x1b[0m\"\n\n    click.echo(styled_text, color=False)\n    out, err = capfd.readouterr()\n    assert out == f\"{text}\\n\"\n\n    click.echo(styled_text, color=True)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = True\n    click.echo(styled_text)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = False\n    # Faking isatty() is not enough on Windows;\n    # the implementation caches the colorama wrapped stream\n    # so we have to use a new stream for each test\n    stream = StringIO()\n    click.echo(styled_text, file=stream)\n    assert stream.getvalue() == f\"{text}\\n\"\n\n    stream = StringIO()\n    click.echo(styled_text, file=stream, color=True)\n    assert stream.getvalue() == f\"{styled_text}\\n\"\n\n\ndef test_prompt_cast_default(capfd, monkeypatch):\n    monkeypatch.setattr(sys, \"stdin\", StringIO(\"\\n\"))\n    value = click.prompt(\"value\", default=\"100\", type=int)\n    capfd.readouterr()\n    assert isinstance(value, int)\n\n\n@pytest.mark.skipif(WIN, reason=\"Test too complex to make work windows.\")\ndef test_echo_writing_to_standard_error(capfd, monkeypatch):\n    def emulate_input(text):\n        \"\"\"Emulate keyboard input.\"\"\"\n        monkeypatch.setattr(sys, \"stdin\", StringIO(text))\n\n    click.echo(\"Echo to standard output\")\n    out, err = capfd.readouterr()\n    assert out == \"Echo to standard output\\n\"\n    assert err == \"\"\n\n    click.echo(\"Echo to standard error\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Echo to standard error\\n\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin: \"\n    assert err == \"\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr:\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin [y/N]: \"\n    assert err == \"\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr [y/N]:\"\n\n    monkeypatch.setattr(click.termui, \"isatty\", lambda x: True)\n    monkeypatch.setattr(click.termui, \"getchar\", lambda: \" \")\n\n    click.pause(\"Pause to stdout\")\n    out, err = capfd.readouterr()\n    assert out == \"Pause to stdout\\n\"\n    assert err == \"\"\n\n    click.pause(\"Pause to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Pause to stderr\\n\"\n\n\ndef test_echo_with_capsys(capsys):\n    click.echo(\"Capture me.\")\n    out, err = capsys.readouterr()\n    assert out == \"Capture me.\\n\"\n\n\ndef test_open_file(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        click.echo(\"meep\")\n\n    with runner.isolated_filesystem():\n        with open(\"hello.txt\", \"w\") as f:\n            f.write(\"Cool stuff\")\n\n        result = runner.invoke(cli, [\"hello.txt\"])\n        assert result.exception is None\n        assert result.output == \"Cool stuff\\nmeep\\n\"\n\n        result = runner.invoke(cli, [\"-\"], input=\"foobar\")\n        assert result.exception is None\n        assert result.output == \"foobar\\nmeep\\n\"\n\n\ndef test_open_file_pathlib_dash(runner):\n    @click.command()\n    @click.argument(\n        \"filename\", type=click.Path(allow_dash=True, path_type=pathlib.Path)\n    )\n    def cli(filename):\n        click.echo(str(type(filename)))\n\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        result = runner.invoke(cli, [\"-\"], input=\"value\")\n        assert result.exception is None\n        assert result.output == \"pathlib.Path\\nvalue\\n\"\n\n\ndef test_open_file_ignore_errors_stdin(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename, errors=\"ignore\") as f:\n            click.echo(f.read())\n\n    result = runner.invoke(cli, [\"-\"], input=os.urandom(16))\n    assert result.exception is None\n\n\ndef test_open_file_respects_ignore(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"w\") as f:\n            f.write(\"Hello world!\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            assert f.errors == \"ignore\"\n\n\ndef test_open_file_ignore_invalid_utf8(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"wb\") as f:\n            f.write(b\"\\xe2\\x28\\xa1\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            f.read()\n\n\ndef test_open_file_ignore_no_encoding(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.bin\", \"wb\") as f:\n            f.write(os.urandom(16))\n\n        with click.open_file(\"test.bin\", errors=\"ignore\") as f:\n            f.read()\n\n\n@pytest.mark.skipif(WIN, reason=\"os.chmod() is not fully supported on Windows.\")\n@pytest.mark.parametrize(\"permissions\", [0o400, 0o444, 0o600, 0o644])\ndef test_open_file_atomic_permissions_existing_file(runner, permissions):\n    with runner.isolated_filesystem():\n        with open(\"existing.txt\", \"w\") as f:\n            f.write(\"content\")\n        os.chmod(\"existing.txt\", permissions)\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        result = runner.invoke(cli, [\"existing.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"existing.txt\").st_mode) == permissions\n\n\n@pytest.mark.skipif(WIN, reason=\"os.stat() is not fully supported on Windows.\")\ndef test_open_file_atomic_permissions_new_file(runner):\n    with runner.isolated_filesystem():\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        # Create a test file to get the expected permissions for new files\n        # according to the current umask.\n        with open(\"test.txt\", \"w\"):\n            pass\n        permissions = stat.S_IMODE(os.stat(\"test.txt\").st_mode)\n\n        result = runner.invoke(cli, [\"new.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"new.txt\").st_mode) == permissions\n\n\ndef test_iter_keepopenfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        for e_line, a_line in zip(expected, click.utils.KeepOpenFile(f), strict=False):\n            assert e_line == a_line.strip()\n\n\ndef test_iter_lazyfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        with click.utils.LazyFile(f.name) as lf:\n            for e_line, a_line in zip(expected, lf, strict=False):\n                assert e_line == a_line.strip()\n\n\nclass MockMain:\n    __slots__ = \"__package__\"\n\n    def __init__(self, package_name):\n        self.__package__ = package_name\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"main\", \"expected\"),\n    [\n        (\"example.py\", None, \"example.py\"),\n        (str(pathlib.Path(\"/foo/bar/example.py\")), None, \"example.py\"),\n        (\"example\", None, \"example\"),\n        (str(pathlib.Path(\"example/__main__.py\")), \"example\", \"python -m example\"),\n        (str(pathlib.Path(\"example/cli.py\")), \"example\", \"python -m example.cli\"),\n        (str(pathlib.Path(\"./example\")), \"\", \"example\"),\n    ],\n)\ndef test_detect_program_name(path, main, expected):\n    assert click.utils._detect_program_name(path, _main=MockMain(main)) == expected\n\n\ndef test_expand_args(monkeypatch):\n    user = os.path.expanduser(\"~\")\n    assert user in click.utils._expand_args([\"~\"])\n    monkeypatch.setenv(\"CLICK_TEST\", \"hello\")\n    assert \"hello\" in click.utils._expand_args([\"$CLICK_TEST\"])\n    assert \"pyproject.toml\" in click.utils._expand_args([\"*.toml\"])\n    assert os.path.join(\"docs\", \"conf.py\") in click.utils._expand_args([\"**/conf.py\"])\n    assert \"*.not-found\" in click.utils._expand_args([\"*.not-found\"])\n    # a bad glob pattern, such as a pytest identifier, should return itself\n    assert click.utils._expand_args([\"test.py::test_bad\"])[0] == \"test.py::test_bad\"\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"max_length\", \"expect\"),\n    [\n        pytest.param(\"\", 10, \"\", id=\"empty\"),\n        pytest.param(\"123 567 90\", 10, \"123 567 90\", id=\"equal length, no dot\"),\n        pytest.param(\"123 567 9. aaaa bbb\", 10, \"123 567 9.\", id=\"sentence < max\"),\n        pytest.param(\"123 567\\n\\n 9. aaaa bbb\", 10, \"123 567\", id=\"paragraph < max\"),\n        pytest.param(\"123 567 90123.\", 10, \"123 567...\", id=\"truncate\"),\n        pytest.param(\"123 5678 xxxxxx\", 10, \"123...\", id=\"length includes suffix\"),\n        pytest.param(\n            \"token in ~/.netrc ciao ciao\",\n            20,\n            \"token in ~/.netrc...\",\n            id=\"ignore dot in word\",\n        ),\n    ],\n)\n@pytest.mark.parametrize(\n    \"alter\",\n    [\n        pytest.param(None, id=\"\"),\n        pytest.param(\n            lambda text: \"\\n\\b\\n\" + \"  \".join(text.split(\" \")) + \"\\n\", id=\"no-wrap mark\"\n        ),\n    ],\n)\ndef test_make_default_short_help(value, max_length, alter, expect):\n    assert len(expect) <= max_length\n\n    if alter:\n        value = alter(value)\n\n    out = click.utils.make_default_short_help(value, max_length)\n    assert out == expect\n",
      "code_after": "import os\nimport pathlib\nimport stat\nimport subprocess\nimport sys\nfrom collections import namedtuple\nfrom contextlib import nullcontext\nfrom functools import partial\nfrom io import StringIO\nfrom pathlib import Path\nfrom tempfile import tempdir\nfrom unittest.mock import patch\n\nimport pytest\n\nimport click._termui_impl\nimport click.utils\nfrom click._compat import WIN\n\n\ndef test_echo(runner):\n    with runner.isolation() as outstreams:\n        click.echo(\"\\N{SNOWMAN}\")\n        click.echo(b\"\\x44\\x44\")\n        click.echo(42, nl=False)\n        click.echo(b\"a\", nl=False)\n        click.echo(\"\\x1b[31mx\\x1b[39m\", nl=False)\n        bytes = outstreams[0].getvalue().replace(b\"\\r\\n\", b\"\\n\")\n        assert bytes == b\"\\xe2\\x98\\x83\\nDD\\n42ax\"\n\n    # if wrapped, we expect bytes to survive.\n    @click.command()\n    def cli():\n        click.echo(b\"\\xf6\")\n\n    result = runner.invoke(cli, [])\n    assert result.stdout_bytes == b\"\\xf6\\n\"\n\n    # Ensure we do not strip for bytes.\n    with runner.isolation() as outstreams:\n        click.echo(bytearray(b\"\\x1b[31mx\\x1b[39m\"), nl=False)\n        assert outstreams[0].getvalue() == b\"\\x1b[31mx\\x1b[39m\"\n\n\ndef test_echo_custom_file():\n    f = StringIO()\n    click.echo(\"hello\", file=f)\n    assert f.getvalue() == \"hello\\n\"\n\n\ndef test_echo_no_streams(monkeypatch, runner):\n    \"\"\"echo should not fail when stdout and stderr are None with pythonw on Windows.\"\"\"\n    with runner.isolation():\n        sys.stdout = None\n        sys.stderr = None\n        click.echo(\"test\")\n        click.echo(\"test\", err=True)\n\n\n@pytest.mark.parametrize(\n    (\"styles\", \"ref\"),\n    [\n        ({\"fg\": \"black\"}, \"\\x1b[30mx y\\x1b[0m\"),\n        ({\"fg\": \"red\"}, \"\\x1b[31mx y\\x1b[0m\"),\n        ({\"fg\": \"green\"}, \"\\x1b[32mx y\\x1b[0m\"),\n        ({\"fg\": \"yellow\"}, \"\\x1b[33mx y\\x1b[0m\"),\n        ({\"fg\": \"blue\"}, \"\\x1b[34mx y\\x1b[0m\"),\n        ({\"fg\": \"magenta\"}, \"\\x1b[35mx y\\x1b[0m\"),\n        ({\"fg\": \"cyan\"}, \"\\x1b[36mx y\\x1b[0m\"),\n        ({\"fg\": \"white\"}, \"\\x1b[37mx y\\x1b[0m\"),\n        ({\"bg\": \"black\"}, \"\\x1b[40mx y\\x1b[0m\"),\n        ({\"bg\": \"red\"}, \"\\x1b[41mx y\\x1b[0m\"),\n        ({\"bg\": \"green\"}, \"\\x1b[42mx y\\x1b[0m\"),\n        ({\"bg\": \"yellow\"}, \"\\x1b[43mx y\\x1b[0m\"),\n        ({\"bg\": \"blue\"}, \"\\x1b[44mx y\\x1b[0m\"),\n        ({\"bg\": \"magenta\"}, \"\\x1b[45mx y\\x1b[0m\"),\n        ({\"bg\": \"cyan\"}, \"\\x1b[46mx y\\x1b[0m\"),\n        ({\"bg\": \"white\"}, \"\\x1b[47mx y\\x1b[0m\"),\n        ({\"bg\": 91}, \"\\x1b[48;5;91mx y\\x1b[0m\"),\n        ({\"bg\": (135, 0, 175)}, \"\\x1b[48;2;135;0;175mx y\\x1b[0m\"),\n        ({\"bold\": True}, \"\\x1b[1mx y\\x1b[0m\"),\n        ({\"dim\": True}, \"\\x1b[2mx y\\x1b[0m\"),\n        ({\"underline\": True}, \"\\x1b[4mx y\\x1b[0m\"),\n        ({\"overline\": True}, \"\\x1b[53mx y\\x1b[0m\"),\n        ({\"italic\": True}, \"\\x1b[3mx y\\x1b[0m\"),\n        ({\"blink\": True}, \"\\x1b[5mx y\\x1b[0m\"),\n        ({\"reverse\": True}, \"\\x1b[7mx y\\x1b[0m\"),\n        ({\"strikethrough\": True}, \"\\x1b[9mx y\\x1b[0m\"),\n        ({\"bold\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"dim\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"underline\": False}, \"\\x1b[24mx y\\x1b[0m\"),\n        ({\"overline\": False}, \"\\x1b[55mx y\\x1b[0m\"),\n        ({\"italic\": False}, \"\\x1b[23mx y\\x1b[0m\"),\n        ({\"blink\": False}, \"\\x1b[25mx y\\x1b[0m\"),\n        ({\"reverse\": False}, \"\\x1b[27mx y\\x1b[0m\"),\n        ({\"strikethrough\": False}, \"\\x1b[29mx y\\x1b[0m\"),\n        ({\"fg\": \"black\", \"reset\": False}, \"\\x1b[30mx y\"),\n    ],\n)\ndef test_styling(styles, ref):\n    assert click.style(\"x y\", **styles) == ref\n    assert click.unstyle(ref) == \"x y\"\n\n\n@pytest.mark.parametrize((\"text\", \"expect\"), [(\"\\x1b[?25lx y\\x1b[?25h\", \"x y\")])\ndef test_unstyle_other_ansi(text, expect):\n    assert click.unstyle(text) == expect\n\n\ndef test_filename_formatting():\n    assert click.format_filename(b\"foo.txt\") == \"foo.txt\"\n    assert click.format_filename(b\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\", shorten=True) == \"foo.txt\"\n    assert click.format_filename(\"/x/\\ufffd.txt\", shorten=True) == \"\ufffd.txt\"\n\n\ndef test_prompts(runner):\n    @click.command()\n    def test():\n        if click.confirm(\"Foo\"):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: y\\nyes!\\n\"\n\n    result = runner.invoke(test, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: \\nno :(\\n\"\n\n    result = runner.invoke(test, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: n\\nno :(\\n\"\n\n    @click.command()\n    def test_no():\n        if click.confirm(\"Foo\", default=True):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test_no, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: y\\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: \\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: n\\nno :(\\n\"\n\n\ndef test_confirm_repeat(runner):\n    cli = click.Command(\n        \"cli\", params=[click.Option([\"--a/--no-a\"], default=None, prompt=True)]\n    )\n    result = runner.invoke(cli, input=\"\\ny\\n\")\n    assert result.output == \"A [y/n]: \\nError: invalid input\\nA [y/n]: y\\n\"\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\ndef test_prompts_abort(monkeypatch, capsys):\n    def f(_):\n        raise KeyboardInterrupt()\n\n    monkeypatch.setattr(\"click.termui.hidden_prompt_func\", f)\n\n    try:\n        click.prompt(\"Password\", hide_input=True)\n    except click.Abort:\n        click.echo(\"interrupted\")\n\n    out, err = capsys.readouterr()\n    assert out == \"Password:\\ninterrupted\\n\"\n\n\ndef test_prompts_eof(runner):\n    \"\"\"If too few lines of input are given, prompt should exit, not hang.\"\"\"\n\n    @click.command\n    def echo():\n        for _ in range(3):\n            click.echo(click.prompt(\"\", type=int))\n\n    # only provide two lines of input for three prompts\n    result = runner.invoke(echo, input=\"1\\n2\\n\")\n    assert result.exit_code == 1\n\n\ndef _test_gen_func():\n    yield \"a\"\n    yield \"b\"\n    yield \"c\"\n    yield \"abc\"\n\n\ndef _test_gen_func_fails():\n    yield \"test\"\n    raise RuntimeError(\"This is a test.\")\n\n\ndef _test_gen_func_echo(file=None):\n    yield \"test\"\n    click.echo(\"hello\", file=file)\n    yield \"test\"\n\n\ndef _test_simulate_keyboard_interrupt(file=None):\n    yield \"output_before_keyboard_interrupt\"\n    raise KeyboardInterrupt()\n\n\nEchoViaPagerTest = namedtuple(\n    \"EchoViaPagerTest\",\n    (\n        \"description\",\n        \"test_input\",\n        \"expected_pager\",\n        \"expected_stdout\",\n        \"expected_stderr\",\n        \"expected_error\",\n    ),\n)\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\n@pytest.mark.parametrize(\n    \"pager_cmd\", [\"cat\", \"cat \", \" cat \", \"less\", \" less\", \" less \"]\n)\n@pytest.mark.parametrize(\n    \"test\",\n    [\n        # We need to pass a parameter function instead of a plain param\n        # as pytest.mark.parametrize will reuse the parameters causing the\n        # generators to be used up so they will not yield anymore\n        EchoViaPagerTest(\n            description=\"Plain string argument\",\n            test_input=lambda: \"just text\",\n            expected_pager=\"just text\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Iterable argument\",\n            test_input=lambda: [\"itera\", \"ble\"],\n            expected_pager=\"iterable\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Generator function argument\",\n            test_input=lambda: _test_gen_func,\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"String generator argument\",\n            test_input=lambda: _test_gen_func(),\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Number generator expression argument\",\n            test_input=lambda: (c for c in range(6)),\n            expected_pager=\"012345\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator function argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have\n            # a chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have a\n            # chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Keyboard interrupt should not terminate the pager\",\n            test_input=lambda: _test_simulate_keyboard_interrupt(),\n            # Due to the keyboard interrupt during pager execution, click program\n            # should abort, but the pager should stay open.\n            # This allows users to cancel the program and search in the pager\n            # output, before they decide to terminate the pager.\n            expected_pager=\"output_before_keyboard_interrupt\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=KeyboardInterrupt,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stdout during generator execution\",\n            test_input=lambda: _test_gen_func_echo(),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"hello\\n\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stderr during generator execution\",\n            test_input=lambda: _test_gen_func_echo(file=sys.stderr),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"hello\\n\",\n            expected_error=None,\n        ),\n    ],\n)\ndef test_echo_via_pager(monkeypatch, capfd, pager_cmd, test):\n    monkeypatch.setitem(os.environ, \"PAGER\", pager_cmd)\n    monkeypatch.setattr(click._termui_impl, \"isatty\", lambda x: True)\n\n    test_input = test.test_input()\n    expected_pager = test.expected_pager\n    expected_stdout = test.expected_stdout\n    expected_stderr = test.expected_stderr\n    expected_error = test.expected_error\n\n    check_raise = pytest.raises(expected_error) if expected_error else nullcontext()\n\n    pager_out_tmp = Path(tempdir) / \"pager_out.txt\"\n    pager_out_tmp.unlink(missing_ok=True)\n    with pager_out_tmp.open(\"w\") as f:\n        force_subprocess_stdout = patch.object(\n            subprocess,\n            \"Popen\",\n            partial(subprocess.Popen, stdout=f),\n        )\n        with force_subprocess_stdout:\n            with check_raise:\n                click.echo_via_pager(test_input)\n\n    out, err = capfd.readouterr()\n\n    pager = pager_out_tmp.read_text()\n\n    assert pager == expected_pager, (\n        f\"Unexpected pager output in test case '{test.description}'\"\n    )\n    assert out == expected_stdout, (\n        f\"Unexpected stdout in test case '{test.description}'\"\n    )\n    assert err == expected_stderr, (\n        f\"Unexpected stderr in test case '{test.description}'\"\n    )\n\n\ndef test_echo_color_flag(monkeypatch, capfd):\n    isatty = True\n    monkeypatch.setattr(click._compat, \"isatty\", lambda x: isatty)\n\n    text = \"foo\"\n    styled_text = click.style(text, fg=\"red\")\n    assert styled_text == \"\\x1b[31mfoo\\x1b[0m\"\n\n    click.echo(styled_text, color=False)\n    out, err = capfd.readouterr()\n    assert out == f\"{text}\\n\"\n\n    click.echo(styled_text, color=True)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = True\n    click.echo(styled_text)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = False\n    # Faking isatty() is not enough on Windows;\n    # the implementation caches the colorama wrapped stream\n    # so we have to use a new stream for each test\n    stream = StringIO()\n    click.echo(styled_text, file=stream)\n    assert stream.getvalue() == f\"{text}\\n\"\n\n    stream = StringIO()\n    click.echo(styled_text, file=stream, color=True)\n    assert stream.getvalue() == f\"{styled_text}\\n\"\n\n\ndef test_prompt_cast_default(capfd, monkeypatch):\n    monkeypatch.setattr(sys, \"stdin\", StringIO(\"\\n\"))\n    value = click.prompt(\"value\", default=\"100\", type=int)\n    capfd.readouterr()\n    assert isinstance(value, int)\n\n\n@pytest.mark.skipif(WIN, reason=\"Test too complex to make work windows.\")\ndef test_echo_writing_to_standard_error(capfd, monkeypatch):\n    def emulate_input(text):\n        \"\"\"Emulate keyboard input.\"\"\"\n        monkeypatch.setattr(sys, \"stdin\", StringIO(text))\n\n    click.echo(\"Echo to standard output\")\n    out, err = capfd.readouterr()\n    assert out == \"Echo to standard output\\n\"\n    assert err == \"\"\n\n    click.echo(\"Echo to standard error\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Echo to standard error\\n\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin: \"\n    assert err == \"\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stdin with no suffix\", prompt_suffix=\"\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin with no suffix\"\n    assert err == \"\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr:\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stderr with no suffix\", prompt_suffix=\"\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"x\"\n    assert err == \"Prompt to stderr with no suffi\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin [y/N]: \"\n    assert err == \"\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stdin with no suffix\", prompt_suffix=\"\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin with no suffix [y/N]\"\n    assert err == \"\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr [y/N]:\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stderr with no suffix\", prompt_suffix=\"\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"]\"\n    assert err == \"Prompt to stderr with no suffix [y/N\"\n\n    monkeypatch.setattr(click.termui, \"isatty\", lambda x: True)\n    monkeypatch.setattr(click.termui, \"getchar\", lambda: \" \")\n\n    click.pause(\"Pause to stdout\")\n    out, err = capfd.readouterr()\n    assert out == \"Pause to stdout\\n\"\n    assert err == \"\"\n\n    click.pause(\"Pause to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Pause to stderr\\n\"\n\n\ndef test_echo_with_capsys(capsys):\n    click.echo(\"Capture me.\")\n    out, err = capsys.readouterr()\n    assert out == \"Capture me.\\n\"\n\n\ndef test_open_file(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        click.echo(\"meep\")\n\n    with runner.isolated_filesystem():\n        with open(\"hello.txt\", \"w\") as f:\n            f.write(\"Cool stuff\")\n\n        result = runner.invoke(cli, [\"hello.txt\"])\n        assert result.exception is None\n        assert result.output == \"Cool stuff\\nmeep\\n\"\n\n        result = runner.invoke(cli, [\"-\"], input=\"foobar\")\n        assert result.exception is None\n        assert result.output == \"foobar\\nmeep\\n\"\n\n\ndef test_open_file_pathlib_dash(runner):\n    @click.command()\n    @click.argument(\n        \"filename\", type=click.Path(allow_dash=True, path_type=pathlib.Path)\n    )\n    def cli(filename):\n        click.echo(str(type(filename)))\n\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        result = runner.invoke(cli, [\"-\"], input=\"value\")\n        assert result.exception is None\n        assert result.output == \"pathlib.Path\\nvalue\\n\"\n\n\ndef test_open_file_ignore_errors_stdin(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename, errors=\"ignore\") as f:\n            click.echo(f.read())\n\n    result = runner.invoke(cli, [\"-\"], input=os.urandom(16))\n    assert result.exception is None\n\n\ndef test_open_file_respects_ignore(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"w\") as f:\n            f.write(\"Hello world!\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            assert f.errors == \"ignore\"\n\n\ndef test_open_file_ignore_invalid_utf8(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"wb\") as f:\n            f.write(b\"\\xe2\\x28\\xa1\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            f.read()\n\n\ndef test_open_file_ignore_no_encoding(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.bin\", \"wb\") as f:\n            f.write(os.urandom(16))\n\n        with click.open_file(\"test.bin\", errors=\"ignore\") as f:\n            f.read()\n\n\n@pytest.mark.skipif(WIN, reason=\"os.chmod() is not fully supported on Windows.\")\n@pytest.mark.parametrize(\"permissions\", [0o400, 0o444, 0o600, 0o644])\ndef test_open_file_atomic_permissions_existing_file(runner, permissions):\n    with runner.isolated_filesystem():\n        with open(\"existing.txt\", \"w\") as f:\n            f.write(\"content\")\n        os.chmod(\"existing.txt\", permissions)\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        result = runner.invoke(cli, [\"existing.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"existing.txt\").st_mode) == permissions\n\n\n@pytest.mark.skipif(WIN, reason=\"os.stat() is not fully supported on Windows.\")\ndef test_open_file_atomic_permissions_new_file(runner):\n    with runner.isolated_filesystem():\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        # Create a test file to get the expected permissions for new files\n        # according to the current umask.\n        with open(\"test.txt\", \"w\"):\n            pass\n        permissions = stat.S_IMODE(os.stat(\"test.txt\").st_mode)\n\n        result = runner.invoke(cli, [\"new.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"new.txt\").st_mode) == permissions\n\n\ndef test_iter_keepopenfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        for e_line, a_line in zip(expected, click.utils.KeepOpenFile(f), strict=False):\n            assert e_line == a_line.strip()\n\n\ndef test_iter_lazyfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        with click.utils.LazyFile(f.name) as lf:\n            for e_line, a_line in zip(expected, lf, strict=False):\n                assert e_line == a_line.strip()\n\n\nclass MockMain:\n    __slots__ = \"__package__\"\n\n    def __init__(self, package_name):\n        self.__package__ = package_name\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"main\", \"expected\"),\n    [\n        (\"example.py\", None, \"example.py\"),\n        (str(pathlib.Path(\"/foo/bar/example.py\")), None, \"example.py\"),\n        (\"example\", None, \"example\"),\n        (str(pathlib.Path(\"example/__main__.py\")), \"example\", \"python -m example\"),\n        (str(pathlib.Path(\"example/cli.py\")), \"example\", \"python -m example.cli\"),\n        (str(pathlib.Path(\"./example\")), \"\", \"example\"),\n    ],\n)\ndef test_detect_program_name(path, main, expected):\n    assert click.utils._detect_program_name(path, _main=MockMain(main)) == expected\n\n\ndef test_expand_args(monkeypatch):\n    user = os.path.expanduser(\"~\")\n    assert user in click.utils._expand_args([\"~\"])\n    monkeypatch.setenv(\"CLICK_TEST\", \"hello\")\n    assert \"hello\" in click.utils._expand_args([\"$CLICK_TEST\"])\n    assert \"pyproject.toml\" in click.utils._expand_args([\"*.toml\"])\n    assert os.path.join(\"docs\", \"conf.py\") in click.utils._expand_args([\"**/conf.py\"])\n    assert \"*.not-found\" in click.utils._expand_args([\"*.not-found\"])\n    # a bad glob pattern, such as a pytest identifier, should return itself\n    assert click.utils._expand_args([\"test.py::test_bad\"])[0] == \"test.py::test_bad\"\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"max_length\", \"expect\"),\n    [\n        pytest.param(\"\", 10, \"\", id=\"empty\"),\n        pytest.param(\"123 567 90\", 10, \"123 567 90\", id=\"equal length, no dot\"),\n        pytest.param(\"123 567 9. aaaa bbb\", 10, \"123 567 9.\", id=\"sentence < max\"),\n        pytest.param(\"123 567\\n\\n 9. aaaa bbb\", 10, \"123 567\", id=\"paragraph < max\"),\n        pytest.param(\"123 567 90123.\", 10, \"123 567...\", id=\"truncate\"),\n        pytest.param(\"123 5678 xxxxxx\", 10, \"123...\", id=\"length includes suffix\"),\n        pytest.param(\n            \"token in ~/.netrc ciao ciao\",\n            20,\n            \"token in ~/.netrc...\",\n            id=\"ignore dot in word\",\n        ),\n    ],\n)\n@pytest.mark.parametrize(\n    \"alter\",\n    [\n        pytest.param(None, id=\"\"),\n        pytest.param(\n            lambda text: \"\\n\\b\\n\" + \"  \".join(text.split(\" \")) + \"\\n\", id=\"no-wrap mark\"\n        ),\n    ],\n)\ndef test_make_default_short_help(value, max_length, alter, expect):\n    assert len(expect) <= max_length\n\n    if alter:\n        value = alter(value)\n\n    out = click.utils.make_default_short_help(value, max_length)\n    assert out == expect\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "9a33b11bee31",
      "repo": "click",
      "commit_hash": "e37cad2",
      "commit_message": "BUG/TST: fix a race in `click.testing.StreamMixer`'s finalization, seen in a multi-threaded context",
      "file_path": "src/click/testing.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport contextlib\nimport io\nimport os\nimport shlex\nimport shutil\nimport sys\nimport tempfile\nimport typing as t\nfrom types import TracebackType\n\nfrom . import _compat\nfrom . import formatting\nfrom . import termui\nfrom . import utils\nfrom ._compat import _find_binary_reader\n\nif t.TYPE_CHECKING:\n    from _typeshed import ReadableBuffer\n\n    from .core import Command\n\n\nclass EchoingStdin:\n    def __init__(self, input: t.BinaryIO, output: t.BinaryIO) -> None:\n        self._input = input\n        self._output = output\n        self._paused = False\n\n    def __getattr__(self, x: str) -> t.Any:\n        return getattr(self._input, x)\n\n    def _echo(self, rv: bytes) -> bytes:\n        if not self._paused:\n            self._output.write(rv)\n\n        return rv\n\n    def read(self, n: int = -1) -> bytes:\n        return self._echo(self._input.read(n))\n\n    def read1(self, n: int = -1) -> bytes:\n        return self._echo(self._input.read1(n))  # type: ignore\n\n    def readline(self, n: int = -1) -> bytes:\n        return self._echo(self._input.readline(n))\n\n    def readlines(self) -> list[bytes]:\n        return [self._echo(x) for x in self._input.readlines()]\n\n    def __iter__(self) -> cabc.Iterator[bytes]:\n        return iter(self._echo(x) for x in self._input)\n\n    def __repr__(self) -> str:\n        return repr(self._input)\n\n\n@contextlib.contextmanager\ndef _pause_echo(stream: EchoingStdin | None) -> cabc.Iterator[None]:\n    if stream is None:\n        yield\n    else:\n        stream._paused = True\n        yield\n        stream._paused = False\n\n\nclass BytesIOCopy(io.BytesIO):\n    \"\"\"Patch ``io.BytesIO`` to let the written stream be copied to another.\n\n    .. versionadded:: 8.2\n    \"\"\"\n\n    def __init__(self, copy_to: io.BytesIO) -> None:\n        super().__init__()\n        self.copy_to = copy_to\n\n    def flush(self) -> None:\n        super().flush()\n        self.copy_to.flush()\n\n    def write(self, b: ReadableBuffer) -> int:\n        self.copy_to.write(b)\n        return super().write(b)\n\n\nclass StreamMixer:\n    \"\"\"Mixes `<stdout>` and `<stderr>` streams.\n\n    The result is available in the ``output`` attribute.\n\n    .. versionadded:: 8.2\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.output: io.BytesIO = io.BytesIO()\n        self.stdout: io.BytesIO = BytesIOCopy(copy_to=self.output)\n        self.stderr: io.BytesIO = BytesIOCopy(copy_to=self.output)\n\n\nclass _NamedTextIOWrapper(io.TextIOWrapper):\n    def __init__(\n        self, buffer: t.BinaryIO, name: str, mode: str, **kwargs: t.Any\n    ) -> None:\n        super().__init__(buffer, **kwargs)\n        self._name = name\n        self._mode = mode\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @property\n    def mode(self) -> str:\n        return self._mode\n\n    def __next__(self) -> str:  # type: ignore\n        try:\n            line = super().__next__()\n        except StopIteration as e:\n            raise EOFError() from e\n        return line\n\n\ndef make_input_stream(\n    input: str | bytes | t.IO[t.Any] | None, charset: str\n) -> t.BinaryIO:\n    # Is already an input stream.\n    if hasattr(input, \"read\"):\n        rv = _find_binary_reader(t.cast(\"t.IO[t.Any]\", input))\n\n        if rv is not None:\n            return rv\n\n        raise TypeError(\"Could not find binary reader for input stream.\")\n\n    if input is None:\n        input = b\"\"\n    elif isinstance(input, str):\n        input = input.encode(charset)\n\n    return io.BytesIO(input)\n\n\nclass Result:\n    \"\"\"Holds the captured result of an invoked CLI script.\n\n    :param runner: The runner that created the result\n    :param stdout_bytes: The standard output as bytes.\n    :param stderr_bytes: The standard error as bytes.\n    :param output_bytes: A mix of ``stdout_bytes`` and ``stderr_bytes``, as the\n        user would see  it in its terminal.\n    :param return_value: The value returned from the invoked command.\n    :param exit_code: The exit code as integer.\n    :param exception: The exception that happened if one did.\n    :param exc_info: Exception information (exception type, exception instance,\n        traceback type).\n\n    .. versionchanged:: 8.2\n        ``stderr_bytes`` no longer optional, ``output_bytes`` introduced and\n        ``mix_stderr`` has been removed.\n\n    .. versionadded:: 8.0\n        Added ``return_value``.\n    \"\"\"\n\n    def __init__(\n        self,\n        runner: CliRunner,\n        stdout_bytes: bytes,\n        stderr_bytes: bytes,\n        output_bytes: bytes,\n        return_value: t.Any,\n        exit_code: int,\n        exception: BaseException | None,\n        exc_info: tuple[type[BaseException], BaseException, TracebackType]\n        | None = None,\n    ):\n        self.runner = runner\n        self.stdout_bytes = stdout_bytes\n        self.stderr_bytes = stderr_bytes\n        self.output_bytes = output_bytes\n        self.return_value = return_value\n        self.exit_code = exit_code\n        self.exception = exception\n        self.exc_info = exc_info\n\n    @property\n    def output(self) -> str:\n        \"\"\"The terminal output as unicode string, as the user would see it.\n\n        .. versionchanged:: 8.2\n            No longer a proxy for ``self.stdout``. Now has its own independent stream\n            that is mixing `<stdout>` and `<stderr>`, in the order they were written.\n        \"\"\"\n        return self.output_bytes.decode(self.runner.charset, \"replace\").replace(\n            \"\\r\\n\", \"\\n\"\n        )\n\n    @property\n    def stdout(self) -> str:\n        \"\"\"The standard output as unicode string.\"\"\"\n        return self.stdout_bytes.decode(self.runner.charset, \"replace\").replace(\n            \"\\r\\n\", \"\\n\"\n        )\n\n    @property\n    def stderr(self) -> str:\n        \"\"\"The standard error as unicode string.\n\n        .. versionchanged:: 8.2\n            No longer raise an exception, always returns the `<stderr>` string.\n        \"\"\"\n        return self.stderr_bytes.decode(self.runner.charset, \"replace\").replace(\n            \"\\r\\n\", \"\\n\"\n        )\n\n    def __repr__(self) -> str:\n        exc_str = repr(self.exception) if self.exception else \"okay\"\n        return f\"<{type(self).__name__} {exc_str}>\"\n\n\nclass CliRunner:\n    \"\"\"The CLI runner provides functionality to invoke a Click command line\n    script for unittesting purposes in a isolated environment.  This only\n    works in single-threaded systems without any concurrency as it changes the\n    global interpreter state.\n\n    :param charset: the character set for the input and output data.\n    :param env: a dictionary with environment variables for overriding.\n    :param echo_stdin: if this is set to `True`, then reading from `<stdin>` writes\n                       to `<stdout>`.  This is useful for showing examples in\n                       some circumstances.  Note that regular prompts\n                       will automatically echo the input.\n    :param catch_exceptions: Whether to catch any exceptions other than\n                             ``SystemExit`` when running :meth:`~CliRunner.invoke`.\n\n    .. versionchanged:: 8.2\n        Added the ``catch_exceptions`` parameter.\n\n    .. versionchanged:: 8.2\n        ``mix_stderr`` parameter has been removed.\n    \"\"\"\n\n    def __init__(\n        self,\n        charset: str = \"utf-8\",\n        env: cabc.Mapping[str, str | None] | None = None,\n        echo_stdin: bool = False,\n        catch_exceptions: bool = True,\n    ) -> None:\n        self.charset = charset\n        self.env: cabc.Mapping[str, str | None] = env or {}\n        self.echo_stdin = echo_stdin\n        self.catch_exceptions = catch_exceptions\n\n    def get_default_prog_name(self, cli: Command) -> str:\n        \"\"\"Given a command object it will return the default program name\n        for it.  The default is the `name` attribute or ``\"root\"`` if not\n        set.\n        \"\"\"\n        return cli.name or \"root\"\n\n    def make_env(\n        self, overrides: cabc.Mapping[str, str | None] | None = None\n    ) -> cabc.Mapping[str, str | None]:\n        \"\"\"Returns the environment overrides for invoking a script.\"\"\"\n        rv = dict(self.env)\n        if overrides:\n            rv.update(overrides)\n        return rv\n\n    @contextlib.contextmanager\n    def isolation(\n        self,\n        input: str | bytes | t.IO[t.Any] | None = None,\n        env: cabc.Mapping[str, str | None] | None = None,\n        color: bool = False,\n    ) -> cabc.Iterator[tuple[io.BytesIO, io.BytesIO, io.BytesIO]]:\n        \"\"\"A context manager that sets up the isolation for invoking of a\n        command line tool.  This sets up `<stdin>` with the given input data\n        and `os.environ` with the overrides from the given dictionary.\n        This also rebinds some internals in Click to be mocked (like the\n        prompt functionality).\n\n        This is automatically done in the :meth:`invoke` method.\n\n        :param input: the input stream to put into `sys.stdin`.\n        :param env: the environment overrides as dictionary.\n        :param color: whether the output should contain color codes. The\n                      application can still override this explicitly.\n\n        .. versionadded:: 8.2\n            An additional output stream is returned, which is a mix of\n            `<stdout>` and `<stderr>` streams.\n\n        .. versionchanged:: 8.2\n            Always returns the `<stderr>` stream.\n\n        .. versionchanged:: 8.0\n            `<stderr>` is opened with ``errors=\"backslashreplace\"``\n            instead of the default ``\"strict\"``.\n\n        .. versionchanged:: 4.0\n            Added the ``color`` parameter.\n        \"\"\"\n        bytes_input = make_input_stream(input, self.charset)\n        echo_input = None\n\n        old_stdin = sys.stdin\n        old_stdout = sys.stdout\n        old_stderr = sys.stderr\n        old_forced_width = formatting.FORCED_WIDTH\n        formatting.FORCED_WIDTH = 80\n\n        env = self.make_env(env)\n\n        stream_mixer = StreamMixer()\n\n        if self.echo_stdin:\n            bytes_input = echo_input = t.cast(\n                t.BinaryIO, EchoingStdin(bytes_input, stream_mixer.stdout)\n            )\n\n        sys.stdin = text_input = _NamedTextIOWrapper(\n            bytes_input, encoding=self.charset, name=\"<stdin>\", mode=\"r\"\n        )\n\n        if self.echo_stdin:\n            # Force unbuffered reads, otherwise TextIOWrapper reads a\n            # large chunk which is echoed early.\n            text_input._CHUNK_SIZE = 1  # type: ignore\n\n        sys.stdout = _NamedTextIOWrapper(\n            stream_mixer.stdout, encoding=self.charset, name=\"<stdout>\", mode=\"w\"\n        )\n\n        sys.stderr = _NamedTextIOWrapper(\n            stream_mixer.stderr,\n            encoding=self.charset,\n            name=\"<stderr>\",\n            mode=\"w\",\n            errors=\"backslashreplace\",\n        )\n\n        @_pause_echo(echo_input)  # type: ignore\n        def visible_input(prompt: str | None = None) -> str:\n            sys.stdout.write(prompt or \"\")\n            val = next(text_input).rstrip(\"\\r\\n\")\n            sys.stdout.write(f\"{val}\\n\")\n            sys.stdout.flush()\n            return val\n\n        @_pause_echo(echo_input)  # type: ignore\n        def hidden_input(prompt: str | None = None) -> str:\n            sys.stdout.write(f\"{prompt or ''}\\n\")\n            sys.stdout.flush()\n            return next(text_input).rstrip(\"\\r\\n\")\n\n        @_pause_echo(echo_input)  # type: ignore\n        def _getchar(echo: bool) -> str:\n            char = sys.stdin.read(1)\n\n            if echo:\n                sys.stdout.write(char)\n\n            sys.stdout.flush()\n            return char\n\n        default_color = color\n\n        def should_strip_ansi(\n            stream: t.IO[t.Any] | None = None, color: bool | None = None\n        ) -> bool:\n            if color is None:\n                return not default_color\n            return not color\n\n        old_visible_prompt_func = termui.visible_prompt_func\n        old_hidden_prompt_func = termui.hidden_prompt_func\n        old__getchar_func = termui._getchar\n        old_should_strip_ansi = utils.should_strip_ansi  # type: ignore\n        old__compat_should_strip_ansi = _compat.should_strip_ansi\n        termui.visible_prompt_func = visible_input\n        termui.hidden_prompt_func = hidden_input\n        termui._getchar = _getchar\n        utils.should_strip_ansi = should_strip_ansi  # type: ignore\n        _compat.should_strip_ansi = should_strip_ansi\n\n        old_env = {}\n        try:\n            for key, value in env.items():\n                old_env[key] = os.environ.get(key)\n                if value is None:\n                    try:\n                        del os.environ[key]\n                    except Exception:\n                        pass\n                else:\n                    os.environ[key] = value\n            yield (stream_mixer.stdout, stream_mixer.stderr, stream_mixer.output)\n        finally:\n            for key, value in old_env.items():\n                if value is None:\n                    try:\n                        del os.environ[key]\n                    except Exception:\n                        pass\n                else:\n                    os.environ[key] = value\n            sys.stdout = old_stdout\n            sys.stderr = old_stderr\n            sys.stdin = old_stdin\n            termui.visible_prompt_func = old_visible_prompt_func\n            termui.hidden_prompt_func = old_hidden_prompt_func\n            termui._getchar = old__getchar_func\n            utils.should_strip_ansi = old_should_strip_ansi  # type: ignore\n            _compat.should_strip_ansi = old__compat_should_strip_ansi\n            formatting.FORCED_WIDTH = old_forced_width\n\n    def invoke(\n        self,\n        cli: Command,\n        args: str | cabc.Sequence[str] | None = None,\n        input: str | bytes | t.IO[t.Any] | None = None,\n        env: cabc.Mapping[str, str | None] | None = None,\n        catch_exceptions: bool | None = None,\n        color: bool = False,\n        **extra: t.Any,\n    ) -> Result:\n        \"\"\"Invokes a command in an isolated environment.  The arguments are\n        forwarded directly to the command line script, the `extra` keyword\n        arguments are passed to the :meth:`~clickpkg.Command.main` function of\n        the command.\n\n        This returns a :class:`Result` object.\n\n        :param cli: the command to invoke\n        :param args: the arguments to invoke. It may be given as an iterable\n                     or a string. When given as string it will be interpreted\n                     as a Unix shell command. More details at\n                     :func:`shlex.split`.\n        :param input: the input data for `sys.stdin`.\n        :param env: the environment overrides.\n        :param catch_exceptions: Whether to catch any other exceptions than\n                                 ``SystemExit``. If :data:`None`, the value\n                                 from :class:`CliRunner` is used.\n        :param extra: the keyword arguments to pass to :meth:`main`.\n        :param color: whether the output should contain color codes. The\n                      application can still override this explicitly.\n\n        .. versionadded:: 8.2\n            The result object has the ``output_bytes`` attribute with\n            the mix of ``stdout_bytes`` and ``stderr_bytes``, as the user would\n            see it in its terminal.\n\n        .. versionchanged:: 8.2\n            The result object always returns the ``stderr_bytes`` stream.\n\n        .. versionchanged:: 8.0\n            The result object has the ``return_value`` attribute with\n            the value returned from the invoked command.\n\n        .. versionchanged:: 4.0\n            Added the ``color`` parameter.\n\n        .. versionchanged:: 3.0\n            Added the ``catch_exceptions`` parameter.\n\n        .. versionchanged:: 3.0\n            The result object has the ``exc_info`` attribute with the\n            traceback if available.\n        \"\"\"\n        exc_info = None\n        if catch_exceptions is None:\n            catch_exceptions = self.catch_exceptions\n\n        with self.isolation(input=input, env=env, color=color) as outstreams:\n            return_value = None\n            exception: BaseException | None = None\n            exit_code = 0\n\n            if isinstance(args, str):\n                args = shlex.split(args)\n\n            try:\n                prog_name = extra.pop(\"prog_name\")\n            except KeyError:\n                prog_name = self.get_default_prog_name(cli)\n\n            try:\n                return_value = cli.main(args=args or (), prog_name=prog_name, **extra)\n            except SystemExit as e:\n                exc_info = sys.exc_info()\n                e_code = t.cast(\"int | t.Any | None\", e.code)\n\n                if e_code is None:\n                    e_code = 0\n\n                if e_code != 0:\n                    exception = e\n\n                if not isinstance(e_code, int):\n                    sys.stdout.write(str(e_code))\n                    sys.stdout.write(\"\\n\")\n                    e_code = 1\n\n                exit_code = e_code\n\n            except Exception as e:\n                if not catch_exceptions:\n                    raise\n                exception = e\n                exit_code = 1\n                exc_info = sys.exc_info()\n            finally:\n                sys.stdout.flush()\n                sys.stderr.flush()\n                stdout = outstreams[0].getvalue()\n                stderr = outstreams[1].getvalue()\n                output = outstreams[2].getvalue()\n\n        return Result(\n            runner=self,\n            stdout_bytes=stdout,\n            stderr_bytes=stderr,\n            output_bytes=output,\n            return_value=return_value,\n            exit_code=exit_code,\n            exception=exception,\n            exc_info=exc_info,  # type: ignore\n        )\n\n    @contextlib.contextmanager\n    def isolated_filesystem(\n        self, temp_dir: str | os.PathLike[str] | None = None\n    ) -> cabc.Iterator[str]:\n        \"\"\"A context manager that creates a temporary directory and\n        changes the current working directory to it. This isolates tests\n        that affect the contents of the CWD to prevent them from\n        interfering with each other.\n\n        :param temp_dir: Create the temporary directory under this\n            directory. If given, the created directory is not removed\n            when exiting.\n\n        .. versionchanged:: 8.0\n            Added the ``temp_dir`` parameter.\n        \"\"\"\n        cwd = os.getcwd()\n        dt = tempfile.mkdtemp(dir=temp_dir)\n        os.chdir(dt)\n\n        try:\n            yield dt\n        finally:\n            os.chdir(cwd)\n\n            if temp_dir is None:\n                try:\n                    shutil.rmtree(dt)\n                except OSError:\n                    pass\n",
      "code_after": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport contextlib\nimport io\nimport os\nimport shlex\nimport shutil\nimport sys\nimport tempfile\nimport typing as t\nfrom types import TracebackType\n\nfrom . import _compat\nfrom . import formatting\nfrom . import termui\nfrom . import utils\nfrom ._compat import _find_binary_reader\n\nif t.TYPE_CHECKING:\n    from _typeshed import ReadableBuffer\n\n    from .core import Command\n\n\nclass EchoingStdin:\n    def __init__(self, input: t.BinaryIO, output: t.BinaryIO) -> None:\n        self._input = input\n        self._output = output\n        self._paused = False\n\n    def __getattr__(self, x: str) -> t.Any:\n        return getattr(self._input, x)\n\n    def _echo(self, rv: bytes) -> bytes:\n        if not self._paused:\n            self._output.write(rv)\n\n        return rv\n\n    def read(self, n: int = -1) -> bytes:\n        return self._echo(self._input.read(n))\n\n    def read1(self, n: int = -1) -> bytes:\n        return self._echo(self._input.read1(n))  # type: ignore\n\n    def readline(self, n: int = -1) -> bytes:\n        return self._echo(self._input.readline(n))\n\n    def readlines(self) -> list[bytes]:\n        return [self._echo(x) for x in self._input.readlines()]\n\n    def __iter__(self) -> cabc.Iterator[bytes]:\n        return iter(self._echo(x) for x in self._input)\n\n    def __repr__(self) -> str:\n        return repr(self._input)\n\n\n@contextlib.contextmanager\ndef _pause_echo(stream: EchoingStdin | None) -> cabc.Iterator[None]:\n    if stream is None:\n        yield\n    else:\n        stream._paused = True\n        yield\n        stream._paused = False\n\n\nclass BytesIOCopy(io.BytesIO):\n    \"\"\"Patch ``io.BytesIO`` to let the written stream be copied to another.\n\n    .. versionadded:: 8.2\n    \"\"\"\n\n    def __init__(self, copy_to: io.BytesIO) -> None:\n        super().__init__()\n        self.copy_to = copy_to\n\n    def flush(self) -> None:\n        super().flush()\n        self.copy_to.flush()\n\n    def write(self, b: ReadableBuffer) -> int:\n        self.copy_to.write(b)\n        return super().write(b)\n\n\nclass StreamMixer:\n    \"\"\"Mixes `<stdout>` and `<stderr>` streams.\n\n    The result is available in the ``output`` attribute.\n\n    .. versionadded:: 8.2\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.output: io.BytesIO = io.BytesIO()\n        self.stdout: io.BytesIO = BytesIOCopy(copy_to=self.output)\n        self.stderr: io.BytesIO = BytesIOCopy(copy_to=self.output)\n\n    def __del__(self) -> None:\n        \"\"\"\n        Guarantee that embedded file-like objects are closed in a\n        predictable order, protecting against races between\n        self.output being closed and other streams being flushed on close\n\n        .. versionadded:: 8.2.2\n        \"\"\"\n        self.stderr.close()\n        self.stdout.close()\n        self.output.close()\n\n\nclass _NamedTextIOWrapper(io.TextIOWrapper):\n    def __init__(\n        self, buffer: t.BinaryIO, name: str, mode: str, **kwargs: t.Any\n    ) -> None:\n        super().__init__(buffer, **kwargs)\n        self._name = name\n        self._mode = mode\n\n    @property\n    def name(self) -> str:\n        return self._name\n\n    @property\n    def mode(self) -> str:\n        return self._mode\n\n    def __next__(self) -> str:  # type: ignore\n        try:\n            line = super().__next__()\n        except StopIteration as e:\n            raise EOFError() from e\n        return line\n\n\ndef make_input_stream(\n    input: str | bytes | t.IO[t.Any] | None, charset: str\n) -> t.BinaryIO:\n    # Is already an input stream.\n    if hasattr(input, \"read\"):\n        rv = _find_binary_reader(t.cast(\"t.IO[t.Any]\", input))\n\n        if rv is not None:\n            return rv\n\n        raise TypeError(\"Could not find binary reader for input stream.\")\n\n    if input is None:\n        input = b\"\"\n    elif isinstance(input, str):\n        input = input.encode(charset)\n\n    return io.BytesIO(input)\n\n\nclass Result:\n    \"\"\"Holds the captured result of an invoked CLI script.\n\n    :param runner: The runner that created the result\n    :param stdout_bytes: The standard output as bytes.\n    :param stderr_bytes: The standard error as bytes.\n    :param output_bytes: A mix of ``stdout_bytes`` and ``stderr_bytes``, as the\n        user would see  it in its terminal.\n    :param return_value: The value returned from the invoked command.\n    :param exit_code: The exit code as integer.\n    :param exception: The exception that happened if one did.\n    :param exc_info: Exception information (exception type, exception instance,\n        traceback type).\n\n    .. versionchanged:: 8.2\n        ``stderr_bytes`` no longer optional, ``output_bytes`` introduced and\n        ``mix_stderr`` has been removed.\n\n    .. versionadded:: 8.0\n        Added ``return_value``.\n    \"\"\"\n\n    def __init__(\n        self,\n        runner: CliRunner,\n        stdout_bytes: bytes,\n        stderr_bytes: bytes,\n        output_bytes: bytes,\n        return_value: t.Any,\n        exit_code: int,\n        exception: BaseException | None,\n        exc_info: tuple[type[BaseException], BaseException, TracebackType]\n        | None = None,\n    ):\n        self.runner = runner\n        self.stdout_bytes = stdout_bytes\n        self.stderr_bytes = stderr_bytes\n        self.output_bytes = output_bytes\n        self.return_value = return_value\n        self.exit_code = exit_code\n        self.exception = exception\n        self.exc_info = exc_info\n\n    @property\n    def output(self) -> str:\n        \"\"\"The terminal output as unicode string, as the user would see it.\n\n        .. versionchanged:: 8.2\n            No longer a proxy for ``self.stdout``. Now has its own independent stream\n            that is mixing `<stdout>` and `<stderr>`, in the order they were written.\n        \"\"\"\n        return self.output_bytes.decode(self.runner.charset, \"replace\").replace(\n            \"\\r\\n\", \"\\n\"\n        )\n\n    @property\n    def stdout(self) -> str:\n        \"\"\"The standard output as unicode string.\"\"\"\n        return self.stdout_bytes.decode(self.runner.charset, \"replace\").replace(\n            \"\\r\\n\", \"\\n\"\n        )\n\n    @property\n    def stderr(self) -> str:\n        \"\"\"The standard error as unicode string.\n\n        .. versionchanged:: 8.2\n            No longer raise an exception, always returns the `<stderr>` string.\n        \"\"\"\n        return self.stderr_bytes.decode(self.runner.charset, \"replace\").replace(\n            \"\\r\\n\", \"\\n\"\n        )\n\n    def __repr__(self) -> str:\n        exc_str = repr(self.exception) if self.exception else \"okay\"\n        return f\"<{type(self).__name__} {exc_str}>\"\n\n\nclass CliRunner:\n    \"\"\"The CLI runner provides functionality to invoke a Click command line\n    script for unittesting purposes in a isolated environment.  This only\n    works in single-threaded systems without any concurrency as it changes the\n    global interpreter state.\n\n    :param charset: the character set for the input and output data.\n    :param env: a dictionary with environment variables for overriding.\n    :param echo_stdin: if this is set to `True`, then reading from `<stdin>` writes\n                       to `<stdout>`.  This is useful for showing examples in\n                       some circumstances.  Note that regular prompts\n                       will automatically echo the input.\n    :param catch_exceptions: Whether to catch any exceptions other than\n                             ``SystemExit`` when running :meth:`~CliRunner.invoke`.\n\n    .. versionchanged:: 8.2\n        Added the ``catch_exceptions`` parameter.\n\n    .. versionchanged:: 8.2\n        ``mix_stderr`` parameter has been removed.\n    \"\"\"\n\n    def __init__(\n        self,\n        charset: str = \"utf-8\",\n        env: cabc.Mapping[str, str | None] | None = None,\n        echo_stdin: bool = False,\n        catch_exceptions: bool = True,\n    ) -> None:\n        self.charset = charset\n        self.env: cabc.Mapping[str, str | None] = env or {}\n        self.echo_stdin = echo_stdin\n        self.catch_exceptions = catch_exceptions\n\n    def get_default_prog_name(self, cli: Command) -> str:\n        \"\"\"Given a command object it will return the default program name\n        for it.  The default is the `name` attribute or ``\"root\"`` if not\n        set.\n        \"\"\"\n        return cli.name or \"root\"\n\n    def make_env(\n        self, overrides: cabc.Mapping[str, str | None] | None = None\n    ) -> cabc.Mapping[str, str | None]:\n        \"\"\"Returns the environment overrides for invoking a script.\"\"\"\n        rv = dict(self.env)\n        if overrides:\n            rv.update(overrides)\n        return rv\n\n    @contextlib.contextmanager\n    def isolation(\n        self,\n        input: str | bytes | t.IO[t.Any] | None = None,\n        env: cabc.Mapping[str, str | None] | None = None,\n        color: bool = False,\n    ) -> cabc.Iterator[tuple[io.BytesIO, io.BytesIO, io.BytesIO]]:\n        \"\"\"A context manager that sets up the isolation for invoking of a\n        command line tool.  This sets up `<stdin>` with the given input data\n        and `os.environ` with the overrides from the given dictionary.\n        This also rebinds some internals in Click to be mocked (like the\n        prompt functionality).\n\n        This is automatically done in the :meth:`invoke` method.\n\n        :param input: the input stream to put into `sys.stdin`.\n        :param env: the environment overrides as dictionary.\n        :param color: whether the output should contain color codes. The\n                      application can still override this explicitly.\n\n        .. versionadded:: 8.2\n            An additional output stream is returned, which is a mix of\n            `<stdout>` and `<stderr>` streams.\n\n        .. versionchanged:: 8.2\n            Always returns the `<stderr>` stream.\n\n        .. versionchanged:: 8.0\n            `<stderr>` is opened with ``errors=\"backslashreplace\"``\n            instead of the default ``\"strict\"``.\n\n        .. versionchanged:: 4.0\n            Added the ``color`` parameter.\n        \"\"\"\n        bytes_input = make_input_stream(input, self.charset)\n        echo_input = None\n\n        old_stdin = sys.stdin\n        old_stdout = sys.stdout\n        old_stderr = sys.stderr\n        old_forced_width = formatting.FORCED_WIDTH\n        formatting.FORCED_WIDTH = 80\n\n        env = self.make_env(env)\n\n        stream_mixer = StreamMixer()\n\n        if self.echo_stdin:\n            bytes_input = echo_input = t.cast(\n                t.BinaryIO, EchoingStdin(bytes_input, stream_mixer.stdout)\n            )\n\n        sys.stdin = text_input = _NamedTextIOWrapper(\n            bytes_input, encoding=self.charset, name=\"<stdin>\", mode=\"r\"\n        )\n\n        if self.echo_stdin:\n            # Force unbuffered reads, otherwise TextIOWrapper reads a\n            # large chunk which is echoed early.\n            text_input._CHUNK_SIZE = 1  # type: ignore\n\n        sys.stdout = _NamedTextIOWrapper(\n            stream_mixer.stdout, encoding=self.charset, name=\"<stdout>\", mode=\"w\"\n        )\n\n        sys.stderr = _NamedTextIOWrapper(\n            stream_mixer.stderr,\n            encoding=self.charset,\n            name=\"<stderr>\",\n            mode=\"w\",\n            errors=\"backslashreplace\",\n        )\n\n        @_pause_echo(echo_input)  # type: ignore\n        def visible_input(prompt: str | None = None) -> str:\n            sys.stdout.write(prompt or \"\")\n            val = next(text_input).rstrip(\"\\r\\n\")\n            sys.stdout.write(f\"{val}\\n\")\n            sys.stdout.flush()\n            return val\n\n        @_pause_echo(echo_input)  # type: ignore\n        def hidden_input(prompt: str | None = None) -> str:\n            sys.stdout.write(f\"{prompt or ''}\\n\")\n            sys.stdout.flush()\n            return next(text_input).rstrip(\"\\r\\n\")\n\n        @_pause_echo(echo_input)  # type: ignore\n        def _getchar(echo: bool) -> str:\n            char = sys.stdin.read(1)\n\n            if echo:\n                sys.stdout.write(char)\n\n            sys.stdout.flush()\n            return char\n\n        default_color = color\n\n        def should_strip_ansi(\n            stream: t.IO[t.Any] | None = None, color: bool | None = None\n        ) -> bool:\n            if color is None:\n                return not default_color\n            return not color\n\n        old_visible_prompt_func = termui.visible_prompt_func\n        old_hidden_prompt_func = termui.hidden_prompt_func\n        old__getchar_func = termui._getchar\n        old_should_strip_ansi = utils.should_strip_ansi  # type: ignore\n        old__compat_should_strip_ansi = _compat.should_strip_ansi\n        termui.visible_prompt_func = visible_input\n        termui.hidden_prompt_func = hidden_input\n        termui._getchar = _getchar\n        utils.should_strip_ansi = should_strip_ansi  # type: ignore\n        _compat.should_strip_ansi = should_strip_ansi\n\n        old_env = {}\n        try:\n            for key, value in env.items():\n                old_env[key] = os.environ.get(key)\n                if value is None:\n                    try:\n                        del os.environ[key]\n                    except Exception:\n                        pass\n                else:\n                    os.environ[key] = value\n            yield (stream_mixer.stdout, stream_mixer.stderr, stream_mixer.output)\n        finally:\n            for key, value in old_env.items():\n                if value is None:\n                    try:\n                        del os.environ[key]\n                    except Exception:\n                        pass\n                else:\n                    os.environ[key] = value\n            sys.stdout = old_stdout\n            sys.stderr = old_stderr\n            sys.stdin = old_stdin\n            termui.visible_prompt_func = old_visible_prompt_func\n            termui.hidden_prompt_func = old_hidden_prompt_func\n            termui._getchar = old__getchar_func\n            utils.should_strip_ansi = old_should_strip_ansi  # type: ignore\n            _compat.should_strip_ansi = old__compat_should_strip_ansi\n            formatting.FORCED_WIDTH = old_forced_width\n\n    def invoke(\n        self,\n        cli: Command,\n        args: str | cabc.Sequence[str] | None = None,\n        input: str | bytes | t.IO[t.Any] | None = None,\n        env: cabc.Mapping[str, str | None] | None = None,\n        catch_exceptions: bool | None = None,\n        color: bool = False,\n        **extra: t.Any,\n    ) -> Result:\n        \"\"\"Invokes a command in an isolated environment.  The arguments are\n        forwarded directly to the command line script, the `extra` keyword\n        arguments are passed to the :meth:`~clickpkg.Command.main` function of\n        the command.\n\n        This returns a :class:`Result` object.\n\n        :param cli: the command to invoke\n        :param args: the arguments to invoke. It may be given as an iterable\n                     or a string. When given as string it will be interpreted\n                     as a Unix shell command. More details at\n                     :func:`shlex.split`.\n        :param input: the input data for `sys.stdin`.\n        :param env: the environment overrides.\n        :param catch_exceptions: Whether to catch any other exceptions than\n                                 ``SystemExit``. If :data:`None`, the value\n                                 from :class:`CliRunner` is used.\n        :param extra: the keyword arguments to pass to :meth:`main`.\n        :param color: whether the output should contain color codes. The\n                      application can still override this explicitly.\n\n        .. versionadded:: 8.2\n            The result object has the ``output_bytes`` attribute with\n            the mix of ``stdout_bytes`` and ``stderr_bytes``, as the user would\n            see it in its terminal.\n\n        .. versionchanged:: 8.2\n            The result object always returns the ``stderr_bytes`` stream.\n\n        .. versionchanged:: 8.0\n            The result object has the ``return_value`` attribute with\n            the value returned from the invoked command.\n\n        .. versionchanged:: 4.0\n            Added the ``color`` parameter.\n\n        .. versionchanged:: 3.0\n            Added the ``catch_exceptions`` parameter.\n\n        .. versionchanged:: 3.0\n            The result object has the ``exc_info`` attribute with the\n            traceback if available.\n        \"\"\"\n        exc_info = None\n        if catch_exceptions is None:\n            catch_exceptions = self.catch_exceptions\n\n        with self.isolation(input=input, env=env, color=color) as outstreams:\n            return_value = None\n            exception: BaseException | None = None\n            exit_code = 0\n\n            if isinstance(args, str):\n                args = shlex.split(args)\n\n            try:\n                prog_name = extra.pop(\"prog_name\")\n            except KeyError:\n                prog_name = self.get_default_prog_name(cli)\n\n            try:\n                return_value = cli.main(args=args or (), prog_name=prog_name, **extra)\n            except SystemExit as e:\n                exc_info = sys.exc_info()\n                e_code = t.cast(\"int | t.Any | None\", e.code)\n\n                if e_code is None:\n                    e_code = 0\n\n                if e_code != 0:\n                    exception = e\n\n                if not isinstance(e_code, int):\n                    sys.stdout.write(str(e_code))\n                    sys.stdout.write(\"\\n\")\n                    e_code = 1\n\n                exit_code = e_code\n\n            except Exception as e:\n                if not catch_exceptions:\n                    raise\n                exception = e\n                exit_code = 1\n                exc_info = sys.exc_info()\n            finally:\n                sys.stdout.flush()\n                sys.stderr.flush()\n                stdout = outstreams[0].getvalue()\n                stderr = outstreams[1].getvalue()\n                output = outstreams[2].getvalue()\n\n        return Result(\n            runner=self,\n            stdout_bytes=stdout,\n            stderr_bytes=stderr,\n            output_bytes=output,\n            return_value=return_value,\n            exit_code=exit_code,\n            exception=exception,\n            exc_info=exc_info,  # type: ignore\n        )\n\n    @contextlib.contextmanager\n    def isolated_filesystem(\n        self, temp_dir: str | os.PathLike[str] | None = None\n    ) -> cabc.Iterator[str]:\n        \"\"\"A context manager that creates a temporary directory and\n        changes the current working directory to it. This isolates tests\n        that affect the contents of the CWD to prevent them from\n        interfering with each other.\n\n        :param temp_dir: Create the temporary directory under this\n            directory. If given, the created directory is not removed\n            when exiting.\n\n        .. versionchanged:: 8.0\n            Added the ``temp_dir`` parameter.\n        \"\"\"\n        cwd = os.getcwd()\n        dt = tempfile.mkdtemp(dir=temp_dir)\n        os.chdir(dt)\n\n        try:\n            yield dt\n        finally:\n            os.chdir(cwd)\n\n            if temp_dir is None:\n                try:\n                    shutil.rmtree(dt)\n                except OSError:\n                    pass\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "680c2256c727",
      "repo": "click",
      "commit_hash": "3155dca",
      "commit_message": "fix(typing): Using correct typing for `param_hint`",
      "file_path": "src/click/exceptions.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom ._compat import get_text_stderr\nfrom .globals import resolve_color_default\nfrom .utils import echo\nfrom .utils import format_filename\n\nif t.TYPE_CHECKING:\n    from .core import Command\n    from .core import Context\n    from .core import Parameter\n\n\ndef _join_param_hints(param_hint: cabc.Sequence[str] | str | None) -> str | None:\n    if param_hint is not None and not isinstance(param_hint, str):\n        return \" / \".join(repr(x) for x in param_hint)\n\n    return param_hint\n\n\nclass ClickException(Exception):\n    \"\"\"An exception that Click can handle and show to the user.\"\"\"\n\n    #: The exit code for this exception.\n    exit_code = 1\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message)\n        # The context will be removed by the time we print the message, so cache\n        # the color settings here to be used later on (in `show`)\n        self.show_color: bool | None = resolve_color_default()\n        self.message = message\n\n    def format_message(self) -> str:\n        return self.message\n\n    def __str__(self) -> str:\n        return self.message\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=self.show_color,\n        )\n\n\nclass UsageError(ClickException):\n    \"\"\"An internal exception that signals a usage error.  This typically\n    aborts any further handling.\n\n    :param message: the error message to display.\n    :param ctx: optionally the context that caused this error.  Click will\n                fill in the context automatically in some situations.\n    \"\"\"\n\n    exit_code = 2\n\n    def __init__(self, message: str, ctx: Context | None = None) -> None:\n        super().__init__(message)\n        self.ctx = ctx\n        self.cmd: Command | None = self.ctx.command if self.ctx else None\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n        color = None\n        hint = \"\"\n        if (\n            self.ctx is not None\n            and self.ctx.command.get_help_option(self.ctx) is not None\n        ):\n            hint = _(\"Try '{command} {option}' for help.\").format(\n                command=self.ctx.command_path, option=self.ctx.help_option_names[0]\n            )\n            hint = f\"{hint}\\n\"\n        if self.ctx is not None:\n            color = self.ctx.color\n            echo(f\"{self.ctx.get_usage()}\\n{hint}\", file=file, color=color)\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=color,\n        )\n\n\nclass BadParameter(UsageError):\n    \"\"\"An exception that formats out a standardized error message for a\n    bad parameter.  This is useful when thrown from a callback or type as\n    Click will attach contextual information to it (for instance, which\n    parameter it is).\n\n    .. versionadded:: 2.0\n\n    :param param: the parameter object that caused this error.  This can\n                  be left out, and Click will attach this info itself\n                  if possible.\n    :param param_hint: a string that shows up as parameter name.  This\n                       can be used as alternative to `param` in cases\n                       where custom validation should happen.  If it is\n                       a string it's used as such, if it's a list then\n                       each item is quoted and separated.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        ctx: Context | None = None,\n        param: Parameter | None = None,\n        param_hint: str | None = None,\n    ) -> None:\n        super().__init__(message, ctx)\n        self.param = param\n        self.param_hint = param_hint\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            return _(\"Invalid value: {message}\").format(message=self.message)\n\n        return _(\"Invalid value for {param_hint}: {message}\").format(\n            param_hint=_join_param_hints(param_hint), message=self.message\n        )\n\n\nclass MissingParameter(BadParameter):\n    \"\"\"Raised if click required an option or argument but it was not\n    provided when invoking the script.\n\n    .. versionadded:: 4.0\n\n    :param param_type: a string that indicates the type of the parameter.\n                       The default is to inherit the parameter type from\n                       the given `param`.  Valid values are ``'parameter'``,\n                       ``'option'`` or ``'argument'``.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str | None = None,\n        ctx: Context | None = None,\n        param: Parameter | None = None,\n        param_hint: str | None = None,\n        param_type: str | None = None,\n    ) -> None:\n        super().__init__(message or \"\", ctx, param, param_hint)\n        self.param_type = param_type\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint: str | None = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            param_hint = None\n\n        param_hint = _join_param_hints(param_hint)\n        param_hint = f\" {param_hint}\" if param_hint else \"\"\n\n        param_type = self.param_type\n        if param_type is None and self.param is not None:\n            param_type = self.param.param_type_name\n\n        msg = self.message\n        if self.param is not None:\n            msg_extra = self.param.type.get_missing_message(\n                param=self.param, ctx=self.ctx\n            )\n            if msg_extra:\n                if msg:\n                    msg += f\". {msg_extra}\"\n                else:\n                    msg = msg_extra\n\n        msg = f\" {msg}\" if msg else \"\"\n\n        # Translate param_type for known types.\n        if param_type == \"argument\":\n            missing = _(\"Missing argument\")\n        elif param_type == \"option\":\n            missing = _(\"Missing option\")\n        elif param_type == \"parameter\":\n            missing = _(\"Missing parameter\")\n        else:\n            missing = _(\"Missing {param_type}\").format(param_type=param_type)\n\n        return f\"{missing}{param_hint}.{msg}\"\n\n    def __str__(self) -> str:\n        if not self.message:\n            param_name = self.param.name if self.param else None\n            return _(\"Missing parameter: {param_name}\").format(param_name=param_name)\n        else:\n            return self.message\n\n\nclass NoSuchOption(UsageError):\n    \"\"\"Raised if click attempted to handle an option that does not\n    exist.\n\n    .. versionadded:: 4.0\n    \"\"\"\n\n    def __init__(\n        self,\n        option_name: str,\n        message: str | None = None,\n        possibilities: cabc.Sequence[str] | None = None,\n        ctx: Context | None = None,\n    ) -> None:\n        if message is None:\n            message = _(\"No such option: {name}\").format(name=option_name)\n\n        super().__init__(message, ctx)\n        self.option_name = option_name\n        self.possibilities = possibilities\n\n    def format_message(self) -> str:\n        if not self.possibilities:\n            return self.message\n\n        possibility_str = \", \".join(sorted(self.possibilities))\n        suggest = ngettext(\n            \"Did you mean {possibility}?\",\n            \"(Possible options: {possibilities})\",\n            len(self.possibilities),\n        ).format(possibility=possibility_str, possibilities=possibility_str)\n        return f\"{self.message} {suggest}\"\n\n\nclass BadOptionUsage(UsageError):\n    \"\"\"Raised if an option is generally supplied but the use of the option\n    was incorrect.  This is for instance raised if the number of arguments\n    for an option is not correct.\n\n    .. versionadded:: 4.0\n\n    :param option_name: the name of the option being used incorrectly.\n    \"\"\"\n\n    def __init__(\n        self, option_name: str, message: str, ctx: Context | None = None\n    ) -> None:\n        super().__init__(message, ctx)\n        self.option_name = option_name\n\n\nclass BadArgumentUsage(UsageError):\n    \"\"\"Raised if an argument is generally supplied but the use of the argument\n    was incorrect.  This is for instance raised if the number of values\n    for an argument is not correct.\n\n    .. versionadded:: 6.0\n    \"\"\"\n\n\nclass NoArgsIsHelpError(UsageError):\n    def __init__(self, ctx: Context) -> None:\n        self.ctx: Context\n        super().__init__(ctx.get_help(), ctx=ctx)\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        echo(self.format_message(), file=file, err=True, color=self.ctx.color)\n\n\nclass FileError(ClickException):\n    \"\"\"Raised if a file cannot be opened.\"\"\"\n\n    def __init__(self, filename: str, hint: str | None = None) -> None:\n        if hint is None:\n            hint = _(\"unknown error\")\n\n        super().__init__(hint)\n        self.ui_filename: str = format_filename(filename)\n        self.filename = filename\n\n    def format_message(self) -> str:\n        return _(\"Could not open file {filename!r}: {message}\").format(\n            filename=self.ui_filename, message=self.message\n        )\n\n\nclass Abort(RuntimeError):\n    \"\"\"An internal signalling exception that signals Click to abort.\"\"\"\n\n\nclass Exit(RuntimeError):\n    \"\"\"An exception that indicates that the application should exit with some\n    status code.\n\n    :param code: the status code to exit with.\n    \"\"\"\n\n    __slots__ = (\"exit_code\",)\n\n    def __init__(self, code: int = 0) -> None:\n        self.exit_code: int = code\n",
      "code_after": "from __future__ import annotations\n\nimport collections.abc as cabc\nimport typing as t\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom ._compat import get_text_stderr\nfrom .globals import resolve_color_default\nfrom .utils import echo\nfrom .utils import format_filename\n\nif t.TYPE_CHECKING:\n    from .core import Command\n    from .core import Context\n    from .core import Parameter\n\n\ndef _join_param_hints(param_hint: cabc.Sequence[str] | str | None) -> str | None:\n    if param_hint is not None and not isinstance(param_hint, str):\n        return \" / \".join(repr(x) for x in param_hint)\n\n    return param_hint\n\n\nclass ClickException(Exception):\n    \"\"\"An exception that Click can handle and show to the user.\"\"\"\n\n    #: The exit code for this exception.\n    exit_code = 1\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message)\n        # The context will be removed by the time we print the message, so cache\n        # the color settings here to be used later on (in `show`)\n        self.show_color: bool | None = resolve_color_default()\n        self.message = message\n\n    def format_message(self) -> str:\n        return self.message\n\n    def __str__(self) -> str:\n        return self.message\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=self.show_color,\n        )\n\n\nclass UsageError(ClickException):\n    \"\"\"An internal exception that signals a usage error.  This typically\n    aborts any further handling.\n\n    :param message: the error message to display.\n    :param ctx: optionally the context that caused this error.  Click will\n                fill in the context automatically in some situations.\n    \"\"\"\n\n    exit_code = 2\n\n    def __init__(self, message: str, ctx: Context | None = None) -> None:\n        super().__init__(message)\n        self.ctx = ctx\n        self.cmd: Command | None = self.ctx.command if self.ctx else None\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n        color = None\n        hint = \"\"\n        if (\n            self.ctx is not None\n            and self.ctx.command.get_help_option(self.ctx) is not None\n        ):\n            hint = _(\"Try '{command} {option}' for help.\").format(\n                command=self.ctx.command_path, option=self.ctx.help_option_names[0]\n            )\n            hint = f\"{hint}\\n\"\n        if self.ctx is not None:\n            color = self.ctx.color\n            echo(f\"{self.ctx.get_usage()}\\n{hint}\", file=file, color=color)\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=color,\n        )\n\n\nclass BadParameter(UsageError):\n    \"\"\"An exception that formats out a standardized error message for a\n    bad parameter.  This is useful when thrown from a callback or type as\n    Click will attach contextual information to it (for instance, which\n    parameter it is).\n\n    .. versionadded:: 2.0\n\n    :param param: the parameter object that caused this error.  This can\n                  be left out, and Click will attach this info itself\n                  if possible.\n    :param param_hint: a string that shows up as parameter name.  This\n                       can be used as alternative to `param` in cases\n                       where custom validation should happen.  If it is\n                       a string it's used as such, if it's a list then\n                       each item is quoted and separated.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        ctx: Context | None = None,\n        param: Parameter | None = None,\n        param_hint: cabc.Sequence[str] | str | None = None,\n    ) -> None:\n        super().__init__(message, ctx)\n        self.param = param\n        self.param_hint = param_hint\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            return _(\"Invalid value: {message}\").format(message=self.message)\n\n        return _(\"Invalid value for {param_hint}: {message}\").format(\n            param_hint=_join_param_hints(param_hint), message=self.message\n        )\n\n\nclass MissingParameter(BadParameter):\n    \"\"\"Raised if click required an option or argument but it was not\n    provided when invoking the script.\n\n    .. versionadded:: 4.0\n\n    :param param_type: a string that indicates the type of the parameter.\n                       The default is to inherit the parameter type from\n                       the given `param`.  Valid values are ``'parameter'``,\n                       ``'option'`` or ``'argument'``.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str | None = None,\n        ctx: Context | None = None,\n        param: Parameter | None = None,\n        param_hint: cabc.Sequence[str] | str | None = None,\n        param_type: str | None = None,\n    ) -> None:\n        super().__init__(message or \"\", ctx, param, param_hint)\n        self.param_type = param_type\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint: cabc.Sequence[str] | str | None = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            param_hint = None\n\n        param_hint = _join_param_hints(param_hint)\n        param_hint = f\" {param_hint}\" if param_hint else \"\"\n\n        param_type = self.param_type\n        if param_type is None and self.param is not None:\n            param_type = self.param.param_type_name\n\n        msg = self.message\n        if self.param is not None:\n            msg_extra = self.param.type.get_missing_message(\n                param=self.param, ctx=self.ctx\n            )\n            if msg_extra:\n                if msg:\n                    msg += f\". {msg_extra}\"\n                else:\n                    msg = msg_extra\n\n        msg = f\" {msg}\" if msg else \"\"\n\n        # Translate param_type for known types.\n        if param_type == \"argument\":\n            missing = _(\"Missing argument\")\n        elif param_type == \"option\":\n            missing = _(\"Missing option\")\n        elif param_type == \"parameter\":\n            missing = _(\"Missing parameter\")\n        else:\n            missing = _(\"Missing {param_type}\").format(param_type=param_type)\n\n        return f\"{missing}{param_hint}.{msg}\"\n\n    def __str__(self) -> str:\n        if not self.message:\n            param_name = self.param.name if self.param else None\n            return _(\"Missing parameter: {param_name}\").format(param_name=param_name)\n        else:\n            return self.message\n\n\nclass NoSuchOption(UsageError):\n    \"\"\"Raised if click attempted to handle an option that does not\n    exist.\n\n    .. versionadded:: 4.0\n    \"\"\"\n\n    def __init__(\n        self,\n        option_name: str,\n        message: str | None = None,\n        possibilities: cabc.Sequence[str] | None = None,\n        ctx: Context | None = None,\n    ) -> None:\n        if message is None:\n            message = _(\"No such option: {name}\").format(name=option_name)\n\n        super().__init__(message, ctx)\n        self.option_name = option_name\n        self.possibilities = possibilities\n\n    def format_message(self) -> str:\n        if not self.possibilities:\n            return self.message\n\n        possibility_str = \", \".join(sorted(self.possibilities))\n        suggest = ngettext(\n            \"Did you mean {possibility}?\",\n            \"(Possible options: {possibilities})\",\n            len(self.possibilities),\n        ).format(possibility=possibility_str, possibilities=possibility_str)\n        return f\"{self.message} {suggest}\"\n\n\nclass BadOptionUsage(UsageError):\n    \"\"\"Raised if an option is generally supplied but the use of the option\n    was incorrect.  This is for instance raised if the number of arguments\n    for an option is not correct.\n\n    .. versionadded:: 4.0\n\n    :param option_name: the name of the option being used incorrectly.\n    \"\"\"\n\n    def __init__(\n        self, option_name: str, message: str, ctx: Context | None = None\n    ) -> None:\n        super().__init__(message, ctx)\n        self.option_name = option_name\n\n\nclass BadArgumentUsage(UsageError):\n    \"\"\"Raised if an argument is generally supplied but the use of the argument\n    was incorrect.  This is for instance raised if the number of values\n    for an argument is not correct.\n\n    .. versionadded:: 6.0\n    \"\"\"\n\n\nclass NoArgsIsHelpError(UsageError):\n    def __init__(self, ctx: Context) -> None:\n        self.ctx: Context\n        super().__init__(ctx.get_help(), ctx=ctx)\n\n    def show(self, file: t.IO[t.Any] | None = None) -> None:\n        echo(self.format_message(), file=file, err=True, color=self.ctx.color)\n\n\nclass FileError(ClickException):\n    \"\"\"Raised if a file cannot be opened.\"\"\"\n\n    def __init__(self, filename: str, hint: str | None = None) -> None:\n        if hint is None:\n            hint = _(\"unknown error\")\n\n        super().__init__(hint)\n        self.ui_filename: str = format_filename(filename)\n        self.filename = filename\n\n    def format_message(self) -> str:\n        return _(\"Could not open file {filename!r}: {message}\").format(\n            filename=self.ui_filename, message=self.message\n        )\n\n\nclass Abort(RuntimeError):\n    \"\"\"An internal signalling exception that signals Click to abort.\"\"\"\n\n\nclass Exit(RuntimeError):\n    \"\"\"An exception that indicates that the application should exit with some\n    status code.\n\n    :param code: the status code to exit with.\n    \"\"\"\n\n    __slots__ = (\"exit_code\",)\n\n    def __init__(self, code: int = 0) -> None:\n        self.exit_code: int = code\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 1.0
    },
    {
      "bug_id": "2d2bcc93d63f",
      "repo": "click",
      "commit_hash": "2fa500c",
      "commit_message": "fix filename formatting test for Windows compatibility",
      "file_path": "tests/test_utils.py",
      "language": "python",
      "code_before": "import os\nimport pathlib\nimport stat\nimport subprocess\nimport sys\nfrom collections import namedtuple\nfrom contextlib import nullcontext\nfrom functools import partial\nfrom io import StringIO\nfrom pathlib import Path\nfrom tempfile import tempdir\nfrom unittest.mock import patch\n\nimport pytest\n\nimport click._termui_impl\nimport click.utils\nfrom click._compat import WIN\n\n\ndef test_echo(runner):\n    with runner.isolation() as outstreams:\n        click.echo(\"\\N{SNOWMAN}\")\n        click.echo(b\"\\x44\\x44\")\n        click.echo(42, nl=False)\n        click.echo(b\"a\", nl=False)\n        click.echo(\"\\x1b[31mx\\x1b[39m\", nl=False)\n        bytes = outstreams[0].getvalue().replace(b\"\\r\\n\", b\"\\n\")\n        assert bytes == b\"\\xe2\\x98\\x83\\nDD\\n42ax\"\n\n    # if wrapped, we expect bytes to survive.\n    @click.command()\n    def cli():\n        click.echo(b\"\\xf6\")\n\n    result = runner.invoke(cli, [])\n    assert result.stdout_bytes == b\"\\xf6\\n\"\n\n    # Ensure we do not strip for bytes.\n    with runner.isolation() as outstreams:\n        click.echo(bytearray(b\"\\x1b[31mx\\x1b[39m\"), nl=False)\n        assert outstreams[0].getvalue() == b\"\\x1b[31mx\\x1b[39m\"\n\n\ndef test_echo_custom_file():\n    f = StringIO()\n    click.echo(\"hello\", file=f)\n    assert f.getvalue() == \"hello\\n\"\n\n\ndef test_echo_no_streams(monkeypatch, runner):\n    \"\"\"echo should not fail when stdout and stderr are None with pythonw on Windows.\"\"\"\n    with runner.isolation():\n        sys.stdout = None\n        sys.stderr = None\n        click.echo(\"test\")\n        click.echo(\"test\", err=True)\n\n\n@pytest.mark.parametrize(\n    (\"styles\", \"ref\"),\n    [\n        ({\"fg\": \"black\"}, \"\\x1b[30mx y\\x1b[0m\"),\n        ({\"fg\": \"red\"}, \"\\x1b[31mx y\\x1b[0m\"),\n        ({\"fg\": \"green\"}, \"\\x1b[32mx y\\x1b[0m\"),\n        ({\"fg\": \"yellow\"}, \"\\x1b[33mx y\\x1b[0m\"),\n        ({\"fg\": \"blue\"}, \"\\x1b[34mx y\\x1b[0m\"),\n        ({\"fg\": \"magenta\"}, \"\\x1b[35mx y\\x1b[0m\"),\n        ({\"fg\": \"cyan\"}, \"\\x1b[36mx y\\x1b[0m\"),\n        ({\"fg\": \"white\"}, \"\\x1b[37mx y\\x1b[0m\"),\n        ({\"bg\": \"black\"}, \"\\x1b[40mx y\\x1b[0m\"),\n        ({\"bg\": \"red\"}, \"\\x1b[41mx y\\x1b[0m\"),\n        ({\"bg\": \"green\"}, \"\\x1b[42mx y\\x1b[0m\"),\n        ({\"bg\": \"yellow\"}, \"\\x1b[43mx y\\x1b[0m\"),\n        ({\"bg\": \"blue\"}, \"\\x1b[44mx y\\x1b[0m\"),\n        ({\"bg\": \"magenta\"}, \"\\x1b[45mx y\\x1b[0m\"),\n        ({\"bg\": \"cyan\"}, \"\\x1b[46mx y\\x1b[0m\"),\n        ({\"bg\": \"white\"}, \"\\x1b[47mx y\\x1b[0m\"),\n        ({\"bg\": 91}, \"\\x1b[48;5;91mx y\\x1b[0m\"),\n        ({\"bg\": (135, 0, 175)}, \"\\x1b[48;2;135;0;175mx y\\x1b[0m\"),\n        ({\"bold\": True}, \"\\x1b[1mx y\\x1b[0m\"),\n        ({\"dim\": True}, \"\\x1b[2mx y\\x1b[0m\"),\n        ({\"underline\": True}, \"\\x1b[4mx y\\x1b[0m\"),\n        ({\"overline\": True}, \"\\x1b[53mx y\\x1b[0m\"),\n        ({\"italic\": True}, \"\\x1b[3mx y\\x1b[0m\"),\n        ({\"blink\": True}, \"\\x1b[5mx y\\x1b[0m\"),\n        ({\"reverse\": True}, \"\\x1b[7mx y\\x1b[0m\"),\n        ({\"strikethrough\": True}, \"\\x1b[9mx y\\x1b[0m\"),\n        ({\"bold\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"dim\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"underline\": False}, \"\\x1b[24mx y\\x1b[0m\"),\n        ({\"overline\": False}, \"\\x1b[55mx y\\x1b[0m\"),\n        ({\"italic\": False}, \"\\x1b[23mx y\\x1b[0m\"),\n        ({\"blink\": False}, \"\\x1b[25mx y\\x1b[0m\"),\n        ({\"reverse\": False}, \"\\x1b[27mx y\\x1b[0m\"),\n        ({\"strikethrough\": False}, \"\\x1b[29mx y\\x1b[0m\"),\n        ({\"fg\": \"black\", \"reset\": False}, \"\\x1b[30mx y\"),\n    ],\n)\ndef test_styling(styles, ref):\n    assert click.style(\"x y\", **styles) == ref\n    assert click.unstyle(ref) == \"x y\"\n\n\n@pytest.mark.parametrize((\"text\", \"expect\"), [(\"\\x1b[?25lx y\\x1b[?25h\", \"x y\")])\ndef test_unstyle_other_ansi(text, expect):\n    assert click.unstyle(text) == expect\n\n\ndef test_filename_formatting():\n    assert click.format_filename(b\"foo.txt\") == \"foo.txt\"\n    assert click.format_filename(b\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\", shorten=True) == \"foo.txt\"\n    assert click.format_filename(b\"/x/\\xff.txt\", shorten=True) == \"\ufffd.txt\"\n\n\ndef test_prompts(runner):\n    @click.command()\n    def test():\n        if click.confirm(\"Foo\"):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: y\\nyes!\\n\"\n\n    result = runner.invoke(test, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: \\nno :(\\n\"\n\n    result = runner.invoke(test, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: n\\nno :(\\n\"\n\n    @click.command()\n    def test_no():\n        if click.confirm(\"Foo\", default=True):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test_no, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: y\\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: \\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: n\\nno :(\\n\"\n\n\ndef test_confirm_repeat(runner):\n    cli = click.Command(\n        \"cli\", params=[click.Option([\"--a/--no-a\"], default=None, prompt=True)]\n    )\n    result = runner.invoke(cli, input=\"\\ny\\n\")\n    assert result.output == \"A [y/n]: \\nError: invalid input\\nA [y/n]: y\\n\"\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\ndef test_prompts_abort(monkeypatch, capsys):\n    def f(_):\n        raise KeyboardInterrupt()\n\n    monkeypatch.setattr(\"click.termui.hidden_prompt_func\", f)\n\n    try:\n        click.prompt(\"Password\", hide_input=True)\n    except click.Abort:\n        click.echo(\"interrupted\")\n\n    out, err = capsys.readouterr()\n    assert out == \"Password:\\ninterrupted\\n\"\n\n\ndef _test_gen_func():\n    yield \"a\"\n    yield \"b\"\n    yield \"c\"\n    yield \"abc\"\n\n\ndef _test_gen_func_fails():\n    yield \"test\"\n    raise RuntimeError(\"This is a test.\")\n\n\ndef _test_gen_func_echo(file=None):\n    yield \"test\"\n    click.echo(\"hello\", file=file)\n    yield \"test\"\n\n\ndef _test_simulate_keyboard_interrupt(file=None):\n    yield \"output_before_keyboard_interrupt\"\n    raise KeyboardInterrupt()\n\n\nEchoViaPagerTest = namedtuple(\n    \"EchoViaPagerTest\",\n    (\n        \"description\",\n        \"test_input\",\n        \"expected_pager\",\n        \"expected_stdout\",\n        \"expected_stderr\",\n        \"expected_error\",\n    ),\n)\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\n@pytest.mark.parametrize(\n    \"pager_cmd\", [\"cat\", \"cat \", \" cat \", \"less\", \" less\", \" less \"]\n)\n@pytest.mark.parametrize(\n    \"test\",\n    [\n        # We need to pass a parameter function instead of a plain param\n        # as pytest.mark.parametrize will reuse the parameters causing the\n        # generators to be used up so they will not yield anymore\n        EchoViaPagerTest(\n            description=\"Plain string argument\",\n            test_input=lambda: \"just text\",\n            expected_pager=\"just text\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Iterable argument\",\n            test_input=lambda: [\"itera\", \"ble\"],\n            expected_pager=\"iterable\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Generator function argument\",\n            test_input=lambda: _test_gen_func,\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"String generator argument\",\n            test_input=lambda: _test_gen_func(),\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Number generator expression argument\",\n            test_input=lambda: (c for c in range(6)),\n            expected_pager=\"012345\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator function argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have\n            # a chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have a\n            # chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Keyboard interrupt should not terminate the pager\",\n            test_input=lambda: _test_simulate_keyboard_interrupt(),\n            # Due to the keyboard interrupt during pager execution, click program\n            # should abort, but the pager should stay open.\n            # This allows users to cancel the program and search in the pager\n            # output, before they decide to terminate the pager.\n            expected_pager=\"output_before_keyboard_interrupt\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=KeyboardInterrupt,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stdout during generator execution\",\n            test_input=lambda: _test_gen_func_echo(),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"hello\\n\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stderr during generator execution\",\n            test_input=lambda: _test_gen_func_echo(file=sys.stderr),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"hello\\n\",\n            expected_error=None,\n        ),\n    ],\n)\ndef test_echo_via_pager(monkeypatch, capfd, pager_cmd, test):\n    monkeypatch.setitem(os.environ, \"PAGER\", pager_cmd)\n    monkeypatch.setattr(click._termui_impl, \"isatty\", lambda x: True)\n\n    test_input = test.test_input()\n    expected_pager = test.expected_pager\n    expected_stdout = test.expected_stdout\n    expected_stderr = test.expected_stderr\n    expected_error = test.expected_error\n\n    check_raise = pytest.raises(expected_error) if expected_error else nullcontext()\n\n    pager_out_tmp = Path(tempdir) / \"pager_out.txt\"\n    pager_out_tmp.unlink(missing_ok=True)\n    with pager_out_tmp.open(\"w\") as f:\n        force_subprocess_stdout = patch.object(\n            subprocess,\n            \"Popen\",\n            partial(subprocess.Popen, stdout=f),\n        )\n        with force_subprocess_stdout:\n            with check_raise:\n                click.echo_via_pager(test_input)\n\n    out, err = capfd.readouterr()\n\n    pager = pager_out_tmp.read_text()\n\n    assert pager == expected_pager, (\n        f\"Unexpected pager output in test case '{test.description}'\"\n    )\n    assert out == expected_stdout, (\n        f\"Unexpected stdout in test case '{test.description}'\"\n    )\n    assert err == expected_stderr, (\n        f\"Unexpected stderr in test case '{test.description}'\"\n    )\n\n\ndef test_echo_color_flag(monkeypatch, capfd):\n    isatty = True\n    monkeypatch.setattr(click._compat, \"isatty\", lambda x: isatty)\n\n    text = \"foo\"\n    styled_text = click.style(text, fg=\"red\")\n    assert styled_text == \"\\x1b[31mfoo\\x1b[0m\"\n\n    click.echo(styled_text, color=False)\n    out, err = capfd.readouterr()\n    assert out == f\"{text}\\n\"\n\n    click.echo(styled_text, color=True)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = True\n    click.echo(styled_text)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = False\n    # Faking isatty() is not enough on Windows;\n    # the implementation caches the colorama wrapped stream\n    # so we have to use a new stream for each test\n    stream = StringIO()\n    click.echo(styled_text, file=stream)\n    assert stream.getvalue() == f\"{text}\\n\"\n\n    stream = StringIO()\n    click.echo(styled_text, file=stream, color=True)\n    assert stream.getvalue() == f\"{styled_text}\\n\"\n\n\ndef test_prompt_cast_default(capfd, monkeypatch):\n    monkeypatch.setattr(sys, \"stdin\", StringIO(\"\\n\"))\n    value = click.prompt(\"value\", default=\"100\", type=int)\n    capfd.readouterr()\n    assert isinstance(value, int)\n\n\n@pytest.mark.skipif(WIN, reason=\"Test too complex to make work windows.\")\ndef test_echo_writing_to_standard_error(capfd, monkeypatch):\n    def emulate_input(text):\n        \"\"\"Emulate keyboard input.\"\"\"\n        monkeypatch.setattr(sys, \"stdin\", StringIO(text))\n\n    click.echo(\"Echo to standard output\")\n    out, err = capfd.readouterr()\n    assert out == \"Echo to standard output\\n\"\n    assert err == \"\"\n\n    click.echo(\"Echo to standard error\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Echo to standard error\\n\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin: \"\n    assert err == \"\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr:\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin [y/N]: \"\n    assert err == \"\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr [y/N]:\"\n\n    monkeypatch.setattr(click.termui, \"isatty\", lambda x: True)\n    monkeypatch.setattr(click.termui, \"getchar\", lambda: \" \")\n\n    click.pause(\"Pause to stdout\")\n    out, err = capfd.readouterr()\n    assert out == \"Pause to stdout\\n\"\n    assert err == \"\"\n\n    click.pause(\"Pause to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Pause to stderr\\n\"\n\n\ndef test_echo_with_capsys(capsys):\n    click.echo(\"Capture me.\")\n    out, err = capsys.readouterr()\n    assert out == \"Capture me.\\n\"\n\n\ndef test_open_file(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        click.echo(\"meep\")\n\n    with runner.isolated_filesystem():\n        with open(\"hello.txt\", \"w\") as f:\n            f.write(\"Cool stuff\")\n\n        result = runner.invoke(cli, [\"hello.txt\"])\n        assert result.exception is None\n        assert result.output == \"Cool stuff\\nmeep\\n\"\n\n        result = runner.invoke(cli, [\"-\"], input=\"foobar\")\n        assert result.exception is None\n        assert result.output == \"foobar\\nmeep\\n\"\n\n\ndef test_open_file_pathlib_dash(runner):\n    @click.command()\n    @click.argument(\n        \"filename\", type=click.Path(allow_dash=True, path_type=pathlib.Path)\n    )\n    def cli(filename):\n        click.echo(str(type(filename)))\n\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        result = runner.invoke(cli, [\"-\"], input=\"value\")\n        assert result.exception is None\n        assert result.output == \"pathlib.Path\\nvalue\\n\"\n\n\ndef test_open_file_ignore_errors_stdin(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename, errors=\"ignore\") as f:\n            click.echo(f.read())\n\n    result = runner.invoke(cli, [\"-\"], input=os.urandom(16))\n    assert result.exception is None\n\n\ndef test_open_file_respects_ignore(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"w\") as f:\n            f.write(\"Hello world!\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            assert f.errors == \"ignore\"\n\n\ndef test_open_file_ignore_invalid_utf8(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"wb\") as f:\n            f.write(b\"\\xe2\\x28\\xa1\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            f.read()\n\n\ndef test_open_file_ignore_no_encoding(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.bin\", \"wb\") as f:\n            f.write(os.urandom(16))\n\n        with click.open_file(\"test.bin\", errors=\"ignore\") as f:\n            f.read()\n\n\n@pytest.mark.skipif(WIN, reason=\"os.chmod() is not fully supported on Windows.\")\n@pytest.mark.parametrize(\"permissions\", [0o400, 0o444, 0o600, 0o644])\ndef test_open_file_atomic_permissions_existing_file(runner, permissions):\n    with runner.isolated_filesystem():\n        with open(\"existing.txt\", \"w\") as f:\n            f.write(\"content\")\n        os.chmod(\"existing.txt\", permissions)\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        result = runner.invoke(cli, [\"existing.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"existing.txt\").st_mode) == permissions\n\n\n@pytest.mark.skipif(WIN, reason=\"os.stat() is not fully supported on Windows.\")\ndef test_open_file_atomic_permissions_new_file(runner):\n    with runner.isolated_filesystem():\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        # Create a test file to get the expected permissions for new files\n        # according to the current umask.\n        with open(\"test.txt\", \"w\"):\n            pass\n        permissions = stat.S_IMODE(os.stat(\"test.txt\").st_mode)\n\n        result = runner.invoke(cli, [\"new.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"new.txt\").st_mode) == permissions\n\n\ndef test_iter_keepopenfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        for e_line, a_line in zip(expected, click.utils.KeepOpenFile(f), strict=False):\n            assert e_line == a_line.strip()\n\n\ndef test_iter_lazyfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        with click.utils.LazyFile(f.name) as lf:\n            for e_line, a_line in zip(expected, lf, strict=False):\n                assert e_line == a_line.strip()\n\n\nclass MockMain:\n    __slots__ = \"__package__\"\n\n    def __init__(self, package_name):\n        self.__package__ = package_name\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"main\", \"expected\"),\n    [\n        (\"example.py\", None, \"example.py\"),\n        (str(pathlib.Path(\"/foo/bar/example.py\")), None, \"example.py\"),\n        (\"example\", None, \"example\"),\n        (str(pathlib.Path(\"example/__main__.py\")), \"example\", \"python -m example\"),\n        (str(pathlib.Path(\"example/cli.py\")), \"example\", \"python -m example.cli\"),\n        (str(pathlib.Path(\"./example\")), \"\", \"example\"),\n    ],\n)\ndef test_detect_program_name(path, main, expected):\n    assert click.utils._detect_program_name(path, _main=MockMain(main)) == expected\n\n\ndef test_expand_args(monkeypatch):\n    user = os.path.expanduser(\"~\")\n    assert user in click.utils._expand_args([\"~\"])\n    monkeypatch.setenv(\"CLICK_TEST\", \"hello\")\n    assert \"hello\" in click.utils._expand_args([\"$CLICK_TEST\"])\n    assert \"pyproject.toml\" in click.utils._expand_args([\"*.toml\"])\n    assert os.path.join(\"docs\", \"conf.py\") in click.utils._expand_args([\"**/conf.py\"])\n    assert \"*.not-found\" in click.utils._expand_args([\"*.not-found\"])\n    # a bad glob pattern, such as a pytest identifier, should return itself\n    assert click.utils._expand_args([\"test.py::test_bad\"])[0] == \"test.py::test_bad\"\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"max_length\", \"expect\"),\n    [\n        pytest.param(\"\", 10, \"\", id=\"empty\"),\n        pytest.param(\"123 567 90\", 10, \"123 567 90\", id=\"equal length, no dot\"),\n        pytest.param(\"123 567 9. aaaa bbb\", 10, \"123 567 9.\", id=\"sentence < max\"),\n        pytest.param(\"123 567\\n\\n 9. aaaa bbb\", 10, \"123 567\", id=\"paragraph < max\"),\n        pytest.param(\"123 567 90123.\", 10, \"123 567...\", id=\"truncate\"),\n        pytest.param(\"123 5678 xxxxxx\", 10, \"123...\", id=\"length includes suffix\"),\n        pytest.param(\n            \"token in ~/.netrc ciao ciao\",\n            20,\n            \"token in ~/.netrc...\",\n            id=\"ignore dot in word\",\n        ),\n    ],\n)\n@pytest.mark.parametrize(\n    \"alter\",\n    [\n        pytest.param(None, id=\"\"),\n        pytest.param(\n            lambda text: \"\\n\\b\\n\" + \"  \".join(text.split(\" \")) + \"\\n\", id=\"no-wrap mark\"\n        ),\n    ],\n)\ndef test_make_default_short_help(value, max_length, alter, expect):\n    assert len(expect) <= max_length\n\n    if alter:\n        value = alter(value)\n\n    out = click.utils.make_default_short_help(value, max_length)\n    assert out == expect\n",
      "code_after": "import os\nimport pathlib\nimport stat\nimport subprocess\nimport sys\nfrom collections import namedtuple\nfrom contextlib import nullcontext\nfrom functools import partial\nfrom io import StringIO\nfrom pathlib import Path\nfrom tempfile import tempdir\nfrom unittest.mock import patch\n\nimport pytest\n\nimport click._termui_impl\nimport click.utils\nfrom click._compat import WIN\n\n\ndef test_echo(runner):\n    with runner.isolation() as outstreams:\n        click.echo(\"\\N{SNOWMAN}\")\n        click.echo(b\"\\x44\\x44\")\n        click.echo(42, nl=False)\n        click.echo(b\"a\", nl=False)\n        click.echo(\"\\x1b[31mx\\x1b[39m\", nl=False)\n        bytes = outstreams[0].getvalue().replace(b\"\\r\\n\", b\"\\n\")\n        assert bytes == b\"\\xe2\\x98\\x83\\nDD\\n42ax\"\n\n    # if wrapped, we expect bytes to survive.\n    @click.command()\n    def cli():\n        click.echo(b\"\\xf6\")\n\n    result = runner.invoke(cli, [])\n    assert result.stdout_bytes == b\"\\xf6\\n\"\n\n    # Ensure we do not strip for bytes.\n    with runner.isolation() as outstreams:\n        click.echo(bytearray(b\"\\x1b[31mx\\x1b[39m\"), nl=False)\n        assert outstreams[0].getvalue() == b\"\\x1b[31mx\\x1b[39m\"\n\n\ndef test_echo_custom_file():\n    f = StringIO()\n    click.echo(\"hello\", file=f)\n    assert f.getvalue() == \"hello\\n\"\n\n\ndef test_echo_no_streams(monkeypatch, runner):\n    \"\"\"echo should not fail when stdout and stderr are None with pythonw on Windows.\"\"\"\n    with runner.isolation():\n        sys.stdout = None\n        sys.stderr = None\n        click.echo(\"test\")\n        click.echo(\"test\", err=True)\n\n\n@pytest.mark.parametrize(\n    (\"styles\", \"ref\"),\n    [\n        ({\"fg\": \"black\"}, \"\\x1b[30mx y\\x1b[0m\"),\n        ({\"fg\": \"red\"}, \"\\x1b[31mx y\\x1b[0m\"),\n        ({\"fg\": \"green\"}, \"\\x1b[32mx y\\x1b[0m\"),\n        ({\"fg\": \"yellow\"}, \"\\x1b[33mx y\\x1b[0m\"),\n        ({\"fg\": \"blue\"}, \"\\x1b[34mx y\\x1b[0m\"),\n        ({\"fg\": \"magenta\"}, \"\\x1b[35mx y\\x1b[0m\"),\n        ({\"fg\": \"cyan\"}, \"\\x1b[36mx y\\x1b[0m\"),\n        ({\"fg\": \"white\"}, \"\\x1b[37mx y\\x1b[0m\"),\n        ({\"bg\": \"black\"}, \"\\x1b[40mx y\\x1b[0m\"),\n        ({\"bg\": \"red\"}, \"\\x1b[41mx y\\x1b[0m\"),\n        ({\"bg\": \"green\"}, \"\\x1b[42mx y\\x1b[0m\"),\n        ({\"bg\": \"yellow\"}, \"\\x1b[43mx y\\x1b[0m\"),\n        ({\"bg\": \"blue\"}, \"\\x1b[44mx y\\x1b[0m\"),\n        ({\"bg\": \"magenta\"}, \"\\x1b[45mx y\\x1b[0m\"),\n        ({\"bg\": \"cyan\"}, \"\\x1b[46mx y\\x1b[0m\"),\n        ({\"bg\": \"white\"}, \"\\x1b[47mx y\\x1b[0m\"),\n        ({\"bg\": 91}, \"\\x1b[48;5;91mx y\\x1b[0m\"),\n        ({\"bg\": (135, 0, 175)}, \"\\x1b[48;2;135;0;175mx y\\x1b[0m\"),\n        ({\"bold\": True}, \"\\x1b[1mx y\\x1b[0m\"),\n        ({\"dim\": True}, \"\\x1b[2mx y\\x1b[0m\"),\n        ({\"underline\": True}, \"\\x1b[4mx y\\x1b[0m\"),\n        ({\"overline\": True}, \"\\x1b[53mx y\\x1b[0m\"),\n        ({\"italic\": True}, \"\\x1b[3mx y\\x1b[0m\"),\n        ({\"blink\": True}, \"\\x1b[5mx y\\x1b[0m\"),\n        ({\"reverse\": True}, \"\\x1b[7mx y\\x1b[0m\"),\n        ({\"strikethrough\": True}, \"\\x1b[9mx y\\x1b[0m\"),\n        ({\"bold\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"dim\": False}, \"\\x1b[22mx y\\x1b[0m\"),\n        ({\"underline\": False}, \"\\x1b[24mx y\\x1b[0m\"),\n        ({\"overline\": False}, \"\\x1b[55mx y\\x1b[0m\"),\n        ({\"italic\": False}, \"\\x1b[23mx y\\x1b[0m\"),\n        ({\"blink\": False}, \"\\x1b[25mx y\\x1b[0m\"),\n        ({\"reverse\": False}, \"\\x1b[27mx y\\x1b[0m\"),\n        ({\"strikethrough\": False}, \"\\x1b[29mx y\\x1b[0m\"),\n        ({\"fg\": \"black\", \"reset\": False}, \"\\x1b[30mx y\"),\n    ],\n)\ndef test_styling(styles, ref):\n    assert click.style(\"x y\", **styles) == ref\n    assert click.unstyle(ref) == \"x y\"\n\n\n@pytest.mark.parametrize((\"text\", \"expect\"), [(\"\\x1b[?25lx y\\x1b[?25h\", \"x y\")])\ndef test_unstyle_other_ansi(text, expect):\n    assert click.unstyle(text) == expect\n\n\ndef test_filename_formatting():\n    assert click.format_filename(b\"foo.txt\") == \"foo.txt\"\n    assert click.format_filename(b\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\") == \"/x/foo.txt\"\n    assert click.format_filename(\"/x/foo.txt\", shorten=True) == \"foo.txt\"\n    assert click.format_filename(\"/x/\\ufffd.txt\", shorten=True) == \"\ufffd.txt\"\n\n\ndef test_prompts(runner):\n    @click.command()\n    def test():\n        if click.confirm(\"Foo\"):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: y\\nyes!\\n\"\n\n    result = runner.invoke(test, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: \\nno :(\\n\"\n\n    result = runner.invoke(test, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [y/N]: n\\nno :(\\n\"\n\n    @click.command()\n    def test_no():\n        if click.confirm(\"Foo\", default=True):\n            click.echo(\"yes!\")\n        else:\n            click.echo(\"no :(\")\n\n    result = runner.invoke(test_no, input=\"y\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: y\\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: \\nyes!\\n\"\n\n    result = runner.invoke(test_no, input=\"n\\n\")\n    assert not result.exception\n    assert result.output == \"Foo [Y/n]: n\\nno :(\\n\"\n\n\ndef test_confirm_repeat(runner):\n    cli = click.Command(\n        \"cli\", params=[click.Option([\"--a/--no-a\"], default=None, prompt=True)]\n    )\n    result = runner.invoke(cli, input=\"\\ny\\n\")\n    assert result.output == \"A [y/n]: \\nError: invalid input\\nA [y/n]: y\\n\"\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\ndef test_prompts_abort(monkeypatch, capsys):\n    def f(_):\n        raise KeyboardInterrupt()\n\n    monkeypatch.setattr(\"click.termui.hidden_prompt_func\", f)\n\n    try:\n        click.prompt(\"Password\", hide_input=True)\n    except click.Abort:\n        click.echo(\"interrupted\")\n\n    out, err = capsys.readouterr()\n    assert out == \"Password:\\ninterrupted\\n\"\n\n\ndef _test_gen_func():\n    yield \"a\"\n    yield \"b\"\n    yield \"c\"\n    yield \"abc\"\n\n\ndef _test_gen_func_fails():\n    yield \"test\"\n    raise RuntimeError(\"This is a test.\")\n\n\ndef _test_gen_func_echo(file=None):\n    yield \"test\"\n    click.echo(\"hello\", file=file)\n    yield \"test\"\n\n\ndef _test_simulate_keyboard_interrupt(file=None):\n    yield \"output_before_keyboard_interrupt\"\n    raise KeyboardInterrupt()\n\n\nEchoViaPagerTest = namedtuple(\n    \"EchoViaPagerTest\",\n    (\n        \"description\",\n        \"test_input\",\n        \"expected_pager\",\n        \"expected_stdout\",\n        \"expected_stderr\",\n        \"expected_error\",\n    ),\n)\n\n\n@pytest.mark.skipif(WIN, reason=\"Different behavior on windows.\")\n@pytest.mark.parametrize(\n    \"pager_cmd\", [\"cat\", \"cat \", \" cat \", \"less\", \" less\", \" less \"]\n)\n@pytest.mark.parametrize(\n    \"test\",\n    [\n        # We need to pass a parameter function instead of a plain param\n        # as pytest.mark.parametrize will reuse the parameters causing the\n        # generators to be used up so they will not yield anymore\n        EchoViaPagerTest(\n            description=\"Plain string argument\",\n            test_input=lambda: \"just text\",\n            expected_pager=\"just text\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Iterable argument\",\n            test_input=lambda: [\"itera\", \"ble\"],\n            expected_pager=\"iterable\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Generator function argument\",\n            test_input=lambda: _test_gen_func,\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"String generator argument\",\n            test_input=lambda: _test_gen_func(),\n            expected_pager=\"abcabc\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Number generator expression argument\",\n            test_input=lambda: (c for c in range(6)),\n            expected_pager=\"012345\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator function argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have\n            # a chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Exception in generator argument\",\n            test_input=lambda: _test_gen_func_fails,\n            # Because generator throws early on, the pager did not have a\n            # chance yet to write the file.\n            expected_pager=\"\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=RuntimeError,\n        ),\n        EchoViaPagerTest(\n            description=\"Keyboard interrupt should not terminate the pager\",\n            test_input=lambda: _test_simulate_keyboard_interrupt(),\n            # Due to the keyboard interrupt during pager execution, click program\n            # should abort, but the pager should stay open.\n            # This allows users to cancel the program and search in the pager\n            # output, before they decide to terminate the pager.\n            expected_pager=\"output_before_keyboard_interrupt\",\n            expected_stdout=\"\",\n            expected_stderr=\"\",\n            expected_error=KeyboardInterrupt,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stdout during generator execution\",\n            test_input=lambda: _test_gen_func_echo(),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"hello\\n\",\n            expected_stderr=\"\",\n            expected_error=None,\n        ),\n        EchoViaPagerTest(\n            description=\"Writing to stderr during generator execution\",\n            test_input=lambda: _test_gen_func_echo(file=sys.stderr),\n            expected_pager=\"testtest\\n\",\n            expected_stdout=\"\",\n            expected_stderr=\"hello\\n\",\n            expected_error=None,\n        ),\n    ],\n)\ndef test_echo_via_pager(monkeypatch, capfd, pager_cmd, test):\n    monkeypatch.setitem(os.environ, \"PAGER\", pager_cmd)\n    monkeypatch.setattr(click._termui_impl, \"isatty\", lambda x: True)\n\n    test_input = test.test_input()\n    expected_pager = test.expected_pager\n    expected_stdout = test.expected_stdout\n    expected_stderr = test.expected_stderr\n    expected_error = test.expected_error\n\n    check_raise = pytest.raises(expected_error) if expected_error else nullcontext()\n\n    pager_out_tmp = Path(tempdir) / \"pager_out.txt\"\n    pager_out_tmp.unlink(missing_ok=True)\n    with pager_out_tmp.open(\"w\") as f:\n        force_subprocess_stdout = patch.object(\n            subprocess,\n            \"Popen\",\n            partial(subprocess.Popen, stdout=f),\n        )\n        with force_subprocess_stdout:\n            with check_raise:\n                click.echo_via_pager(test_input)\n\n    out, err = capfd.readouterr()\n\n    pager = pager_out_tmp.read_text()\n\n    assert pager == expected_pager, (\n        f\"Unexpected pager output in test case '{test.description}'\"\n    )\n    assert out == expected_stdout, (\n        f\"Unexpected stdout in test case '{test.description}'\"\n    )\n    assert err == expected_stderr, (\n        f\"Unexpected stderr in test case '{test.description}'\"\n    )\n\n\ndef test_echo_color_flag(monkeypatch, capfd):\n    isatty = True\n    monkeypatch.setattr(click._compat, \"isatty\", lambda x: isatty)\n\n    text = \"foo\"\n    styled_text = click.style(text, fg=\"red\")\n    assert styled_text == \"\\x1b[31mfoo\\x1b[0m\"\n\n    click.echo(styled_text, color=False)\n    out, err = capfd.readouterr()\n    assert out == f\"{text}\\n\"\n\n    click.echo(styled_text, color=True)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = True\n    click.echo(styled_text)\n    out, err = capfd.readouterr()\n    assert out == f\"{styled_text}\\n\"\n\n    isatty = False\n    # Faking isatty() is not enough on Windows;\n    # the implementation caches the colorama wrapped stream\n    # so we have to use a new stream for each test\n    stream = StringIO()\n    click.echo(styled_text, file=stream)\n    assert stream.getvalue() == f\"{text}\\n\"\n\n    stream = StringIO()\n    click.echo(styled_text, file=stream, color=True)\n    assert stream.getvalue() == f\"{styled_text}\\n\"\n\n\ndef test_prompt_cast_default(capfd, monkeypatch):\n    monkeypatch.setattr(sys, \"stdin\", StringIO(\"\\n\"))\n    value = click.prompt(\"value\", default=\"100\", type=int)\n    capfd.readouterr()\n    assert isinstance(value, int)\n\n\n@pytest.mark.skipif(WIN, reason=\"Test too complex to make work windows.\")\ndef test_echo_writing_to_standard_error(capfd, monkeypatch):\n    def emulate_input(text):\n        \"\"\"Emulate keyboard input.\"\"\"\n        monkeypatch.setattr(sys, \"stdin\", StringIO(text))\n\n    click.echo(\"Echo to standard output\")\n    out, err = capfd.readouterr()\n    assert out == \"Echo to standard output\\n\"\n    assert err == \"\"\n\n    click.echo(\"Echo to standard error\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Echo to standard error\\n\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin: \"\n    assert err == \"\"\n\n    emulate_input(\"asdlkj\\n\")\n    click.prompt(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr:\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stdin\")\n    out, err = capfd.readouterr()\n    assert out == \"Prompt to stdin [y/N]: \"\n    assert err == \"\"\n\n    emulate_input(\"y\\n\")\n    click.confirm(\"Prompt to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \" \"\n    assert err == \"Prompt to stderr [y/N]:\"\n\n    monkeypatch.setattr(click.termui, \"isatty\", lambda x: True)\n    monkeypatch.setattr(click.termui, \"getchar\", lambda: \" \")\n\n    click.pause(\"Pause to stdout\")\n    out, err = capfd.readouterr()\n    assert out == \"Pause to stdout\\n\"\n    assert err == \"\"\n\n    click.pause(\"Pause to stderr\", err=True)\n    out, err = capfd.readouterr()\n    assert out == \"\"\n    assert err == \"Pause to stderr\\n\"\n\n\ndef test_echo_with_capsys(capsys):\n    click.echo(\"Capture me.\")\n    out, err = capsys.readouterr()\n    assert out == \"Capture me.\\n\"\n\n\ndef test_open_file(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        click.echo(\"meep\")\n\n    with runner.isolated_filesystem():\n        with open(\"hello.txt\", \"w\") as f:\n            f.write(\"Cool stuff\")\n\n        result = runner.invoke(cli, [\"hello.txt\"])\n        assert result.exception is None\n        assert result.output == \"Cool stuff\\nmeep\\n\"\n\n        result = runner.invoke(cli, [\"-\"], input=\"foobar\")\n        assert result.exception is None\n        assert result.output == \"foobar\\nmeep\\n\"\n\n\ndef test_open_file_pathlib_dash(runner):\n    @click.command()\n    @click.argument(\n        \"filename\", type=click.Path(allow_dash=True, path_type=pathlib.Path)\n    )\n    def cli(filename):\n        click.echo(str(type(filename)))\n\n        with click.open_file(filename) as f:\n            click.echo(f.read())\n\n        result = runner.invoke(cli, [\"-\"], input=\"value\")\n        assert result.exception is None\n        assert result.output == \"pathlib.Path\\nvalue\\n\"\n\n\ndef test_open_file_ignore_errors_stdin(runner):\n    @click.command()\n    @click.argument(\"filename\")\n    def cli(filename):\n        with click.open_file(filename, errors=\"ignore\") as f:\n            click.echo(f.read())\n\n    result = runner.invoke(cli, [\"-\"], input=os.urandom(16))\n    assert result.exception is None\n\n\ndef test_open_file_respects_ignore(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"w\") as f:\n            f.write(\"Hello world!\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            assert f.errors == \"ignore\"\n\n\ndef test_open_file_ignore_invalid_utf8(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.txt\", \"wb\") as f:\n            f.write(b\"\\xe2\\x28\\xa1\")\n\n        with click.open_file(\"test.txt\", encoding=\"utf8\", errors=\"ignore\") as f:\n            f.read()\n\n\ndef test_open_file_ignore_no_encoding(runner):\n    with runner.isolated_filesystem():\n        with open(\"test.bin\", \"wb\") as f:\n            f.write(os.urandom(16))\n\n        with click.open_file(\"test.bin\", errors=\"ignore\") as f:\n            f.read()\n\n\n@pytest.mark.skipif(WIN, reason=\"os.chmod() is not fully supported on Windows.\")\n@pytest.mark.parametrize(\"permissions\", [0o400, 0o444, 0o600, 0o644])\ndef test_open_file_atomic_permissions_existing_file(runner, permissions):\n    with runner.isolated_filesystem():\n        with open(\"existing.txt\", \"w\") as f:\n            f.write(\"content\")\n        os.chmod(\"existing.txt\", permissions)\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        result = runner.invoke(cli, [\"existing.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"existing.txt\").st_mode) == permissions\n\n\n@pytest.mark.skipif(WIN, reason=\"os.stat() is not fully supported on Windows.\")\ndef test_open_file_atomic_permissions_new_file(runner):\n    with runner.isolated_filesystem():\n\n        @click.command()\n        @click.argument(\"filename\")\n        def cli(filename):\n            click.open_file(filename, \"w\", atomic=True).close()\n\n        # Create a test file to get the expected permissions for new files\n        # according to the current umask.\n        with open(\"test.txt\", \"w\"):\n            pass\n        permissions = stat.S_IMODE(os.stat(\"test.txt\").st_mode)\n\n        result = runner.invoke(cli, [\"new.txt\"])\n        assert result.exception is None\n        assert stat.S_IMODE(os.stat(\"new.txt\").st_mode) == permissions\n\n\ndef test_iter_keepopenfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        for e_line, a_line in zip(expected, click.utils.KeepOpenFile(f), strict=False):\n            assert e_line == a_line.strip()\n\n\ndef test_iter_lazyfile(tmpdir):\n    expected = list(map(str, range(10)))\n    p = tmpdir.mkdir(\"testdir\").join(\"testfile\")\n    p.write(\"\\n\".join(expected))\n    with p.open() as f:\n        with click.utils.LazyFile(f.name) as lf:\n            for e_line, a_line in zip(expected, lf, strict=False):\n                assert e_line == a_line.strip()\n\n\nclass MockMain:\n    __slots__ = \"__package__\"\n\n    def __init__(self, package_name):\n        self.__package__ = package_name\n\n\n@pytest.mark.parametrize(\n    (\"path\", \"main\", \"expected\"),\n    [\n        (\"example.py\", None, \"example.py\"),\n        (str(pathlib.Path(\"/foo/bar/example.py\")), None, \"example.py\"),\n        (\"example\", None, \"example\"),\n        (str(pathlib.Path(\"example/__main__.py\")), \"example\", \"python -m example\"),\n        (str(pathlib.Path(\"example/cli.py\")), \"example\", \"python -m example.cli\"),\n        (str(pathlib.Path(\"./example\")), \"\", \"example\"),\n    ],\n)\ndef test_detect_program_name(path, main, expected):\n    assert click.utils._detect_program_name(path, _main=MockMain(main)) == expected\n\n\ndef test_expand_args(monkeypatch):\n    user = os.path.expanduser(\"~\")\n    assert user in click.utils._expand_args([\"~\"])\n    monkeypatch.setenv(\"CLICK_TEST\", \"hello\")\n    assert \"hello\" in click.utils._expand_args([\"$CLICK_TEST\"])\n    assert \"pyproject.toml\" in click.utils._expand_args([\"*.toml\"])\n    assert os.path.join(\"docs\", \"conf.py\") in click.utils._expand_args([\"**/conf.py\"])\n    assert \"*.not-found\" in click.utils._expand_args([\"*.not-found\"])\n    # a bad glob pattern, such as a pytest identifier, should return itself\n    assert click.utils._expand_args([\"test.py::test_bad\"])[0] == \"test.py::test_bad\"\n\n\n@pytest.mark.parametrize(\n    (\"value\", \"max_length\", \"expect\"),\n    [\n        pytest.param(\"\", 10, \"\", id=\"empty\"),\n        pytest.param(\"123 567 90\", 10, \"123 567 90\", id=\"equal length, no dot\"),\n        pytest.param(\"123 567 9. aaaa bbb\", 10, \"123 567 9.\", id=\"sentence < max\"),\n        pytest.param(\"123 567\\n\\n 9. aaaa bbb\", 10, \"123 567\", id=\"paragraph < max\"),\n        pytest.param(\"123 567 90123.\", 10, \"123 567...\", id=\"truncate\"),\n        pytest.param(\"123 5678 xxxxxx\", 10, \"123...\", id=\"length includes suffix\"),\n        pytest.param(\n            \"token in ~/.netrc ciao ciao\",\n            20,\n            \"token in ~/.netrc...\",\n            id=\"ignore dot in word\",\n        ),\n    ],\n)\n@pytest.mark.parametrize(\n    \"alter\",\n    [\n        pytest.param(None, id=\"\"),\n        pytest.param(\n            lambda text: \"\\n\\b\\n\" + \"  \".join(text.split(\" \")) + \"\\n\", id=\"no-wrap mark\"\n        ),\n    ],\n)\ndef test_make_default_short_help(value, max_length, alter, expect):\n    assert len(expect) <= max_length\n\n    if alter:\n        value = alter(value)\n\n    out = click.utils.make_default_short_help(value, max_length)\n    assert out == expect\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "70496242f45a",
      "repo": "click",
      "commit_hash": "6fec395",
      "commit_message": "fix pyright findings",
      "file_path": "src/click/_winconsole.py",
      "language": "python",
      "code_before": "# This module is based on the excellent work by Adam Barto\u0161 who\n# provided a lot of what went into the implementation here in\n# the discussion to issue1602 in the Python bug tracker.\n#\n# There are some general differences in regards to how this works\n# compared to the original patches as we do not need to patch\n# the entire interpreter but just work in our little world of\n# echo and prompt.\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport io\nimport sys\nimport time\nimport typing as t\nfrom ctypes import Array\nfrom ctypes import byref\nfrom ctypes import c_char\nfrom ctypes import c_char_p\nfrom ctypes import c_int\nfrom ctypes import c_ssize_t\nfrom ctypes import c_ulong\nfrom ctypes import c_void_p\nfrom ctypes import POINTER\nfrom ctypes import py_object\nfrom ctypes import Structure\nfrom ctypes.wintypes import DWORD\nfrom ctypes.wintypes import HANDLE\nfrom ctypes.wintypes import LPCWSTR\nfrom ctypes.wintypes import LPWSTR\n\nfrom ._compat import _NonClosingTextIOWrapper\n\nassert sys.platform == \"win32\"\nimport msvcrt  # noqa: E402\nfrom ctypes import windll  # noqa: E402\nfrom ctypes import WINFUNCTYPE  # noqa: E402\n\nc_ssize_p = POINTER(c_ssize_t)\n\nkernel32 = windll.kernel32\nGetStdHandle = kernel32.GetStdHandle\nReadConsoleW = kernel32.ReadConsoleW\nWriteConsoleW = kernel32.WriteConsoleW\nGetConsoleMode = kernel32.GetConsoleMode\nGetLastError = kernel32.GetLastError\nGetCommandLineW = WINFUNCTYPE(LPWSTR)((\"GetCommandLineW\", windll.kernel32))\nCommandLineToArgvW = WINFUNCTYPE(POINTER(LPWSTR), LPCWSTR, POINTER(c_int))(\n    (\"CommandLineToArgvW\", windll.shell32)\n)\nLocalFree = WINFUNCTYPE(c_void_p, c_void_p)((\"LocalFree\", windll.kernel32))\n\nSTDIN_HANDLE = GetStdHandle(-10)\nSTDOUT_HANDLE = GetStdHandle(-11)\nSTDERR_HANDLE = GetStdHandle(-12)\n\nPyBUF_SIMPLE = 0\nPyBUF_WRITABLE = 1\n\nERROR_SUCCESS = 0\nERROR_NOT_ENOUGH_MEMORY = 8\nERROR_OPERATION_ABORTED = 995\n\nSTDIN_FILENO = 0\nSTDOUT_FILENO = 1\nSTDERR_FILENO = 2\n\nEOF = b\"\\x1a\"\nMAX_BYTES_WRITTEN = 32767\n\nif t.TYPE_CHECKING:\n    try:\n        # Using `typing_extensions.Buffer` instead of `collections.abc`\n        # on Windows for some reason does not have `Sized` implemented.\n        from collections.abc import Buffer  # type: ignore\n    except ImportError:\n        from typing_extensions import Buffer\n\ntry:\n    from ctypes import pythonapi\nexcept ImportError:\n    # On PyPy we cannot get buffers so our ability to operate here is\n    # severely limited.\n    get_buffer = None\nelse:\n\n    class Py_buffer(Structure):\n        _fields_ = [  # noqa: RUF012\n            (\"buf\", c_void_p),\n            (\"obj\", py_object),\n            (\"len\", c_ssize_t),\n            (\"itemsize\", c_ssize_t),\n            (\"readonly\", c_int),\n            (\"ndim\", c_int),\n            (\"format\", c_char_p),\n            (\"shape\", c_ssize_p),\n            (\"strides\", c_ssize_p),\n            (\"suboffsets\", c_ssize_p),\n            (\"internal\", c_void_p),\n        ]\n\n    PyObject_GetBuffer = pythonapi.PyObject_GetBuffer\n    PyBuffer_Release = pythonapi.PyBuffer_Release\n\n    def get_buffer(obj: Buffer, writable: bool = False) -> Array[c_char]:\n        buf = Py_buffer()\n        flags: int = PyBUF_WRITABLE if writable else PyBUF_SIMPLE\n        PyObject_GetBuffer(py_object(obj), byref(buf), flags)\n\n        try:\n            buffer_type: Array[c_char] = c_char * buf.len\n            return buffer_type.from_address(buf.buf)  # type: ignore[attr-defined, no-any-return]\n        finally:\n            PyBuffer_Release(byref(buf))\n\n\nclass _WindowsConsoleRawIOBase(io.RawIOBase):\n    def __init__(self, handle: int | None) -> None:\n        self.handle = handle\n\n    def isatty(self) -> t.Literal[True]:\n        super().isatty()\n        return True\n\n\nclass _WindowsConsoleReader(_WindowsConsoleRawIOBase):\n    def readable(self) -> t.Literal[True]:\n        return True\n\n    def readinto(self, b: Buffer) -> int:\n        bytes_to_be_read = len(b)\n        if not bytes_to_be_read:\n            return 0\n        elif bytes_to_be_read % 2:\n            raise ValueError(\n                \"cannot read odd number of bytes from UTF-16-LE encoded console\"\n            )\n\n        buffer = get_buffer(b, writable=True)\n        code_units_to_be_read = bytes_to_be_read // 2\n        code_units_read = c_ulong()\n\n        rv = ReadConsoleW(\n            HANDLE(self.handle),\n            buffer,\n            code_units_to_be_read,\n            byref(code_units_read),\n            None,\n        )\n        if GetLastError() == ERROR_OPERATION_ABORTED:\n            # wait for KeyboardInterrupt\n            time.sleep(0.1)\n        if not rv:\n            raise OSError(f\"Windows error: {GetLastError()}\")\n\n        if buffer[0] == EOF:\n            return 0\n        return 2 * code_units_read.value\n\n\nclass _WindowsConsoleWriter(_WindowsConsoleRawIOBase):\n    def writable(self) -> t.Literal[True]:\n        return True\n\n    @staticmethod\n    def _get_error_message(errno: int) -> str:\n        if errno == ERROR_SUCCESS:\n            return \"ERROR_SUCCESS\"\n        elif errno == ERROR_NOT_ENOUGH_MEMORY:\n            return \"ERROR_NOT_ENOUGH_MEMORY\"\n        return f\"Windows error {errno}\"\n\n    def write(self, b: Buffer) -> int:\n        bytes_to_be_written = len(b)\n        buf = get_buffer(b)\n        code_units_to_be_written = min(bytes_to_be_written, MAX_BYTES_WRITTEN) // 2\n        code_units_written = c_ulong()\n\n        WriteConsoleW(\n            HANDLE(self.handle),\n            buf,\n            code_units_to_be_written,\n            byref(code_units_written),\n            None,\n        )\n        bytes_written = 2 * code_units_written.value\n\n        if bytes_written == 0 and bytes_to_be_written > 0:\n            raise OSError(self._get_error_message(GetLastError()))\n        return bytes_written\n\n\nclass ConsoleStream:\n    def __init__(self, text_stream: t.TextIO, byte_stream: t.BinaryIO) -> None:\n        self._text_stream = text_stream\n        self.buffer = byte_stream\n\n    @property\n    def name(self) -> str:\n        return self.buffer.name\n\n    def write(self, x: t.AnyStr) -> int:\n        if isinstance(x, str):\n            return self._text_stream.write(x)\n        try:\n            self.flush()\n        except Exception:\n            pass\n        return self.buffer.write(x)\n\n    def writelines(self, lines: cabc.Iterable[t.AnyStr]) -> None:\n        for line in lines:\n            self.write(line)\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self._text_stream, name)\n\n    def isatty(self) -> bool:\n        return self.buffer.isatty()\n\n    def __repr__(self) -> str:\n        return f\"<ConsoleStream name={self.name!r} encoding={self.encoding!r}>\"\n\n\ndef _get_text_stdin(buffer_stream: t.BinaryIO) -> t.TextIO:\n    text_stream = _NonClosingTextIOWrapper(\n        io.BufferedReader(_WindowsConsoleReader(STDIN_HANDLE)),\n        \"utf-16-le\",\n        \"strict\",\n        line_buffering=True,\n    )\n    return t.cast(t.TextIO, ConsoleStream(text_stream, buffer_stream))\n\n\ndef _get_text_stdout(buffer_stream: t.BinaryIO) -> t.TextIO:\n    text_stream = _NonClosingTextIOWrapper(\n        io.BufferedWriter(_WindowsConsoleWriter(STDOUT_HANDLE)),\n        \"utf-16-le\",\n        \"strict\",\n        line_buffering=True,\n    )\n    return t.cast(t.TextIO, ConsoleStream(text_stream, buffer_stream))\n\n\ndef _get_text_stderr(buffer_stream: t.BinaryIO) -> t.TextIO:\n    text_stream = _NonClosingTextIOWrapper(\n        io.BufferedWriter(_WindowsConsoleWriter(STDERR_HANDLE)),\n        \"utf-16-le\",\n        \"strict\",\n        line_buffering=True,\n    )\n    return t.cast(t.TextIO, ConsoleStream(text_stream, buffer_stream))\n\n\n_stream_factories: cabc.Mapping[int, t.Callable[[t.BinaryIO], t.TextIO]] = {\n    0: _get_text_stdin,\n    1: _get_text_stdout,\n    2: _get_text_stderr,\n}\n\n\ndef _is_console(f: t.TextIO) -> bool:\n    if not hasattr(f, \"fileno\"):\n        return False\n\n    try:\n        fileno = f.fileno()\n    except (OSError, io.UnsupportedOperation):\n        return False\n\n    handle = msvcrt.get_osfhandle(fileno)\n    return bool(GetConsoleMode(handle, byref(DWORD())))\n\n\ndef _get_windows_console_stream(\n    f: t.TextIO, encoding: str | None, errors: str | None\n) -> t.TextIO | None:\n    if (\n        get_buffer is None\n        or encoding not in {\"utf-16-le\", None}\n        or errors not in {\"strict\", None}\n        or not _is_console(f)\n    ):\n        return None\n\n    func = _stream_factories.get(f.fileno())\n    if func is None:\n        return None\n\n    b = getattr(f, \"buffer\", None)\n\n    if b is None:\n        return None\n\n    return func(b)\n",
      "code_after": "# This module is based on the excellent work by Adam Barto\u0161 who\n# provided a lot of what went into the implementation here in\n# the discussion to issue1602 in the Python bug tracker.\n#\n# There are some general differences in regards to how this works\n# compared to the original patches as we do not need to patch\n# the entire interpreter but just work in our little world of\n# echo and prompt.\nfrom __future__ import annotations\n\nimport collections.abc as cabc\nimport io\nimport sys\nimport time\nimport typing as t\nfrom ctypes import Array\nfrom ctypes import byref\nfrom ctypes import c_char\nfrom ctypes import c_char_p\nfrom ctypes import c_int\nfrom ctypes import c_ssize_t\nfrom ctypes import c_ulong\nfrom ctypes import c_void_p\nfrom ctypes import POINTER\nfrom ctypes import py_object\nfrom ctypes import Structure\nfrom ctypes.wintypes import DWORD\nfrom ctypes.wintypes import HANDLE\nfrom ctypes.wintypes import LPCWSTR\nfrom ctypes.wintypes import LPWSTR\n\nfrom ._compat import _NonClosingTextIOWrapper\n\nassert sys.platform == \"win32\"\nimport msvcrt  # noqa: E402\nfrom ctypes import windll  # noqa: E402\nfrom ctypes import WINFUNCTYPE  # noqa: E402\n\nc_ssize_p = POINTER(c_ssize_t)\n\nkernel32 = windll.kernel32\nGetStdHandle = kernel32.GetStdHandle\nReadConsoleW = kernel32.ReadConsoleW\nWriteConsoleW = kernel32.WriteConsoleW\nGetConsoleMode = kernel32.GetConsoleMode\nGetLastError = kernel32.GetLastError\nGetCommandLineW = WINFUNCTYPE(LPWSTR)((\"GetCommandLineW\", windll.kernel32))\nCommandLineToArgvW = WINFUNCTYPE(POINTER(LPWSTR), LPCWSTR, POINTER(c_int))(\n    (\"CommandLineToArgvW\", windll.shell32)\n)\nLocalFree = WINFUNCTYPE(c_void_p, c_void_p)((\"LocalFree\", windll.kernel32))\n\nSTDIN_HANDLE = GetStdHandle(-10)\nSTDOUT_HANDLE = GetStdHandle(-11)\nSTDERR_HANDLE = GetStdHandle(-12)\n\nPyBUF_SIMPLE = 0\nPyBUF_WRITABLE = 1\n\nERROR_SUCCESS = 0\nERROR_NOT_ENOUGH_MEMORY = 8\nERROR_OPERATION_ABORTED = 995\n\nSTDIN_FILENO = 0\nSTDOUT_FILENO = 1\nSTDERR_FILENO = 2\n\nEOF = b\"\\x1a\"\nMAX_BYTES_WRITTEN = 32767\n\nif t.TYPE_CHECKING:\n    try:\n        # Using `typing_extensions.Buffer` instead of `collections.abc`\n        # on Windows for some reason does not have `Sized` implemented.\n        from collections.abc import Buffer  # type: ignore\n    except ImportError:\n        from typing_extensions import Buffer\n\ntry:\n    from ctypes import pythonapi\nexcept ImportError:\n    # On PyPy we cannot get buffers so our ability to operate here is\n    # severely limited.\n    get_buffer = None\nelse:\n\n    class Py_buffer(Structure):\n        _fields_ = [  # noqa: RUF012\n            (\"buf\", c_void_p),\n            (\"obj\", py_object),\n            (\"len\", c_ssize_t),\n            (\"itemsize\", c_ssize_t),\n            (\"readonly\", c_int),\n            (\"ndim\", c_int),\n            (\"format\", c_char_p),\n            (\"shape\", c_ssize_p),\n            (\"strides\", c_ssize_p),\n            (\"suboffsets\", c_ssize_p),\n            (\"internal\", c_void_p),\n        ]\n\n    PyObject_GetBuffer = pythonapi.PyObject_GetBuffer\n    PyBuffer_Release = pythonapi.PyBuffer_Release\n\n    def get_buffer(obj: Buffer, writable: bool = False) -> Array[c_char]:\n        buf = Py_buffer()\n        flags: int = PyBUF_WRITABLE if writable else PyBUF_SIMPLE\n        PyObject_GetBuffer(py_object(obj), byref(buf), flags)\n\n        try:\n            buffer_type = c_char * buf.len\n            out: Array[c_char] = buffer_type.from_address(buf.buf)\n            return out\n        finally:\n            PyBuffer_Release(byref(buf))\n\n\nclass _WindowsConsoleRawIOBase(io.RawIOBase):\n    def __init__(self, handle: int | None) -> None:\n        self.handle = handle\n\n    def isatty(self) -> t.Literal[True]:\n        super().isatty()\n        return True\n\n\nclass _WindowsConsoleReader(_WindowsConsoleRawIOBase):\n    def readable(self) -> t.Literal[True]:\n        return True\n\n    def readinto(self, b: Buffer) -> int:\n        bytes_to_be_read = len(b)\n        if not bytes_to_be_read:\n            return 0\n        elif bytes_to_be_read % 2:\n            raise ValueError(\n                \"cannot read odd number of bytes from UTF-16-LE encoded console\"\n            )\n\n        buffer = get_buffer(b, writable=True)\n        code_units_to_be_read = bytes_to_be_read // 2\n        code_units_read = c_ulong()\n\n        rv = ReadConsoleW(\n            HANDLE(self.handle),\n            buffer,\n            code_units_to_be_read,\n            byref(code_units_read),\n            None,\n        )\n        if GetLastError() == ERROR_OPERATION_ABORTED:\n            # wait for KeyboardInterrupt\n            time.sleep(0.1)\n        if not rv:\n            raise OSError(f\"Windows error: {GetLastError()}\")\n\n        if buffer[0] == EOF:\n            return 0\n        return 2 * code_units_read.value\n\n\nclass _WindowsConsoleWriter(_WindowsConsoleRawIOBase):\n    def writable(self) -> t.Literal[True]:\n        return True\n\n    @staticmethod\n    def _get_error_message(errno: int) -> str:\n        if errno == ERROR_SUCCESS:\n            return \"ERROR_SUCCESS\"\n        elif errno == ERROR_NOT_ENOUGH_MEMORY:\n            return \"ERROR_NOT_ENOUGH_MEMORY\"\n        return f\"Windows error {errno}\"\n\n    def write(self, b: Buffer) -> int:\n        bytes_to_be_written = len(b)\n        buf = get_buffer(b)\n        code_units_to_be_written = min(bytes_to_be_written, MAX_BYTES_WRITTEN) // 2\n        code_units_written = c_ulong()\n\n        WriteConsoleW(\n            HANDLE(self.handle),\n            buf,\n            code_units_to_be_written,\n            byref(code_units_written),\n            None,\n        )\n        bytes_written = 2 * code_units_written.value\n\n        if bytes_written == 0 and bytes_to_be_written > 0:\n            raise OSError(self._get_error_message(GetLastError()))\n        return bytes_written\n\n\nclass ConsoleStream:\n    def __init__(self, text_stream: t.TextIO, byte_stream: t.BinaryIO) -> None:\n        self._text_stream = text_stream\n        self.buffer = byte_stream\n\n    @property\n    def name(self) -> str:\n        return self.buffer.name\n\n    def write(self, x: t.AnyStr) -> int:\n        if isinstance(x, str):\n            return self._text_stream.write(x)\n        try:\n            self.flush()\n        except Exception:\n            pass\n        return self.buffer.write(x)\n\n    def writelines(self, lines: cabc.Iterable[t.AnyStr]) -> None:\n        for line in lines:\n            self.write(line)\n\n    def __getattr__(self, name: str) -> t.Any:\n        return getattr(self._text_stream, name)\n\n    def isatty(self) -> bool:\n        return self.buffer.isatty()\n\n    def __repr__(self) -> str:\n        return f\"<ConsoleStream name={self.name!r} encoding={self.encoding!r}>\"\n\n\ndef _get_text_stdin(buffer_stream: t.BinaryIO) -> t.TextIO:\n    text_stream = _NonClosingTextIOWrapper(\n        io.BufferedReader(_WindowsConsoleReader(STDIN_HANDLE)),\n        \"utf-16-le\",\n        \"strict\",\n        line_buffering=True,\n    )\n    return t.cast(t.TextIO, ConsoleStream(text_stream, buffer_stream))\n\n\ndef _get_text_stdout(buffer_stream: t.BinaryIO) -> t.TextIO:\n    text_stream = _NonClosingTextIOWrapper(\n        io.BufferedWriter(_WindowsConsoleWriter(STDOUT_HANDLE)),\n        \"utf-16-le\",\n        \"strict\",\n        line_buffering=True,\n    )\n    return t.cast(t.TextIO, ConsoleStream(text_stream, buffer_stream))\n\n\ndef _get_text_stderr(buffer_stream: t.BinaryIO) -> t.TextIO:\n    text_stream = _NonClosingTextIOWrapper(\n        io.BufferedWriter(_WindowsConsoleWriter(STDERR_HANDLE)),\n        \"utf-16-le\",\n        \"strict\",\n        line_buffering=True,\n    )\n    return t.cast(t.TextIO, ConsoleStream(text_stream, buffer_stream))\n\n\n_stream_factories: cabc.Mapping[int, t.Callable[[t.BinaryIO], t.TextIO]] = {\n    0: _get_text_stdin,\n    1: _get_text_stdout,\n    2: _get_text_stderr,\n}\n\n\ndef _is_console(f: t.TextIO) -> bool:\n    if not hasattr(f, \"fileno\"):\n        return False\n\n    try:\n        fileno = f.fileno()\n    except (OSError, io.UnsupportedOperation):\n        return False\n\n    handle = msvcrt.get_osfhandle(fileno)\n    return bool(GetConsoleMode(handle, byref(DWORD())))\n\n\ndef _get_windows_console_stream(\n    f: t.TextIO, encoding: str | None, errors: str | None\n) -> t.TextIO | None:\n    if (\n        get_buffer is None\n        or encoding not in {\"utf-16-le\", None}\n        or errors not in {\"strict\", None}\n        or not _is_console(f)\n    ):\n        return None\n\n    func = _stream_factories.get(f.fileno())\n    if func is None:\n        return None\n\n    b = getattr(f, \"buffer\", None)\n\n    if b is None:\n        return None\n\n    return func(b)\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "1d1a0599f135",
      "repo": "click",
      "commit_hash": "4d7ce02",
      "commit_message": "fix mypy findings",
      "file_path": "src/click/decorators.py",
      "language": "python",
      "code_before": "import inspect\nimport types\nimport typing as t\nfrom functools import update_wrapper\nfrom gettext import gettext as _\n\nfrom .core import Argument\nfrom .core import Command\nfrom .core import Context\nfrom .core import Group\nfrom .core import Option\nfrom .core import Parameter\nfrom .globals import get_current_context\nfrom .utils import echo\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    P = te.ParamSpec(\"P\")\n\nR = t.TypeVar(\"R\")\nT = t.TypeVar(\"T\")\n_AnyCallable = t.Callable[..., t.Any]\nFC = t.TypeVar(\"FC\", bound=t.Union[_AnyCallable, Command])\n\n\ndef pass_context(f: \"t.Callable[te.Concatenate[Context, P], R]\") -> \"t.Callable[P, R]\":\n    \"\"\"Marks a callback as wanting to receive the current context\n    object as first argument.\n    \"\"\"\n\n    def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> \"R\":\n        return f(get_current_context(), *args, **kwargs)\n\n    return update_wrapper(new_func, f)\n\n\ndef pass_obj(f: \"t.Callable[te.Concatenate[t.Any, P], R]\") -> \"t.Callable[P, R]\":\n    \"\"\"Similar to :func:`pass_context`, but only pass the object on the\n    context onwards (:attr:`Context.obj`).  This is useful if that object\n    represents the state of a nested system.\n    \"\"\"\n\n    def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> \"R\":\n        return f(get_current_context().obj, *args, **kwargs)\n\n    return update_wrapper(new_func, f)\n\n\ndef make_pass_decorator(\n    object_type: t.Type[T], ensure: bool = False\n) -> t.Callable[[\"t.Callable[te.Concatenate[T, P], R]\"], \"t.Callable[P, R]\"]:\n    \"\"\"Given an object type this creates a decorator that will work\n    similar to :func:`pass_obj` but instead of passing the object of the\n    current context, it will find the innermost context of type\n    :func:`object_type`.\n\n    This generates a decorator that works roughly like this::\n\n        from functools import update_wrapper\n\n        def decorator(f):\n            @pass_context\n            def new_func(ctx, *args, **kwargs):\n                obj = ctx.find_object(object_type)\n                return ctx.invoke(f, obj, *args, **kwargs)\n            return update_wrapper(new_func, f)\n        return decorator\n\n    :param object_type: the type of the object to pass.\n    :param ensure: if set to `True`, a new object will be created and\n                   remembered on the context if it's not there yet.\n    \"\"\"\n\n    def decorator(f: \"t.Callable[te.Concatenate[T, P], R]\") -> \"t.Callable[P, R]\":\n        def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> \"R\":\n            ctx = get_current_context()\n\n            obj: t.Optional[T]\n            if ensure:\n                obj = ctx.ensure_object(object_type)\n            else:\n                obj = ctx.find_object(object_type)\n\n            if obj is None:\n                raise RuntimeError(\n                    \"Managed to invoke callback without a context\"\n                    f\" object of type {object_type.__name__!r}\"\n                    \" existing.\"\n                )\n\n            return ctx.invoke(f, obj, *args, **kwargs)\n\n        return update_wrapper(new_func, f)\n\n    return decorator  # type: ignore[return-value]\n\n\ndef pass_meta_key(\n    key: str, *, doc_description: t.Optional[str] = None\n) -> \"t.Callable[[t.Callable[te.Concatenate[t.Any, P], R]], t.Callable[P, R]]\":\n    \"\"\"Create a decorator that passes a key from\n    :attr:`click.Context.meta` as the first argument to the decorated\n    function.\n\n    :param key: Key in ``Context.meta`` to pass.\n    :param doc_description: Description of the object being passed,\n        inserted into the decorator's docstring. Defaults to \"the 'key'\n        key from Context.meta\".\n\n    .. versionadded:: 8.0\n    \"\"\"\n\n    def decorator(f: \"t.Callable[te.Concatenate[t.Any, P], R]\") -> \"t.Callable[P, R]\":\n        def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> R:\n            ctx = get_current_context()\n            obj = ctx.meta[key]\n            return ctx.invoke(f, obj, *args, **kwargs)\n\n        return update_wrapper(new_func, f)\n\n    if doc_description is None:\n        doc_description = f\"the {key!r} key from :attr:`click.Context.meta`\"\n\n    decorator.__doc__ = (\n        f\"Decorator that passes {doc_description} as the first argument\"\n        \" to the decorated function.\"\n    )\n    return decorator  # type: ignore[return-value]\n\n\nCmdType = t.TypeVar(\"CmdType\", bound=Command)\n\n\n# variant: no call, directly as decorator for a function.\n@t.overload\ndef command(name: _AnyCallable) -> Command: ...\n\n\n# variant: with positional name and with positional or keyword cls argument:\n# @command(namearg, CommandCls, ...) or @command(namearg, cls=CommandCls, ...)\n@t.overload\ndef command(\n    name: t.Optional[str],\n    cls: t.Type[CmdType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], CmdType]: ...\n\n\n# variant: name omitted, cls _must_ be a keyword argument, @command(cls=CommandCls, ...)\n@t.overload\ndef command(\n    name: None = None,\n    *,\n    cls: t.Type[CmdType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], CmdType]: ...\n\n\n# variant: with optional string name, no cls argument provided.\n@t.overload\ndef command(\n    name: t.Optional[str] = ..., cls: None = None, **attrs: t.Any\n) -> t.Callable[[_AnyCallable], Command]: ...\n\n\ndef command(\n    name: t.Union[t.Optional[str], _AnyCallable] = None,\n    cls: t.Optional[t.Type[CmdType]] = None,\n    **attrs: t.Any,\n) -> t.Union[Command, t.Callable[[_AnyCallable], t.Union[Command, CmdType]]]:\n    r\"\"\"Creates a new :class:`Command` and uses the decorated function as\n    callback.  This will also automatically attach all decorated\n    :func:`option`\\s and :func:`argument`\\s as parameters to the command.\n\n    The name of the command defaults to the name of the function with\n    underscores replaced by dashes.  If you want to change that, you can\n    pass the intended name as the first argument.\n\n    All keyword arguments are forwarded to the underlying command class.\n    For the ``params`` argument, any decorated params are appended to\n    the end of the list.\n\n    Once decorated the function turns into a :class:`Command` instance\n    that can be invoked as a command line utility or be attached to a\n    command :class:`Group`.\n\n    :param name: the name of the command.  This defaults to the function\n                 name with underscores replaced by dashes.\n    :param cls: the command class to instantiate.  This defaults to\n                :class:`Command`.\n\n    .. versionchanged:: 8.1\n        This decorator can be applied without parentheses.\n\n    .. versionchanged:: 8.1\n        The ``params`` argument can be used. Decorated params are\n        appended to the end of the list.\n    \"\"\"\n\n    func: t.Optional[t.Callable[[_AnyCallable], t.Any]] = None\n\n    if callable(name):\n        func = name\n        name = None\n        assert cls is None, \"Use 'command(cls=cls)(callable)' to specify a class.\"\n        assert not attrs, \"Use 'command(**kwargs)(callable)' to provide arguments.\"\n\n    if cls is None:\n        cls = t.cast(t.Type[CmdType], Command)\n\n    def decorator(f: _AnyCallable) -> CmdType:\n        if isinstance(f, Command):\n            raise TypeError(\"Attempted to convert a callback into a command twice.\")\n\n        attr_params = attrs.pop(\"params\", None)\n        params = attr_params if attr_params is not None else []\n\n        try:\n            decorator_params = f.__click_params__  # type: ignore\n        except AttributeError:\n            pass\n        else:\n            del f.__click_params__  # type: ignore\n            params.extend(reversed(decorator_params))\n\n        if attrs.get(\"help\") is None:\n            attrs[\"help\"] = f.__doc__\n\n        if t.TYPE_CHECKING:\n            assert cls is not None\n            assert not callable(name)\n\n        cmd = cls(\n            name=name or f.__name__.lower().replace(\"_\", \"-\"),\n            callback=f,\n            params=params,\n            **attrs,\n        )\n        cmd.__doc__ = f.__doc__\n        return cmd\n\n    if func is not None:\n        return decorator(func)\n\n    return decorator\n\n\nGrpType = t.TypeVar(\"GrpType\", bound=Group)\n\n\n# variant: no call, directly as decorator for a function.\n@t.overload\ndef group(name: _AnyCallable) -> Group: ...\n\n\n# variant: with positional name and with positional or keyword cls argument:\n# @group(namearg, GroupCls, ...) or @group(namearg, cls=GroupCls, ...)\n@t.overload\ndef group(\n    name: t.Optional[str],\n    cls: t.Type[GrpType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], GrpType]: ...\n\n\n# variant: name omitted, cls _must_ be a keyword argument, @group(cmd=GroupCls, ...)\n@t.overload\ndef group(\n    name: None = None,\n    *,\n    cls: t.Type[GrpType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], GrpType]: ...\n\n\n# variant: with optional string name, no cls argument provided.\n@t.overload\ndef group(\n    name: t.Optional[str] = ..., cls: None = None, **attrs: t.Any\n) -> t.Callable[[_AnyCallable], Group]: ...\n\n\ndef group(\n    name: t.Union[str, _AnyCallable, None] = None,\n    cls: t.Optional[t.Type[GrpType]] = None,\n    **attrs: t.Any,\n) -> t.Union[Group, t.Callable[[_AnyCallable], t.Union[Group, GrpType]]]:\n    \"\"\"Creates a new :class:`Group` with a function as callback.  This\n    works otherwise the same as :func:`command` just that the `cls`\n    parameter is set to :class:`Group`.\n\n    .. versionchanged:: 8.1\n        This decorator can be applied without parentheses.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(t.Type[GrpType], Group)\n\n    if callable(name):\n        return command(cls=cls, **attrs)(name)\n\n    return command(name, cls, **attrs)\n\n\ndef _param_memo(f: t.Callable[..., t.Any], param: Parameter) -> None:\n    if isinstance(f, Command):\n        f.params.append(param)\n    else:\n        if not hasattr(f, \"__click_params__\"):\n            f.__click_params__ = []  # type: ignore\n\n        f.__click_params__.append(param)  # type: ignore\n\n\ndef argument(\n    *param_decls: str, cls: t.Optional[t.Type[Argument]] = None, **attrs: t.Any\n) -> t.Callable[[FC], FC]:\n    \"\"\"Attaches an argument to the command.  All positional arguments are\n    passed as parameter declarations to :class:`Argument`; all keyword\n    arguments are forwarded unchanged (except ``cls``).\n    This is equivalent to creating an :class:`Argument` instance manually\n    and attaching it to the :attr:`Command.params` list.\n\n    For the default argument class, refer to :class:`Argument` and\n    :class:`Parameter` for descriptions of parameters.\n\n    :param cls: the argument class to instantiate.  This defaults to\n                :class:`Argument`.\n    :param param_decls: Passed as positional arguments to the constructor of\n        ``cls``.\n    :param attrs: Passed as keyword arguments to the constructor of ``cls``.\n    \"\"\"\n    if cls is None:\n        cls = Argument\n\n    def decorator(f: FC) -> FC:\n        _param_memo(f, cls(param_decls, **attrs))\n        return f\n\n    return decorator\n\n\ndef option(\n    *param_decls: str, cls: t.Optional[t.Type[Option]] = None, **attrs: t.Any\n) -> t.Callable[[FC], FC]:\n    \"\"\"Attaches an option to the command.  All positional arguments are\n    passed as parameter declarations to :class:`Option`; all keyword\n    arguments are forwarded unchanged (except ``cls``).\n    This is equivalent to creating an :class:`Option` instance manually\n    and attaching it to the :attr:`Command.params` list.\n\n    For the default option class, refer to :class:`Option` and\n    :class:`Parameter` for descriptions of parameters.\n\n    :param cls: the option class to instantiate.  This defaults to\n                :class:`Option`.\n    :param param_decls: Passed as positional arguments to the constructor of\n        ``cls``.\n    :param attrs: Passed as keyword arguments to the constructor of ``cls``.\n    \"\"\"\n    if cls is None:\n        cls = Option\n\n    def decorator(f: FC) -> FC:\n        _param_memo(f, cls(param_decls, **attrs))\n        return f\n\n    return decorator\n\n\ndef confirmation_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--yes`` option which shows a prompt before continuing if\n    not passed. If the prompt is declined, the program will exit.\n\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--yes\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    \"\"\"\n\n    def callback(ctx: Context, param: Parameter, value: bool) -> None:\n        if not value:\n            ctx.abort()\n\n    if not param_decls:\n        param_decls = (\"--yes\",)\n\n    kwargs.setdefault(\"is_flag\", True)\n    kwargs.setdefault(\"callback\", callback)\n    kwargs.setdefault(\"expose_value\", False)\n    kwargs.setdefault(\"prompt\", \"Do you want to continue?\")\n    kwargs.setdefault(\"help\", \"Confirm the action without prompting.\")\n    return option(*param_decls, **kwargs)\n\n\ndef password_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--password`` option which prompts for a password, hiding\n    input and asking to enter the value again for confirmation.\n\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--password\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    \"\"\"\n    if not param_decls:\n        param_decls = (\"--password\",)\n\n    kwargs.setdefault(\"prompt\", True)\n    kwargs.setdefault(\"confirmation_prompt\", True)\n    kwargs.setdefault(\"hide_input\", True)\n    return option(*param_decls, **kwargs)\n\n\ndef version_option(\n    version: t.Optional[str] = None,\n    *param_decls: str,\n    package_name: t.Optional[str] = None,\n    prog_name: t.Optional[str] = None,\n    message: t.Optional[str] = None,\n    **kwargs: t.Any,\n) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--version`` option which immediately prints the version\n    number and exits the program.\n\n    If ``version`` is not provided, Click will try to detect it using\n    :func:`importlib.metadata.version` to get the version for the\n    ``package_name``. On Python < 3.8, the ``importlib_metadata``\n    backport must be installed.\n\n    If ``package_name`` is not provided, Click will try to detect it by\n    inspecting the stack frames. This will be used to detect the\n    version, so it must match the name of the installed package.\n\n    :param version: The version number to show. If not provided, Click\n        will try to detect it.\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--version\"``.\n    :param package_name: The package name to detect the version from. If\n        not provided, Click will try to detect it.\n    :param prog_name: The name of the CLI to show in the message. If not\n        provided, it will be detected from the command.\n    :param message: The message to show. The values ``%(prog)s``,\n        ``%(package)s``, and ``%(version)s`` are available. Defaults to\n        ``\"%(prog)s, version %(version)s\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    :raise RuntimeError: ``version`` could not be detected.\n\n    .. versionchanged:: 8.0\n        Add the ``package_name`` parameter, and the ``%(package)s``\n        value for messages.\n\n    .. versionchanged:: 8.0\n        Use :mod:`importlib.metadata` instead of ``pkg_resources``. The\n        version is detected based on the package name, not the entry\n        point name. The Python package name must match the installed\n        package name, or be passed with ``package_name=``.\n    \"\"\"\n    if message is None:\n        message = _(\"%(prog)s, version %(version)s\")\n\n    if version is None and package_name is None:\n        frame = inspect.currentframe()\n        f_back = frame.f_back if frame is not None else None\n        f_globals = f_back.f_globals if f_back is not None else None\n        # break reference cycle\n        # https://docs.python.org/3/library/inspect.html#the-interpreter-stack\n        del frame\n\n        if f_globals is not None:\n            package_name = f_globals.get(\"__name__\")\n\n            if package_name == \"__main__\":\n                package_name = f_globals.get(\"__package__\")\n\n            if package_name:\n                package_name = package_name.partition(\".\")[0]\n\n    def callback(ctx: Context, param: Parameter, value: bool) -> None:\n        if not value or ctx.resilient_parsing:\n            return\n\n        nonlocal prog_name\n        nonlocal version\n\n        if prog_name is None:\n            prog_name = ctx.find_root().info_name\n\n        if version is None and package_name is not None:\n            metadata: t.Optional[types.ModuleType]\n\n            try:\n                from importlib import metadata\n            except ImportError:\n                # Python < 3.8\n                import importlib_metadata as metadata  # type: ignore\n\n            try:\n                version = metadata.version(package_name)  # type: ignore\n            except metadata.PackageNotFoundError:  # type: ignore\n                raise RuntimeError(\n                    f\"{package_name!r} is not installed. Try passing\"\n                    \" 'package_name' instead.\"\n                ) from None\n\n        if version is None:\n            raise RuntimeError(\n                f\"Could not determine the version for {package_name!r} automatically.\"\n            )\n\n        echo(\n            message % {\"prog\": prog_name, \"package\": package_name, \"version\": version},\n            color=ctx.color,\n        )\n        ctx.exit()\n\n    if not param_decls:\n        param_decls = (\"--version\",)\n\n    kwargs.setdefault(\"is_flag\", True)\n    kwargs.setdefault(\"expose_value\", False)\n    kwargs.setdefault(\"is_eager\", True)\n    kwargs.setdefault(\"help\", _(\"Show the version and exit.\"))\n    kwargs[\"callback\"] = callback\n    return option(*param_decls, **kwargs)\n\n\ndef help_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--help`` option which immediately prints the help page\n    and exits the program.\n\n    This is usually unnecessary, as the ``--help`` option is added to\n    each command automatically unless ``add_help_option=False`` is\n    passed.\n\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--help\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    \"\"\"\n\n    def callback(ctx: Context, param: Parameter, value: bool) -> None:\n        if not value or ctx.resilient_parsing:\n            return\n\n        echo(ctx.get_help(), color=ctx.color)\n        ctx.exit()\n\n    if not param_decls:\n        param_decls = (\"--help\",)\n\n    kwargs.setdefault(\"is_flag\", True)\n    kwargs.setdefault(\"expose_value\", False)\n    kwargs.setdefault(\"is_eager\", True)\n    kwargs.setdefault(\"help\", _(\"Show this message and exit.\"))\n    kwargs[\"callback\"] = callback\n    return option(*param_decls, **kwargs)\n",
      "code_after": "import inspect\nimport types\nimport typing as t\nfrom functools import update_wrapper\nfrom gettext import gettext as _\n\nfrom .core import Argument\nfrom .core import Command\nfrom .core import Context\nfrom .core import Group\nfrom .core import Option\nfrom .core import Parameter\nfrom .globals import get_current_context\nfrom .utils import echo\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    P = te.ParamSpec(\"P\")\n\nR = t.TypeVar(\"R\")\nT = t.TypeVar(\"T\")\n_AnyCallable = t.Callable[..., t.Any]\nFC = t.TypeVar(\"FC\", bound=t.Union[_AnyCallable, Command])\n\n\ndef pass_context(f: \"t.Callable[te.Concatenate[Context, P], R]\") -> \"t.Callable[P, R]\":\n    \"\"\"Marks a callback as wanting to receive the current context\n    object as first argument.\n    \"\"\"\n\n    def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> \"R\":\n        return f(get_current_context(), *args, **kwargs)\n\n    return update_wrapper(new_func, f)\n\n\ndef pass_obj(f: \"t.Callable[te.Concatenate[t.Any, P], R]\") -> \"t.Callable[P, R]\":\n    \"\"\"Similar to :func:`pass_context`, but only pass the object on the\n    context onwards (:attr:`Context.obj`).  This is useful if that object\n    represents the state of a nested system.\n    \"\"\"\n\n    def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> \"R\":\n        return f(get_current_context().obj, *args, **kwargs)\n\n    return update_wrapper(new_func, f)\n\n\ndef make_pass_decorator(\n    object_type: t.Type[T], ensure: bool = False\n) -> t.Callable[[\"t.Callable[te.Concatenate[T, P], R]\"], \"t.Callable[P, R]\"]:\n    \"\"\"Given an object type this creates a decorator that will work\n    similar to :func:`pass_obj` but instead of passing the object of the\n    current context, it will find the innermost context of type\n    :func:`object_type`.\n\n    This generates a decorator that works roughly like this::\n\n        from functools import update_wrapper\n\n        def decorator(f):\n            @pass_context\n            def new_func(ctx, *args, **kwargs):\n                obj = ctx.find_object(object_type)\n                return ctx.invoke(f, obj, *args, **kwargs)\n            return update_wrapper(new_func, f)\n        return decorator\n\n    :param object_type: the type of the object to pass.\n    :param ensure: if set to `True`, a new object will be created and\n                   remembered on the context if it's not there yet.\n    \"\"\"\n\n    def decorator(f: \"t.Callable[te.Concatenate[T, P], R]\") -> \"t.Callable[P, R]\":\n        def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> \"R\":\n            ctx = get_current_context()\n\n            obj: t.Optional[T]\n            if ensure:\n                obj = ctx.ensure_object(object_type)\n            else:\n                obj = ctx.find_object(object_type)\n\n            if obj is None:\n                raise RuntimeError(\n                    \"Managed to invoke callback without a context\"\n                    f\" object of type {object_type.__name__!r}\"\n                    \" existing.\"\n                )\n\n            return ctx.invoke(f, obj, *args, **kwargs)\n\n        return update_wrapper(new_func, f)\n\n    return decorator\n\n\ndef pass_meta_key(\n    key: str, *, doc_description: t.Optional[str] = None\n) -> \"t.Callable[[t.Callable[te.Concatenate[t.Any, P], R]], t.Callable[P, R]]\":\n    \"\"\"Create a decorator that passes a key from\n    :attr:`click.Context.meta` as the first argument to the decorated\n    function.\n\n    :param key: Key in ``Context.meta`` to pass.\n    :param doc_description: Description of the object being passed,\n        inserted into the decorator's docstring. Defaults to \"the 'key'\n        key from Context.meta\".\n\n    .. versionadded:: 8.0\n    \"\"\"\n\n    def decorator(f: \"t.Callable[te.Concatenate[t.Any, P], R]\") -> \"t.Callable[P, R]\":\n        def new_func(*args: \"P.args\", **kwargs: \"P.kwargs\") -> R:\n            ctx = get_current_context()\n            obj = ctx.meta[key]\n            return ctx.invoke(f, obj, *args, **kwargs)\n\n        return update_wrapper(new_func, f)\n\n    if doc_description is None:\n        doc_description = f\"the {key!r} key from :attr:`click.Context.meta`\"\n\n    decorator.__doc__ = (\n        f\"Decorator that passes {doc_description} as the first argument\"\n        \" to the decorated function.\"\n    )\n    return decorator\n\n\nCmdType = t.TypeVar(\"CmdType\", bound=Command)\n\n\n# variant: no call, directly as decorator for a function.\n@t.overload\ndef command(name: _AnyCallable) -> Command: ...\n\n\n# variant: with positional name and with positional or keyword cls argument:\n# @command(namearg, CommandCls, ...) or @command(namearg, cls=CommandCls, ...)\n@t.overload\ndef command(\n    name: t.Optional[str],\n    cls: t.Type[CmdType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], CmdType]: ...\n\n\n# variant: name omitted, cls _must_ be a keyword argument, @command(cls=CommandCls, ...)\n@t.overload\ndef command(\n    name: None = None,\n    *,\n    cls: t.Type[CmdType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], CmdType]: ...\n\n\n# variant: with optional string name, no cls argument provided.\n@t.overload\ndef command(\n    name: t.Optional[str] = ..., cls: None = None, **attrs: t.Any\n) -> t.Callable[[_AnyCallable], Command]: ...\n\n\ndef command(\n    name: t.Union[t.Optional[str], _AnyCallable] = None,\n    cls: t.Optional[t.Type[CmdType]] = None,\n    **attrs: t.Any,\n) -> t.Union[Command, t.Callable[[_AnyCallable], t.Union[Command, CmdType]]]:\n    r\"\"\"Creates a new :class:`Command` and uses the decorated function as\n    callback.  This will also automatically attach all decorated\n    :func:`option`\\s and :func:`argument`\\s as parameters to the command.\n\n    The name of the command defaults to the name of the function with\n    underscores replaced by dashes.  If you want to change that, you can\n    pass the intended name as the first argument.\n\n    All keyword arguments are forwarded to the underlying command class.\n    For the ``params`` argument, any decorated params are appended to\n    the end of the list.\n\n    Once decorated the function turns into a :class:`Command` instance\n    that can be invoked as a command line utility or be attached to a\n    command :class:`Group`.\n\n    :param name: the name of the command.  This defaults to the function\n                 name with underscores replaced by dashes.\n    :param cls: the command class to instantiate.  This defaults to\n                :class:`Command`.\n\n    .. versionchanged:: 8.1\n        This decorator can be applied without parentheses.\n\n    .. versionchanged:: 8.1\n        The ``params`` argument can be used. Decorated params are\n        appended to the end of the list.\n    \"\"\"\n\n    func: t.Optional[t.Callable[[_AnyCallable], t.Any]] = None\n\n    if callable(name):\n        func = name\n        name = None\n        assert cls is None, \"Use 'command(cls=cls)(callable)' to specify a class.\"\n        assert not attrs, \"Use 'command(**kwargs)(callable)' to provide arguments.\"\n\n    if cls is None:\n        cls = t.cast(t.Type[CmdType], Command)\n\n    def decorator(f: _AnyCallable) -> CmdType:\n        if isinstance(f, Command):\n            raise TypeError(\"Attempted to convert a callback into a command twice.\")\n\n        attr_params = attrs.pop(\"params\", None)\n        params = attr_params if attr_params is not None else []\n\n        try:\n            decorator_params = f.__click_params__  # type: ignore\n        except AttributeError:\n            pass\n        else:\n            del f.__click_params__  # type: ignore\n            params.extend(reversed(decorator_params))\n\n        if attrs.get(\"help\") is None:\n            attrs[\"help\"] = f.__doc__\n\n        if t.TYPE_CHECKING:\n            assert cls is not None\n            assert not callable(name)\n\n        cmd = cls(\n            name=name or f.__name__.lower().replace(\"_\", \"-\"),\n            callback=f,\n            params=params,\n            **attrs,\n        )\n        cmd.__doc__ = f.__doc__\n        return cmd\n\n    if func is not None:\n        return decorator(func)\n\n    return decorator\n\n\nGrpType = t.TypeVar(\"GrpType\", bound=Group)\n\n\n# variant: no call, directly as decorator for a function.\n@t.overload\ndef group(name: _AnyCallable) -> Group: ...\n\n\n# variant: with positional name and with positional or keyword cls argument:\n# @group(namearg, GroupCls, ...) or @group(namearg, cls=GroupCls, ...)\n@t.overload\ndef group(\n    name: t.Optional[str],\n    cls: t.Type[GrpType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], GrpType]: ...\n\n\n# variant: name omitted, cls _must_ be a keyword argument, @group(cmd=GroupCls, ...)\n@t.overload\ndef group(\n    name: None = None,\n    *,\n    cls: t.Type[GrpType],\n    **attrs: t.Any,\n) -> t.Callable[[_AnyCallable], GrpType]: ...\n\n\n# variant: with optional string name, no cls argument provided.\n@t.overload\ndef group(\n    name: t.Optional[str] = ..., cls: None = None, **attrs: t.Any\n) -> t.Callable[[_AnyCallable], Group]: ...\n\n\ndef group(\n    name: t.Union[str, _AnyCallable, None] = None,\n    cls: t.Optional[t.Type[GrpType]] = None,\n    **attrs: t.Any,\n) -> t.Union[Group, t.Callable[[_AnyCallable], t.Union[Group, GrpType]]]:\n    \"\"\"Creates a new :class:`Group` with a function as callback.  This\n    works otherwise the same as :func:`command` just that the `cls`\n    parameter is set to :class:`Group`.\n\n    .. versionchanged:: 8.1\n        This decorator can be applied without parentheses.\n    \"\"\"\n    if cls is None:\n        cls = t.cast(t.Type[GrpType], Group)\n\n    if callable(name):\n        return command(cls=cls, **attrs)(name)\n\n    return command(name, cls, **attrs)\n\n\ndef _param_memo(f: t.Callable[..., t.Any], param: Parameter) -> None:\n    if isinstance(f, Command):\n        f.params.append(param)\n    else:\n        if not hasattr(f, \"__click_params__\"):\n            f.__click_params__ = []  # type: ignore\n\n        f.__click_params__.append(param)  # type: ignore\n\n\ndef argument(\n    *param_decls: str, cls: t.Optional[t.Type[Argument]] = None, **attrs: t.Any\n) -> t.Callable[[FC], FC]:\n    \"\"\"Attaches an argument to the command.  All positional arguments are\n    passed as parameter declarations to :class:`Argument`; all keyword\n    arguments are forwarded unchanged (except ``cls``).\n    This is equivalent to creating an :class:`Argument` instance manually\n    and attaching it to the :attr:`Command.params` list.\n\n    For the default argument class, refer to :class:`Argument` and\n    :class:`Parameter` for descriptions of parameters.\n\n    :param cls: the argument class to instantiate.  This defaults to\n                :class:`Argument`.\n    :param param_decls: Passed as positional arguments to the constructor of\n        ``cls``.\n    :param attrs: Passed as keyword arguments to the constructor of ``cls``.\n    \"\"\"\n    if cls is None:\n        cls = Argument\n\n    def decorator(f: FC) -> FC:\n        _param_memo(f, cls(param_decls, **attrs))\n        return f\n\n    return decorator\n\n\ndef option(\n    *param_decls: str, cls: t.Optional[t.Type[Option]] = None, **attrs: t.Any\n) -> t.Callable[[FC], FC]:\n    \"\"\"Attaches an option to the command.  All positional arguments are\n    passed as parameter declarations to :class:`Option`; all keyword\n    arguments are forwarded unchanged (except ``cls``).\n    This is equivalent to creating an :class:`Option` instance manually\n    and attaching it to the :attr:`Command.params` list.\n\n    For the default option class, refer to :class:`Option` and\n    :class:`Parameter` for descriptions of parameters.\n\n    :param cls: the option class to instantiate.  This defaults to\n                :class:`Option`.\n    :param param_decls: Passed as positional arguments to the constructor of\n        ``cls``.\n    :param attrs: Passed as keyword arguments to the constructor of ``cls``.\n    \"\"\"\n    if cls is None:\n        cls = Option\n\n    def decorator(f: FC) -> FC:\n        _param_memo(f, cls(param_decls, **attrs))\n        return f\n\n    return decorator\n\n\ndef confirmation_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--yes`` option which shows a prompt before continuing if\n    not passed. If the prompt is declined, the program will exit.\n\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--yes\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    \"\"\"\n\n    def callback(ctx: Context, param: Parameter, value: bool) -> None:\n        if not value:\n            ctx.abort()\n\n    if not param_decls:\n        param_decls = (\"--yes\",)\n\n    kwargs.setdefault(\"is_flag\", True)\n    kwargs.setdefault(\"callback\", callback)\n    kwargs.setdefault(\"expose_value\", False)\n    kwargs.setdefault(\"prompt\", \"Do you want to continue?\")\n    kwargs.setdefault(\"help\", \"Confirm the action without prompting.\")\n    return option(*param_decls, **kwargs)\n\n\ndef password_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--password`` option which prompts for a password, hiding\n    input and asking to enter the value again for confirmation.\n\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--password\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    \"\"\"\n    if not param_decls:\n        param_decls = (\"--password\",)\n\n    kwargs.setdefault(\"prompt\", True)\n    kwargs.setdefault(\"confirmation_prompt\", True)\n    kwargs.setdefault(\"hide_input\", True)\n    return option(*param_decls, **kwargs)\n\n\ndef version_option(\n    version: t.Optional[str] = None,\n    *param_decls: str,\n    package_name: t.Optional[str] = None,\n    prog_name: t.Optional[str] = None,\n    message: t.Optional[str] = None,\n    **kwargs: t.Any,\n) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--version`` option which immediately prints the version\n    number and exits the program.\n\n    If ``version`` is not provided, Click will try to detect it using\n    :func:`importlib.metadata.version` to get the version for the\n    ``package_name``. On Python < 3.8, the ``importlib_metadata``\n    backport must be installed.\n\n    If ``package_name`` is not provided, Click will try to detect it by\n    inspecting the stack frames. This will be used to detect the\n    version, so it must match the name of the installed package.\n\n    :param version: The version number to show. If not provided, Click\n        will try to detect it.\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--version\"``.\n    :param package_name: The package name to detect the version from. If\n        not provided, Click will try to detect it.\n    :param prog_name: The name of the CLI to show in the message. If not\n        provided, it will be detected from the command.\n    :param message: The message to show. The values ``%(prog)s``,\n        ``%(package)s``, and ``%(version)s`` are available. Defaults to\n        ``\"%(prog)s, version %(version)s\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    :raise RuntimeError: ``version`` could not be detected.\n\n    .. versionchanged:: 8.0\n        Add the ``package_name`` parameter, and the ``%(package)s``\n        value for messages.\n\n    .. versionchanged:: 8.0\n        Use :mod:`importlib.metadata` instead of ``pkg_resources``. The\n        version is detected based on the package name, not the entry\n        point name. The Python package name must match the installed\n        package name, or be passed with ``package_name=``.\n    \"\"\"\n    if message is None:\n        message = _(\"%(prog)s, version %(version)s\")\n\n    if version is None and package_name is None:\n        frame = inspect.currentframe()\n        f_back = frame.f_back if frame is not None else None\n        f_globals = f_back.f_globals if f_back is not None else None\n        # break reference cycle\n        # https://docs.python.org/3/library/inspect.html#the-interpreter-stack\n        del frame\n\n        if f_globals is not None:\n            package_name = f_globals.get(\"__name__\")\n\n            if package_name == \"__main__\":\n                package_name = f_globals.get(\"__package__\")\n\n            if package_name:\n                package_name = package_name.partition(\".\")[0]\n\n    def callback(ctx: Context, param: Parameter, value: bool) -> None:\n        if not value or ctx.resilient_parsing:\n            return\n\n        nonlocal prog_name\n        nonlocal version\n\n        if prog_name is None:\n            prog_name = ctx.find_root().info_name\n\n        if version is None and package_name is not None:\n            metadata: t.Optional[types.ModuleType]\n\n            try:\n                from importlib import metadata\n            except ImportError:\n                # Python < 3.8\n                import importlib_metadata as metadata  # type: ignore\n\n            try:\n                version = metadata.version(package_name)  # type: ignore\n            except metadata.PackageNotFoundError:  # type: ignore\n                raise RuntimeError(\n                    f\"{package_name!r} is not installed. Try passing\"\n                    \" 'package_name' instead.\"\n                ) from None\n\n        if version is None:\n            raise RuntimeError(\n                f\"Could not determine the version for {package_name!r} automatically.\"\n            )\n\n        echo(\n            message % {\"prog\": prog_name, \"package\": package_name, \"version\": version},\n            color=ctx.color,\n        )\n        ctx.exit()\n\n    if not param_decls:\n        param_decls = (\"--version\",)\n\n    kwargs.setdefault(\"is_flag\", True)\n    kwargs.setdefault(\"expose_value\", False)\n    kwargs.setdefault(\"is_eager\", True)\n    kwargs.setdefault(\"help\", _(\"Show the version and exit.\"))\n    kwargs[\"callback\"] = callback\n    return option(*param_decls, **kwargs)\n\n\ndef help_option(*param_decls: str, **kwargs: t.Any) -> t.Callable[[FC], FC]:\n    \"\"\"Add a ``--help`` option which immediately prints the help page\n    and exits the program.\n\n    This is usually unnecessary, as the ``--help`` option is added to\n    each command automatically unless ``add_help_option=False`` is\n    passed.\n\n    :param param_decls: One or more option names. Defaults to the single\n        value ``\"--help\"``.\n    :param kwargs: Extra arguments are passed to :func:`option`.\n    \"\"\"\n\n    def callback(ctx: Context, param: Parameter, value: bool) -> None:\n        if not value or ctx.resilient_parsing:\n            return\n\n        echo(ctx.get_help(), color=ctx.color)\n        ctx.exit()\n\n    if not param_decls:\n        param_decls = (\"--help\",)\n\n    kwargs.setdefault(\"is_flag\", True)\n    kwargs.setdefault(\"expose_value\", False)\n    kwargs.setdefault(\"is_eager\", True)\n    kwargs.setdefault(\"help\", _(\"Show this message and exit.\"))\n    kwargs[\"callback\"] = callback\n    return option(*param_decls, **kwargs)\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 1.0
    },
    {
      "bug_id": "8fd01e1b8b3f",
      "repo": "click",
      "commit_hash": "ab91b5a",
      "commit_message": "apply ruff fixes",
      "file_path": "src/click/exceptions.py",
      "language": "python",
      "code_before": "import typing as t\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom ._compat import get_text_stderr\nfrom .utils import echo\nfrom .utils import format_filename\n\nif t.TYPE_CHECKING:\n    from .core import Command\n    from .core import Context\n    from .core import Parameter\n\n\ndef _join_param_hints(\n    param_hint: t.Optional[t.Union[t.Sequence[str], str]],\n) -> t.Optional[str]:\n    if param_hint is not None and not isinstance(param_hint, str):\n        return \" / \".join(repr(x) for x in param_hint)\n\n    return param_hint\n\n\nclass ClickException(Exception):\n    \"\"\"An exception that Click can handle and show to the user.\"\"\"\n\n    #: The exit code for this exception.\n    exit_code = 1\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message)\n        self.message = message\n\n    def format_message(self) -> str:\n        return self.message\n\n    def __str__(self) -> str:\n        return self.message\n\n    def show(self, file: t.Optional[t.IO[t.Any]] = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n\n        echo(_(\"Error: {message}\").format(message=self.format_message()), file=file)\n\n\nclass UsageError(ClickException):\n    \"\"\"An internal exception that signals a usage error.  This typically\n    aborts any further handling.\n\n    :param message: the error message to display.\n    :param ctx: optionally the context that caused this error.  Click will\n                fill in the context automatically in some situations.\n    \"\"\"\n\n    exit_code = 2\n\n    def __init__(self, message: str, ctx: t.Optional[\"Context\"] = None) -> None:\n        super().__init__(message)\n        self.ctx = ctx\n        self.cmd: t.Optional[\"Command\"] = self.ctx.command if self.ctx else None\n\n    def show(self, file: t.Optional[t.IO[t.Any]] = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n        color = None\n        hint = \"\"\n        if (\n            self.ctx is not None\n            and self.ctx.command.get_help_option(self.ctx) is not None\n        ):\n            hint = _(\"Try '{command} {option}' for help.\").format(\n                command=self.ctx.command_path, option=self.ctx.help_option_names[0]\n            )\n            hint = f\"{hint}\\n\"\n        if self.ctx is not None:\n            color = self.ctx.color\n            echo(f\"{self.ctx.get_usage()}\\n{hint}\", file=file, color=color)\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=color,\n        )\n\n\nclass BadParameter(UsageError):\n    \"\"\"An exception that formats out a standardized error message for a\n    bad parameter.  This is useful when thrown from a callback or type as\n    Click will attach contextual information to it (for instance, which\n    parameter it is).\n\n    .. versionadded:: 2.0\n\n    :param param: the parameter object that caused this error.  This can\n                  be left out, and Click will attach this info itself\n                  if possible.\n    :param param_hint: a string that shows up as parameter name.  This\n                       can be used as alternative to `param` in cases\n                       where custom validation should happen.  If it is\n                       a string it's used as such, if it's a list then\n                       each item is quoted and separated.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        ctx: t.Optional[\"Context\"] = None,\n        param: t.Optional[\"Parameter\"] = None,\n        param_hint: t.Optional[str] = None,\n    ) -> None:\n        super().__init__(message, ctx)\n        self.param = param\n        self.param_hint = param_hint\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            return _(\"Invalid value: {message}\").format(message=self.message)\n\n        return _(\"Invalid value for {param_hint}: {message}\").format(\n            param_hint=_join_param_hints(param_hint), message=self.message\n        )\n\n\nclass MissingParameter(BadParameter):\n    \"\"\"Raised if click required an option or argument but it was not\n    provided when invoking the script.\n\n    .. versionadded:: 4.0\n\n    :param param_type: a string that indicates the type of the parameter.\n                       The default is to inherit the parameter type from\n                       the given `param`.  Valid values are ``'parameter'``,\n                       ``'option'`` or ``'argument'``.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: t.Optional[str] = None,\n        ctx: t.Optional[\"Context\"] = None,\n        param: t.Optional[\"Parameter\"] = None,\n        param_hint: t.Optional[str] = None,\n        param_type: t.Optional[str] = None,\n    ) -> None:\n        super().__init__(message or \"\", ctx, param, param_hint)\n        self.param_type = param_type\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint: t.Optional[str] = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            param_hint = None\n\n        param_hint = _join_param_hints(param_hint)\n        param_hint = f\" {param_hint}\" if param_hint else \"\"\n\n        param_type = self.param_type\n        if param_type is None and self.param is not None:\n            param_type = self.param.param_type_name\n\n        msg = self.message\n        if self.param is not None:\n            msg_extra = self.param.type.get_missing_message(self.param)\n            if msg_extra:\n                if msg:\n                    msg += f\". {msg_extra}\"\n                else:\n                    msg = msg_extra\n\n        msg = f\" {msg}\" if msg else \"\"\n\n        # Translate param_type for known types.\n        if param_type == \"argument\":\n            missing = _(\"Missing argument\")\n        elif param_type == \"option\":\n            missing = _(\"Missing option\")\n        elif param_type == \"parameter\":\n            missing = _(\"Missing parameter\")\n        else:\n            missing = _(\"Missing {param_type}\").format(param_type=param_type)\n\n        return f\"{missing}{param_hint}.{msg}\"\n\n    def __str__(self) -> str:\n        if not self.message:\n            param_name = self.param.name if self.param else None\n            return _(\"Missing parameter: {param_name}\").format(param_name=param_name)\n        else:\n            return self.message\n\n\nclass NoSuchOption(UsageError):\n    \"\"\"Raised if click attempted to handle an option that does not\n    exist.\n\n    .. versionadded:: 4.0\n    \"\"\"\n\n    def __init__(\n        self,\n        option_name: str,\n        message: t.Optional[str] = None,\n        possibilities: t.Optional[t.Sequence[str]] = None,\n        ctx: t.Optional[\"Context\"] = None,\n    ) -> None:\n        if message is None:\n            message = _(\"No such option: {name}\").format(name=option_name)\n\n        super().__init__(message, ctx)\n        self.option_name = option_name\n        self.possibilities = possibilities\n\n    def format_message(self) -> str:\n        if not self.possibilities:\n            return self.message\n\n        possibility_str = \", \".join(sorted(self.possibilities))\n        suggest = ngettext(\n            \"Did you mean {possibility}?\",\n            \"(Possible options: {possibilities})\",\n            len(self.possibilities),\n        ).format(possibility=possibility_str, possibilities=possibility_str)\n        return f\"{self.message} {suggest}\"\n\n\nclass BadOptionUsage(UsageError):\n    \"\"\"Raised if an option is generally supplied but the use of the option\n    was incorrect.  This is for instance raised if the number of arguments\n    for an option is not correct.\n\n    .. versionadded:: 4.0\n\n    :param option_name: the name of the option being used incorrectly.\n    \"\"\"\n\n    def __init__(\n        self, option_name: str, message: str, ctx: t.Optional[\"Context\"] = None\n    ) -> None:\n        super().__init__(message, ctx)\n        self.option_name = option_name\n\n\nclass BadArgumentUsage(UsageError):\n    \"\"\"Raised if an argument is generally supplied but the use of the argument\n    was incorrect.  This is for instance raised if the number of values\n    for an argument is not correct.\n\n    .. versionadded:: 6.0\n    \"\"\"\n\n\nclass FileError(ClickException):\n    \"\"\"Raised if a file cannot be opened.\"\"\"\n\n    def __init__(self, filename: str, hint: t.Optional[str] = None) -> None:\n        if hint is None:\n            hint = _(\"unknown error\")\n\n        super().__init__(hint)\n        self.ui_filename: str = format_filename(filename)\n        self.filename = filename\n\n    def format_message(self) -> str:\n        return _(\"Could not open file {filename!r}: {message}\").format(\n            filename=self.ui_filename, message=self.message\n        )\n\n\nclass Abort(RuntimeError):\n    \"\"\"An internal signalling exception that signals Click to abort.\"\"\"\n\n\nclass Exit(RuntimeError):\n    \"\"\"An exception that indicates that the application should exit with some\n    status code.\n\n    :param code: the status code to exit with.\n    \"\"\"\n\n    __slots__ = (\"exit_code\",)\n\n    def __init__(self, code: int = 0) -> None:\n        self.exit_code: int = code\n",
      "code_after": "import typing as t\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom ._compat import get_text_stderr\nfrom .utils import echo\nfrom .utils import format_filename\n\nif t.TYPE_CHECKING:\n    from .core import Command\n    from .core import Context\n    from .core import Parameter\n\n\ndef _join_param_hints(\n    param_hint: t.Optional[t.Union[t.Sequence[str], str]],\n) -> t.Optional[str]:\n    if param_hint is not None and not isinstance(param_hint, str):\n        return \" / \".join(repr(x) for x in param_hint)\n\n    return param_hint\n\n\nclass ClickException(Exception):\n    \"\"\"An exception that Click can handle and show to the user.\"\"\"\n\n    #: The exit code for this exception.\n    exit_code = 1\n\n    def __init__(self, message: str) -> None:\n        super().__init__(message)\n        self.message = message\n\n    def format_message(self) -> str:\n        return self.message\n\n    def __str__(self) -> str:\n        return self.message\n\n    def show(self, file: t.Optional[t.IO[t.Any]] = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n\n        echo(_(\"Error: {message}\").format(message=self.format_message()), file=file)\n\n\nclass UsageError(ClickException):\n    \"\"\"An internal exception that signals a usage error.  This typically\n    aborts any further handling.\n\n    :param message: the error message to display.\n    :param ctx: optionally the context that caused this error.  Click will\n                fill in the context automatically in some situations.\n    \"\"\"\n\n    exit_code = 2\n\n    def __init__(self, message: str, ctx: t.Optional[\"Context\"] = None) -> None:\n        super().__init__(message)\n        self.ctx = ctx\n        self.cmd: t.Optional[Command] = self.ctx.command if self.ctx else None\n\n    def show(self, file: t.Optional[t.IO[t.Any]] = None) -> None:\n        if file is None:\n            file = get_text_stderr()\n        color = None\n        hint = \"\"\n        if (\n            self.ctx is not None\n            and self.ctx.command.get_help_option(self.ctx) is not None\n        ):\n            hint = _(\"Try '{command} {option}' for help.\").format(\n                command=self.ctx.command_path, option=self.ctx.help_option_names[0]\n            )\n            hint = f\"{hint}\\n\"\n        if self.ctx is not None:\n            color = self.ctx.color\n            echo(f\"{self.ctx.get_usage()}\\n{hint}\", file=file, color=color)\n        echo(\n            _(\"Error: {message}\").format(message=self.format_message()),\n            file=file,\n            color=color,\n        )\n\n\nclass BadParameter(UsageError):\n    \"\"\"An exception that formats out a standardized error message for a\n    bad parameter.  This is useful when thrown from a callback or type as\n    Click will attach contextual information to it (for instance, which\n    parameter it is).\n\n    .. versionadded:: 2.0\n\n    :param param: the parameter object that caused this error.  This can\n                  be left out, and Click will attach this info itself\n                  if possible.\n    :param param_hint: a string that shows up as parameter name.  This\n                       can be used as alternative to `param` in cases\n                       where custom validation should happen.  If it is\n                       a string it's used as such, if it's a list then\n                       each item is quoted and separated.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        ctx: t.Optional[\"Context\"] = None,\n        param: t.Optional[\"Parameter\"] = None,\n        param_hint: t.Optional[str] = None,\n    ) -> None:\n        super().__init__(message, ctx)\n        self.param = param\n        self.param_hint = param_hint\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            return _(\"Invalid value: {message}\").format(message=self.message)\n\n        return _(\"Invalid value for {param_hint}: {message}\").format(\n            param_hint=_join_param_hints(param_hint), message=self.message\n        )\n\n\nclass MissingParameter(BadParameter):\n    \"\"\"Raised if click required an option or argument but it was not\n    provided when invoking the script.\n\n    .. versionadded:: 4.0\n\n    :param param_type: a string that indicates the type of the parameter.\n                       The default is to inherit the parameter type from\n                       the given `param`.  Valid values are ``'parameter'``,\n                       ``'option'`` or ``'argument'``.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: t.Optional[str] = None,\n        ctx: t.Optional[\"Context\"] = None,\n        param: t.Optional[\"Parameter\"] = None,\n        param_hint: t.Optional[str] = None,\n        param_type: t.Optional[str] = None,\n    ) -> None:\n        super().__init__(message or \"\", ctx, param, param_hint)\n        self.param_type = param_type\n\n    def format_message(self) -> str:\n        if self.param_hint is not None:\n            param_hint: t.Optional[str] = self.param_hint\n        elif self.param is not None:\n            param_hint = self.param.get_error_hint(self.ctx)  # type: ignore\n        else:\n            param_hint = None\n\n        param_hint = _join_param_hints(param_hint)\n        param_hint = f\" {param_hint}\" if param_hint else \"\"\n\n        param_type = self.param_type\n        if param_type is None and self.param is not None:\n            param_type = self.param.param_type_name\n\n        msg = self.message\n        if self.param is not None:\n            msg_extra = self.param.type.get_missing_message(self.param)\n            if msg_extra:\n                if msg:\n                    msg += f\". {msg_extra}\"\n                else:\n                    msg = msg_extra\n\n        msg = f\" {msg}\" if msg else \"\"\n\n        # Translate param_type for known types.\n        if param_type == \"argument\":\n            missing = _(\"Missing argument\")\n        elif param_type == \"option\":\n            missing = _(\"Missing option\")\n        elif param_type == \"parameter\":\n            missing = _(\"Missing parameter\")\n        else:\n            missing = _(\"Missing {param_type}\").format(param_type=param_type)\n\n        return f\"{missing}{param_hint}.{msg}\"\n\n    def __str__(self) -> str:\n        if not self.message:\n            param_name = self.param.name if self.param else None\n            return _(\"Missing parameter: {param_name}\").format(param_name=param_name)\n        else:\n            return self.message\n\n\nclass NoSuchOption(UsageError):\n    \"\"\"Raised if click attempted to handle an option that does not\n    exist.\n\n    .. versionadded:: 4.0\n    \"\"\"\n\n    def __init__(\n        self,\n        option_name: str,\n        message: t.Optional[str] = None,\n        possibilities: t.Optional[t.Sequence[str]] = None,\n        ctx: t.Optional[\"Context\"] = None,\n    ) -> None:\n        if message is None:\n            message = _(\"No such option: {name}\").format(name=option_name)\n\n        super().__init__(message, ctx)\n        self.option_name = option_name\n        self.possibilities = possibilities\n\n    def format_message(self) -> str:\n        if not self.possibilities:\n            return self.message\n\n        possibility_str = \", \".join(sorted(self.possibilities))\n        suggest = ngettext(\n            \"Did you mean {possibility}?\",\n            \"(Possible options: {possibilities})\",\n            len(self.possibilities),\n        ).format(possibility=possibility_str, possibilities=possibility_str)\n        return f\"{self.message} {suggest}\"\n\n\nclass BadOptionUsage(UsageError):\n    \"\"\"Raised if an option is generally supplied but the use of the option\n    was incorrect.  This is for instance raised if the number of arguments\n    for an option is not correct.\n\n    .. versionadded:: 4.0\n\n    :param option_name: the name of the option being used incorrectly.\n    \"\"\"\n\n    def __init__(\n        self, option_name: str, message: str, ctx: t.Optional[\"Context\"] = None\n    ) -> None:\n        super().__init__(message, ctx)\n        self.option_name = option_name\n\n\nclass BadArgumentUsage(UsageError):\n    \"\"\"Raised if an argument is generally supplied but the use of the argument\n    was incorrect.  This is for instance raised if the number of values\n    for an argument is not correct.\n\n    .. versionadded:: 6.0\n    \"\"\"\n\n\nclass FileError(ClickException):\n    \"\"\"Raised if a file cannot be opened.\"\"\"\n\n    def __init__(self, filename: str, hint: t.Optional[str] = None) -> None:\n        if hint is None:\n            hint = _(\"unknown error\")\n\n        super().__init__(hint)\n        self.ui_filename: str = format_filename(filename)\n        self.filename = filename\n\n    def format_message(self) -> str:\n        return _(\"Could not open file {filename!r}: {message}\").format(\n            filename=self.ui_filename, message=self.message\n        )\n\n\nclass Abort(RuntimeError):\n    \"\"\"An internal signalling exception that signals Click to abort.\"\"\"\n\n\nclass Exit(RuntimeError):\n    \"\"\"An exception that indicates that the application should exit with some\n    status code.\n\n    :param code: the status code to exit with.\n    \"\"\"\n\n    __slots__ = (\"exit_code\",)\n\n    def __init__(self, code: int = 0) -> None:\n        self.exit_code: int = code\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "fc6c0b376868",
      "repo": "click",
      "commit_hash": "ab91b5a",
      "commit_message": "apply ruff fixes",
      "file_path": "src/click/parser.py",
      "language": "python",
      "code_before": "\"\"\"\nThis module started out as largely a copy paste from the stdlib's\noptparse module with the features removed that we do not need from\noptparse because we implement them in Click on a higher level (for\ninstance type handling, help formatting and a lot more).\n\nThe plan is to remove more and more from here over time.\n\nThe reason this is a different module and not optparse from the stdlib\nis that there are differences in 2.x and 3.x about the error messages\ngenerated and optparse in the stdlib uses gettext for no good reason\nand might cause us issues.\n\nClick uses parts of optparse written by Gregory P. Ward and maintained\nby the Python Software Foundation. This is limited to code in parser.py.\n\nCopyright 2001-2006 Gregory P. Ward. All rights reserved.\nCopyright 2002-2006 Python Software Foundation. All rights reserved.\n\"\"\"\n\n# This code uses parts of optparse written by Gregory P. Ward and\n# maintained by the Python Software Foundation.\n# Copyright 2001-2006 Gregory P. Ward\n# Copyright 2002-2006 Python Software Foundation\nimport typing as t\nfrom collections import deque\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom .exceptions import BadArgumentUsage\nfrom .exceptions import BadOptionUsage\nfrom .exceptions import NoSuchOption\nfrom .exceptions import UsageError\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .core import Argument as CoreArgument\n    from .core import Context\n    from .core import Option as CoreOption\n    from .core import Parameter as CoreParameter\n\nV = t.TypeVar(\"V\")\n\n# Sentinel value that indicates an option was passed as a flag without a\n# value but is not a flag option. Option.consume_value uses this to\n# prompt or use the flag_value.\n_flag_needs_value = object()\n\n\ndef _unpack_args(\n    args: t.Sequence[str], nargs_spec: t.Sequence[int]\n) -> t.Tuple[t.Sequence[t.Union[str, t.Sequence[t.Optional[str]], None]], t.List[str]]:\n    \"\"\"Given an iterable of arguments and an iterable of nargs specifications,\n    it returns a tuple with all the unpacked arguments at the first index\n    and all remaining arguments as the second.\n\n    The nargs specification is the number of arguments that should be consumed\n    or `-1` to indicate that this position should eat up all the remainders.\n\n    Missing items are filled with `None`.\n    \"\"\"\n    args = deque(args)\n    nargs_spec = deque(nargs_spec)\n    rv: t.List[t.Union[str, t.Tuple[t.Optional[str], ...], None]] = []\n    spos: t.Optional[int] = None\n\n    def _fetch(c: \"te.Deque[V]\") -> t.Optional[V]:\n        try:\n            if spos is None:\n                return c.popleft()\n            else:\n                return c.pop()\n        except IndexError:\n            return None\n\n    while nargs_spec:\n        nargs = _fetch(nargs_spec)\n\n        if nargs is None:\n            continue\n\n        if nargs == 1:\n            rv.append(_fetch(args))\n        elif nargs > 1:\n            x = [_fetch(args) for _ in range(nargs)]\n\n            # If we're reversed, we're pulling in the arguments in reverse,\n            # so we need to turn them around.\n            if spos is not None:\n                x.reverse()\n\n            rv.append(tuple(x))\n        elif nargs < 0:\n            if spos is not None:\n                raise TypeError(\"Cannot have two nargs < 0\")\n\n            spos = len(rv)\n            rv.append(None)\n\n    # spos is the position of the wildcard (star).  If it's not `None`,\n    # we fill it with the remainder.\n    if spos is not None:\n        rv[spos] = tuple(args)\n        args = []\n        rv[spos + 1 :] = reversed(rv[spos + 1 :])\n\n    return tuple(rv), list(args)\n\n\ndef split_opt(opt: str) -> t.Tuple[str, str]:\n    first = opt[:1]\n    if first.isalnum():\n        return \"\", opt\n    if opt[1:2] == first:\n        return opt[:2], opt[2:]\n    return first, opt[1:]\n\n\ndef normalize_opt(opt: str, ctx: t.Optional[\"Context\"]) -> str:\n    if ctx is None or ctx.token_normalize_func is None:\n        return opt\n    prefix, opt = split_opt(opt)\n    return f\"{prefix}{ctx.token_normalize_func(opt)}\"\n\n\ndef split_arg_string(string: str) -> t.List[str]:\n    \"\"\"Split an argument string as with :func:`shlex.split`, but don't\n    fail if the string is incomplete. Ignores a missing closing quote or\n    incomplete escape sequence and uses the partial token as-is.\n\n    .. code-block:: python\n\n        split_arg_string(\"example 'my file\")\n        [\"example\", \"my file\"]\n\n        split_arg_string(\"example my\\\\\")\n        [\"example\", \"my\"]\n\n    :param string: String to split.\n    \"\"\"\n    import shlex\n\n    lex = shlex.shlex(string, posix=True)\n    lex.whitespace_split = True\n    lex.commenters = \"\"\n    out = []\n\n    try:\n        for token in lex:\n            out.append(token)\n    except ValueError:\n        # Raised when end-of-string is reached in an invalid state. Use\n        # the partial token as-is. The quote or escape character is in\n        # lex.state, not lex.token.\n        out.append(lex.token)\n\n    return out\n\n\nclass Option:\n    def __init__(\n        self,\n        obj: \"CoreOption\",\n        opts: t.Sequence[str],\n        dest: t.Optional[str],\n        action: t.Optional[str] = None,\n        nargs: int = 1,\n        const: t.Optional[t.Any] = None,\n    ):\n        self._short_opts = []\n        self._long_opts = []\n        self.prefixes: t.Set[str] = set()\n\n        for opt in opts:\n            prefix, value = split_opt(opt)\n            if not prefix:\n                raise ValueError(f\"Invalid start character for option ({opt})\")\n            self.prefixes.add(prefix[0])\n            if len(prefix) == 1 and len(value) == 1:\n                self._short_opts.append(opt)\n            else:\n                self._long_opts.append(opt)\n                self.prefixes.add(prefix)\n\n        if action is None:\n            action = \"store\"\n\n        self.dest = dest\n        self.action = action\n        self.nargs = nargs\n        self.const = const\n        self.obj = obj\n\n    @property\n    def takes_value(self) -> bool:\n        return self.action in (\"store\", \"append\")\n\n    def process(self, value: t.Any, state: \"ParsingState\") -> None:\n        if self.action == \"store\":\n            state.opts[self.dest] = value  # type: ignore\n        elif self.action == \"store_const\":\n            state.opts[self.dest] = self.const  # type: ignore\n        elif self.action == \"append\":\n            state.opts.setdefault(self.dest, []).append(value)  # type: ignore\n        elif self.action == \"append_const\":\n            state.opts.setdefault(self.dest, []).append(self.const)  # type: ignore\n        elif self.action == \"count\":\n            state.opts[self.dest] = state.opts.get(self.dest, 0) + 1  # type: ignore\n        else:\n            raise ValueError(f\"unknown action '{self.action}'\")\n        state.order.append(self.obj)\n\n\nclass Argument:\n    def __init__(self, obj: \"CoreArgument\", dest: t.Optional[str], nargs: int = 1):\n        self.dest = dest\n        self.nargs = nargs\n        self.obj = obj\n\n    def process(\n        self,\n        value: t.Union[t.Optional[str], t.Sequence[t.Optional[str]]],\n        state: \"ParsingState\",\n    ) -> None:\n        if self.nargs > 1:\n            assert value is not None\n            holes = sum(1 for x in value if x is None)\n            if holes == len(value):\n                value = None\n            elif holes != 0:\n                raise BadArgumentUsage(\n                    _(\"Argument {name!r} takes {nargs} values.\").format(\n                        name=self.dest, nargs=self.nargs\n                    )\n                )\n\n        if self.nargs == -1 and self.obj.envvar is not None and value == ():\n            # Replace empty tuple with None so that a value from the\n            # environment may be tried.\n            value = None\n\n        state.opts[self.dest] = value  # type: ignore\n        state.order.append(self.obj)\n\n\nclass ParsingState:\n    def __init__(self, rargs: t.List[str]) -> None:\n        self.opts: t.Dict[str, t.Any] = {}\n        self.largs: t.List[str] = []\n        self.rargs = rargs\n        self.order: t.List[\"CoreParameter\"] = []\n\n\nclass OptionParser:\n    \"\"\"The option parser is an internal class that is ultimately used to\n    parse options and arguments.  It's modelled after optparse and brings\n    a similar but vastly simplified API.  It should generally not be used\n    directly as the high level Click classes wrap it for you.\n\n    It's not nearly as extensible as optparse or argparse as it does not\n    implement features that are implemented on a higher level (such as\n    types or defaults).\n\n    :param ctx: optionally the :class:`~click.Context` where this parser\n                should go with.\n    \"\"\"\n\n    def __init__(self, ctx: t.Optional[\"Context\"] = None) -> None:\n        #: The :class:`~click.Context` for this parser.  This might be\n        #: `None` for some advanced use cases.\n        self.ctx = ctx\n        #: This controls how the parser deals with interspersed arguments.\n        #: If this is set to `False`, the parser will stop on the first\n        #: non-option.  Click uses this to implement nested subcommands\n        #: safely.\n        self.allow_interspersed_args: bool = True\n        #: This tells the parser how to deal with unknown options.  By\n        #: default it will error out (which is sensible), but there is a\n        #: second mode where it will ignore it and continue processing\n        #: after shifting all the unknown options into the resulting args.\n        self.ignore_unknown_options: bool = False\n\n        if ctx is not None:\n            self.allow_interspersed_args = ctx.allow_interspersed_args\n            self.ignore_unknown_options = ctx.ignore_unknown_options\n\n        self._short_opt: t.Dict[str, Option] = {}\n        self._long_opt: t.Dict[str, Option] = {}\n        self._opt_prefixes = {\"-\", \"--\"}\n        self._args: t.List[Argument] = []\n\n    def add_option(\n        self,\n        obj: \"CoreOption\",\n        opts: t.Sequence[str],\n        dest: t.Optional[str],\n        action: t.Optional[str] = None,\n        nargs: int = 1,\n        const: t.Optional[t.Any] = None,\n    ) -> None:\n        \"\"\"Adds a new option named `dest` to the parser.  The destination\n        is not inferred (unlike with optparse) and needs to be explicitly\n        provided.  Action can be any of ``store``, ``store_const``,\n        ``append``, ``append_const`` or ``count``.\n\n        The `obj` can be used to identify the option in the order list\n        that is returned from the parser.\n        \"\"\"\n        opts = [normalize_opt(opt, self.ctx) for opt in opts]\n        option = Option(obj, opts, dest, action=action, nargs=nargs, const=const)\n        self._opt_prefixes.update(option.prefixes)\n        for opt in option._short_opts:\n            self._short_opt[opt] = option\n        for opt in option._long_opts:\n            self._long_opt[opt] = option\n\n    def add_argument(\n        self, obj: \"CoreArgument\", dest: t.Optional[str], nargs: int = 1\n    ) -> None:\n        \"\"\"Adds a positional argument named `dest` to the parser.\n\n        The `obj` can be used to identify the option in the order list\n        that is returned from the parser.\n        \"\"\"\n        self._args.append(Argument(obj, dest=dest, nargs=nargs))\n\n    def parse_args(\n        self, args: t.List[str]\n    ) -> t.Tuple[t.Dict[str, t.Any], t.List[str], t.List[\"CoreParameter\"]]:\n        \"\"\"Parses positional arguments and returns ``(values, args, order)``\n        for the parsed options and arguments as well as the leftover\n        arguments if there are any.  The order is a list of objects as they\n        appear on the command line.  If arguments appear multiple times they\n        will be memorized multiple times as well.\n        \"\"\"\n        state = ParsingState(args)\n        try:\n            self._process_args_for_options(state)\n            self._process_args_for_args(state)\n        except UsageError:\n            if self.ctx is None or not self.ctx.resilient_parsing:\n                raise\n        return state.opts, state.largs, state.order\n\n    def _process_args_for_args(self, state: ParsingState) -> None:\n        pargs, args = _unpack_args(\n            state.largs + state.rargs, [x.nargs for x in self._args]\n        )\n\n        for idx, arg in enumerate(self._args):\n            arg.process(pargs[idx], state)\n\n        state.largs = args\n        state.rargs = []\n\n    def _process_args_for_options(self, state: ParsingState) -> None:\n        while state.rargs:\n            arg = state.rargs.pop(0)\n            arglen = len(arg)\n            # Double dashes always handled explicitly regardless of what\n            # prefixes are valid.\n            if arg == \"--\":\n                return\n            elif arg[:1] in self._opt_prefixes and arglen > 1:\n                self._process_opts(arg, state)\n            elif self.allow_interspersed_args:\n                state.largs.append(arg)\n            else:\n                state.rargs.insert(0, arg)\n                return\n\n        # Say this is the original argument list:\n        # [arg0, arg1, ..., arg(i-1), arg(i), arg(i+1), ..., arg(N-1)]\n        #                            ^\n        # (we are about to process arg(i)).\n        #\n        # Then rargs is [arg(i), ..., arg(N-1)] and largs is a *subset* of\n        # [arg0, ..., arg(i-1)] (any options and their arguments will have\n        # been removed from largs).\n        #\n        # The while loop will usually consume 1 or more arguments per pass.\n        # If it consumes 1 (eg. arg is an option that takes no arguments),\n        # then after _process_arg() is done the situation is:\n        #\n        #   largs = subset of [arg0, ..., arg(i)]\n        #   rargs = [arg(i+1), ..., arg(N-1)]\n        #\n        # If allow_interspersed_args is false, largs will always be\n        # *empty* -- still a subset of [arg0, ..., arg(i-1)], but\n        # not a very interesting subset!\n\n    def _match_long_opt(\n        self, opt: str, explicit_value: t.Optional[str], state: ParsingState\n    ) -> None:\n        if opt not in self._long_opt:\n            from difflib import get_close_matches\n\n            possibilities = get_close_matches(opt, self._long_opt)\n            raise NoSuchOption(opt, possibilities=possibilities, ctx=self.ctx)\n\n        option = self._long_opt[opt]\n        if option.takes_value:\n            # At this point it's safe to modify rargs by injecting the\n            # explicit value, because no exception is raised in this\n            # branch.  This means that the inserted value will be fully\n            # consumed.\n            if explicit_value is not None:\n                state.rargs.insert(0, explicit_value)\n\n            value = self._get_value_from_state(opt, option, state)\n\n        elif explicit_value is not None:\n            raise BadOptionUsage(\n                opt, _(\"Option {name!r} does not take a value.\").format(name=opt)\n            )\n\n        else:\n            value = None\n\n        option.process(value, state)\n\n    def _match_short_opt(self, arg: str, state: ParsingState) -> None:\n        stop = False\n        i = 1\n        prefix = arg[0]\n        unknown_options = []\n\n        for ch in arg[1:]:\n            opt = normalize_opt(f\"{prefix}{ch}\", self.ctx)\n            option = self._short_opt.get(opt)\n            i += 1\n\n            if not option:\n                if self.ignore_unknown_options:\n                    unknown_options.append(ch)\n                    continue\n                raise NoSuchOption(opt, ctx=self.ctx)\n            if option.takes_value:\n                # Any characters left in arg?  Pretend they're the\n                # next arg, and stop consuming characters of arg.\n                if i < len(arg):\n                    state.rargs.insert(0, arg[i:])\n                    stop = True\n\n                value = self._get_value_from_state(opt, option, state)\n\n            else:\n                value = None\n\n            option.process(value, state)\n\n            if stop:\n                break\n\n        # If we got any unknown options we recombine the string of the\n        # remaining options and re-attach the prefix, then report that\n        # to the state as new larg.  This way there is basic combinatorics\n        # that can be achieved while still ignoring unknown arguments.\n        if self.ignore_unknown_options and unknown_options:\n            state.largs.append(f\"{prefix}{''.join(unknown_options)}\")\n\n    def _get_value_from_state(\n        self, option_name: str, option: Option, state: ParsingState\n    ) -> t.Any:\n        nargs = option.nargs\n\n        if len(state.rargs) < nargs:\n            if option.obj._flag_needs_value:\n                # Option allows omitting the value.\n                value = _flag_needs_value\n            else:\n                raise BadOptionUsage(\n                    option_name,\n                    ngettext(\n                        \"Option {name!r} requires an argument.\",\n                        \"Option {name!r} requires {nargs} arguments.\",\n                        nargs,\n                    ).format(name=option_name, nargs=nargs),\n                )\n        elif nargs == 1:\n            next_rarg = state.rargs[0]\n\n            if (\n                option.obj._flag_needs_value\n                and isinstance(next_rarg, str)\n                and next_rarg[:1] in self._opt_prefixes\n                and len(next_rarg) > 1\n            ):\n                # The next arg looks like the start of an option, don't\n                # use it as the value if omitting the value is allowed.\n                value = _flag_needs_value\n            else:\n                value = state.rargs.pop(0)\n        else:\n            value = tuple(state.rargs[:nargs])\n            del state.rargs[:nargs]\n\n        return value\n\n    def _process_opts(self, arg: str, state: ParsingState) -> None:\n        explicit_value = None\n        # Long option handling happens in two parts.  The first part is\n        # supporting explicitly attached values.  In any case, we will try\n        # to long match the option first.\n        if \"=\" in arg:\n            long_opt, explicit_value = arg.split(\"=\", 1)\n        else:\n            long_opt = arg\n        norm_long_opt = normalize_opt(long_opt, self.ctx)\n\n        # At this point we will match the (assumed) long option through\n        # the long option matching code.  Note that this allows options\n        # like \"-foo\" to be matched as long options.\n        try:\n            self._match_long_opt(norm_long_opt, explicit_value, state)\n        except NoSuchOption:\n            # At this point the long option matching failed, and we need\n            # to try with short options.  However there is a special rule\n            # which says, that if we have a two character options prefix\n            # (applies to \"--foo\" for instance), we do not dispatch to the\n            # short option code and will instead raise the no option\n            # error.\n            if arg[:2] not in self._opt_prefixes:\n                self._match_short_opt(arg, state)\n                return\n\n            if not self.ignore_unknown_options:\n                raise\n\n            state.largs.append(arg)\n",
      "code_after": "\"\"\"\nThis module started out as largely a copy paste from the stdlib's\noptparse module with the features removed that we do not need from\noptparse because we implement them in Click on a higher level (for\ninstance type handling, help formatting and a lot more).\n\nThe plan is to remove more and more from here over time.\n\nThe reason this is a different module and not optparse from the stdlib\nis that there are differences in 2.x and 3.x about the error messages\ngenerated and optparse in the stdlib uses gettext for no good reason\nand might cause us issues.\n\nClick uses parts of optparse written by Gregory P. Ward and maintained\nby the Python Software Foundation. This is limited to code in parser.py.\n\nCopyright 2001-2006 Gregory P. Ward. All rights reserved.\nCopyright 2002-2006 Python Software Foundation. All rights reserved.\n\"\"\"\n\n# This code uses parts of optparse written by Gregory P. Ward and\n# maintained by the Python Software Foundation.\n# Copyright 2001-2006 Gregory P. Ward\n# Copyright 2002-2006 Python Software Foundation\nimport typing as t\nfrom collections import deque\nfrom gettext import gettext as _\nfrom gettext import ngettext\n\nfrom .exceptions import BadArgumentUsage\nfrom .exceptions import BadOptionUsage\nfrom .exceptions import NoSuchOption\nfrom .exceptions import UsageError\n\nif t.TYPE_CHECKING:\n    import typing_extensions as te\n\n    from .core import Argument as CoreArgument\n    from .core import Context\n    from .core import Option as CoreOption\n    from .core import Parameter as CoreParameter\n\nV = t.TypeVar(\"V\")\n\n# Sentinel value that indicates an option was passed as a flag without a\n# value but is not a flag option. Option.consume_value uses this to\n# prompt or use the flag_value.\n_flag_needs_value = object()\n\n\ndef _unpack_args(\n    args: t.Sequence[str], nargs_spec: t.Sequence[int]\n) -> t.Tuple[t.Sequence[t.Union[str, t.Sequence[t.Optional[str]], None]], t.List[str]]:\n    \"\"\"Given an iterable of arguments and an iterable of nargs specifications,\n    it returns a tuple with all the unpacked arguments at the first index\n    and all remaining arguments as the second.\n\n    The nargs specification is the number of arguments that should be consumed\n    or `-1` to indicate that this position should eat up all the remainders.\n\n    Missing items are filled with `None`.\n    \"\"\"\n    args = deque(args)\n    nargs_spec = deque(nargs_spec)\n    rv: t.List[t.Union[str, t.Tuple[t.Optional[str], ...], None]] = []\n    spos: t.Optional[int] = None\n\n    def _fetch(c: \"te.Deque[V]\") -> t.Optional[V]:\n        try:\n            if spos is None:\n                return c.popleft()\n            else:\n                return c.pop()\n        except IndexError:\n            return None\n\n    while nargs_spec:\n        nargs = _fetch(nargs_spec)\n\n        if nargs is None:\n            continue\n\n        if nargs == 1:\n            rv.append(_fetch(args))\n        elif nargs > 1:\n            x = [_fetch(args) for _ in range(nargs)]\n\n            # If we're reversed, we're pulling in the arguments in reverse,\n            # so we need to turn them around.\n            if spos is not None:\n                x.reverse()\n\n            rv.append(tuple(x))\n        elif nargs < 0:\n            if spos is not None:\n                raise TypeError(\"Cannot have two nargs < 0\")\n\n            spos = len(rv)\n            rv.append(None)\n\n    # spos is the position of the wildcard (star).  If it's not `None`,\n    # we fill it with the remainder.\n    if spos is not None:\n        rv[spos] = tuple(args)\n        args = []\n        rv[spos + 1 :] = reversed(rv[spos + 1 :])\n\n    return tuple(rv), list(args)\n\n\ndef split_opt(opt: str) -> t.Tuple[str, str]:\n    first = opt[:1]\n    if first.isalnum():\n        return \"\", opt\n    if opt[1:2] == first:\n        return opt[:2], opt[2:]\n    return first, opt[1:]\n\n\ndef normalize_opt(opt: str, ctx: t.Optional[\"Context\"]) -> str:\n    if ctx is None or ctx.token_normalize_func is None:\n        return opt\n    prefix, opt = split_opt(opt)\n    return f\"{prefix}{ctx.token_normalize_func(opt)}\"\n\n\ndef split_arg_string(string: str) -> t.List[str]:\n    \"\"\"Split an argument string as with :func:`shlex.split`, but don't\n    fail if the string is incomplete. Ignores a missing closing quote or\n    incomplete escape sequence and uses the partial token as-is.\n\n    .. code-block:: python\n\n        split_arg_string(\"example 'my file\")\n        [\"example\", \"my file\"]\n\n        split_arg_string(\"example my\\\\\")\n        [\"example\", \"my\"]\n\n    :param string: String to split.\n    \"\"\"\n    import shlex\n\n    lex = shlex.shlex(string, posix=True)\n    lex.whitespace_split = True\n    lex.commenters = \"\"\n    out = []\n\n    try:\n        for token in lex:\n            out.append(token)\n    except ValueError:\n        # Raised when end-of-string is reached in an invalid state. Use\n        # the partial token as-is. The quote or escape character is in\n        # lex.state, not lex.token.\n        out.append(lex.token)\n\n    return out\n\n\nclass Option:\n    def __init__(\n        self,\n        obj: \"CoreOption\",\n        opts: t.Sequence[str],\n        dest: t.Optional[str],\n        action: t.Optional[str] = None,\n        nargs: int = 1,\n        const: t.Optional[t.Any] = None,\n    ):\n        self._short_opts = []\n        self._long_opts = []\n        self.prefixes: t.Set[str] = set()\n\n        for opt in opts:\n            prefix, value = split_opt(opt)\n            if not prefix:\n                raise ValueError(f\"Invalid start character for option ({opt})\")\n            self.prefixes.add(prefix[0])\n            if len(prefix) == 1 and len(value) == 1:\n                self._short_opts.append(opt)\n            else:\n                self._long_opts.append(opt)\n                self.prefixes.add(prefix)\n\n        if action is None:\n            action = \"store\"\n\n        self.dest = dest\n        self.action = action\n        self.nargs = nargs\n        self.const = const\n        self.obj = obj\n\n    @property\n    def takes_value(self) -> bool:\n        return self.action in (\"store\", \"append\")\n\n    def process(self, value: t.Any, state: \"ParsingState\") -> None:\n        if self.action == \"store\":\n            state.opts[self.dest] = value  # type: ignore\n        elif self.action == \"store_const\":\n            state.opts[self.dest] = self.const  # type: ignore\n        elif self.action == \"append\":\n            state.opts.setdefault(self.dest, []).append(value)  # type: ignore\n        elif self.action == \"append_const\":\n            state.opts.setdefault(self.dest, []).append(self.const)  # type: ignore\n        elif self.action == \"count\":\n            state.opts[self.dest] = state.opts.get(self.dest, 0) + 1  # type: ignore\n        else:\n            raise ValueError(f\"unknown action '{self.action}'\")\n        state.order.append(self.obj)\n\n\nclass Argument:\n    def __init__(self, obj: \"CoreArgument\", dest: t.Optional[str], nargs: int = 1):\n        self.dest = dest\n        self.nargs = nargs\n        self.obj = obj\n\n    def process(\n        self,\n        value: t.Union[t.Optional[str], t.Sequence[t.Optional[str]]],\n        state: \"ParsingState\",\n    ) -> None:\n        if self.nargs > 1:\n            assert value is not None\n            holes = sum(1 for x in value if x is None)\n            if holes == len(value):\n                value = None\n            elif holes != 0:\n                raise BadArgumentUsage(\n                    _(\"Argument {name!r} takes {nargs} values.\").format(\n                        name=self.dest, nargs=self.nargs\n                    )\n                )\n\n        if self.nargs == -1 and self.obj.envvar is not None and value == ():\n            # Replace empty tuple with None so that a value from the\n            # environment may be tried.\n            value = None\n\n        state.opts[self.dest] = value  # type: ignore\n        state.order.append(self.obj)\n\n\nclass ParsingState:\n    def __init__(self, rargs: t.List[str]) -> None:\n        self.opts: t.Dict[str, t.Any] = {}\n        self.largs: t.List[str] = []\n        self.rargs = rargs\n        self.order: t.List[CoreParameter] = []\n\n\nclass OptionParser:\n    \"\"\"The option parser is an internal class that is ultimately used to\n    parse options and arguments.  It's modelled after optparse and brings\n    a similar but vastly simplified API.  It should generally not be used\n    directly as the high level Click classes wrap it for you.\n\n    It's not nearly as extensible as optparse or argparse as it does not\n    implement features that are implemented on a higher level (such as\n    types or defaults).\n\n    :param ctx: optionally the :class:`~click.Context` where this parser\n                should go with.\n    \"\"\"\n\n    def __init__(self, ctx: t.Optional[\"Context\"] = None) -> None:\n        #: The :class:`~click.Context` for this parser.  This might be\n        #: `None` for some advanced use cases.\n        self.ctx = ctx\n        #: This controls how the parser deals with interspersed arguments.\n        #: If this is set to `False`, the parser will stop on the first\n        #: non-option.  Click uses this to implement nested subcommands\n        #: safely.\n        self.allow_interspersed_args: bool = True\n        #: This tells the parser how to deal with unknown options.  By\n        #: default it will error out (which is sensible), but there is a\n        #: second mode where it will ignore it and continue processing\n        #: after shifting all the unknown options into the resulting args.\n        self.ignore_unknown_options: bool = False\n\n        if ctx is not None:\n            self.allow_interspersed_args = ctx.allow_interspersed_args\n            self.ignore_unknown_options = ctx.ignore_unknown_options\n\n        self._short_opt: t.Dict[str, Option] = {}\n        self._long_opt: t.Dict[str, Option] = {}\n        self._opt_prefixes = {\"-\", \"--\"}\n        self._args: t.List[Argument] = []\n\n    def add_option(\n        self,\n        obj: \"CoreOption\",\n        opts: t.Sequence[str],\n        dest: t.Optional[str],\n        action: t.Optional[str] = None,\n        nargs: int = 1,\n        const: t.Optional[t.Any] = None,\n    ) -> None:\n        \"\"\"Adds a new option named `dest` to the parser.  The destination\n        is not inferred (unlike with optparse) and needs to be explicitly\n        provided.  Action can be any of ``store``, ``store_const``,\n        ``append``, ``append_const`` or ``count``.\n\n        The `obj` can be used to identify the option in the order list\n        that is returned from the parser.\n        \"\"\"\n        opts = [normalize_opt(opt, self.ctx) for opt in opts]\n        option = Option(obj, opts, dest, action=action, nargs=nargs, const=const)\n        self._opt_prefixes.update(option.prefixes)\n        for opt in option._short_opts:\n            self._short_opt[opt] = option\n        for opt in option._long_opts:\n            self._long_opt[opt] = option\n\n    def add_argument(\n        self, obj: \"CoreArgument\", dest: t.Optional[str], nargs: int = 1\n    ) -> None:\n        \"\"\"Adds a positional argument named `dest` to the parser.\n\n        The `obj` can be used to identify the option in the order list\n        that is returned from the parser.\n        \"\"\"\n        self._args.append(Argument(obj, dest=dest, nargs=nargs))\n\n    def parse_args(\n        self, args: t.List[str]\n    ) -> t.Tuple[t.Dict[str, t.Any], t.List[str], t.List[\"CoreParameter\"]]:\n        \"\"\"Parses positional arguments and returns ``(values, args, order)``\n        for the parsed options and arguments as well as the leftover\n        arguments if there are any.  The order is a list of objects as they\n        appear on the command line.  If arguments appear multiple times they\n        will be memorized multiple times as well.\n        \"\"\"\n        state = ParsingState(args)\n        try:\n            self._process_args_for_options(state)\n            self._process_args_for_args(state)\n        except UsageError:\n            if self.ctx is None or not self.ctx.resilient_parsing:\n                raise\n        return state.opts, state.largs, state.order\n\n    def _process_args_for_args(self, state: ParsingState) -> None:\n        pargs, args = _unpack_args(\n            state.largs + state.rargs, [x.nargs for x in self._args]\n        )\n\n        for idx, arg in enumerate(self._args):\n            arg.process(pargs[idx], state)\n\n        state.largs = args\n        state.rargs = []\n\n    def _process_args_for_options(self, state: ParsingState) -> None:\n        while state.rargs:\n            arg = state.rargs.pop(0)\n            arglen = len(arg)\n            # Double dashes always handled explicitly regardless of what\n            # prefixes are valid.\n            if arg == \"--\":\n                return\n            elif arg[:1] in self._opt_prefixes and arglen > 1:\n                self._process_opts(arg, state)\n            elif self.allow_interspersed_args:\n                state.largs.append(arg)\n            else:\n                state.rargs.insert(0, arg)\n                return\n\n        # Say this is the original argument list:\n        # [arg0, arg1, ..., arg(i-1), arg(i), arg(i+1), ..., arg(N-1)]\n        #                            ^\n        # (we are about to process arg(i)).\n        #\n        # Then rargs is [arg(i), ..., arg(N-1)] and largs is a *subset* of\n        # [arg0, ..., arg(i-1)] (any options and their arguments will have\n        # been removed from largs).\n        #\n        # The while loop will usually consume 1 or more arguments per pass.\n        # If it consumes 1 (eg. arg is an option that takes no arguments),\n        # then after _process_arg() is done the situation is:\n        #\n        #   largs = subset of [arg0, ..., arg(i)]\n        #   rargs = [arg(i+1), ..., arg(N-1)]\n        #\n        # If allow_interspersed_args is false, largs will always be\n        # *empty* -- still a subset of [arg0, ..., arg(i-1)], but\n        # not a very interesting subset!\n\n    def _match_long_opt(\n        self, opt: str, explicit_value: t.Optional[str], state: ParsingState\n    ) -> None:\n        if opt not in self._long_opt:\n            from difflib import get_close_matches\n\n            possibilities = get_close_matches(opt, self._long_opt)\n            raise NoSuchOption(opt, possibilities=possibilities, ctx=self.ctx)\n\n        option = self._long_opt[opt]\n        if option.takes_value:\n            # At this point it's safe to modify rargs by injecting the\n            # explicit value, because no exception is raised in this\n            # branch.  This means that the inserted value will be fully\n            # consumed.\n            if explicit_value is not None:\n                state.rargs.insert(0, explicit_value)\n\n            value = self._get_value_from_state(opt, option, state)\n\n        elif explicit_value is not None:\n            raise BadOptionUsage(\n                opt, _(\"Option {name!r} does not take a value.\").format(name=opt)\n            )\n\n        else:\n            value = None\n\n        option.process(value, state)\n\n    def _match_short_opt(self, arg: str, state: ParsingState) -> None:\n        stop = False\n        i = 1\n        prefix = arg[0]\n        unknown_options = []\n\n        for ch in arg[1:]:\n            opt = normalize_opt(f\"{prefix}{ch}\", self.ctx)\n            option = self._short_opt.get(opt)\n            i += 1\n\n            if not option:\n                if self.ignore_unknown_options:\n                    unknown_options.append(ch)\n                    continue\n                raise NoSuchOption(opt, ctx=self.ctx)\n            if option.takes_value:\n                # Any characters left in arg?  Pretend they're the\n                # next arg, and stop consuming characters of arg.\n                if i < len(arg):\n                    state.rargs.insert(0, arg[i:])\n                    stop = True\n\n                value = self._get_value_from_state(opt, option, state)\n\n            else:\n                value = None\n\n            option.process(value, state)\n\n            if stop:\n                break\n\n        # If we got any unknown options we recombine the string of the\n        # remaining options and re-attach the prefix, then report that\n        # to the state as new larg.  This way there is basic combinatorics\n        # that can be achieved while still ignoring unknown arguments.\n        if self.ignore_unknown_options and unknown_options:\n            state.largs.append(f\"{prefix}{''.join(unknown_options)}\")\n\n    def _get_value_from_state(\n        self, option_name: str, option: Option, state: ParsingState\n    ) -> t.Any:\n        nargs = option.nargs\n\n        if len(state.rargs) < nargs:\n            if option.obj._flag_needs_value:\n                # Option allows omitting the value.\n                value = _flag_needs_value\n            else:\n                raise BadOptionUsage(\n                    option_name,\n                    ngettext(\n                        \"Option {name!r} requires an argument.\",\n                        \"Option {name!r} requires {nargs} arguments.\",\n                        nargs,\n                    ).format(name=option_name, nargs=nargs),\n                )\n        elif nargs == 1:\n            next_rarg = state.rargs[0]\n\n            if (\n                option.obj._flag_needs_value\n                and isinstance(next_rarg, str)\n                and next_rarg[:1] in self._opt_prefixes\n                and len(next_rarg) > 1\n            ):\n                # The next arg looks like the start of an option, don't\n                # use it as the value if omitting the value is allowed.\n                value = _flag_needs_value\n            else:\n                value = state.rargs.pop(0)\n        else:\n            value = tuple(state.rargs[:nargs])\n            del state.rargs[:nargs]\n\n        return value\n\n    def _process_opts(self, arg: str, state: ParsingState) -> None:\n        explicit_value = None\n        # Long option handling happens in two parts.  The first part is\n        # supporting explicitly attached values.  In any case, we will try\n        # to long match the option first.\n        if \"=\" in arg:\n            long_opt, explicit_value = arg.split(\"=\", 1)\n        else:\n            long_opt = arg\n        norm_long_opt = normalize_opt(long_opt, self.ctx)\n\n        # At this point we will match the (assumed) long option through\n        # the long option matching code.  Note that this allows options\n        # like \"-foo\" to be matched as long options.\n        try:\n            self._match_long_opt(norm_long_opt, explicit_value, state)\n        except NoSuchOption:\n            # At this point the long option matching failed, and we need\n            # to try with short options.  However there is a special rule\n            # which says, that if we have a two character options prefix\n            # (applies to \"--foo\" for instance), we do not dispatch to the\n            # short option code and will instead raise the no option\n            # error.\n            if arg[:2] not in self._opt_prefixes:\n                self._match_short_opt(arg, state)\n                return\n\n            if not self.ignore_unknown_options:\n                raise\n\n            state.largs.append(arg)\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "5f09e2e04ee7",
      "repo": "httpx",
      "commit_hash": "4189b7f",
      "commit_message": "fix typo (#3519)",
      "file_path": "httpx/_models.py",
      "language": "python",
      "code_before": "from __future__ import annotations\n\nimport codecs\nimport datetime\nimport email.message\nimport json as jsonlib\nimport re\nimport typing\nimport urllib.request\nfrom collections.abc import Mapping\nfrom http.cookiejar import Cookie, CookieJar\n\nfrom ._content import ByteStream, UnattachedStream, encode_request, encode_response\nfrom ._decoders import (\n    SUPPORTED_DECODERS,\n    ByteChunker,\n    ContentDecoder,\n    IdentityDecoder,\n    LineDecoder,\n    MultiDecoder,\n    TextChunker,\n    TextDecoder,\n)\nfrom ._exceptions import (\n    CookieConflict,\n    HTTPStatusError,\n    RequestNotRead,\n    ResponseNotRead,\n    StreamClosed,\n    StreamConsumed,\n    request_context,\n)\nfrom ._multipart import get_multipart_boundary_from_content_type\nfrom ._status_codes import codes\nfrom ._types import (\n    AsyncByteStream,\n    CookieTypes,\n    HeaderTypes,\n    QueryParamTypes,\n    RequestContent,\n    RequestData,\n    RequestExtensions,\n    RequestFiles,\n    ResponseContent,\n    ResponseExtensions,\n    SyncByteStream,\n)\nfrom ._urls import URL\nfrom ._utils import to_bytes_or_str, to_str\n\n__all__ = [\"Cookies\", \"Headers\", \"Request\", \"Response\"]\n\nSENSITIVE_HEADERS = {\"authorization\", \"proxy-authorization\"}\n\n\ndef _is_known_encoding(encoding: str) -> bool:\n    \"\"\"\n    Return `True` if `encoding` is a known codec.\n    \"\"\"\n    try:\n        codecs.lookup(encoding)\n    except LookupError:\n        return False\n    return True\n\n\ndef _normalize_header_key(key: str | bytes, encoding: str | None = None) -> bytes:\n    \"\"\"\n    Coerce str/bytes into a strictly byte-wise HTTP header key.\n    \"\"\"\n    return key if isinstance(key, bytes) else key.encode(encoding or \"ascii\")\n\n\ndef _normalize_header_value(value: str | bytes, encoding: str | None = None) -> bytes:\n    \"\"\"\n    Coerce str/bytes into a strictly byte-wise HTTP header value.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    if not isinstance(value, str):\n        raise TypeError(f\"Header value must be str or bytes, not {type(value)}\")\n    return value.encode(encoding or \"ascii\")\n\n\ndef _parse_content_type_charset(content_type: str) -> str | None:\n    # We used to use `cgi.parse_header()` here, but `cgi` became a dead battery.\n    # See: https://peps.python.org/pep-0594/#cgi\n    msg = email.message.Message()\n    msg[\"content-type\"] = content_type\n    return msg.get_content_charset(failobj=None)\n\n\ndef _parse_header_links(value: str) -> list[dict[str, str]]:\n    \"\"\"\n    Returns a list of parsed link headers, for more info see:\n    https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Link\n    The generic syntax of those is:\n    Link: < uri-reference >; param1=value1; param2=\"value2\"\n    So for instance:\n    Link; '<http:/.../front.jpeg>; type=\"image/jpeg\",<http://.../back.jpeg>;'\n    would return\n        [\n            {\"url\": \"http:/.../front.jpeg\", \"type\": \"image/jpeg\"},\n            {\"url\": \"http://.../back.jpeg\"},\n        ]\n    :param value: HTTP Link entity-header field\n    :return: list of parsed link headers\n    \"\"\"\n    links: list[dict[str, str]] = []\n    replace_chars = \" '\\\"\"\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n        links.append(link)\n    return links\n\n\ndef _obfuscate_sensitive_headers(\n    items: typing.Iterable[tuple[typing.AnyStr, typing.AnyStr]],\n) -> typing.Iterator[tuple[typing.AnyStr, typing.AnyStr]]:\n    for k, v in items:\n        if to_str(k.lower()) in SENSITIVE_HEADERS:\n            v = to_bytes_or_str(\"[secure]\", match_type_of=v)\n        yield k, v\n\n\nclass Headers(typing.MutableMapping[str, str]):\n    \"\"\"\n    HTTP headers, as a case-insensitive multi-dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        headers: HeaderTypes | None = None,\n        encoding: str | None = None,\n    ) -> None:\n        self._list = []  # type: typing.List[typing.Tuple[bytes, bytes, bytes]]\n\n        if isinstance(headers, Headers):\n            self._list = list(headers._list)\n        elif isinstance(headers, Mapping):\n            for k, v in headers.items():\n                bytes_key = _normalize_header_key(k, encoding)\n                bytes_value = _normalize_header_value(v, encoding)\n                self._list.append((bytes_key, bytes_key.lower(), bytes_value))\n        elif headers is not None:\n            for k, v in headers:\n                bytes_key = _normalize_header_key(k, encoding)\n                bytes_value = _normalize_header_value(v, encoding)\n                self._list.append((bytes_key, bytes_key.lower(), bytes_value))\n\n        self._encoding = encoding\n\n    @property\n    def encoding(self) -> str:\n        \"\"\"\n        Header encoding is mandated as ascii, but we allow fallbacks to utf-8\n        or iso-8859-1.\n        \"\"\"\n        if self._encoding is None:\n            for encoding in [\"ascii\", \"utf-8\"]:\n                for key, value in self.raw:\n                    try:\n                        key.decode(encoding)\n                        value.decode(encoding)\n                    except UnicodeDecodeError:\n                        break\n                else:\n                    # The else block runs if 'break' did not occur, meaning\n                    # all values fitted the encoding.\n                    self._encoding = encoding\n                    break\n            else:\n                # The ISO-8859-1 encoding covers all 256 code points in a byte,\n                # so will never raise decode errors.\n                self._encoding = \"iso-8859-1\"\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value: str) -> None:\n        self._encoding = value\n\n    @property\n    def raw(self) -> list[tuple[bytes, bytes]]:\n        \"\"\"\n        Returns a list of the raw header items, as byte pairs.\n        \"\"\"\n        return [(raw_key, value) for raw_key, _, value in self._list]\n\n    def keys(self) -> typing.KeysView[str]:\n        return {key.decode(self.encoding): None for _, key, value in self._list}.keys()\n\n    def values(self) -> typing.ValuesView[str]:\n        values_dict: dict[str, str] = {}\n        for _, key, value in self._list:\n            str_key = key.decode(self.encoding)\n            str_value = value.decode(self.encoding)\n            if str_key in values_dict:\n                values_dict[str_key] += f\", {str_value}\"\n            else:\n                values_dict[str_key] = str_value\n        return values_dict.values()\n\n    def items(self) -> typing.ItemsView[str, str]:\n        \"\"\"\n        Return `(key, value)` items of headers. Concatenate headers\n        into a single comma separated value when a key occurs multiple times.\n        \"\"\"\n        values_dict: dict[str, str] = {}\n        for _, key, value in self._list:\n            str_key = key.decode(self.encoding)\n            str_value = value.decode(self.encoding)\n            if str_key in values_dict:\n                values_dict[str_key] += f\", {str_value}\"\n            else:\n                values_dict[str_key] = str_value\n        return values_dict.items()\n\n    def multi_items(self) -> list[tuple[str, str]]:\n        \"\"\"\n        Return a list of `(key, value)` pairs of headers. Allow multiple\n        occurrences of the same key without concatenating into a single\n        comma separated value.\n        \"\"\"\n        return [\n            (key.decode(self.encoding), value.decode(self.encoding))\n            for _, key, value in self._list\n        ]\n\n    def get(self, key: str, default: typing.Any = None) -> typing.Any:\n        \"\"\"\n        Return a header value. If multiple occurrences of the header occur\n        then concatenate them together with commas.\n        \"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def get_list(self, key: str, split_commas: bool = False) -> list[str]:\n        \"\"\"\n        Return a list of all header values for a given key.\n        If `split_commas=True` is passed, then any comma separated header\n        values are split into multiple return strings.\n        \"\"\"\n        get_header_key = key.lower().encode(self.encoding)\n\n        values = [\n            item_value.decode(self.encoding)\n            for _, item_key, item_value in self._list\n            if item_key.lower() == get_header_key\n        ]\n\n        if not split_commas:\n            return values\n\n        split_values = []\n        for value in values:\n            split_values.extend([item.strip() for item in value.split(\",\")])\n        return split_values\n\n    def update(self, headers: HeaderTypes | None = None) -> None:  # type: ignore\n        headers = Headers(headers)\n        for key in headers.keys():\n            if key in self:\n                self.pop(key)\n        self._list.extend(headers._list)\n\n    def copy(self) -> Headers:\n        return Headers(self, encoding=self.encoding)\n\n    def __getitem__(self, key: str) -> str:\n        \"\"\"\n        Return a single header value.\n\n        If there are multiple headers with the same key, then we concatenate\n        them with commas. See: https://tools.ietf.org/html/rfc7230#section-3.2.2\n        \"\"\"\n        normalized_key = key.lower().encode(self.encoding)\n\n        items = [\n            header_value.decode(self.encoding)\n            for _, header_key, header_value in self._list\n            if header_key == normalized_key\n        ]\n\n        if items:\n            return \", \".join(items)\n\n        raise KeyError(key)\n\n    def __setitem__(self, key: str, value: str) -> None:\n        \"\"\"\n        Set the header `key` to `value`, removing any duplicate entries.\n        Retains insertion order.\n        \"\"\"\n        set_key = key.encode(self._encoding or \"utf-8\")\n        set_value = value.encode(self._encoding or \"utf-8\")\n        lookup_key = set_key.lower()\n\n        found_indexes = [\n            idx\n            for idx, (_, item_key, _) in enumerate(self._list)\n            if item_key == lookup_key\n        ]\n\n        for idx in reversed(found_indexes[1:]):\n            del self._list[idx]\n\n        if found_indexes:\n            idx = found_indexes[0]\n            self._list[idx] = (set_key, lookup_key, set_value)\n        else:\n            self._list.append((set_key, lookup_key, set_value))\n\n    def __delitem__(self, key: str) -> None:\n        \"\"\"\n        Remove the header `key`.\n        \"\"\"\n        del_key = key.lower().encode(self.encoding)\n\n        pop_indexes = [\n            idx\n            for idx, (_, item_key, _) in enumerate(self._list)\n            if item_key.lower() == del_key\n        ]\n\n        if not pop_indexes:\n            raise KeyError(key)\n\n        for idx in reversed(pop_indexes):\n            del self._list[idx]\n\n    def __contains__(self, key: typing.Any) -> bool:\n        header_key = key.lower().encode(self.encoding)\n        return header_key in [key for _, key, _ in self._list]\n\n    def __iter__(self) -> typing.Iterator[typing.Any]:\n        return iter(self.keys())\n\n    def __len__(self) -> int:\n        return len(self._list)\n\n    def __eq__(self, other: typing.Any) -> bool:\n        try:\n            other_headers = Headers(other)\n        except ValueError:\n            return False\n\n        self_list = [(key, value) for _, key, value in self._list]\n        other_list = [(key, value) for _, key, value in other_headers._list]\n        return sorted(self_list) == sorted(other_list)\n\n    def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n\n        encoding_str = \"\"\n        if self.encoding != \"ascii\":\n            encoding_str = f\", encoding={self.encoding!r}\"\n\n        as_list = list(_obfuscate_sensitive_headers(self.multi_items()))\n        as_dict = dict(as_list)\n\n        no_duplicate_keys = len(as_dict) == len(as_list)\n        if no_duplicate_keys:\n            return f\"{class_name}({as_dict!r}{encoding_str})\"\n        return f\"{class_name}({as_list!r}{encoding_str})\"\n\n\nclass Request:\n    def __init__(\n        self,\n        method: str,\n        url: URL | str,\n        *,\n        params: QueryParamTypes | None = None,\n        headers: HeaderTypes | None = None,\n        cookies: CookieTypes | None = None,\n        content: RequestContent | None = None,\n        data: RequestData | None = None,\n        files: RequestFiles | None = None,\n        json: typing.Any | None = None,\n        stream: SyncByteStream | AsyncByteStream | None = None,\n        extensions: RequestExtensions | None = None,\n    ) -> None:\n        self.method = method.upper()\n        self.url = URL(url) if params is None else URL(url, params=params)\n        self.headers = Headers(headers)\n        self.extensions = {} if extensions is None else dict(extensions)\n\n        if cookies:\n            Cookies(cookies).set_cookie_header(self)\n\n        if stream is None:\n            content_type: str | None = self.headers.get(\"content-type\")\n            headers, stream = encode_request(\n                content=content,\n                data=data,\n                files=files,\n                json=json,\n                boundary=get_multipart_boundary_from_content_type(\n                    content_type=content_type.encode(self.headers.encoding)\n                    if content_type\n                    else None\n                ),\n            )\n            self._prepare(headers)\n            self.stream = stream\n            # Load the request body, except for streaming content.\n            if isinstance(stream, ByteStream):\n                self.read()\n        else:\n            # There's an important distinction between `Request(content=...)`,\n            # and `Request(stream=...)`.\n            #\n            # Using `content=...` implies automatically populated `Host` and content\n            # headers, of either `Content-Length: ...` or `Transfer-Encoding: chunked`.\n            #\n            # Using `stream=...` will not automatically include *any*\n            # auto-populated headers.\n            #\n            # As an end-user you don't really need `stream=...`. It's only\n            # useful when:\n            #\n            # * Preserving the request stream when copying requests, eg for redirects.\n            # * Creating request instances on the *server-side* of the transport API.\n            self.stream = stream\n\n    def _prepare(self, default_headers: dict[str, str]) -> None:\n        for key, value in default_headers.items():\n            # Ignore Transfer-Encoding if the Content-Length has been set explicitly.\n            if key.lower() == \"transfer-encoding\" and \"Content-Length\" in self.headers:\n                continue\n            self.headers.setdefault(key, value)\n\n        auto_headers: list[tuple[bytes, bytes]] = []\n\n        has_host = \"Host\" in self.headers\n        has_content_length = (\n            \"Content-Length\" in self.headers or \"Transfer-Encoding\" in self.headers\n        )\n\n        if not has_host and self.url.host:\n            auto_headers.append((b\"Host\", self.url.netloc))\n        if not has_content_length and self.method in (\"POST\", \"PUT\", \"PATCH\"):\n            auto_headers.append((b\"Content-Length\", b\"0\"))\n\n        self.headers = Headers(auto_headers + self.headers.raw)\n\n    @property\n    def content(self) -> bytes:\n        if not hasattr(self, \"_content\"):\n            raise RequestNotRead()\n        return self._content\n\n    def read(self) -> bytes:\n        \"\"\"\n        Read and return the request content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            assert isinstance(self.stream, typing.Iterable)\n            self._content = b\"\".join(self.stream)\n            if not isinstance(self.stream, ByteStream):\n                # If a streaming request has been read entirely into memory, then\n                # we can replace the stream with a raw bytes implementation,\n                # to ensure that any non-replayable streams can still be used.\n                self.stream = ByteStream(self._content)\n        return self._content\n\n    async def aread(self) -> bytes:\n        \"\"\"\n        Read and return the request content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            assert isinstance(self.stream, typing.AsyncIterable)\n            self._content = b\"\".join([part async for part in self.stream])\n            if not isinstance(self.stream, ByteStream):\n                # If a streaming request has been read entirely into memory, then\n                # we can replace the stream with a raw bytes implementation,\n                # to ensure that any non-replayable streams can still be used.\n                self.stream = ByteStream(self._content)\n        return self._content\n\n    def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        url = str(self.url)\n        return f\"<{class_name}({self.method!r}, {url!r})>\"\n\n    def __getstate__(self) -> dict[str, typing.Any]:\n        return {\n            name: value\n            for name, value in self.__dict__.items()\n            if name not in [\"extensions\", \"stream\"]\n        }\n\n    def __setstate__(self, state: dict[str, typing.Any]) -> None:\n        for name, value in state.items():\n            setattr(self, name, value)\n        self.extensions = {}\n        self.stream = UnattachedStream()\n\n\nclass Response:\n    def __init__(\n        self,\n        status_code: int,\n        *,\n        headers: HeaderTypes | None = None,\n        content: ResponseContent | None = None,\n        text: str | None = None,\n        html: str | None = None,\n        json: typing.Any = None,\n        stream: SyncByteStream | AsyncByteStream | None = None,\n        request: Request | None = None,\n        extensions: ResponseExtensions | None = None,\n        history: list[Response] | None = None,\n        default_encoding: str | typing.Callable[[bytes], str] = \"utf-8\",\n    ) -> None:\n        self.status_code = status_code\n        self.headers = Headers(headers)\n\n        self._request: Request | None = request\n\n        # When follow_redirects=False and a redirect is received,\n        # the client will set `response.next_request`.\n        self.next_request: Request | None = None\n\n        self.extensions = {} if extensions is None else dict(extensions)\n        self.history = [] if history is None else list(history)\n\n        self.is_closed = False\n        self.is_stream_consumed = False\n\n        self.default_encoding = default_encoding\n\n        if stream is None:\n            headers, stream = encode_response(content, text, html, json)\n            self._prepare(headers)\n            self.stream = stream\n            if isinstance(stream, ByteStream):\n                # Load the response body, except for streaming content.\n                self.read()\n        else:\n            # There's an important distinction between `Response(content=...)`,\n            # and `Response(stream=...)`.\n            #\n            # Using `content=...` implies automatically populated content headers,\n            # of either `Content-Length: ...` or `Transfer-Encoding: chunked`.\n            #\n            # Using `stream=...` will not automatically include any content headers.\n            #\n            # As an end-user you don't really need `stream=...`. It's only\n            # useful when creating response instances having received a stream\n            # from the transport API.\n            self.stream = stream\n\n        self._num_bytes_downloaded = 0\n\n    def _prepare(self, default_headers: dict[str, str]) -> None:\n        for key, value in default_headers.items():\n            # Ignore Transfer-Encoding if the Content-Length has been set explicitly.\n            if key.lower() == \"transfer-encoding\" and \"content-length\" in self.headers:\n                continue\n            self.headers.setdefault(key, value)\n\n    @property\n    def elapsed(self) -> datetime.timedelta:\n        \"\"\"\n        Returns the time taken for the complete request/response\n        cycle to complete.\n        \"\"\"\n        if not hasattr(self, \"_elapsed\"):\n            raise RuntimeError(\n                \"'.elapsed' may only be accessed after the response \"\n                \"has been read or closed.\"\n            )\n        return self._elapsed\n\n    @elapsed.setter\n    def elapsed(self, elapsed: datetime.timedelta) -> None:\n        self._elapsed = elapsed\n\n    @property\n    def request(self) -> Request:\n        \"\"\"\n        Returns the request instance associated to the current response.\n        \"\"\"\n        if self._request is None:\n            raise RuntimeError(\n                \"The request instance has not been set on this response.\"\n            )\n        return self._request\n\n    @request.setter\n    def request(self, value: Request) -> None:\n        self._request = value\n\n    @property\n    def http_version(self) -> str:\n        try:\n            http_version: bytes = self.extensions[\"http_version\"]\n        except KeyError:\n            return \"HTTP/1.1\"\n        else:\n            return http_version.decode(\"ascii\", errors=\"ignore\")\n\n    @property\n    def reason_phrase(self) -> str:\n        try:\n            reason_phrase: bytes = self.extensions[\"reason_phrase\"]\n        except KeyError:\n            return codes.get_reason_phrase(self.status_code)\n        else:\n            return reason_phrase.decode(\"ascii\", errors=\"ignore\")\n\n    @property\n    def url(self) -> URL:\n        \"\"\"\n        Returns the URL for which the request was made.\n        \"\"\"\n        return self.request.url\n\n    @property\n    def content(self) -> bytes:\n        if not hasattr(self, \"_content\"):\n            raise ResponseNotRead()\n        return self._content\n\n    @property\n    def text(self) -> str:\n        if not hasattr(self, \"_text\"):\n            content = self.content\n            if not content:\n                self._text = \"\"\n            else:\n                decoder = TextDecoder(encoding=self.encoding or \"utf-8\")\n                self._text = \"\".join([decoder.decode(self.content), decoder.flush()])\n        return self._text\n\n    @property\n    def encoding(self) -> str | None:\n        \"\"\"\n        Return an encoding to use for decoding the byte content into text.\n        The priority for determining this is given by...\n\n        * `.encoding = <>` has been set explicitly.\n        * The encoding as specified by the charset parameter in the Content-Type header.\n        * The encoding as determined by `default_encoding`, which may either be\n          a string like \"utf-8\" indicating the encoding to use, or may be a callable\n          which enables charset autodetection.\n        \"\"\"\n        if not hasattr(self, \"_encoding\"):\n            encoding = self.charset_encoding\n            if encoding is None or not _is_known_encoding(encoding):\n                if isinstance(self.default_encoding, str):\n                    encoding = self.default_encoding\n                elif hasattr(self, \"_content\"):\n                    encoding = self.default_encoding(self._content)\n            self._encoding = encoding or \"utf-8\"\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value: str) -> None:\n        \"\"\"\n        Set the encoding to use for decoding the byte content into text.\n\n        If the `text` attribute has been accessed, attempting to set the\n        encoding will throw a ValueError.\n        \"\"\"\n        if hasattr(self, \"_text\"):\n            raise ValueError(\n                \"Setting encoding after `text` has been accessed is not allowed.\"\n            )\n        self._encoding = value\n\n    @property\n    def charset_encoding(self) -> str | None:\n        \"\"\"\n        Return the encoding, as specified by the Content-Type header.\n        \"\"\"\n        content_type = self.headers.get(\"Content-Type\")\n        if content_type is None:\n            return None\n\n        return _parse_content_type_charset(content_type)\n\n    def _get_content_decoder(self) -> ContentDecoder:\n        \"\"\"\n        Returns a decoder instance which can be used to decode the raw byte\n        content, depending on the Content-Encoding used in the response.\n        \"\"\"\n        if not hasattr(self, \"_decoder\"):\n            decoders: list[ContentDecoder] = []\n            values = self.headers.get_list(\"content-encoding\", split_commas=True)\n            for value in values:\n                value = value.strip().lower()\n                try:\n                    decoder_cls = SUPPORTED_DECODERS[value]\n                    decoders.append(decoder_cls())\n                except KeyError:\n                    continue\n\n            if len(decoders) == 1:\n                self._decoder = decoders[0]\n            elif len(decoders) > 1:\n                self._decoder = MultiDecoder(children=decoders)\n            else:\n                self._decoder = IdentityDecoder()\n\n        return self._decoder\n\n    @property\n    def is_informational(self) -> bool:\n        \"\"\"\n        A property which is `True` for 1xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_informational(self.status_code)\n\n    @property\n    def is_success(self) -> bool:\n        \"\"\"\n        A property which is `True` for 2xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_success(self.status_code)\n\n    @property\n    def is_redirect(self) -> bool:\n        \"\"\"\n        A property which is `True` for 3xx status codes, `False` otherwise.\n\n        Note that not all responses with a 3xx status code indicate a URL redirect.\n\n        Use `response.has_redirect_location` to determine responses with a properly\n        formed URL redirection.\n        \"\"\"\n        return codes.is_redirect(self.status_code)\n\n    @property\n    def is_client_error(self) -> bool:\n        \"\"\"\n        A property which is `True` for 4xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_client_error(self.status_code)\n\n    @property\n    def is_server_error(self) -> bool:\n        \"\"\"\n        A property which is `True` for 5xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_server_error(self.status_code)\n\n    @property\n    def is_error(self) -> bool:\n        \"\"\"\n        A property which is `True` for 4xx and 5xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_error(self.status_code)\n\n    @property\n    def has_redirect_location(self) -> bool:\n        \"\"\"\n        Returns True for 3xx responses with a properly formed URL redirection,\n        `False` otherwise.\n        \"\"\"\n        return (\n            self.status_code\n            in (\n                # 301 (Cacheable redirect. Method may change to GET.)\n                codes.MOVED_PERMANENTLY,\n                # 302 (Uncacheable redirect. Method may change to GET.)\n                codes.FOUND,\n                # 303 (Client should make a GET or HEAD request.)\n                codes.SEE_OTHER,\n                # 307 (Equiv. 302, but retain method)\n                codes.TEMPORARY_REDIRECT,\n                # 308 (Equiv. 301, but retain method)\n                codes.PERMANENT_REDIRECT,\n            )\n            and \"Location\" in self.headers\n        )\n\n    def raise_for_status(self) -> Response:\n        \"\"\"\n        Raise the `HTTPStatusError` if one occurred.\n        \"\"\"\n        request = self._request\n        if request is None:\n            raise RuntimeError(\n                \"Cannot call `raise_for_status` as the request \"\n                \"instance has not been set on this response.\"\n            )\n\n        if self.is_success:\n            return self\n\n        if self.has_redirect_location:\n            message = (\n                \"{error_type} '{0.status_code} {0.reason_phrase}' for url '{0.url}'\\n\"\n                \"Redirect location: '{0.headers[location]}'\\n\"\n                \"For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/{0.status_code}\"\n            )\n        else:\n            message = (\n                \"{error_type} '{0.status_code} {0.reason_phrase}' for url '{0.url}'\\n\"\n                \"For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/{0.status_code}\"\n            )\n\n        status_class = self.status_code // 100\n        error_types = {\n            1: \"Informational response\",\n            3: \"Redirect response\",\n            4: \"Client error\",\n            5: \"Server error\",\n        }\n        error_type = error_types.get(status_class, \"Invalid status code\")\n        message = message.format(self, error_type=error_type)\n        raise HTTPStatusError(message, request=request, response=self)\n\n    def json(self, **kwargs: typing.Any) -> typing.Any:\n        return jsonlib.loads(self.content, **kwargs)\n\n    @property\n    def cookies(self) -> Cookies:\n        if not hasattr(self, \"_cookies\"):\n            self._cookies = Cookies()\n            self._cookies.extract_cookies(self)\n        return self._cookies\n\n    @property\n    def links(self) -> dict[str | None, dict[str, str]]:\n        \"\"\"\n        Returns the parsed header links of the response, if any\n        \"\"\"\n        header = self.headers.get(\"link\")\n        if header is None:\n            return {}\n\n        return {\n            (link.get(\"rel\") or link.get(\"url\")): link\n            for link in _parse_header_links(header)\n        }\n\n    @property\n    def num_bytes_downloaded(self) -> int:\n        return self._num_bytes_downloaded\n\n    def __repr__(self) -> str:\n        return f\"<Response [{self.status_code} {self.reason_phrase}]>\"\n\n    def __getstate__(self) -> dict[str, typing.Any]:\n        return {\n            name: value\n            for name, value in self.__dict__.items()\n            if name not in [\"extensions\", \"stream\", \"is_closed\", \"_decoder\"]\n        }\n\n    def __setstate__(self, state: dict[str, typing.Any]) -> None:\n        for name, value in state.items():\n            setattr(self, name, value)\n        self.is_closed = True\n        self.extensions = {}\n        self.stream = UnattachedStream()\n\n    def read(self) -> bytes:\n        \"\"\"\n        Read and return the response content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            self._content = b\"\".join(self.iter_bytes())\n        return self._content\n\n    def iter_bytes(self, chunk_size: int | None = None) -> typing.Iterator[bytes]:\n        \"\"\"\n        A byte-iterator over the decoded response content.\n        This allows us to handle gzip, deflate, brotli, and zstd encoded responses.\n        \"\"\"\n        if hasattr(self, \"_content\"):\n            chunk_size = len(self._content) if chunk_size is None else chunk_size\n            for i in range(0, len(self._content), max(chunk_size, 1)):\n                yield self._content[i : i + chunk_size]\n        else:\n            decoder = self._get_content_decoder()\n            chunker = ByteChunker(chunk_size=chunk_size)\n            with request_context(request=self._request):\n                for raw_bytes in self.iter_raw():\n                    decoded = decoder.decode(raw_bytes)\n                    for chunk in chunker.decode(decoded):\n                        yield chunk\n                decoded = decoder.flush()\n                for chunk in chunker.decode(decoded):\n                    yield chunk  # pragma: no cover\n                for chunk in chunker.flush():\n                    yield chunk\n\n    def iter_text(self, chunk_size: int | None = None) -> typing.Iterator[str]:\n        \"\"\"\n        A str-iterator over the decoded response content\n        that handles both gzip, deflate, etc but also detects the content's\n        string encoding.\n        \"\"\"\n        decoder = TextDecoder(encoding=self.encoding or \"utf-8\")\n        chunker = TextChunker(chunk_size=chunk_size)\n        with request_context(request=self._request):\n            for byte_content in self.iter_bytes():\n                text_content = decoder.decode(byte_content)\n                for chunk in chunker.decode(text_content):\n                    yield chunk\n            text_content = decoder.flush()\n            for chunk in chunker.decode(text_content):\n                yield chunk  # pragma: no cover\n            for chunk in chunker.flush():\n                yield chunk\n\n    def iter_lines(self) -> typing.Iterator[str]:\n        decoder = LineDecoder()\n        with request_context(request=self._request):\n            for text in self.iter_text():\n                for line in decoder.decode(text):\n                    yield line\n            for line in decoder.flush():\n                yield line\n\n    def iter_raw(self, chunk_size: int | None = None) -> typing.Iterator[bytes]:\n        \"\"\"\n        A byte-iterator over the raw response content.\n        \"\"\"\n        if self.is_stream_consumed:\n            raise StreamConsumed()\n        if self.is_closed:\n            raise StreamClosed()\n        if not isinstance(self.stream, SyncByteStream):\n            raise RuntimeError(\"Attempted to call a sync iterator on an async stream.\")\n\n        self.is_stream_consumed = True\n        self._num_bytes_downloaded = 0\n        chunker = ByteChunker(chunk_size=chunk_size)\n\n        with request_context(request=self._request):\n            for raw_stream_bytes in self.stream:\n                self._num_bytes_downloaded += len(raw_stream_bytes)\n                for chunk in chunker.decode(raw_stream_bytes):\n                    yield chunk\n\n        for chunk in chunker.flush():\n            yield chunk\n\n        self.close()\n\n    def close(self) -> None:\n        \"\"\"\n        Close the response and release the connection.\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        if not isinstance(self.stream, SyncByteStream):\n            raise RuntimeError(\"Attempted to call an sync close on an async stream.\")\n\n        if not self.is_closed:\n            self.is_closed = True\n            with request_context(request=self._request):\n                self.stream.close()\n\n    async def aread(self) -> bytes:\n        \"\"\"\n        Read and return the response content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            self._content = b\"\".join([part async for part in self.aiter_bytes()])\n        return self._content\n\n    async def aiter_bytes(\n        self, chunk_size: int | None = None\n    ) -> typing.AsyncIterator[bytes]:\n        \"\"\"\n        A byte-iterator over the decoded response content.\n        This allows us to handle gzip, deflate, brotli, and zstd encoded responses.\n        \"\"\"\n        if hasattr(self, \"_content\"):\n            chunk_size = len(self._content) if chunk_size is None else chunk_size\n            for i in range(0, len(self._content), max(chunk_size, 1)):\n                yield self._content[i : i + chunk_size]\n        else:\n            decoder = self._get_content_decoder()\n            chunker = ByteChunker(chunk_size=chunk_size)\n            with request_context(request=self._request):\n                async for raw_bytes in self.aiter_raw():\n                    decoded = decoder.decode(raw_bytes)\n                    for chunk in chunker.decode(decoded):\n                        yield chunk\n                decoded = decoder.flush()\n                for chunk in chunker.decode(decoded):\n                    yield chunk  # pragma: no cover\n                for chunk in chunker.flush():\n                    yield chunk\n\n    async def aiter_text(\n        self, chunk_size: int | None = None\n    ) -> typing.AsyncIterator[str]:\n        \"\"\"\n        A str-iterator over the decoded response content\n        that handles both gzip, deflate, etc but also detects the content's\n        string encoding.\n        \"\"\"\n        decoder = TextDecoder(encoding=self.encoding or \"utf-8\")\n        chunker = TextChunker(chunk_size=chunk_size)\n        with request_context(request=self._request):\n            async for byte_content in self.aiter_bytes():\n                text_content = decoder.decode(byte_content)\n                for chunk in chunker.decode(text_content):\n                    yield chunk\n            text_content = decoder.flush()\n            for chunk in chunker.decode(text_content):\n                yield chunk  # pragma: no cover\n            for chunk in chunker.flush():\n                yield chunk\n\n    async def aiter_lines(self) -> typing.AsyncIterator[str]:\n        decoder = LineDecoder()\n        with request_context(request=self._request):\n            async for text in self.aiter_text():\n                for line in decoder.decode(text):\n                    yield line\n            for line in decoder.flush():\n                yield line\n\n    async def aiter_raw(\n        self, chunk_size: int | None = None\n    ) -> typing.AsyncIterator[bytes]:\n        \"\"\"\n        A byte-iterator over the raw response content.\n        \"\"\"\n        if self.is_stream_consumed:\n            raise StreamConsumed()\n        if self.is_closed:\n            raise StreamClosed()\n        if not isinstance(self.stream, AsyncByteStream):\n            raise RuntimeError(\"Attempted to call an async iterator on an sync stream.\")\n\n        self.is_stream_consumed = True\n        self._num_bytes_downloaded = 0\n        chunker = ByteChunker(chunk_size=chunk_size)\n\n        with request_context(request=self._request):\n            async for raw_stream_bytes in self.stream:\n                self._num_bytes_downloaded += len(raw_stream_bytes)\n                for chunk in chunker.decode(raw_stream_bytes):\n                    yield chunk\n\n        for chunk in chunker.flush():\n            yield chunk\n\n        await self.aclose()\n\n    async def aclose(self) -> None:\n        \"\"\"\n        Close the response and release the connection.\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        if not isinstance(self.stream, AsyncByteStream):\n            raise RuntimeError(\"Attempted to call an async close on an sync stream.\")\n\n        if not self.is_closed:\n            self.is_closed = True\n            with request_context(request=self._request):\n                await self.stream.aclose()\n\n\nclass Cookies(typing.MutableMapping[str, str]):\n    \"\"\"\n    HTTP Cookies, as a mutable mapping.\n    \"\"\"\n\n    def __init__(self, cookies: CookieTypes | None = None) -> None:\n        if cookies is None or isinstance(cookies, dict):\n            self.jar = CookieJar()\n            if isinstance(cookies, dict):\n                for key, value in cookies.items():\n                    self.set(key, value)\n        elif isinstance(cookies, list):\n            self.jar = CookieJar()\n            for key, value in cookies:\n                self.set(key, value)\n        elif isinstance(cookies, Cookies):\n            self.jar = CookieJar()\n            for cookie in cookies.jar:\n                self.jar.set_cookie(cookie)\n        else:\n            self.jar = cookies\n\n    def extract_cookies(self, response: Response) -> None:\n        \"\"\"\n        Loads any cookies based on the response `Set-Cookie` headers.\n        \"\"\"\n        urllib_response = self._CookieCompatResponse(response)\n        urllib_request = self._CookieCompatRequest(response.request)\n\n        self.jar.extract_cookies(urllib_response, urllib_request)  # type: ignore\n\n    def set_cookie_header(self, request: Request) -> None:\n        \"\"\"\n        Sets an appropriate 'Cookie:' HTTP header on the `Request`.\n        \"\"\"\n        urllib_request = self._CookieCompatRequest(request)\n        self.jar.add_cookie_header(urllib_request)\n\n    def set(self, name: str, value: str, domain: str = \"\", path: str = \"/\") -> None:\n        \"\"\"\n        Set a cookie value by name. May optionally include domain and path.\n        \"\"\"\n        kwargs = {\n            \"version\": 0,\n            \"name\": name,\n            \"value\": value,\n            \"port\": None,\n            \"port_specified\": False,\n            \"domain\": domain,\n            \"domain_specified\": bool(domain),\n            \"domain_initial_dot\": domain.startswith(\".\"),\n            \"path\": path,\n            \"path_specified\": bool(path),\n            \"secure\": False,\n            \"expires\": None,\n            \"discard\": True,\n            \"comment\": None,\n            \"comment_url\": None,\n            \"rest\": {\"HttpOnly\": None},\n            \"rfc2109\": False,\n        }\n        cookie = Cookie(**kwargs)  # type: ignore\n        self.jar.set_cookie(cookie)\n\n    def get(  # type: ignore\n        self,\n        name: str,\n        default: str | None = None,\n        domain: str | None = None,\n        path: str | None = None,\n    ) -> str | None:\n        \"\"\"\n        Get a cookie by name. May optionally include domain and path\n        in order to specify exactly which cookie to retrieve.\n        \"\"\"\n        value = None\n        for cookie in self.jar:\n            if cookie.name == name:\n                if domain is None or cookie.domain == domain:\n                    if path is None or cookie.path == path:\n                        if value is not None:\n                            message = f\"Multiple cookies exist with name={name}\"\n                            raise CookieConflict(message)\n                        value = cookie.value\n\n        if value is None:\n            return default\n        return value\n\n    def delete(\n        self,\n        name: str,\n        domain: str | None = None,\n        path: str | None = None,\n    ) -> None:\n        \"\"\"\n        Delete a cookie by name. May optionally include domain and path\n        in order to specify exactly which cookie to delete.\n        \"\"\"\n        if domain is not None and path is not None:\n            return self.jar.clear(domain, path, name)\n\n        remove = [\n            cookie\n            for cookie in self.jar\n            if cookie.name == name\n            and (domain is None or cookie.domain == domain)\n            and (path is None or cookie.path == path)\n        ]\n\n        for cookie in remove:\n            self.jar.clear(cookie.domain, cookie.path, cookie.name)\n\n    def clear(self, domain: str | None = None, path: str | None = None) -> None:\n        \"\"\"\n        Delete all cookies. Optionally include a domain and path in\n        order to only delete a subset of all the cookies.\n        \"\"\"\n        args = []\n        if domain is not None:\n            args.append(domain)\n        if path is not None:\n            assert domain is not None\n            args.append(path)\n        self.jar.clear(*args)\n\n    def update(self, cookies: CookieTypes | None = None) -> None:  # type: ignore\n        cookies = Cookies(cookies)\n        for cookie in cookies.jar:\n            self.jar.set_cookie(cookie)\n\n    def __setitem__(self, name: str, value: str) -> None:\n        return self.set(name, value)\n\n    def __getitem__(self, name: str) -> str:\n        value = self.get(name)\n        if value is None:\n            raise KeyError(name)\n        return value\n\n    def __delitem__(self, name: str) -> None:\n        return self.delete(name)\n\n    def __len__(self) -> int:\n        return len(self.jar)\n\n    def __iter__(self) -> typing.Iterator[str]:\n        return (cookie.name for cookie in self.jar)\n\n    def __bool__(self) -> bool:\n        for _ in self.jar:\n            return True\n        return False\n\n    def __repr__(self) -> str:\n        cookies_repr = \", \".join(\n            [\n                f\"<Cookie {cookie.name}={cookie.value} for {cookie.domain} />\"\n                for cookie in self.jar\n            ]\n        )\n\n        return f\"<Cookies[{cookies_repr}]>\"\n\n    class _CookieCompatRequest(urllib.request.Request):\n        \"\"\"\n        Wraps a `Request` instance up in a compatibility interface suitable\n        for use with `CookieJar` operations.\n        \"\"\"\n\n        def __init__(self, request: Request) -> None:\n            super().__init__(\n                url=str(request.url),\n                headers=dict(request.headers),\n                method=request.method,\n            )\n            self.request = request\n\n        def add_unredirected_header(self, key: str, value: str) -> None:\n            super().add_unredirected_header(key, value)\n            self.request.headers[key] = value\n\n    class _CookieCompatResponse:\n        \"\"\"\n        Wraps a `Request` instance up in a compatibility interface suitable\n        for use with `CookieJar` operations.\n        \"\"\"\n\n        def __init__(self, response: Response) -> None:\n            self.response = response\n\n        def info(self) -> email.message.Message:\n            info = email.message.Message()\n            for key, value in self.response.headers.multi_items():\n                # Note that setting `info[key]` here is an \"append\" operation,\n                # not a \"replace\" operation.\n                # https://docs.python.org/3/library/email.compat32-message.html#email.message.Message.__setitem__\n                info[key] = value\n            return info\n",
      "code_after": "from __future__ import annotations\n\nimport codecs\nimport datetime\nimport email.message\nimport json as jsonlib\nimport re\nimport typing\nimport urllib.request\nfrom collections.abc import Mapping\nfrom http.cookiejar import Cookie, CookieJar\n\nfrom ._content import ByteStream, UnattachedStream, encode_request, encode_response\nfrom ._decoders import (\n    SUPPORTED_DECODERS,\n    ByteChunker,\n    ContentDecoder,\n    IdentityDecoder,\n    LineDecoder,\n    MultiDecoder,\n    TextChunker,\n    TextDecoder,\n)\nfrom ._exceptions import (\n    CookieConflict,\n    HTTPStatusError,\n    RequestNotRead,\n    ResponseNotRead,\n    StreamClosed,\n    StreamConsumed,\n    request_context,\n)\nfrom ._multipart import get_multipart_boundary_from_content_type\nfrom ._status_codes import codes\nfrom ._types import (\n    AsyncByteStream,\n    CookieTypes,\n    HeaderTypes,\n    QueryParamTypes,\n    RequestContent,\n    RequestData,\n    RequestExtensions,\n    RequestFiles,\n    ResponseContent,\n    ResponseExtensions,\n    SyncByteStream,\n)\nfrom ._urls import URL\nfrom ._utils import to_bytes_or_str, to_str\n\n__all__ = [\"Cookies\", \"Headers\", \"Request\", \"Response\"]\n\nSENSITIVE_HEADERS = {\"authorization\", \"proxy-authorization\"}\n\n\ndef _is_known_encoding(encoding: str) -> bool:\n    \"\"\"\n    Return `True` if `encoding` is a known codec.\n    \"\"\"\n    try:\n        codecs.lookup(encoding)\n    except LookupError:\n        return False\n    return True\n\n\ndef _normalize_header_key(key: str | bytes, encoding: str | None = None) -> bytes:\n    \"\"\"\n    Coerce str/bytes into a strictly byte-wise HTTP header key.\n    \"\"\"\n    return key if isinstance(key, bytes) else key.encode(encoding or \"ascii\")\n\n\ndef _normalize_header_value(value: str | bytes, encoding: str | None = None) -> bytes:\n    \"\"\"\n    Coerce str/bytes into a strictly byte-wise HTTP header value.\n    \"\"\"\n    if isinstance(value, bytes):\n        return value\n    if not isinstance(value, str):\n        raise TypeError(f\"Header value must be str or bytes, not {type(value)}\")\n    return value.encode(encoding or \"ascii\")\n\n\ndef _parse_content_type_charset(content_type: str) -> str | None:\n    # We used to use `cgi.parse_header()` here, but `cgi` became a dead battery.\n    # See: https://peps.python.org/pep-0594/#cgi\n    msg = email.message.Message()\n    msg[\"content-type\"] = content_type\n    return msg.get_content_charset(failobj=None)\n\n\ndef _parse_header_links(value: str) -> list[dict[str, str]]:\n    \"\"\"\n    Returns a list of parsed link headers, for more info see:\n    https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Link\n    The generic syntax of those is:\n    Link: < uri-reference >; param1=value1; param2=\"value2\"\n    So for instance:\n    Link; '<http:/.../front.jpeg>; type=\"image/jpeg\",<http://.../back.jpeg>;'\n    would return\n        [\n            {\"url\": \"http:/.../front.jpeg\", \"type\": \"image/jpeg\"},\n            {\"url\": \"http://.../back.jpeg\"},\n        ]\n    :param value: HTTP Link entity-header field\n    :return: list of parsed link headers\n    \"\"\"\n    links: list[dict[str, str]] = []\n    replace_chars = \" '\\\"\"\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n        links.append(link)\n    return links\n\n\ndef _obfuscate_sensitive_headers(\n    items: typing.Iterable[tuple[typing.AnyStr, typing.AnyStr]],\n) -> typing.Iterator[tuple[typing.AnyStr, typing.AnyStr]]:\n    for k, v in items:\n        if to_str(k.lower()) in SENSITIVE_HEADERS:\n            v = to_bytes_or_str(\"[secure]\", match_type_of=v)\n        yield k, v\n\n\nclass Headers(typing.MutableMapping[str, str]):\n    \"\"\"\n    HTTP headers, as a case-insensitive multi-dict.\n    \"\"\"\n\n    def __init__(\n        self,\n        headers: HeaderTypes | None = None,\n        encoding: str | None = None,\n    ) -> None:\n        self._list = []  # type: typing.List[typing.Tuple[bytes, bytes, bytes]]\n\n        if isinstance(headers, Headers):\n            self._list = list(headers._list)\n        elif isinstance(headers, Mapping):\n            for k, v in headers.items():\n                bytes_key = _normalize_header_key(k, encoding)\n                bytes_value = _normalize_header_value(v, encoding)\n                self._list.append((bytes_key, bytes_key.lower(), bytes_value))\n        elif headers is not None:\n            for k, v in headers:\n                bytes_key = _normalize_header_key(k, encoding)\n                bytes_value = _normalize_header_value(v, encoding)\n                self._list.append((bytes_key, bytes_key.lower(), bytes_value))\n\n        self._encoding = encoding\n\n    @property\n    def encoding(self) -> str:\n        \"\"\"\n        Header encoding is mandated as ascii, but we allow fallbacks to utf-8\n        or iso-8859-1.\n        \"\"\"\n        if self._encoding is None:\n            for encoding in [\"ascii\", \"utf-8\"]:\n                for key, value in self.raw:\n                    try:\n                        key.decode(encoding)\n                        value.decode(encoding)\n                    except UnicodeDecodeError:\n                        break\n                else:\n                    # The else block runs if 'break' did not occur, meaning\n                    # all values fitted the encoding.\n                    self._encoding = encoding\n                    break\n            else:\n                # The ISO-8859-1 encoding covers all 256 code points in a byte,\n                # so will never raise decode errors.\n                self._encoding = \"iso-8859-1\"\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value: str) -> None:\n        self._encoding = value\n\n    @property\n    def raw(self) -> list[tuple[bytes, bytes]]:\n        \"\"\"\n        Returns a list of the raw header items, as byte pairs.\n        \"\"\"\n        return [(raw_key, value) for raw_key, _, value in self._list]\n\n    def keys(self) -> typing.KeysView[str]:\n        return {key.decode(self.encoding): None for _, key, value in self._list}.keys()\n\n    def values(self) -> typing.ValuesView[str]:\n        values_dict: dict[str, str] = {}\n        for _, key, value in self._list:\n            str_key = key.decode(self.encoding)\n            str_value = value.decode(self.encoding)\n            if str_key in values_dict:\n                values_dict[str_key] += f\", {str_value}\"\n            else:\n                values_dict[str_key] = str_value\n        return values_dict.values()\n\n    def items(self) -> typing.ItemsView[str, str]:\n        \"\"\"\n        Return `(key, value)` items of headers. Concatenate headers\n        into a single comma separated value when a key occurs multiple times.\n        \"\"\"\n        values_dict: dict[str, str] = {}\n        for _, key, value in self._list:\n            str_key = key.decode(self.encoding)\n            str_value = value.decode(self.encoding)\n            if str_key in values_dict:\n                values_dict[str_key] += f\", {str_value}\"\n            else:\n                values_dict[str_key] = str_value\n        return values_dict.items()\n\n    def multi_items(self) -> list[tuple[str, str]]:\n        \"\"\"\n        Return a list of `(key, value)` pairs of headers. Allow multiple\n        occurrences of the same key without concatenating into a single\n        comma separated value.\n        \"\"\"\n        return [\n            (key.decode(self.encoding), value.decode(self.encoding))\n            for _, key, value in self._list\n        ]\n\n    def get(self, key: str, default: typing.Any = None) -> typing.Any:\n        \"\"\"\n        Return a header value. If multiple occurrences of the header occur\n        then concatenate them together with commas.\n        \"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def get_list(self, key: str, split_commas: bool = False) -> list[str]:\n        \"\"\"\n        Return a list of all header values for a given key.\n        If `split_commas=True` is passed, then any comma separated header\n        values are split into multiple return strings.\n        \"\"\"\n        get_header_key = key.lower().encode(self.encoding)\n\n        values = [\n            item_value.decode(self.encoding)\n            for _, item_key, item_value in self._list\n            if item_key.lower() == get_header_key\n        ]\n\n        if not split_commas:\n            return values\n\n        split_values = []\n        for value in values:\n            split_values.extend([item.strip() for item in value.split(\",\")])\n        return split_values\n\n    def update(self, headers: HeaderTypes | None = None) -> None:  # type: ignore\n        headers = Headers(headers)\n        for key in headers.keys():\n            if key in self:\n                self.pop(key)\n        self._list.extend(headers._list)\n\n    def copy(self) -> Headers:\n        return Headers(self, encoding=self.encoding)\n\n    def __getitem__(self, key: str) -> str:\n        \"\"\"\n        Return a single header value.\n\n        If there are multiple headers with the same key, then we concatenate\n        them with commas. See: https://tools.ietf.org/html/rfc7230#section-3.2.2\n        \"\"\"\n        normalized_key = key.lower().encode(self.encoding)\n\n        items = [\n            header_value.decode(self.encoding)\n            for _, header_key, header_value in self._list\n            if header_key == normalized_key\n        ]\n\n        if items:\n            return \", \".join(items)\n\n        raise KeyError(key)\n\n    def __setitem__(self, key: str, value: str) -> None:\n        \"\"\"\n        Set the header `key` to `value`, removing any duplicate entries.\n        Retains insertion order.\n        \"\"\"\n        set_key = key.encode(self._encoding or \"utf-8\")\n        set_value = value.encode(self._encoding or \"utf-8\")\n        lookup_key = set_key.lower()\n\n        found_indexes = [\n            idx\n            for idx, (_, item_key, _) in enumerate(self._list)\n            if item_key == lookup_key\n        ]\n\n        for idx in reversed(found_indexes[1:]):\n            del self._list[idx]\n\n        if found_indexes:\n            idx = found_indexes[0]\n            self._list[idx] = (set_key, lookup_key, set_value)\n        else:\n            self._list.append((set_key, lookup_key, set_value))\n\n    def __delitem__(self, key: str) -> None:\n        \"\"\"\n        Remove the header `key`.\n        \"\"\"\n        del_key = key.lower().encode(self.encoding)\n\n        pop_indexes = [\n            idx\n            for idx, (_, item_key, _) in enumerate(self._list)\n            if item_key.lower() == del_key\n        ]\n\n        if not pop_indexes:\n            raise KeyError(key)\n\n        for idx in reversed(pop_indexes):\n            del self._list[idx]\n\n    def __contains__(self, key: typing.Any) -> bool:\n        header_key = key.lower().encode(self.encoding)\n        return header_key in [key for _, key, _ in self._list]\n\n    def __iter__(self) -> typing.Iterator[typing.Any]:\n        return iter(self.keys())\n\n    def __len__(self) -> int:\n        return len(self._list)\n\n    def __eq__(self, other: typing.Any) -> bool:\n        try:\n            other_headers = Headers(other)\n        except ValueError:\n            return False\n\n        self_list = [(key, value) for _, key, value in self._list]\n        other_list = [(key, value) for _, key, value in other_headers._list]\n        return sorted(self_list) == sorted(other_list)\n\n    def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n\n        encoding_str = \"\"\n        if self.encoding != \"ascii\":\n            encoding_str = f\", encoding={self.encoding!r}\"\n\n        as_list = list(_obfuscate_sensitive_headers(self.multi_items()))\n        as_dict = dict(as_list)\n\n        no_duplicate_keys = len(as_dict) == len(as_list)\n        if no_duplicate_keys:\n            return f\"{class_name}({as_dict!r}{encoding_str})\"\n        return f\"{class_name}({as_list!r}{encoding_str})\"\n\n\nclass Request:\n    def __init__(\n        self,\n        method: str,\n        url: URL | str,\n        *,\n        params: QueryParamTypes | None = None,\n        headers: HeaderTypes | None = None,\n        cookies: CookieTypes | None = None,\n        content: RequestContent | None = None,\n        data: RequestData | None = None,\n        files: RequestFiles | None = None,\n        json: typing.Any | None = None,\n        stream: SyncByteStream | AsyncByteStream | None = None,\n        extensions: RequestExtensions | None = None,\n    ) -> None:\n        self.method = method.upper()\n        self.url = URL(url) if params is None else URL(url, params=params)\n        self.headers = Headers(headers)\n        self.extensions = {} if extensions is None else dict(extensions)\n\n        if cookies:\n            Cookies(cookies).set_cookie_header(self)\n\n        if stream is None:\n            content_type: str | None = self.headers.get(\"content-type\")\n            headers, stream = encode_request(\n                content=content,\n                data=data,\n                files=files,\n                json=json,\n                boundary=get_multipart_boundary_from_content_type(\n                    content_type=content_type.encode(self.headers.encoding)\n                    if content_type\n                    else None\n                ),\n            )\n            self._prepare(headers)\n            self.stream = stream\n            # Load the request body, except for streaming content.\n            if isinstance(stream, ByteStream):\n                self.read()\n        else:\n            # There's an important distinction between `Request(content=...)`,\n            # and `Request(stream=...)`.\n            #\n            # Using `content=...` implies automatically populated `Host` and content\n            # headers, of either `Content-Length: ...` or `Transfer-Encoding: chunked`.\n            #\n            # Using `stream=...` will not automatically include *any*\n            # auto-populated headers.\n            #\n            # As an end-user you don't really need `stream=...`. It's only\n            # useful when:\n            #\n            # * Preserving the request stream when copying requests, eg for redirects.\n            # * Creating request instances on the *server-side* of the transport API.\n            self.stream = stream\n\n    def _prepare(self, default_headers: dict[str, str]) -> None:\n        for key, value in default_headers.items():\n            # Ignore Transfer-Encoding if the Content-Length has been set explicitly.\n            if key.lower() == \"transfer-encoding\" and \"Content-Length\" in self.headers:\n                continue\n            self.headers.setdefault(key, value)\n\n        auto_headers: list[tuple[bytes, bytes]] = []\n\n        has_host = \"Host\" in self.headers\n        has_content_length = (\n            \"Content-Length\" in self.headers or \"Transfer-Encoding\" in self.headers\n        )\n\n        if not has_host and self.url.host:\n            auto_headers.append((b\"Host\", self.url.netloc))\n        if not has_content_length and self.method in (\"POST\", \"PUT\", \"PATCH\"):\n            auto_headers.append((b\"Content-Length\", b\"0\"))\n\n        self.headers = Headers(auto_headers + self.headers.raw)\n\n    @property\n    def content(self) -> bytes:\n        if not hasattr(self, \"_content\"):\n            raise RequestNotRead()\n        return self._content\n\n    def read(self) -> bytes:\n        \"\"\"\n        Read and return the request content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            assert isinstance(self.stream, typing.Iterable)\n            self._content = b\"\".join(self.stream)\n            if not isinstance(self.stream, ByteStream):\n                # If a streaming request has been read entirely into memory, then\n                # we can replace the stream with a raw bytes implementation,\n                # to ensure that any non-replayable streams can still be used.\n                self.stream = ByteStream(self._content)\n        return self._content\n\n    async def aread(self) -> bytes:\n        \"\"\"\n        Read and return the request content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            assert isinstance(self.stream, typing.AsyncIterable)\n            self._content = b\"\".join([part async for part in self.stream])\n            if not isinstance(self.stream, ByteStream):\n                # If a streaming request has been read entirely into memory, then\n                # we can replace the stream with a raw bytes implementation,\n                # to ensure that any non-replayable streams can still be used.\n                self.stream = ByteStream(self._content)\n        return self._content\n\n    def __repr__(self) -> str:\n        class_name = self.__class__.__name__\n        url = str(self.url)\n        return f\"<{class_name}({self.method!r}, {url!r})>\"\n\n    def __getstate__(self) -> dict[str, typing.Any]:\n        return {\n            name: value\n            for name, value in self.__dict__.items()\n            if name not in [\"extensions\", \"stream\"]\n        }\n\n    def __setstate__(self, state: dict[str, typing.Any]) -> None:\n        for name, value in state.items():\n            setattr(self, name, value)\n        self.extensions = {}\n        self.stream = UnattachedStream()\n\n\nclass Response:\n    def __init__(\n        self,\n        status_code: int,\n        *,\n        headers: HeaderTypes | None = None,\n        content: ResponseContent | None = None,\n        text: str | None = None,\n        html: str | None = None,\n        json: typing.Any = None,\n        stream: SyncByteStream | AsyncByteStream | None = None,\n        request: Request | None = None,\n        extensions: ResponseExtensions | None = None,\n        history: list[Response] | None = None,\n        default_encoding: str | typing.Callable[[bytes], str] = \"utf-8\",\n    ) -> None:\n        self.status_code = status_code\n        self.headers = Headers(headers)\n\n        self._request: Request | None = request\n\n        # When follow_redirects=False and a redirect is received,\n        # the client will set `response.next_request`.\n        self.next_request: Request | None = None\n\n        self.extensions = {} if extensions is None else dict(extensions)\n        self.history = [] if history is None else list(history)\n\n        self.is_closed = False\n        self.is_stream_consumed = False\n\n        self.default_encoding = default_encoding\n\n        if stream is None:\n            headers, stream = encode_response(content, text, html, json)\n            self._prepare(headers)\n            self.stream = stream\n            if isinstance(stream, ByteStream):\n                # Load the response body, except for streaming content.\n                self.read()\n        else:\n            # There's an important distinction between `Response(content=...)`,\n            # and `Response(stream=...)`.\n            #\n            # Using `content=...` implies automatically populated content headers,\n            # of either `Content-Length: ...` or `Transfer-Encoding: chunked`.\n            #\n            # Using `stream=...` will not automatically include any content headers.\n            #\n            # As an end-user you don't really need `stream=...`. It's only\n            # useful when creating response instances having received a stream\n            # from the transport API.\n            self.stream = stream\n\n        self._num_bytes_downloaded = 0\n\n    def _prepare(self, default_headers: dict[str, str]) -> None:\n        for key, value in default_headers.items():\n            # Ignore Transfer-Encoding if the Content-Length has been set explicitly.\n            if key.lower() == \"transfer-encoding\" and \"content-length\" in self.headers:\n                continue\n            self.headers.setdefault(key, value)\n\n    @property\n    def elapsed(self) -> datetime.timedelta:\n        \"\"\"\n        Returns the time taken for the complete request/response\n        cycle to complete.\n        \"\"\"\n        if not hasattr(self, \"_elapsed\"):\n            raise RuntimeError(\n                \"'.elapsed' may only be accessed after the response \"\n                \"has been read or closed.\"\n            )\n        return self._elapsed\n\n    @elapsed.setter\n    def elapsed(self, elapsed: datetime.timedelta) -> None:\n        self._elapsed = elapsed\n\n    @property\n    def request(self) -> Request:\n        \"\"\"\n        Returns the request instance associated to the current response.\n        \"\"\"\n        if self._request is None:\n            raise RuntimeError(\n                \"The request instance has not been set on this response.\"\n            )\n        return self._request\n\n    @request.setter\n    def request(self, value: Request) -> None:\n        self._request = value\n\n    @property\n    def http_version(self) -> str:\n        try:\n            http_version: bytes = self.extensions[\"http_version\"]\n        except KeyError:\n            return \"HTTP/1.1\"\n        else:\n            return http_version.decode(\"ascii\", errors=\"ignore\")\n\n    @property\n    def reason_phrase(self) -> str:\n        try:\n            reason_phrase: bytes = self.extensions[\"reason_phrase\"]\n        except KeyError:\n            return codes.get_reason_phrase(self.status_code)\n        else:\n            return reason_phrase.decode(\"ascii\", errors=\"ignore\")\n\n    @property\n    def url(self) -> URL:\n        \"\"\"\n        Returns the URL for which the request was made.\n        \"\"\"\n        return self.request.url\n\n    @property\n    def content(self) -> bytes:\n        if not hasattr(self, \"_content\"):\n            raise ResponseNotRead()\n        return self._content\n\n    @property\n    def text(self) -> str:\n        if not hasattr(self, \"_text\"):\n            content = self.content\n            if not content:\n                self._text = \"\"\n            else:\n                decoder = TextDecoder(encoding=self.encoding or \"utf-8\")\n                self._text = \"\".join([decoder.decode(self.content), decoder.flush()])\n        return self._text\n\n    @property\n    def encoding(self) -> str | None:\n        \"\"\"\n        Return an encoding to use for decoding the byte content into text.\n        The priority for determining this is given by...\n\n        * `.encoding = <>` has been set explicitly.\n        * The encoding as specified by the charset parameter in the Content-Type header.\n        * The encoding as determined by `default_encoding`, which may either be\n          a string like \"utf-8\" indicating the encoding to use, or may be a callable\n          which enables charset autodetection.\n        \"\"\"\n        if not hasattr(self, \"_encoding\"):\n            encoding = self.charset_encoding\n            if encoding is None or not _is_known_encoding(encoding):\n                if isinstance(self.default_encoding, str):\n                    encoding = self.default_encoding\n                elif hasattr(self, \"_content\"):\n                    encoding = self.default_encoding(self._content)\n            self._encoding = encoding or \"utf-8\"\n        return self._encoding\n\n    @encoding.setter\n    def encoding(self, value: str) -> None:\n        \"\"\"\n        Set the encoding to use for decoding the byte content into text.\n\n        If the `text` attribute has been accessed, attempting to set the\n        encoding will throw a ValueError.\n        \"\"\"\n        if hasattr(self, \"_text\"):\n            raise ValueError(\n                \"Setting encoding after `text` has been accessed is not allowed.\"\n            )\n        self._encoding = value\n\n    @property\n    def charset_encoding(self) -> str | None:\n        \"\"\"\n        Return the encoding, as specified by the Content-Type header.\n        \"\"\"\n        content_type = self.headers.get(\"Content-Type\")\n        if content_type is None:\n            return None\n\n        return _parse_content_type_charset(content_type)\n\n    def _get_content_decoder(self) -> ContentDecoder:\n        \"\"\"\n        Returns a decoder instance which can be used to decode the raw byte\n        content, depending on the Content-Encoding used in the response.\n        \"\"\"\n        if not hasattr(self, \"_decoder\"):\n            decoders: list[ContentDecoder] = []\n            values = self.headers.get_list(\"content-encoding\", split_commas=True)\n            for value in values:\n                value = value.strip().lower()\n                try:\n                    decoder_cls = SUPPORTED_DECODERS[value]\n                    decoders.append(decoder_cls())\n                except KeyError:\n                    continue\n\n            if len(decoders) == 1:\n                self._decoder = decoders[0]\n            elif len(decoders) > 1:\n                self._decoder = MultiDecoder(children=decoders)\n            else:\n                self._decoder = IdentityDecoder()\n\n        return self._decoder\n\n    @property\n    def is_informational(self) -> bool:\n        \"\"\"\n        A property which is `True` for 1xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_informational(self.status_code)\n\n    @property\n    def is_success(self) -> bool:\n        \"\"\"\n        A property which is `True` for 2xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_success(self.status_code)\n\n    @property\n    def is_redirect(self) -> bool:\n        \"\"\"\n        A property which is `True` for 3xx status codes, `False` otherwise.\n\n        Note that not all responses with a 3xx status code indicate a URL redirect.\n\n        Use `response.has_redirect_location` to determine responses with a properly\n        formed URL redirection.\n        \"\"\"\n        return codes.is_redirect(self.status_code)\n\n    @property\n    def is_client_error(self) -> bool:\n        \"\"\"\n        A property which is `True` for 4xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_client_error(self.status_code)\n\n    @property\n    def is_server_error(self) -> bool:\n        \"\"\"\n        A property which is `True` for 5xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_server_error(self.status_code)\n\n    @property\n    def is_error(self) -> bool:\n        \"\"\"\n        A property which is `True` for 4xx and 5xx status codes, `False` otherwise.\n        \"\"\"\n        return codes.is_error(self.status_code)\n\n    @property\n    def has_redirect_location(self) -> bool:\n        \"\"\"\n        Returns True for 3xx responses with a properly formed URL redirection,\n        `False` otherwise.\n        \"\"\"\n        return (\n            self.status_code\n            in (\n                # 301 (Cacheable redirect. Method may change to GET.)\n                codes.MOVED_PERMANENTLY,\n                # 302 (Uncacheable redirect. Method may change to GET.)\n                codes.FOUND,\n                # 303 (Client should make a GET or HEAD request.)\n                codes.SEE_OTHER,\n                # 307 (Equiv. 302, but retain method)\n                codes.TEMPORARY_REDIRECT,\n                # 308 (Equiv. 301, but retain method)\n                codes.PERMANENT_REDIRECT,\n            )\n            and \"Location\" in self.headers\n        )\n\n    def raise_for_status(self) -> Response:\n        \"\"\"\n        Raise the `HTTPStatusError` if one occurred.\n        \"\"\"\n        request = self._request\n        if request is None:\n            raise RuntimeError(\n                \"Cannot call `raise_for_status` as the request \"\n                \"instance has not been set on this response.\"\n            )\n\n        if self.is_success:\n            return self\n\n        if self.has_redirect_location:\n            message = (\n                \"{error_type} '{0.status_code} {0.reason_phrase}' for url '{0.url}'\\n\"\n                \"Redirect location: '{0.headers[location]}'\\n\"\n                \"For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/{0.status_code}\"\n            )\n        else:\n            message = (\n                \"{error_type} '{0.status_code} {0.reason_phrase}' for url '{0.url}'\\n\"\n                \"For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/{0.status_code}\"\n            )\n\n        status_class = self.status_code // 100\n        error_types = {\n            1: \"Informational response\",\n            3: \"Redirect response\",\n            4: \"Client error\",\n            5: \"Server error\",\n        }\n        error_type = error_types.get(status_class, \"Invalid status code\")\n        message = message.format(self, error_type=error_type)\n        raise HTTPStatusError(message, request=request, response=self)\n\n    def json(self, **kwargs: typing.Any) -> typing.Any:\n        return jsonlib.loads(self.content, **kwargs)\n\n    @property\n    def cookies(self) -> Cookies:\n        if not hasattr(self, \"_cookies\"):\n            self._cookies = Cookies()\n            self._cookies.extract_cookies(self)\n        return self._cookies\n\n    @property\n    def links(self) -> dict[str | None, dict[str, str]]:\n        \"\"\"\n        Returns the parsed header links of the response, if any\n        \"\"\"\n        header = self.headers.get(\"link\")\n        if header is None:\n            return {}\n\n        return {\n            (link.get(\"rel\") or link.get(\"url\")): link\n            for link in _parse_header_links(header)\n        }\n\n    @property\n    def num_bytes_downloaded(self) -> int:\n        return self._num_bytes_downloaded\n\n    def __repr__(self) -> str:\n        return f\"<Response [{self.status_code} {self.reason_phrase}]>\"\n\n    def __getstate__(self) -> dict[str, typing.Any]:\n        return {\n            name: value\n            for name, value in self.__dict__.items()\n            if name not in [\"extensions\", \"stream\", \"is_closed\", \"_decoder\"]\n        }\n\n    def __setstate__(self, state: dict[str, typing.Any]) -> None:\n        for name, value in state.items():\n            setattr(self, name, value)\n        self.is_closed = True\n        self.extensions = {}\n        self.stream = UnattachedStream()\n\n    def read(self) -> bytes:\n        \"\"\"\n        Read and return the response content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            self._content = b\"\".join(self.iter_bytes())\n        return self._content\n\n    def iter_bytes(self, chunk_size: int | None = None) -> typing.Iterator[bytes]:\n        \"\"\"\n        A byte-iterator over the decoded response content.\n        This allows us to handle gzip, deflate, brotli, and zstd encoded responses.\n        \"\"\"\n        if hasattr(self, \"_content\"):\n            chunk_size = len(self._content) if chunk_size is None else chunk_size\n            for i in range(0, len(self._content), max(chunk_size, 1)):\n                yield self._content[i : i + chunk_size]\n        else:\n            decoder = self._get_content_decoder()\n            chunker = ByteChunker(chunk_size=chunk_size)\n            with request_context(request=self._request):\n                for raw_bytes in self.iter_raw():\n                    decoded = decoder.decode(raw_bytes)\n                    for chunk in chunker.decode(decoded):\n                        yield chunk\n                decoded = decoder.flush()\n                for chunk in chunker.decode(decoded):\n                    yield chunk  # pragma: no cover\n                for chunk in chunker.flush():\n                    yield chunk\n\n    def iter_text(self, chunk_size: int | None = None) -> typing.Iterator[str]:\n        \"\"\"\n        A str-iterator over the decoded response content\n        that handles both gzip, deflate, etc but also detects the content's\n        string encoding.\n        \"\"\"\n        decoder = TextDecoder(encoding=self.encoding or \"utf-8\")\n        chunker = TextChunker(chunk_size=chunk_size)\n        with request_context(request=self._request):\n            for byte_content in self.iter_bytes():\n                text_content = decoder.decode(byte_content)\n                for chunk in chunker.decode(text_content):\n                    yield chunk\n            text_content = decoder.flush()\n            for chunk in chunker.decode(text_content):\n                yield chunk  # pragma: no cover\n            for chunk in chunker.flush():\n                yield chunk\n\n    def iter_lines(self) -> typing.Iterator[str]:\n        decoder = LineDecoder()\n        with request_context(request=self._request):\n            for text in self.iter_text():\n                for line in decoder.decode(text):\n                    yield line\n            for line in decoder.flush():\n                yield line\n\n    def iter_raw(self, chunk_size: int | None = None) -> typing.Iterator[bytes]:\n        \"\"\"\n        A byte-iterator over the raw response content.\n        \"\"\"\n        if self.is_stream_consumed:\n            raise StreamConsumed()\n        if self.is_closed:\n            raise StreamClosed()\n        if not isinstance(self.stream, SyncByteStream):\n            raise RuntimeError(\"Attempted to call a sync iterator on an async stream.\")\n\n        self.is_stream_consumed = True\n        self._num_bytes_downloaded = 0\n        chunker = ByteChunker(chunk_size=chunk_size)\n\n        with request_context(request=self._request):\n            for raw_stream_bytes in self.stream:\n                self._num_bytes_downloaded += len(raw_stream_bytes)\n                for chunk in chunker.decode(raw_stream_bytes):\n                    yield chunk\n\n        for chunk in chunker.flush():\n            yield chunk\n\n        self.close()\n\n    def close(self) -> None:\n        \"\"\"\n        Close the response and release the connection.\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        if not isinstance(self.stream, SyncByteStream):\n            raise RuntimeError(\"Attempted to call a sync close on an async stream.\")\n\n        if not self.is_closed:\n            self.is_closed = True\n            with request_context(request=self._request):\n                self.stream.close()\n\n    async def aread(self) -> bytes:\n        \"\"\"\n        Read and return the response content.\n        \"\"\"\n        if not hasattr(self, \"_content\"):\n            self._content = b\"\".join([part async for part in self.aiter_bytes()])\n        return self._content\n\n    async def aiter_bytes(\n        self, chunk_size: int | None = None\n    ) -> typing.AsyncIterator[bytes]:\n        \"\"\"\n        A byte-iterator over the decoded response content.\n        This allows us to handle gzip, deflate, brotli, and zstd encoded responses.\n        \"\"\"\n        if hasattr(self, \"_content\"):\n            chunk_size = len(self._content) if chunk_size is None else chunk_size\n            for i in range(0, len(self._content), max(chunk_size, 1)):\n                yield self._content[i : i + chunk_size]\n        else:\n            decoder = self._get_content_decoder()\n            chunker = ByteChunker(chunk_size=chunk_size)\n            with request_context(request=self._request):\n                async for raw_bytes in self.aiter_raw():\n                    decoded = decoder.decode(raw_bytes)\n                    for chunk in chunker.decode(decoded):\n                        yield chunk\n                decoded = decoder.flush()\n                for chunk in chunker.decode(decoded):\n                    yield chunk  # pragma: no cover\n                for chunk in chunker.flush():\n                    yield chunk\n\n    async def aiter_text(\n        self, chunk_size: int | None = None\n    ) -> typing.AsyncIterator[str]:\n        \"\"\"\n        A str-iterator over the decoded response content\n        that handles both gzip, deflate, etc but also detects the content's\n        string encoding.\n        \"\"\"\n        decoder = TextDecoder(encoding=self.encoding or \"utf-8\")\n        chunker = TextChunker(chunk_size=chunk_size)\n        with request_context(request=self._request):\n            async for byte_content in self.aiter_bytes():\n                text_content = decoder.decode(byte_content)\n                for chunk in chunker.decode(text_content):\n                    yield chunk\n            text_content = decoder.flush()\n            for chunk in chunker.decode(text_content):\n                yield chunk  # pragma: no cover\n            for chunk in chunker.flush():\n                yield chunk\n\n    async def aiter_lines(self) -> typing.AsyncIterator[str]:\n        decoder = LineDecoder()\n        with request_context(request=self._request):\n            async for text in self.aiter_text():\n                for line in decoder.decode(text):\n                    yield line\n            for line in decoder.flush():\n                yield line\n\n    async def aiter_raw(\n        self, chunk_size: int | None = None\n    ) -> typing.AsyncIterator[bytes]:\n        \"\"\"\n        A byte-iterator over the raw response content.\n        \"\"\"\n        if self.is_stream_consumed:\n            raise StreamConsumed()\n        if self.is_closed:\n            raise StreamClosed()\n        if not isinstance(self.stream, AsyncByteStream):\n            raise RuntimeError(\"Attempted to call an async iterator on a sync stream.\")\n\n        self.is_stream_consumed = True\n        self._num_bytes_downloaded = 0\n        chunker = ByteChunker(chunk_size=chunk_size)\n\n        with request_context(request=self._request):\n            async for raw_stream_bytes in self.stream:\n                self._num_bytes_downloaded += len(raw_stream_bytes)\n                for chunk in chunker.decode(raw_stream_bytes):\n                    yield chunk\n\n        for chunk in chunker.flush():\n            yield chunk\n\n        await self.aclose()\n\n    async def aclose(self) -> None:\n        \"\"\"\n        Close the response and release the connection.\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        if not isinstance(self.stream, AsyncByteStream):\n            raise RuntimeError(\"Attempted to call an async close on a sync stream.\")\n\n        if not self.is_closed:\n            self.is_closed = True\n            with request_context(request=self._request):\n                await self.stream.aclose()\n\n\nclass Cookies(typing.MutableMapping[str, str]):\n    \"\"\"\n    HTTP Cookies, as a mutable mapping.\n    \"\"\"\n\n    def __init__(self, cookies: CookieTypes | None = None) -> None:\n        if cookies is None or isinstance(cookies, dict):\n            self.jar = CookieJar()\n            if isinstance(cookies, dict):\n                for key, value in cookies.items():\n                    self.set(key, value)\n        elif isinstance(cookies, list):\n            self.jar = CookieJar()\n            for key, value in cookies:\n                self.set(key, value)\n        elif isinstance(cookies, Cookies):\n            self.jar = CookieJar()\n            for cookie in cookies.jar:\n                self.jar.set_cookie(cookie)\n        else:\n            self.jar = cookies\n\n    def extract_cookies(self, response: Response) -> None:\n        \"\"\"\n        Loads any cookies based on the response `Set-Cookie` headers.\n        \"\"\"\n        urllib_response = self._CookieCompatResponse(response)\n        urllib_request = self._CookieCompatRequest(response.request)\n\n        self.jar.extract_cookies(urllib_response, urllib_request)  # type: ignore\n\n    def set_cookie_header(self, request: Request) -> None:\n        \"\"\"\n        Sets an appropriate 'Cookie:' HTTP header on the `Request`.\n        \"\"\"\n        urllib_request = self._CookieCompatRequest(request)\n        self.jar.add_cookie_header(urllib_request)\n\n    def set(self, name: str, value: str, domain: str = \"\", path: str = \"/\") -> None:\n        \"\"\"\n        Set a cookie value by name. May optionally include domain and path.\n        \"\"\"\n        kwargs = {\n            \"version\": 0,\n            \"name\": name,\n            \"value\": value,\n            \"port\": None,\n            \"port_specified\": False,\n            \"domain\": domain,\n            \"domain_specified\": bool(domain),\n            \"domain_initial_dot\": domain.startswith(\".\"),\n            \"path\": path,\n            \"path_specified\": bool(path),\n            \"secure\": False,\n            \"expires\": None,\n            \"discard\": True,\n            \"comment\": None,\n            \"comment_url\": None,\n            \"rest\": {\"HttpOnly\": None},\n            \"rfc2109\": False,\n        }\n        cookie = Cookie(**kwargs)  # type: ignore\n        self.jar.set_cookie(cookie)\n\n    def get(  # type: ignore\n        self,\n        name: str,\n        default: str | None = None,\n        domain: str | None = None,\n        path: str | None = None,\n    ) -> str | None:\n        \"\"\"\n        Get a cookie by name. May optionally include domain and path\n        in order to specify exactly which cookie to retrieve.\n        \"\"\"\n        value = None\n        for cookie in self.jar:\n            if cookie.name == name:\n                if domain is None or cookie.domain == domain:\n                    if path is None or cookie.path == path:\n                        if value is not None:\n                            message = f\"Multiple cookies exist with name={name}\"\n                            raise CookieConflict(message)\n                        value = cookie.value\n\n        if value is None:\n            return default\n        return value\n\n    def delete(\n        self,\n        name: str,\n        domain: str | None = None,\n        path: str | None = None,\n    ) -> None:\n        \"\"\"\n        Delete a cookie by name. May optionally include domain and path\n        in order to specify exactly which cookie to delete.\n        \"\"\"\n        if domain is not None and path is not None:\n            return self.jar.clear(domain, path, name)\n\n        remove = [\n            cookie\n            for cookie in self.jar\n            if cookie.name == name\n            and (domain is None or cookie.domain == domain)\n            and (path is None or cookie.path == path)\n        ]\n\n        for cookie in remove:\n            self.jar.clear(cookie.domain, cookie.path, cookie.name)\n\n    def clear(self, domain: str | None = None, path: str | None = None) -> None:\n        \"\"\"\n        Delete all cookies. Optionally include a domain and path in\n        order to only delete a subset of all the cookies.\n        \"\"\"\n        args = []\n        if domain is not None:\n            args.append(domain)\n        if path is not None:\n            assert domain is not None\n            args.append(path)\n        self.jar.clear(*args)\n\n    def update(self, cookies: CookieTypes | None = None) -> None:  # type: ignore\n        cookies = Cookies(cookies)\n        for cookie in cookies.jar:\n            self.jar.set_cookie(cookie)\n\n    def __setitem__(self, name: str, value: str) -> None:\n        return self.set(name, value)\n\n    def __getitem__(self, name: str) -> str:\n        value = self.get(name)\n        if value is None:\n            raise KeyError(name)\n        return value\n\n    def __delitem__(self, name: str) -> None:\n        return self.delete(name)\n\n    def __len__(self) -> int:\n        return len(self.jar)\n\n    def __iter__(self) -> typing.Iterator[str]:\n        return (cookie.name for cookie in self.jar)\n\n    def __bool__(self) -> bool:\n        for _ in self.jar:\n            return True\n        return False\n\n    def __repr__(self) -> str:\n        cookies_repr = \", \".join(\n            [\n                f\"<Cookie {cookie.name}={cookie.value} for {cookie.domain} />\"\n                for cookie in self.jar\n            ]\n        )\n\n        return f\"<Cookies[{cookies_repr}]>\"\n\n    class _CookieCompatRequest(urllib.request.Request):\n        \"\"\"\n        Wraps a `Request` instance up in a compatibility interface suitable\n        for use with `CookieJar` operations.\n        \"\"\"\n\n        def __init__(self, request: Request) -> None:\n            super().__init__(\n                url=str(request.url),\n                headers=dict(request.headers),\n                method=request.method,\n            )\n            self.request = request\n\n        def add_unredirected_header(self, key: str, value: str) -> None:\n            super().add_unredirected_header(key, value)\n            self.request.headers[key] = value\n\n    class _CookieCompatResponse:\n        \"\"\"\n        Wraps a `Request` instance up in a compatibility interface suitable\n        for use with `CookieJar` operations.\n        \"\"\"\n\n        def __init__(self, response: Response) -> None:\n            self.response = response\n\n        def info(self) -> email.message.Message:\n            info = email.message.Message()\n            for key, value in self.response.headers.multi_items():\n                # Note that setting `info[key]` here is an \"append\" operation,\n                # not a \"replace\" operation.\n                # https://docs.python.org/3/library/email.compat32-message.html#email.message.Message.__setitem__\n                info[key] = value\n            return info\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "1b0164c0713a",
      "repo": "httpx",
      "commit_hash": "88a81c5",
      "commit_message": "[fix] Use proxy ssl context consistently (#3175)",
      "file_path": "httpx/_transports/default.py",
      "language": "python",
      "code_before": "\"\"\"\nCustom transports, with nicely configured defaults.\n\nThe following additional keyword arguments are currently supported by httpcore...\n\n* uds: str\n* local_address: str\n* retries: int\n\nExample usages...\n\n# Disable HTTP/2 on a single specific domain.\nmounts = {\n    \"all://\": httpx.HTTPTransport(http2=True),\n    \"all://*example.org\": httpx.HTTPTransport()\n}\n\n# Using advanced httpcore configuration, with connection retries.\ntransport = httpx.HTTPTransport(retries=1)\nclient = httpx.Client(transport=transport)\n\n# Using advanced httpcore configuration, with unix domain sockets.\ntransport = httpx.HTTPTransport(uds=\"socket.uds\")\nclient = httpx.Client(transport=transport)\n\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport typing\nfrom types import TracebackType\n\nimport httpcore\n\nfrom .._config import DEFAULT_LIMITS, Limits, Proxy, create_ssl_context\nfrom .._exceptions import (\n    ConnectError,\n    ConnectTimeout,\n    LocalProtocolError,\n    NetworkError,\n    PoolTimeout,\n    ProtocolError,\n    ProxyError,\n    ReadError,\n    ReadTimeout,\n    RemoteProtocolError,\n    TimeoutException,\n    UnsupportedProtocol,\n    WriteError,\n    WriteTimeout,\n)\nfrom .._models import Request, Response\nfrom .._types import AsyncByteStream, CertTypes, ProxyTypes, SyncByteStream, VerifyTypes\nfrom .._urls import URL\nfrom .base import AsyncBaseTransport, BaseTransport\n\nT = typing.TypeVar(\"T\", bound=\"HTTPTransport\")\nA = typing.TypeVar(\"A\", bound=\"AsyncHTTPTransport\")\n\nSOCKET_OPTION = typing.Union[\n    typing.Tuple[int, int, int],\n    typing.Tuple[int, int, typing.Union[bytes, bytearray]],\n    typing.Tuple[int, int, None, int],\n]\n\n__all__ = [\"AsyncHTTPTransport\", \"HTTPTransport\"]\n\n\n@contextlib.contextmanager\ndef map_httpcore_exceptions() -> typing.Iterator[None]:\n    try:\n        yield\n    except Exception as exc:\n        mapped_exc = None\n\n        for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n            if not isinstance(exc, from_exc):\n                continue\n            # We want to map to the most specific exception we can find.\n            # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n            # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n            if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                mapped_exc = to_exc\n\n        if mapped_exc is None:  # pragma: no cover\n            raise\n\n        message = str(exc)\n        raise mapped_exc(message) from exc\n\n\nHTTPCORE_EXC_MAP = {\n    httpcore.TimeoutException: TimeoutException,\n    httpcore.ConnectTimeout: ConnectTimeout,\n    httpcore.ReadTimeout: ReadTimeout,\n    httpcore.WriteTimeout: WriteTimeout,\n    httpcore.PoolTimeout: PoolTimeout,\n    httpcore.NetworkError: NetworkError,\n    httpcore.ConnectError: ConnectError,\n    httpcore.ReadError: ReadError,\n    httpcore.WriteError: WriteError,\n    httpcore.ProxyError: ProxyError,\n    httpcore.UnsupportedProtocol: UnsupportedProtocol,\n    httpcore.ProtocolError: ProtocolError,\n    httpcore.LocalProtocolError: LocalProtocolError,\n    httpcore.RemoteProtocolError: RemoteProtocolError,\n}\n\n\nclass ResponseStream(SyncByteStream):\n    def __init__(self, httpcore_stream: typing.Iterable[bytes]) -> None:\n        self._httpcore_stream = httpcore_stream\n\n    def __iter__(self) -> typing.Iterator[bytes]:\n        with map_httpcore_exceptions():\n            for part in self._httpcore_stream:\n                yield part\n\n    def close(self) -> None:\n        if hasattr(self._httpcore_stream, \"close\"):\n            self._httpcore_stream.close()\n\n\nclass HTTPTransport(BaseTransport):\n    def __init__(\n        self,\n        verify: VerifyTypes = True,\n        cert: CertTypes | None = None,\n        http1: bool = True,\n        http2: bool = False,\n        limits: Limits = DEFAULT_LIMITS,\n        trust_env: bool = True,\n        proxy: ProxyTypes | None = None,\n        uds: str | None = None,\n        local_address: str | None = None,\n        retries: int = 0,\n        socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n    ) -> None:\n        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n        proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n\n        if proxy is None:\n            self._pool = httpcore.ConnectionPool(\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                uds=uds,\n                local_address=local_address,\n                retries=retries,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme in (\"http\", \"https\"):\n            self._pool = httpcore.HTTPProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                proxy_headers=proxy.headers.raw,\n                ssl_context=ssl_context,\n                proxy_ssl_context=proxy.ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme == \"socks5\":\n            try:\n                import socksio  # noqa\n            except ImportError:  # pragma: no cover\n                raise ImportError(\n                    \"Using SOCKS proxy, but the 'socksio' package is not installed. \"\n                    \"Make sure to install httpx using `pip install httpx[socks]`.\"\n                ) from None\n\n            self._pool = httpcore.SOCKSProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n            )\n        else:  # pragma: no cover\n            raise ValueError(\n                \"Proxy protocol must be either 'http', 'https', or 'socks5',\"\n                f\" but got {proxy.url.scheme!r}.\"\n            )\n\n    def __enter__(self: T) -> T:  # Use generics for subclass support.\n        self._pool.__enter__()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None = None,\n        exc_value: BaseException | None = None,\n        traceback: TracebackType | None = None,\n    ) -> None:\n        with map_httpcore_exceptions():\n            self._pool.__exit__(exc_type, exc_value, traceback)\n\n    def handle_request(\n        self,\n        request: Request,\n    ) -> Response:\n        assert isinstance(request.stream, SyncByteStream)\n\n        req = httpcore.Request(\n            method=request.method,\n            url=httpcore.URL(\n                scheme=request.url.raw_scheme,\n                host=request.url.raw_host,\n                port=request.url.port,\n                target=request.url.raw_path,\n            ),\n            headers=request.headers.raw,\n            content=request.stream,\n            extensions=request.extensions,\n        )\n        with map_httpcore_exceptions():\n            resp = self._pool.handle_request(req)\n\n        assert isinstance(resp.stream, typing.Iterable)\n\n        return Response(\n            status_code=resp.status,\n            headers=resp.headers,\n            stream=ResponseStream(resp.stream),\n            extensions=resp.extensions,\n        )\n\n    def close(self) -> None:\n        self._pool.close()\n\n\nclass AsyncResponseStream(AsyncByteStream):\n    def __init__(self, httpcore_stream: typing.AsyncIterable[bytes]) -> None:\n        self._httpcore_stream = httpcore_stream\n\n    async def __aiter__(self) -> typing.AsyncIterator[bytes]:\n        with map_httpcore_exceptions():\n            async for part in self._httpcore_stream:\n                yield part\n\n    async def aclose(self) -> None:\n        if hasattr(self._httpcore_stream, \"aclose\"):\n            await self._httpcore_stream.aclose()\n\n\nclass AsyncHTTPTransport(AsyncBaseTransport):\n    def __init__(\n        self,\n        verify: VerifyTypes = True,\n        cert: CertTypes | None = None,\n        http1: bool = True,\n        http2: bool = False,\n        limits: Limits = DEFAULT_LIMITS,\n        trust_env: bool = True,\n        proxy: ProxyTypes | None = None,\n        uds: str | None = None,\n        local_address: str | None = None,\n        retries: int = 0,\n        socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n    ) -> None:\n        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n        proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n\n        if proxy is None:\n            self._pool = httpcore.AsyncConnectionPool(\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                uds=uds,\n                local_address=local_address,\n                retries=retries,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme in (\"http\", \"https\"):\n            self._pool = httpcore.AsyncHTTPProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                proxy_headers=proxy.headers.raw,\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme == \"socks5\":\n            try:\n                import socksio  # noqa\n            except ImportError:  # pragma: no cover\n                raise ImportError(\n                    \"Using SOCKS proxy, but the 'socksio' package is not installed. \"\n                    \"Make sure to install httpx using `pip install httpx[socks]`.\"\n                ) from None\n\n            self._pool = httpcore.AsyncSOCKSProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n            )\n        else:  # pragma: no cover\n            raise ValueError(\n                \"Proxy protocol must be either 'http', 'https', or 'socks5',\"\n                \" but got {proxy.url.scheme!r}.\"\n            )\n\n    async def __aenter__(self: A) -> A:  # Use generics for subclass support.\n        await self._pool.__aenter__()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None = None,\n        exc_value: BaseException | None = None,\n        traceback: TracebackType | None = None,\n    ) -> None:\n        with map_httpcore_exceptions():\n            await self._pool.__aexit__(exc_type, exc_value, traceback)\n\n    async def handle_async_request(\n        self,\n        request: Request,\n    ) -> Response:\n        assert isinstance(request.stream, AsyncByteStream)\n\n        req = httpcore.Request(\n            method=request.method,\n            url=httpcore.URL(\n                scheme=request.url.raw_scheme,\n                host=request.url.raw_host,\n                port=request.url.port,\n                target=request.url.raw_path,\n            ),\n            headers=request.headers.raw,\n            content=request.stream,\n            extensions=request.extensions,\n        )\n        with map_httpcore_exceptions():\n            resp = await self._pool.handle_async_request(req)\n\n        assert isinstance(resp.stream, typing.AsyncIterable)\n\n        return Response(\n            status_code=resp.status,\n            headers=resp.headers,\n            stream=AsyncResponseStream(resp.stream),\n            extensions=resp.extensions,\n        )\n\n    async def aclose(self) -> None:\n        await self._pool.aclose()\n",
      "code_after": "\"\"\"\nCustom transports, with nicely configured defaults.\n\nThe following additional keyword arguments are currently supported by httpcore...\n\n* uds: str\n* local_address: str\n* retries: int\n\nExample usages...\n\n# Disable HTTP/2 on a single specific domain.\nmounts = {\n    \"all://\": httpx.HTTPTransport(http2=True),\n    \"all://*example.org\": httpx.HTTPTransport()\n}\n\n# Using advanced httpcore configuration, with connection retries.\ntransport = httpx.HTTPTransport(retries=1)\nclient = httpx.Client(transport=transport)\n\n# Using advanced httpcore configuration, with unix domain sockets.\ntransport = httpx.HTTPTransport(uds=\"socket.uds\")\nclient = httpx.Client(transport=transport)\n\"\"\"\n\nfrom __future__ import annotations\n\nimport contextlib\nimport typing\nfrom types import TracebackType\n\nimport httpcore\n\nfrom .._config import DEFAULT_LIMITS, Limits, Proxy, create_ssl_context\nfrom .._exceptions import (\n    ConnectError,\n    ConnectTimeout,\n    LocalProtocolError,\n    NetworkError,\n    PoolTimeout,\n    ProtocolError,\n    ProxyError,\n    ReadError,\n    ReadTimeout,\n    RemoteProtocolError,\n    TimeoutException,\n    UnsupportedProtocol,\n    WriteError,\n    WriteTimeout,\n)\nfrom .._models import Request, Response\nfrom .._types import AsyncByteStream, CertTypes, ProxyTypes, SyncByteStream, VerifyTypes\nfrom .._urls import URL\nfrom .base import AsyncBaseTransport, BaseTransport\n\nT = typing.TypeVar(\"T\", bound=\"HTTPTransport\")\nA = typing.TypeVar(\"A\", bound=\"AsyncHTTPTransport\")\n\nSOCKET_OPTION = typing.Union[\n    typing.Tuple[int, int, int],\n    typing.Tuple[int, int, typing.Union[bytes, bytearray]],\n    typing.Tuple[int, int, None, int],\n]\n\n__all__ = [\"AsyncHTTPTransport\", \"HTTPTransport\"]\n\n\n@contextlib.contextmanager\ndef map_httpcore_exceptions() -> typing.Iterator[None]:\n    try:\n        yield\n    except Exception as exc:\n        mapped_exc = None\n\n        for from_exc, to_exc in HTTPCORE_EXC_MAP.items():\n            if not isinstance(exc, from_exc):\n                continue\n            # We want to map to the most specific exception we can find.\n            # Eg if `exc` is an `httpcore.ReadTimeout`, we want to map to\n            # `httpx.ReadTimeout`, not just `httpx.TimeoutException`.\n            if mapped_exc is None or issubclass(to_exc, mapped_exc):\n                mapped_exc = to_exc\n\n        if mapped_exc is None:  # pragma: no cover\n            raise\n\n        message = str(exc)\n        raise mapped_exc(message) from exc\n\n\nHTTPCORE_EXC_MAP = {\n    httpcore.TimeoutException: TimeoutException,\n    httpcore.ConnectTimeout: ConnectTimeout,\n    httpcore.ReadTimeout: ReadTimeout,\n    httpcore.WriteTimeout: WriteTimeout,\n    httpcore.PoolTimeout: PoolTimeout,\n    httpcore.NetworkError: NetworkError,\n    httpcore.ConnectError: ConnectError,\n    httpcore.ReadError: ReadError,\n    httpcore.WriteError: WriteError,\n    httpcore.ProxyError: ProxyError,\n    httpcore.UnsupportedProtocol: UnsupportedProtocol,\n    httpcore.ProtocolError: ProtocolError,\n    httpcore.LocalProtocolError: LocalProtocolError,\n    httpcore.RemoteProtocolError: RemoteProtocolError,\n}\n\n\nclass ResponseStream(SyncByteStream):\n    def __init__(self, httpcore_stream: typing.Iterable[bytes]) -> None:\n        self._httpcore_stream = httpcore_stream\n\n    def __iter__(self) -> typing.Iterator[bytes]:\n        with map_httpcore_exceptions():\n            for part in self._httpcore_stream:\n                yield part\n\n    def close(self) -> None:\n        if hasattr(self._httpcore_stream, \"close\"):\n            self._httpcore_stream.close()\n\n\nclass HTTPTransport(BaseTransport):\n    def __init__(\n        self,\n        verify: VerifyTypes = True,\n        cert: CertTypes | None = None,\n        http1: bool = True,\n        http2: bool = False,\n        limits: Limits = DEFAULT_LIMITS,\n        trust_env: bool = True,\n        proxy: ProxyTypes | None = None,\n        uds: str | None = None,\n        local_address: str | None = None,\n        retries: int = 0,\n        socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n    ) -> None:\n        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n        proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n\n        if proxy is None:\n            self._pool = httpcore.ConnectionPool(\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                uds=uds,\n                local_address=local_address,\n                retries=retries,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme in (\"http\", \"https\"):\n            self._pool = httpcore.HTTPProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                proxy_headers=proxy.headers.raw,\n                ssl_context=ssl_context,\n                proxy_ssl_context=proxy.ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme == \"socks5\":\n            try:\n                import socksio  # noqa\n            except ImportError:  # pragma: no cover\n                raise ImportError(\n                    \"Using SOCKS proxy, but the 'socksio' package is not installed. \"\n                    \"Make sure to install httpx using `pip install httpx[socks]`.\"\n                ) from None\n\n            self._pool = httpcore.SOCKSProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n            )\n        else:  # pragma: no cover\n            raise ValueError(\n                \"Proxy protocol must be either 'http', 'https', or 'socks5',\"\n                f\" but got {proxy.url.scheme!r}.\"\n            )\n\n    def __enter__(self: T) -> T:  # Use generics for subclass support.\n        self._pool.__enter__()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None = None,\n        exc_value: BaseException | None = None,\n        traceback: TracebackType | None = None,\n    ) -> None:\n        with map_httpcore_exceptions():\n            self._pool.__exit__(exc_type, exc_value, traceback)\n\n    def handle_request(\n        self,\n        request: Request,\n    ) -> Response:\n        assert isinstance(request.stream, SyncByteStream)\n\n        req = httpcore.Request(\n            method=request.method,\n            url=httpcore.URL(\n                scheme=request.url.raw_scheme,\n                host=request.url.raw_host,\n                port=request.url.port,\n                target=request.url.raw_path,\n            ),\n            headers=request.headers.raw,\n            content=request.stream,\n            extensions=request.extensions,\n        )\n        with map_httpcore_exceptions():\n            resp = self._pool.handle_request(req)\n\n        assert isinstance(resp.stream, typing.Iterable)\n\n        return Response(\n            status_code=resp.status,\n            headers=resp.headers,\n            stream=ResponseStream(resp.stream),\n            extensions=resp.extensions,\n        )\n\n    def close(self) -> None:\n        self._pool.close()\n\n\nclass AsyncResponseStream(AsyncByteStream):\n    def __init__(self, httpcore_stream: typing.AsyncIterable[bytes]) -> None:\n        self._httpcore_stream = httpcore_stream\n\n    async def __aiter__(self) -> typing.AsyncIterator[bytes]:\n        with map_httpcore_exceptions():\n            async for part in self._httpcore_stream:\n                yield part\n\n    async def aclose(self) -> None:\n        if hasattr(self._httpcore_stream, \"aclose\"):\n            await self._httpcore_stream.aclose()\n\n\nclass AsyncHTTPTransport(AsyncBaseTransport):\n    def __init__(\n        self,\n        verify: VerifyTypes = True,\n        cert: CertTypes | None = None,\n        http1: bool = True,\n        http2: bool = False,\n        limits: Limits = DEFAULT_LIMITS,\n        trust_env: bool = True,\n        proxy: ProxyTypes | None = None,\n        uds: str | None = None,\n        local_address: str | None = None,\n        retries: int = 0,\n        socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n    ) -> None:\n        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n        proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n\n        if proxy is None:\n            self._pool = httpcore.AsyncConnectionPool(\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                uds=uds,\n                local_address=local_address,\n                retries=retries,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme in (\"http\", \"https\"):\n            self._pool = httpcore.AsyncHTTPProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                proxy_headers=proxy.headers.raw,\n                proxy_ssl_context=proxy.ssl_context,\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n                socket_options=socket_options,\n            )\n        elif proxy.url.scheme == \"socks5\":\n            try:\n                import socksio  # noqa\n            except ImportError:  # pragma: no cover\n                raise ImportError(\n                    \"Using SOCKS proxy, but the 'socksio' package is not installed. \"\n                    \"Make sure to install httpx using `pip install httpx[socks]`.\"\n                ) from None\n\n            self._pool = httpcore.AsyncSOCKSProxy(\n                proxy_url=httpcore.URL(\n                    scheme=proxy.url.raw_scheme,\n                    host=proxy.url.raw_host,\n                    port=proxy.url.port,\n                    target=proxy.url.raw_path,\n                ),\n                proxy_auth=proxy.raw_auth,\n                ssl_context=ssl_context,\n                max_connections=limits.max_connections,\n                max_keepalive_connections=limits.max_keepalive_connections,\n                keepalive_expiry=limits.keepalive_expiry,\n                http1=http1,\n                http2=http2,\n            )\n        else:  # pragma: no cover\n            raise ValueError(\n                \"Proxy protocol must be either 'http', 'https', or 'socks5',\"\n                \" but got {proxy.url.scheme!r}.\"\n            )\n\n    async def __aenter__(self: A) -> A:  # Use generics for subclass support.\n        await self._pool.__aenter__()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None = None,\n        exc_value: BaseException | None = None,\n        traceback: TracebackType | None = None,\n    ) -> None:\n        with map_httpcore_exceptions():\n            await self._pool.__aexit__(exc_type, exc_value, traceback)\n\n    async def handle_async_request(\n        self,\n        request: Request,\n    ) -> Response:\n        assert isinstance(request.stream, AsyncByteStream)\n\n        req = httpcore.Request(\n            method=request.method,\n            url=httpcore.URL(\n                scheme=request.url.raw_scheme,\n                host=request.url.raw_host,\n                port=request.url.port,\n                target=request.url.raw_path,\n            ),\n            headers=request.headers.raw,\n            content=request.stream,\n            extensions=request.extensions,\n        )\n        with map_httpcore_exceptions():\n            resp = await self._pool.handle_async_request(req)\n\n        assert isinstance(resp.stream, typing.AsyncIterable)\n\n        return Response(\n            status_code=resp.status,\n            headers=resp.headers,\n            stream=AsyncResponseStream(resp.stream),\n            extensions=resp.extensions,\n        )\n\n    async def aclose(self) -> None:\n        await self._pool.aclose()\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "c7de4ca3a451",
      "repo": "httpx",
      "commit_hash": "adbcd0e",
      "commit_message": "Change extensions type (#2803)",
      "file_path": "httpx/_types.py",
      "language": "python",
      "code_before": "\"\"\"\nType definitions for type checking purposes.\n\"\"\"\n\nimport ssl\nfrom http.cookiejar import CookieJar\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    AsyncIterable,\n    AsyncIterator,\n    Callable,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    NamedTuple,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nif TYPE_CHECKING:  # pragma: no cover\n    from ._auth import Auth  # noqa: F401\n    from ._config import Proxy, Timeout  # noqa: F401\n    from ._models import Cookies, Headers, Request  # noqa: F401\n    from ._urls import URL, QueryParams  # noqa: F401\n\n\nPrimitiveData = Optional[Union[str, int, float, bool]]\n\nRawURL = NamedTuple(\n    \"RawURL\",\n    [\n        (\"raw_scheme\", bytes),\n        (\"raw_host\", bytes),\n        (\"port\", Optional[int]),\n        (\"raw_path\", bytes),\n    ],\n)\n\nURLTypes = Union[\"URL\", str]\n\nQueryParamTypes = Union[\n    \"QueryParams\",\n    Mapping[str, Union[PrimitiveData, Sequence[PrimitiveData]]],\n    List[Tuple[str, PrimitiveData]],\n    Tuple[Tuple[str, PrimitiveData], ...],\n    str,\n    bytes,\n]\n\nHeaderTypes = Union[\n    \"Headers\",\n    Mapping[str, str],\n    Mapping[bytes, bytes],\n    Sequence[Tuple[str, str]],\n    Sequence[Tuple[bytes, bytes]],\n]\n\nCookieTypes = Union[\"Cookies\", CookieJar, Dict[str, str], List[Tuple[str, str]]]\n\nCertTypes = Union[\n    # certfile\n    str,\n    # (certfile, keyfile)\n    Tuple[str, Optional[str]],\n    # (certfile, keyfile, password)\n    Tuple[str, Optional[str], Optional[str]],\n]\nVerifyTypes = Union[str, bool, ssl.SSLContext]\nTimeoutTypes = Union[\n    Optional[float],\n    Tuple[Optional[float], Optional[float], Optional[float], Optional[float]],\n    \"Timeout\",\n]\nProxiesTypes = Union[URLTypes, \"Proxy\", Dict[URLTypes, Union[None, URLTypes, \"Proxy\"]]]\n\nAuthTypes = Union[\n    Tuple[Union[str, bytes], Union[str, bytes]],\n    Callable[[\"Request\"], \"Request\"],\n    \"Auth\",\n]\n\nRequestContent = Union[str, bytes, Iterable[bytes], AsyncIterable[bytes]]\nResponseContent = Union[str, bytes, Iterable[bytes], AsyncIterable[bytes]]\nResponseExtensions = Mapping[str, Any]\n\nRequestData = Mapping[str, Any]\n\nFileContent = Union[IO[bytes], bytes, str]\nFileTypes = Union[\n    # file (or bytes)\n    FileContent,\n    # (filename, file (or bytes))\n    Tuple[Optional[str], FileContent],\n    # (filename, file (or bytes), content_type)\n    Tuple[Optional[str], FileContent, Optional[str]],\n    # (filename, file (or bytes), content_type, headers)\n    Tuple[Optional[str], FileContent, Optional[str], Mapping[str, str]],\n]\nRequestFiles = Union[Mapping[str, FileTypes], Sequence[Tuple[str, FileTypes]]]\n\nRequestExtensions = Mapping[str, Any]\n\n\nclass SyncByteStream:\n    def __iter__(self) -> Iterator[bytes]:\n        raise NotImplementedError(\n            \"The '__iter__' method must be implemented.\"\n        )  # pragma: no cover\n        yield b\"\"  # pragma: no cover\n\n    def close(self) -> None:\n        \"\"\"\n        Subclasses can override this method to release any network resources\n        after a request/response cycle is complete.\n        \"\"\"\n\n\nclass AsyncByteStream:\n    async def __aiter__(self) -> AsyncIterator[bytes]:\n        raise NotImplementedError(\n            \"The '__aiter__' method must be implemented.\"\n        )  # pragma: no cover\n        yield b\"\"  # pragma: no cover\n\n    async def aclose(self) -> None:\n        pass\n",
      "code_after": "\"\"\"\nType definitions for type checking purposes.\n\"\"\"\n\nimport ssl\nfrom http.cookiejar import CookieJar\nfrom typing import (\n    IO,\n    TYPE_CHECKING,\n    Any,\n    AsyncIterable,\n    AsyncIterator,\n    Callable,\n    Dict,\n    Iterable,\n    Iterator,\n    List,\n    Mapping,\n    MutableMapping,\n    NamedTuple,\n    Optional,\n    Sequence,\n    Tuple,\n    Union,\n)\n\nif TYPE_CHECKING:  # pragma: no cover\n    from ._auth import Auth  # noqa: F401\n    from ._config import Proxy, Timeout  # noqa: F401\n    from ._models import Cookies, Headers, Request  # noqa: F401\n    from ._urls import URL, QueryParams  # noqa: F401\n\n\nPrimitiveData = Optional[Union[str, int, float, bool]]\n\nRawURL = NamedTuple(\n    \"RawURL\",\n    [\n        (\"raw_scheme\", bytes),\n        (\"raw_host\", bytes),\n        (\"port\", Optional[int]),\n        (\"raw_path\", bytes),\n    ],\n)\n\nURLTypes = Union[\"URL\", str]\n\nQueryParamTypes = Union[\n    \"QueryParams\",\n    Mapping[str, Union[PrimitiveData, Sequence[PrimitiveData]]],\n    List[Tuple[str, PrimitiveData]],\n    Tuple[Tuple[str, PrimitiveData], ...],\n    str,\n    bytes,\n]\n\nHeaderTypes = Union[\n    \"Headers\",\n    Mapping[str, str],\n    Mapping[bytes, bytes],\n    Sequence[Tuple[str, str]],\n    Sequence[Tuple[bytes, bytes]],\n]\n\nCookieTypes = Union[\"Cookies\", CookieJar, Dict[str, str], List[Tuple[str, str]]]\n\nCertTypes = Union[\n    # certfile\n    str,\n    # (certfile, keyfile)\n    Tuple[str, Optional[str]],\n    # (certfile, keyfile, password)\n    Tuple[str, Optional[str], Optional[str]],\n]\nVerifyTypes = Union[str, bool, ssl.SSLContext]\nTimeoutTypes = Union[\n    Optional[float],\n    Tuple[Optional[float], Optional[float], Optional[float], Optional[float]],\n    \"Timeout\",\n]\nProxiesTypes = Union[URLTypes, \"Proxy\", Dict[URLTypes, Union[None, URLTypes, \"Proxy\"]]]\n\nAuthTypes = Union[\n    Tuple[Union[str, bytes], Union[str, bytes]],\n    Callable[[\"Request\"], \"Request\"],\n    \"Auth\",\n]\n\nRequestContent = Union[str, bytes, Iterable[bytes], AsyncIterable[bytes]]\nResponseContent = Union[str, bytes, Iterable[bytes], AsyncIterable[bytes]]\nResponseExtensions = MutableMapping[str, Any]\n\nRequestData = Mapping[str, Any]\n\nFileContent = Union[IO[bytes], bytes, str]\nFileTypes = Union[\n    # file (or bytes)\n    FileContent,\n    # (filename, file (or bytes))\n    Tuple[Optional[str], FileContent],\n    # (filename, file (or bytes), content_type)\n    Tuple[Optional[str], FileContent, Optional[str]],\n    # (filename, file (or bytes), content_type, headers)\n    Tuple[Optional[str], FileContent, Optional[str], Mapping[str, str]],\n]\nRequestFiles = Union[Mapping[str, FileTypes], Sequence[Tuple[str, FileTypes]]]\n\nRequestExtensions = MutableMapping[str, Any]\n\n\nclass SyncByteStream:\n    def __iter__(self) -> Iterator[bytes]:\n        raise NotImplementedError(\n            \"The '__iter__' method must be implemented.\"\n        )  # pragma: no cover\n        yield b\"\"  # pragma: no cover\n\n    def close(self) -> None:\n        \"\"\"\n        Subclasses can override this method to release any network resources\n        after a request/response cycle is complete.\n        \"\"\"\n\n\nclass AsyncByteStream:\n    async def __aiter__(self) -> AsyncIterator[bytes]:\n        raise NotImplementedError(\n            \"The '__aiter__' method must be implemented.\"\n        )  # pragma: no cover\n        yield b\"\"  # pragma: no cover\n\n    async def aclose(self) -> None:\n        pass\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.2
    },
    {
      "bug_id": "12a9b7d0aceb",
      "repo": "requests",
      "commit_hash": "3ff3ff2",
      "commit_message": "Fix #6628 - JSONDecodeError are not deserializable",
      "file_path": "src/requests/exceptions.py",
      "language": "python",
      "code_before": "\"\"\"\nrequests.exceptions\n~~~~~~~~~~~~~~~~~~~\n\nThis module contains the set of Requests' exceptions.\n\"\"\"\nfrom urllib3.exceptions import HTTPError as BaseHTTPError\n\nfrom .compat import JSONDecodeError as CompatJSONDecodeError\n\n\nclass RequestException(IOError):\n    \"\"\"There was an ambiguous exception that occurred while handling your\n    request.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n        response = kwargs.pop(\"response\", None)\n        self.response = response\n        self.request = kwargs.pop(\"request\", None)\n        if response is not None and not self.request and hasattr(response, \"request\"):\n            self.request = self.response.request\n        super().__init__(*args, **kwargs)\n\n\nclass InvalidJSONError(RequestException):\n    \"\"\"A JSON error occurred.\"\"\"\n\n\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n    \"\"\"Couldn't decode the text into json\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.\n        \"\"\"\n        CompatJSONDecodeError.__init__(self, *args)\n        InvalidJSONError.__init__(self, *self.args, **kwargs)\n\n\nclass HTTPError(RequestException):\n    \"\"\"An HTTP error occurred.\"\"\"\n\n\nclass ConnectionError(RequestException):\n    \"\"\"A Connection error occurred.\"\"\"\n\n\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\n\n\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\n\n\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\n\n\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n\n    Requests that produced this error are safe to retry.\n    \"\"\"\n\n\nclass ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\n\n\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\n\n\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\n\n\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\n\n\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n\n\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\n\n\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\n\n\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\n\n\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n\n\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\n\n\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\n\n\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\n\n\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n\n\n# Warnings\n\n\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\n\n\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\n\n\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"\n",
      "code_after": "\"\"\"\nrequests.exceptions\n~~~~~~~~~~~~~~~~~~~\n\nThis module contains the set of Requests' exceptions.\n\"\"\"\nfrom urllib3.exceptions import HTTPError as BaseHTTPError\n\nfrom .compat import JSONDecodeError as CompatJSONDecodeError\n\n\nclass RequestException(IOError):\n    \"\"\"There was an ambiguous exception that occurred while handling your\n    request.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\n        response = kwargs.pop(\"response\", None)\n        self.response = response\n        self.request = kwargs.pop(\"request\", None)\n        if response is not None and not self.request and hasattr(response, \"request\"):\n            self.request = self.response.request\n        super().__init__(*args, **kwargs)\n\n\nclass InvalidJSONError(RequestException):\n    \"\"\"A JSON error occurred.\"\"\"\n\n\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n    \"\"\"Couldn't decode the text into json\"\"\"\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Construct the JSONDecodeError instance first with all\n        args. Then use it's args to construct the IOError so that\n        the json specific args aren't used as IOError specific args\n        and the error message from JSONDecodeError is preserved.\n        \"\"\"\n        CompatJSONDecodeError.__init__(self, *args)\n        InvalidJSONError.__init__(self, *self.args, **kwargs)\n\n    def __reduce__(self):\n        \"\"\"\n        The __reduce__ method called when pickling the object must\n        be the one from the JSONDecodeError (be it json/simplejson)\n        as it expects all the arguments for instantiation, not just\n        one like the IOError, and the MRO would by default call the\n        __reduce__ method from the IOError due to the inheritance order.\n        \"\"\"\n        return CompatJSONDecodeError.__reduce__(self)\n\n\nclass HTTPError(RequestException):\n    \"\"\"An HTTP error occurred.\"\"\"\n\n\nclass ConnectionError(RequestException):\n    \"\"\"A Connection error occurred.\"\"\"\n\n\nclass ProxyError(ConnectionError):\n    \"\"\"A proxy error occurred.\"\"\"\n\n\nclass SSLError(ConnectionError):\n    \"\"\"An SSL error occurred.\"\"\"\n\n\nclass Timeout(RequestException):\n    \"\"\"The request timed out.\n\n    Catching this error will catch both\n    :exc:`~requests.exceptions.ConnectTimeout` and\n    :exc:`~requests.exceptions.ReadTimeout` errors.\n    \"\"\"\n\n\nclass ConnectTimeout(ConnectionError, Timeout):\n    \"\"\"The request timed out while trying to connect to the remote server.\n\n    Requests that produced this error are safe to retry.\n    \"\"\"\n\n\nclass ReadTimeout(Timeout):\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\n\n\nclass URLRequired(RequestException):\n    \"\"\"A valid URL is required to make a request.\"\"\"\n\n\nclass TooManyRedirects(RequestException):\n    \"\"\"Too many redirects.\"\"\"\n\n\nclass MissingSchema(RequestException, ValueError):\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\n\n\nclass InvalidSchema(RequestException, ValueError):\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\n\n\nclass InvalidURL(RequestException, ValueError):\n    \"\"\"The URL provided was somehow invalid.\"\"\"\n\n\nclass InvalidHeader(RequestException, ValueError):\n    \"\"\"The header value provided was somehow invalid.\"\"\"\n\n\nclass InvalidProxyURL(InvalidURL):\n    \"\"\"The proxy URL provided is invalid.\"\"\"\n\n\nclass ChunkedEncodingError(RequestException):\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\n\n\nclass ContentDecodingError(RequestException, BaseHTTPError):\n    \"\"\"Failed to decode response content.\"\"\"\n\n\nclass StreamConsumedError(RequestException, TypeError):\n    \"\"\"The content for this response was already consumed.\"\"\"\n\n\nclass RetryError(RequestException):\n    \"\"\"Custom retries logic failed\"\"\"\n\n\nclass UnrewindableBodyError(RequestException):\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\n\n\n# Warnings\n\n\nclass RequestsWarning(Warning):\n    \"\"\"Base warning for Requests.\"\"\"\n\n\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\n\n\nclass RequestsDependencyWarning(RequestsWarning):\n    \"\"\"An imported dependency doesn't match the expected version range.\"\"\"\n",
      "bug_category": "readability",
      "error_type": "readability",
      "confidence": 0.2
    },
    {
      "bug_id": "c0d71a41a801",
      "repo": "requests",
      "commit_hash": "c799b81",
      "commit_message": "docs: fix dead links to kenreitz.org",
      "file_path": "docs/conf.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n#\n# Requests documentation build configuration file, created by\n# sphinx-quickstart on Fri Feb 19 00:05:47 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath('.'))\n\n# Insert Requests' path into the system.\nsys.path.insert(0, os.path.abspath(\"..\"))\nsys.path.insert(0, os.path.abspath(\"_themes\"))\n\nimport requests\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# General information about the project.\nproject = u\"Requests\"\ncopyright = u'MMXVIX. A <a href=\"https://kenreitz.org/projects\">Kenneth Reitz</a> Project'\nauthor = u\"Kenneth Reitz\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = requests.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = requests.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = ''\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\nadd_function_parentheses = False\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"flask_theme_support.FlaskyStyle\"\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as \"system message\" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"alabaster\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \"show_powered_by\": False,\n    \"github_user\": \"requests\",\n    \"github_repo\": \"requests\",\n    \"github_banner\": True,\n    \"show_related\": False,\n    \"note_bg\": \"#FFF59C\",\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\nhtml_use_smartypants = False\n\n# Custom sidebar templates, maps document names to template names.\nhtml_sidebars = {\n    \"index\": [\"sidebarintro.html\", \"sourcelink.html\", \"searchbox.html\", \"hacks.html\"],\n    \"**\": [\n        \"sidebarlogo.html\",\n        \"localtoc.html\",\n        \"relations.html\",\n        \"sourcelink.html\",\n        \"searchbox.html\",\n        \"hacks.html\",\n    ],\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\nhtml_show_sourcelink = False\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\nhtml_show_sphinx = False\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\nhtml_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'\n#   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'\n# html_search_language = 'en'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only 'ja' uses this config value\n# html_search_options = {'type': 'default'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = 'scorer.js'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \"Requestsdoc\"\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #'preamble': '',\n    # Latex figure (float) alignment\n    #'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \"Requests.tex\", u\"Requests Documentation\", u\"Kenneth Reitz\", \"manual\")\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \"requests\", u\"Requests Documentation\", [author], 1)]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        \"Requests\",\n        u\"Requests Documentation\",\n        author,\n        \"Requests\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    )\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# texinfo_show_urls = 'footnote'\n\n# If true, do not generate a @detailmenu in the \"Top\" node's menu.\n# texinfo_no_detailmenu = False\n\n\n# -- Options for Epub output ----------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\nepub_author = author\nepub_publisher = author\nepub_copyright = copyright\n\n# The basename for the epub file. It defaults to the project name.\n# epub_basename = project\n\n# The HTML theme for the epub output. Since the default themes are not\n# optimized for small screen space, using the same theme for HTML and epub\n# output is usually not wise. This defaults to 'epub', a theme designed to save\n# visual space.\n# epub_theme = 'epub'\n\n# The language of the text. It defaults to the language option\n# or 'en' if the language is not set.\n# epub_language = ''\n\n# The scheme of the identifier. Typical schemes are ISBN or URL.\n# epub_scheme = ''\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n# epub_identifier = ''\n\n# A unique identification for the text.\n# epub_uid = ''\n\n# A tuple containing the cover image and cover page html template filenames.\n# epub_cover = ()\n\n# A sequence of (type, uri, title) tuples for the guide element of content.opf.\n# epub_guide = ()\n\n# HTML files that should be inserted before the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n# epub_pre_files = []\n\n# HTML files that should be inserted after the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n# epub_post_files = []\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\"search.html\"]\n\n# The depth of the table of contents in toc.ncx.\n# epub_tocdepth = 3\n\n# Allow duplicate toc entries.\n# epub_tocdup = True\n\n# Choose between 'default' and 'includehidden'.\n# epub_tocscope = 'default'\n\n# Fix unsupported image types using the Pillow.\n# epub_fix_images = False\n\n# Scale large images.\n# epub_max_image_width = 0\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# epub_show_urls = 'inline'\n\n# If false, no index is generated.\n# epub_use_index = True\n\nintersphinx_mapping = {\n    \"python\": (\"https://docs.python.org/3/\", None),\n    \"urllib3\": (\"https://urllib3.readthedocs.io/en/latest\", None),\n}\n",
      "code_after": "# -*- coding: utf-8 -*-\n#\n# Requests documentation build configuration file, created by\n# sphinx-quickstart on Fri Feb 19 00:05:47 2016.\n#\n# This file is execfile()d with the current directory set to its\n# containing dir.\n#\n# Note that not all possible configuration values are present in this\n# autogenerated file.\n#\n# All configuration values have a default; values that are commented out\n# serve to show the default.\n\nimport sys\nimport os\n\n# If extensions (or modules to document with autodoc) are in another directory,\n# add these directories to sys.path here. If the directory is relative to the\n# documentation root, use os.path.abspath to make it absolute, like shown here.\n# sys.path.insert(0, os.path.abspath('.'))\n\n# Insert Requests' path into the system.\nsys.path.insert(0, os.path.abspath(\"..\"))\nsys.path.insert(0, os.path.abspath(\"_themes\"))\n\nimport requests\n\n\n# -- General configuration ------------------------------------------------\n\n# If your documentation needs a minimal Sphinx version, state it here.\n# needs_sphinx = '1.0'\n\n# Add any Sphinx extension module names here, as strings. They can be\n# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom\n# ones.\nextensions = [\n    \"sphinx.ext.autodoc\",\n    \"sphinx.ext.intersphinx\",\n    \"sphinx.ext.todo\",\n    \"sphinx.ext.viewcode\",\n]\n\n# Add any paths that contain templates here, relative to this directory.\ntemplates_path = [\"_templates\"]\n\n# The suffix(es) of source filenames.\n# You can specify multiple suffix as a list of string:\n# source_suffix = ['.rst', '.md']\nsource_suffix = \".rst\"\n\n# The encoding of source files.\n# source_encoding = 'utf-8-sig'\n\n# The master toctree document.\nmaster_doc = \"index\"\n\n# General information about the project.\nproject = u\"Requests\"\ncopyright = u'MMXVIX. A <a href=\"https://kennethreitz.org/software/\">Kenneth Reitz</a> Project'\nauthor = u\"Kenneth Reitz\"\n\n# The version info for the project you're documenting, acts as replacement for\n# |version| and |release|, also used in various other places throughout the\n# built documents.\n#\n# The short X.Y version.\nversion = requests.__version__\n# The full version, including alpha/beta/rc tags.\nrelease = requests.__version__\n\n# The language for content autogenerated by Sphinx. Refer to documentation\n# for a list of supported languages.\n#\n# This is also used if you do content translation via gettext catalogs.\n# Usually you set \"language\" from the command line for these cases.\nlanguage = None\n\n# There are two options for replacing |today|: either, you set today to some\n# non-false value, then it is used:\n# today = ''\n# Else, today_fmt is used as the format for a strftime call.\n# today_fmt = '%B %d, %Y'\n\n# List of patterns, relative to source directory, that match files and\n# directories to ignore when looking for source files.\nexclude_patterns = [\"_build\"]\n\n# The reST default role (used for this markup: `text`) to use for all\n# documents.\n# default_role = None\n\n# If true, '()' will be appended to :func: etc. cross-reference text.\nadd_function_parentheses = False\n\n# If true, the current module name will be prepended to all description\n# unit titles (such as .. function::).\nadd_module_names = True\n\n# If true, sectionauthor and moduleauthor directives will be shown in the\n# output. They are ignored by default.\n# show_authors = False\n\n# The name of the Pygments (syntax highlighting) style to use.\npygments_style = \"flask_theme_support.FlaskyStyle\"\n\n# A list of ignored prefixes for module index sorting.\n# modindex_common_prefix = []\n\n# If true, keep warnings as \"system message\" paragraphs in the built documents.\n# keep_warnings = False\n\n# If true, `todo` and `todoList` produce output, else they produce nothing.\ntodo_include_todos = True\n\n\n# -- Options for HTML output ----------------------------------------------\n\n# The theme to use for HTML and HTML Help pages.  See the documentation for\n# a list of builtin themes.\nhtml_theme = \"alabaster\"\n\n# Theme options are theme-specific and customize the look and feel of a theme\n# further.  For a list of options available for each theme, see the\n# documentation.\nhtml_theme_options = {\n    \"show_powered_by\": False,\n    \"github_user\": \"requests\",\n    \"github_repo\": \"requests\",\n    \"github_banner\": True,\n    \"show_related\": False,\n    \"note_bg\": \"#FFF59C\",\n}\n\n# Add any paths that contain custom themes here, relative to this directory.\n# html_theme_path = []\n\n# The name for this set of Sphinx documents.  If None, it defaults to\n# \"<project> v<release> documentation\".\n# html_title = None\n\n# A shorter title for the navigation bar.  Default is the same as html_title.\n# html_short_title = None\n\n# The name of an image file (relative to this directory) to place at the top\n# of the sidebar.\n# html_logo = None\n\n# The name of an image file (within the static path) to use as favicon of the\n# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32\n# pixels large.\n# html_favicon = None\n\n# Add any paths that contain custom static files (such as style sheets) here,\n# relative to this directory. They are copied after the builtin static files,\n# so a file named \"default.css\" will overwrite the builtin \"default.css\".\nhtml_static_path = [\"_static\"]\n\n# Add any extra paths that contain custom files (such as robots.txt or\n# .htaccess) here, relative to this directory. These files are copied\n# directly to the root of the documentation.\n# html_extra_path = []\n\n# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,\n# using the given strftime format.\n# html_last_updated_fmt = '%b %d, %Y'\n\n# If true, SmartyPants will be used to convert quotes and dashes to\n# typographically correct entities.\nhtml_use_smartypants = False\n\n# Custom sidebar templates, maps document names to template names.\nhtml_sidebars = {\n    \"index\": [\"sidebarintro.html\", \"sourcelink.html\", \"searchbox.html\", \"hacks.html\"],\n    \"**\": [\n        \"sidebarlogo.html\",\n        \"localtoc.html\",\n        \"relations.html\",\n        \"sourcelink.html\",\n        \"searchbox.html\",\n        \"hacks.html\",\n    ],\n}\n\n# Additional templates that should be rendered to pages, maps page names to\n# template names.\n# html_additional_pages = {}\n\n# If false, no module index is generated.\n# html_domain_indices = True\n\n# If false, no index is generated.\n# html_use_index = True\n\n# If true, the index is split into individual pages for each letter.\n# html_split_index = False\n\n# If true, links to the reST sources are added to the pages.\nhtml_show_sourcelink = False\n\n# If true, \"Created using Sphinx\" is shown in the HTML footer. Default is True.\nhtml_show_sphinx = False\n\n# If true, \"(C) Copyright ...\" is shown in the HTML footer. Default is True.\nhtml_show_copyright = True\n\n# If true, an OpenSearch description file will be output, and all pages will\n# contain a <link> tag referring to it.  The value of this option must be the\n# base URL from which the finished HTML is served.\n# html_use_opensearch = ''\n\n# This is the file name suffix for HTML files (e.g. \".xhtml\").\n# html_file_suffix = None\n\n# Language to be used for generating the HTML full-text search index.\n# Sphinx supports the following languages:\n#   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'\n#   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'\n# html_search_language = 'en'\n\n# A dictionary with options for the search language support, empty by default.\n# Now only 'ja' uses this config value\n# html_search_options = {'type': 'default'}\n\n# The name of a javascript file (relative to the configuration directory) that\n# implements a search results scorer. If empty, the default will be used.\n# html_search_scorer = 'scorer.js'\n\n# Output file base name for HTML help builder.\nhtmlhelp_basename = \"Requestsdoc\"\n\n# -- Options for LaTeX output ---------------------------------------------\n\nlatex_elements = {\n    # The paper size ('letterpaper' or 'a4paper').\n    #'papersize': 'letterpaper',\n    # The font size ('10pt', '11pt' or '12pt').\n    #'pointsize': '10pt',\n    # Additional stuff for the LaTeX preamble.\n    #'preamble': '',\n    # Latex figure (float) alignment\n    #'figure_align': 'htbp',\n}\n\n# Grouping the document tree into LaTeX files. List of tuples\n# (source start file, target name, title,\n#  author, documentclass [howto, manual, or own class]).\nlatex_documents = [\n    (master_doc, \"Requests.tex\", u\"Requests Documentation\", u\"Kenneth Reitz\", \"manual\")\n]\n\n# The name of an image file (relative to this directory) to place at the top of\n# the title page.\n# latex_logo = None\n\n# For \"manual\" documents, if this is true, then toplevel headings are parts,\n# not chapters.\n# latex_use_parts = False\n\n# If true, show page references after internal links.\n# latex_show_pagerefs = False\n\n# If true, show URL addresses after external links.\n# latex_show_urls = False\n\n# Documents to append as an appendix to all manuals.\n# latex_appendices = []\n\n# If false, no module index is generated.\n# latex_domain_indices = True\n\n\n# -- Options for manual page output ---------------------------------------\n\n# One entry per manual page. List of tuples\n# (source start file, name, description, authors, manual section).\nman_pages = [(master_doc, \"requests\", u\"Requests Documentation\", [author], 1)]\n\n# If true, show URL addresses after external links.\n# man_show_urls = False\n\n\n# -- Options for Texinfo output -------------------------------------------\n\n# Grouping the document tree into Texinfo files. List of tuples\n# (source start file, target name, title, author,\n#  dir menu entry, description, category)\ntexinfo_documents = [\n    (\n        master_doc,\n        \"Requests\",\n        u\"Requests Documentation\",\n        author,\n        \"Requests\",\n        \"One line description of project.\",\n        \"Miscellaneous\",\n    )\n]\n\n# Documents to append as an appendix to all manuals.\n# texinfo_appendices = []\n\n# If false, no module index is generated.\n# texinfo_domain_indices = True\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# texinfo_show_urls = 'footnote'\n\n# If true, do not generate a @detailmenu in the \"Top\" node's menu.\n# texinfo_no_detailmenu = False\n\n\n# -- Options for Epub output ----------------------------------------------\n\n# Bibliographic Dublin Core info.\nepub_title = project\nepub_author = author\nepub_publisher = author\nepub_copyright = copyright\n\n# The basename for the epub file. It defaults to the project name.\n# epub_basename = project\n\n# The HTML theme for the epub output. Since the default themes are not\n# optimized for small screen space, using the same theme for HTML and epub\n# output is usually not wise. This defaults to 'epub', a theme designed to save\n# visual space.\n# epub_theme = 'epub'\n\n# The language of the text. It defaults to the language option\n# or 'en' if the language is not set.\n# epub_language = ''\n\n# The scheme of the identifier. Typical schemes are ISBN or URL.\n# epub_scheme = ''\n\n# The unique identifier of the text. This can be a ISBN number\n# or the project homepage.\n# epub_identifier = ''\n\n# A unique identification for the text.\n# epub_uid = ''\n\n# A tuple containing the cover image and cover page html template filenames.\n# epub_cover = ()\n\n# A sequence of (type, uri, title) tuples for the guide element of content.opf.\n# epub_guide = ()\n\n# HTML files that should be inserted before the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n# epub_pre_files = []\n\n# HTML files that should be inserted after the pages created by sphinx.\n# The format is a list of tuples containing the path and title.\n# epub_post_files = []\n\n# A list of files that should not be packed into the epub file.\nepub_exclude_files = [\"search.html\"]\n\n# The depth of the table of contents in toc.ncx.\n# epub_tocdepth = 3\n\n# Allow duplicate toc entries.\n# epub_tocdup = True\n\n# Choose between 'default' and 'includehidden'.\n# epub_tocscope = 'default'\n\n# Fix unsupported image types using the Pillow.\n# epub_fix_images = False\n\n# Scale large images.\n# epub_max_image_width = 0\n\n# How to display URL addresses: 'footnote', 'no', or 'inline'.\n# epub_show_urls = 'inline'\n\n# If false, no index is generated.\n# epub_use_index = True\n\nintersphinx_mapping = {\n    \"python\": (\"https://docs.python.org/3/\", None),\n    \"urllib3\": (\"https://urllib3.readthedocs.io/en/latest\", None),\n}\n",
      "bug_category": "readability",
      "error_type": "readability",
      "confidence": 0.2
    },
    {
      "bug_id": "2726c1f1a5d4",
      "repo": "requests",
      "commit_hash": "c0813a2",
      "commit_message": "Use TLS settings in selecting connection pool",
      "file_path": "src/requests/adapters.py",
      "language": "python",
      "code_before": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \"\"\"Initializes a urllib3 PoolManager.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param connections: The number of urllib3 connection pools to cache.\n        :param maxsize: The maximum number of connections to save in the pool.\n        :param block: Block when no free connections are available.\n        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n        \"\"\"\n        # save these values for pickling\n        self._pool_connections = connections\n        self._pool_maxsize = maxsize\n        self._pool_block = block\n\n        self.poolmanager = PoolManager(\n            num_pools=connections,\n            maxsize=maxsize,\n            block=block,\n            **pool_kwargs,\n        )\n\n    def proxy_manager_for(self, proxy, **proxy_kwargs):\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n        :returns: ProxyManager\n        :rtype: urllib3.ProxyManager\n        \"\"\"\n        if proxy in self.proxy_manager:\n            manager = self.proxy_manager[proxy]\n        elif proxy.lower().startswith(\"socks\"):\n            username, password = get_auth_from_url(proxy)\n            manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                proxy,\n                username=username,\n                password=password,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n        else:\n            proxy_headers = self.proxy_headers(proxy)\n            manager = self.proxy_manager[proxy] = proxy_from_url(\n                proxy,\n                proxy_headers=proxy_headers,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n\n        return manager\n\n    def cert_verify(self, conn, url, verify, cert):\n        \"\"\"Verify a SSL certificate. This method should not be called from user\n        code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param conn: The urllib3 connection object associated with the cert.\n        :param url: The requested URL.\n        :param verify: Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: The SSL certificate to verify.\n        \"\"\"\n        if url.lower().startswith(\"https\") and verify:\n            cert_loc = None\n\n            # Allow self-specified cert location.\n            if verify is not True:\n                cert_loc = verify\n\n            if not cert_loc:\n                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)\n\n            if not cert_loc or not os.path.exists(cert_loc):\n                raise OSError(\n                    f\"Could not find a suitable TLS CA certificate bundle, \"\n                    f\"invalid path: {cert_loc}\"\n                )\n\n            conn.cert_reqs = \"CERT_REQUIRED\"\n\n            if not os.path.isdir(cert_loc):\n                conn.ca_certs = cert_loc\n            else:\n                conn.ca_cert_dir = cert_loc\n        else:\n            conn.cert_reqs = \"CERT_NONE\"\n            conn.ca_certs = None\n            conn.ca_cert_dir = None\n\n        if cert:\n            if not isinstance(cert, basestring):\n                conn.cert_file = cert[0]\n                conn.key_file = cert[1]\n            else:\n                conn.cert_file = cert\n                conn.key_file = None\n            if conn.cert_file and not os.path.exists(conn.cert_file):\n                raise OSError(\n                    f\"Could not find the TLS certificate file, \"\n                    f\"invalid path: {conn.cert_file}\"\n                )\n            if conn.key_file and not os.path.exists(conn.key_file):\n                raise OSError(\n                    f\"Could not find the TLS key file, invalid path: {conn.key_file}\"\n                )\n\n    def build_response(self, req, resp):\n        \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n        response. This should not be called from user code, and is only exposed\n        for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n\n        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n        :param resp: The urllib3 response object.\n        :rtype: requests.Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response\n\n    def get_connection(self, url, proxies=None):\n        \"\"\"Returns a urllib3 connection for the given URL. This should not be\n        called from user code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param url: The URL to connect to.\n        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n        :rtype: urllib3.ConnectionPool\n        \"\"\"\n        proxy = select_proxy(url, proxies)\n\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_url(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n\n        try:\n            conn = self.get_connection(request.url, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n\n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n\n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n\n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n\n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n\n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n\n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n\n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n\n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n\n            raise ConnectionError(e, request=request)\n\n        except ClosedPoolError as e:\n            raise ConnectionError(e, request=request)\n\n        except _ProxyError as e:\n            raise ProxyError(e)\n\n        except (_SSLError, _HTTPError) as e:\n            if isinstance(e, _SSLError):\n                # This branch is for urllib3 versions earlier than v1.22\n                raise SSLError(e, request=request)\n            elif isinstance(e, ReadTimeoutError):\n                raise ReadTimeout(e, request=request)\n            elif isinstance(e, _InvalidHeader):\n                raise InvalidHeader(e, request=request)\n            else:\n                raise\n\n        return self.build_response(request, resp)\n",
      "code_after": "\"\"\"\nrequests.adapters\n~~~~~~~~~~~~~~~~~\n\nThis module contains the transport adapters that Requests uses to define\nand maintain connections.\n\"\"\"\n\nimport os.path\nimport socket  # noqa: F401\nimport typing\n\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\nfrom urllib3.exceptions import HTTPError as _HTTPError\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\nfrom urllib3.exceptions import (\n    LocationValueError,\n    MaxRetryError,\n    NewConnectionError,\n    ProtocolError,\n)\nfrom urllib3.exceptions import ProxyError as _ProxyError\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\nfrom urllib3.exceptions import SSLError as _SSLError\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\nfrom urllib3.util import Timeout as TimeoutSauce\nfrom urllib3.util import parse_url\nfrom urllib3.util.retry import Retry\n\nfrom .auth import _basic_auth_str\nfrom .compat import basestring, urlparse\nfrom .cookies import extract_cookies_to_jar\nfrom .exceptions import (\n    ConnectionError,\n    ConnectTimeout,\n    InvalidHeader,\n    InvalidProxyURL,\n    InvalidSchema,\n    InvalidURL,\n    ProxyError,\n    ReadTimeout,\n    RetryError,\n    SSLError,\n)\nfrom .models import Response\nfrom .structures import CaseInsensitiveDict\nfrom .utils import (\n    DEFAULT_CA_BUNDLE_PATH,\n    extract_zipped_paths,\n    get_auth_from_url,\n    get_encoding_from_headers,\n    prepend_scheme_if_needed,\n    select_proxy,\n    urldefragauth,\n)\n\ntry:\n    from urllib3.contrib.socks import SOCKSProxyManager\nexcept ImportError:\n\n    def SOCKSProxyManager(*args, **kwargs):\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n\n\nif typing.TYPE_CHECKING:\n    from .models import PreparedRequest\n\n\nDEFAULT_POOLBLOCK = False\nDEFAULT_POOLSIZE = 10\nDEFAULT_RETRIES = 0\nDEFAULT_POOL_TIMEOUT = None\n\n\ndef _urllib3_request_context(\n    request: \"PreparedRequest\", verify: \"bool | str | None\"\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\n    host_params = {}\n    pool_kwargs = {}\n    parsed_request_url = urlparse(request.url)\n    scheme = parsed_request_url.scheme.lower()\n    port = parsed_request_url.port\n    cert_reqs = \"CERT_REQUIRED\"\n    if verify is False:\n        cert_reqs = \"CERT_NONE\"\n    if isinstance(verify, str):\n        pool_kwargs[\"ca_certs\"] = verify\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\n    host_params = {\n        \"scheme\": scheme,\n        \"host\": parsed_request_url.hostname,\n        \"port\": port,\n    }\n    return host_params, pool_kwargs\n\n\nclass BaseAdapter:\n    \"\"\"The Base Transport Adapter\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n        raise NotImplementedError\n\n    def close(self):\n        \"\"\"Cleans up adapter specific items.\"\"\"\n        raise NotImplementedError\n\n\nclass HTTPAdapter(BaseAdapter):\n    \"\"\"The built-in HTTP Adapter for urllib3.\n\n    Provides a general-case interface for Requests sessions to contact HTTP and\n    HTTPS urls by implementing the Transport Adapter interface. This class will\n    usually be created by the :class:`Session <Session>` class under the\n    covers.\n\n    :param pool_connections: The number of urllib3 connection pools to cache.\n    :param pool_maxsize: The maximum number of connections to save in the pool.\n    :param max_retries: The maximum number of retries each connection\n        should attempt. Note, this applies only to failed DNS lookups, socket\n        connections and connection timeouts, never to requests where data has\n        made it to the server. By default, Requests does not retry failed\n        connections. If you need granular control over the conditions under\n        which we retry a request, import urllib3's ``Retry`` class and pass\n        that instead.\n    :param pool_block: Whether the connection pool should block for connections.\n\n    Usage::\n\n      >>> import requests\n      >>> s = requests.Session()\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n      >>> s.mount('http://', a)\n    \"\"\"\n\n    __attrs__ = [\n        \"max_retries\",\n        \"config\",\n        \"_pool_connections\",\n        \"_pool_maxsize\",\n        \"_pool_block\",\n    ]\n\n    def __init__(\n        self,\n        pool_connections=DEFAULT_POOLSIZE,\n        pool_maxsize=DEFAULT_POOLSIZE,\n        max_retries=DEFAULT_RETRIES,\n        pool_block=DEFAULT_POOLBLOCK,\n    ):\n        if max_retries == DEFAULT_RETRIES:\n            self.max_retries = Retry(0, read=False)\n        else:\n            self.max_retries = Retry.from_int(max_retries)\n        self.config = {}\n        self.proxy_manager = {}\n\n        super().__init__()\n\n        self._pool_connections = pool_connections\n        self._pool_maxsize = pool_maxsize\n        self._pool_block = pool_block\n\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n\n    def __getstate__(self):\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n        # self.poolmanager uses a lambda function, which isn't pickleable.\n        self.proxy_manager = {}\n        self.config = {}\n\n        for attr, value in state.items():\n            setattr(self, attr, value)\n\n        self.init_poolmanager(\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\n        )\n\n    def init_poolmanager(\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\n    ):\n        \"\"\"Initializes a urllib3 PoolManager.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param connections: The number of urllib3 connection pools to cache.\n        :param maxsize: The maximum number of connections to save in the pool.\n        :param block: Block when no free connections are available.\n        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n        \"\"\"\n        # save these values for pickling\n        self._pool_connections = connections\n        self._pool_maxsize = maxsize\n        self._pool_block = block\n\n        self.poolmanager = PoolManager(\n            num_pools=connections,\n            maxsize=maxsize,\n            block=block,\n            **pool_kwargs,\n        )\n\n    def proxy_manager_for(self, proxy, **proxy_kwargs):\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\n\n        This method should not be called from user code, and is only\n        exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n        :returns: ProxyManager\n        :rtype: urllib3.ProxyManager\n        \"\"\"\n        if proxy in self.proxy_manager:\n            manager = self.proxy_manager[proxy]\n        elif proxy.lower().startswith(\"socks\"):\n            username, password = get_auth_from_url(proxy)\n            manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n                proxy,\n                username=username,\n                password=password,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n        else:\n            proxy_headers = self.proxy_headers(proxy)\n            manager = self.proxy_manager[proxy] = proxy_from_url(\n                proxy,\n                proxy_headers=proxy_headers,\n                num_pools=self._pool_connections,\n                maxsize=self._pool_maxsize,\n                block=self._pool_block,\n                **proxy_kwargs,\n            )\n\n        return manager\n\n    def cert_verify(self, conn, url, verify, cert):\n        \"\"\"Verify a SSL certificate. This method should not be called from user\n        code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param conn: The urllib3 connection object associated with the cert.\n        :param url: The requested URL.\n        :param verify: Either a boolean, in which case it controls whether we verify\n            the server's TLS certificate, or a string, in which case it must be a path\n            to a CA bundle to use\n        :param cert: The SSL certificate to verify.\n        \"\"\"\n        if url.lower().startswith(\"https\") and verify:\n            cert_loc = None\n\n            # Allow self-specified cert location.\n            if verify is not True:\n                cert_loc = verify\n\n            if not cert_loc:\n                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)\n\n            if not cert_loc or not os.path.exists(cert_loc):\n                raise OSError(\n                    f\"Could not find a suitable TLS CA certificate bundle, \"\n                    f\"invalid path: {cert_loc}\"\n                )\n\n            conn.cert_reqs = \"CERT_REQUIRED\"\n\n            if not os.path.isdir(cert_loc):\n                conn.ca_certs = cert_loc\n            else:\n                conn.ca_cert_dir = cert_loc\n        else:\n            conn.cert_reqs = \"CERT_NONE\"\n            conn.ca_certs = None\n            conn.ca_cert_dir = None\n\n        if cert:\n            if not isinstance(cert, basestring):\n                conn.cert_file = cert[0]\n                conn.key_file = cert[1]\n            else:\n                conn.cert_file = cert\n                conn.key_file = None\n            if conn.cert_file and not os.path.exists(conn.cert_file):\n                raise OSError(\n                    f\"Could not find the TLS certificate file, \"\n                    f\"invalid path: {conn.cert_file}\"\n                )\n            if conn.key_file and not os.path.exists(conn.key_file):\n                raise OSError(\n                    f\"Could not find the TLS key file, invalid path: {conn.key_file}\"\n                )\n\n    def build_response(self, req, resp):\n        \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n        response. This should not be called from user code, and is only exposed\n        for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n\n        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n        :param resp: The urllib3 response object.\n        :rtype: requests.Response\n        \"\"\"\n        response = Response()\n\n        # Fallback to None if there's no status_code, for whatever reason.\n        response.status_code = getattr(resp, \"status\", None)\n\n        # Make headers case-insensitive.\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\n\n        # Set encoding.\n        response.encoding = get_encoding_from_headers(response.headers)\n        response.raw = resp\n        response.reason = response.raw.reason\n\n        if isinstance(req.url, bytes):\n            response.url = req.url.decode(\"utf-8\")\n        else:\n            response.url = req.url\n\n        # Add new cookies from the server.\n        extract_cookies_to_jar(response.cookies, req, resp)\n\n        # Give the Response some context.\n        response.request = req\n        response.connection = self\n\n        return response\n\n    def _get_connection(self, request, verify, proxies=None):\n        # Replace the existing get_connection without breaking things and\n        # ensure that TLS settings are considered when we interact with\n        # urllib3 HTTP Pools\n        proxy = select_proxy(request.url, proxies)\n        try:\n            host_params, pool_kwargs = _urllib3_request_context(request, verify)\n        except ValueError as e:\n            raise InvalidURL(e, request=request)\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_host(\n                **host_params, pool_kwargs=pool_kwargs\n            )\n        else:\n            # Only scheme should be lower case\n            conn = self.poolmanager.connection_from_host(\n                **host_params, pool_kwargs=pool_kwargs\n            )\n\n        return conn\n\n    def get_connection(self, url, proxies=None):\n        \"\"\"Returns a urllib3 connection for the given URL. This should not be\n        called from user code, and is only exposed for use when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param url: The URL to connect to.\n        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n        :rtype: urllib3.ConnectionPool\n        \"\"\"\n        proxy = select_proxy(url, proxies)\n\n        if proxy:\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\n            proxy_url = parse_url(proxy)\n            if not proxy_url.host:\n                raise InvalidProxyURL(\n                    \"Please check proxy URL. It is malformed \"\n                    \"and could be missing the host.\"\n                )\n            proxy_manager = self.proxy_manager_for(proxy)\n            conn = proxy_manager.connection_from_url(url)\n        else:\n            # Only scheme should be lower case\n            parsed = urlparse(url)\n            url = parsed.geturl()\n            conn = self.poolmanager.connection_from_url(url)\n\n        return conn\n\n    def close(self):\n        \"\"\"Disposes of any internal state.\n\n        Currently, this closes the PoolManager and any active ProxyManager,\n        which closes any pooled connections.\n        \"\"\"\n        self.poolmanager.clear()\n        for proxy in self.proxy_manager.values():\n            proxy.clear()\n\n    def request_url(self, request, proxies):\n        \"\"\"Obtain the url to use when making the final request.\n\n        If the message is being sent through a HTTP proxy, the full URL has to\n        be used. Otherwise, we should only use the path portion of the URL.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n        :rtype: str\n        \"\"\"\n        proxy = select_proxy(request.url, proxies)\n        scheme = urlparse(request.url).scheme\n\n        is_proxied_http_request = proxy and scheme != \"https\"\n        using_socks_proxy = False\n        if proxy:\n            proxy_scheme = urlparse(proxy).scheme.lower()\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\n\n        url = request.path_url\n        if url.startswith(\"//\"):  # Don't confuse urllib3\n            url = f\"/{url.lstrip('/')}\"\n\n        if is_proxied_http_request and not using_socks_proxy:\n            url = urldefragauth(request.url)\n\n        return url\n\n    def add_headers(self, request, **kwargs):\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n        nothing by default, but is left for overriding by users that subclass\n        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n        :param kwargs: The keyword arguments from the call to send().\n        \"\"\"\n        pass\n\n    def proxy_headers(self, proxy):\n        \"\"\"Returns a dictionary of the headers to add to any request sent\n        through a proxy. This works with urllib3 magic to ensure that they are\n        correctly sent to the proxy, rather than in a tunnelled request if\n        CONNECT is being used.\n\n        This should not be called from user code, and is only exposed for use\n        when subclassing the\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n\n        :param proxy: The url of the proxy being used for this request.\n        :rtype: dict\n        \"\"\"\n        headers = {}\n        username, password = get_auth_from_url(proxy)\n\n        if username:\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\n\n        return headers\n\n    def send(\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\n    ):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a :ref:`(connect timeout,\n            read timeout) <timeouts>` tuple.\n        :type timeout: float or tuple or urllib3 Timeout object\n        :param verify: (optional) Either a boolean, in which case it controls whether\n            we verify the server's TLS certificate, or a string, in which case it\n            must be a path to a CA bundle to use\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        :rtype: requests.Response\n        \"\"\"\n\n        try:\n            conn = self._get_connection(request, verify, proxies)\n        except LocationValueError as e:\n            raise InvalidURL(e, request=request)\n\n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(\n            request,\n            stream=stream,\n            timeout=timeout,\n            verify=verify,\n            cert=cert,\n            proxies=proxies,\n        )\n\n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\n\n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError:\n                raise ValueError(\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\n                    f\"or a single float to set both timeouts to the same value.\"\n                )\n        elif isinstance(timeout, TimeoutSauce):\n            pass\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n\n        try:\n            resp = conn.urlopen(\n                method=request.method,\n                url=url,\n                body=request.body,\n                headers=request.headers,\n                redirect=False,\n                assert_same_host=False,\n                preload_content=False,\n                decode_content=False,\n                retries=self.max_retries,\n                timeout=timeout,\n                chunked=chunked,\n            )\n\n        except (ProtocolError, OSError) as err:\n            raise ConnectionError(err, request=request)\n\n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                # TODO: Remove this in 3.0.0: see #2811\n                if not isinstance(e.reason, NewConnectionError):\n                    raise ConnectTimeout(e, request=request)\n\n            if isinstance(e.reason, ResponseError):\n                raise RetryError(e, request=request)\n\n            if isinstance(e.reason, _ProxyError):\n                raise ProxyError(e, request=request)\n\n            if isinstance(e.reason, _SSLError):\n                # This branch is for urllib3 v1.22 and later.\n                raise SSLError(e, request=request)\n\n            raise ConnectionError(e, request=request)\n\n        except ClosedPoolError as e:\n            raise ConnectionError(e, request=request)\n\n        except _ProxyError as e:\n            raise ProxyError(e)\n\n        except (_SSLError, _HTTPError) as e:\n            if isinstance(e, _SSLError):\n                # This branch is for urllib3 versions earlier than v1.22\n                raise SSLError(e, request=request)\n            elif isinstance(e, ReadTimeoutError):\n                raise ReadTimeout(e, request=request)\n            elif isinstance(e, _InvalidHeader):\n                raise InvalidHeader(e, request=request)\n            else:\n                raise\n\n        return self.build_response(request, resp)\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 1.0
    },
    {
      "bug_id": "761a723abcc7",
      "repo": "requests",
      "commit_hash": "3fd309a",
      "commit_message": "Enhance `super_len` to count encoded bytes for str",
      "file_path": "src/requests/utils.py",
      "language": "python",
      "code_before": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import (  # noqa: F401\n    _HEADER_VALIDATORS_BYTE,\n    _HEADER_VALIDATORS_STR,\n    HEADER_VALIDATORS,\n    to_native_string,\n)\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except (OSError, ValueError):\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such as NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)\n\n\ndef _validate_header_part(header, header_part, header_validator_index):\n    if isinstance(header_part, str):\n        validator = _HEADER_VALIDATORS_STR[header_validator_index]\n    elif isinstance(header_part, bytes):\n        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]\n    else:\n        raise InvalidHeader(\n            f\"Header part ({header_part!r}) from {header} \"\n            f\"must be of type str or bytes, not {type(header_part)}\"\n        )\n\n    if not validator.match(header_part):\n        header_kind = \"name\" if header_validator_index == 0 else \"value\"\n        raise InvalidHeader(\n            f\"Invalid leading whitespace, reserved character(s), or return \"\n            f\"character(s) in header {header_kind}: {header_part!r}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "code_after": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import (  # noqa: F401\n    _HEADER_VALIDATORS_BYTE,\n    _HEADER_VALIDATORS_STR,\n    HEADER_VALIDATORS,\n    to_native_string,\n)\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except (OSError, ValueError):\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if isinstance(o, str):\n        o = o.encode(\"utf-8\")\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such as NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)\n\n\ndef _validate_header_part(header, header_part, header_validator_index):\n    if isinstance(header_part, str):\n        validator = _HEADER_VALIDATORS_STR[header_validator_index]\n    elif isinstance(header_part, bytes):\n        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]\n    else:\n        raise InvalidHeader(\n            f\"Header part ({header_part!r}) from {header} \"\n            f\"must be of type str or bytes, not {type(header_part)}\"\n        )\n\n    if not validator.match(header_part):\n        header_kind = \"name\" if header_validator_index == 0 else \"value\"\n        raise InvalidHeader(\n            f\"Invalid leading whitespace, reserved character(s), or return \"\n            f\"character(s) in header {header_kind}: {header_part!r}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "43af810a4b23",
      "repo": "requests",
      "commit_hash": "1584994",
      "commit_message": "fix docstring typo: a -> as",
      "file_path": "src/requests/utils.py",
      "language": "python",
      "code_before": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import (  # noqa: F401\n    _HEADER_VALIDATORS_BYTE,\n    _HEADER_VALIDATORS_STR,\n    HEADER_VALIDATORS,\n    to_native_string,\n)\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except (OSError, ValueError):\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such a NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)\n\n\ndef _validate_header_part(header, header_part, header_validator_index):\n    if isinstance(header_part, str):\n        validator = _HEADER_VALIDATORS_STR[header_validator_index]\n    elif isinstance(header_part, bytes):\n        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]\n    else:\n        raise InvalidHeader(\n            f\"Header part ({header_part!r}) from {header} \"\n            f\"must be of type str or bytes, not {type(header_part)}\"\n        )\n\n    if not validator.match(header_part):\n        header_kind = \"name\" if header_validator_index == 0 else \"value\"\n        raise InvalidHeader(\n            f\"Invalid leading whitespace, reserved character(s), or return \"\n            f\"character(s) in header {header_kind}: {header_part!r}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "code_after": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import (  # noqa: F401\n    _HEADER_VALIDATORS_BYTE,\n    _HEADER_VALIDATORS_STR,\n    HEADER_VALIDATORS,\n    to_native_string,\n)\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except (OSError, ValueError):\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such as NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header parts don't contain leading whitespace\n    reserved characters, or return characters.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n    _validate_header_part(header, name, 0)\n    _validate_header_part(header, value, 1)\n\n\ndef _validate_header_part(header, header_part, header_validator_index):\n    if isinstance(header_part, str):\n        validator = _HEADER_VALIDATORS_STR[header_validator_index]\n    elif isinstance(header_part, bytes):\n        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]\n    else:\n        raise InvalidHeader(\n            f\"Header part ({header_part!r}) from {header} \"\n            f\"must be of type str or bytes, not {type(header_part)}\"\n        )\n\n    if not validator.match(header_part):\n        header_kind = \"name\" if header_validator_index == 0 else \"value\"\n        raise InvalidHeader(\n            f\"Invalid leading whitespace, reserved character(s), or return \"\n            f\"character(s) in header {header_kind}: {header_part!r}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "f22a608a20ea",
      "repo": "requests",
      "commit_hash": "16a17a3",
      "commit_message": "fix: Remove '<4' from python_requires (#6333)",
      "file_path": "setup.py",
      "language": "python",
      "code_before": "#!/usr/bin/env python\nimport os\nimport sys\nfrom codecs import open\n\nfrom setuptools import setup\nfrom setuptools.command.test import test as TestCommand\n\nCURRENT_PYTHON = sys.version_info[:2]\nREQUIRED_PYTHON = (3, 7)\n\nif CURRENT_PYTHON < REQUIRED_PYTHON:\n    sys.stderr.write(\n        \"\"\"\n==========================\nUnsupported Python version\n==========================\nThis version of Requests requires at least Python {}.{}, but\nyou're trying to install it on Python {}.{}. To resolve this,\nconsider upgrading to a supported Python version.\n\nIf you can't upgrade your Python version, you'll need to\npin to an older version of Requests (<2.28).\n\"\"\".format(\n            *(REQUIRED_PYTHON + CURRENT_PYTHON)\n        )\n    )\n    sys.exit(1)\n\n\nclass PyTest(TestCommand):\n    user_options = [(\"pytest-args=\", \"a\", \"Arguments to pass into py.test\")]\n\n    def initialize_options(self):\n        TestCommand.initialize_options(self)\n        try:\n            from multiprocessing import cpu_count\n\n            self.pytest_args = [\"-n\", str(cpu_count()), \"--boxed\"]\n        except (ImportError, NotImplementedError):\n            self.pytest_args = [\"-n\", \"1\", \"--boxed\"]\n\n    def finalize_options(self):\n        TestCommand.finalize_options(self)\n        self.test_args = []\n        self.test_suite = True\n\n    def run_tests(self):\n        import pytest\n\n        errno = pytest.main(self.pytest_args)\n        sys.exit(errno)\n\n\n# 'setup.py publish' shortcut.\nif sys.argv[-1] == \"publish\":\n    os.system(\"python setup.py sdist bdist_wheel\")\n    os.system(\"twine upload dist/*\")\n    sys.exit()\n\nrequires = [\n    \"charset_normalizer>=2,<4\",\n    \"idna>=2.5,<4\",\n    \"urllib3>=1.21.1,<1.27\",\n    \"certifi>=2017.4.17\",\n]\ntest_requirements = [\n    \"pytest-httpbin==0.0.7\",\n    \"pytest-cov\",\n    \"pytest-mock\",\n    \"pytest-xdist\",\n    \"PySocks>=1.5.6, !=1.5.7\",\n    \"pytest>=3\",\n]\n\nabout = {}\nhere = os.path.abspath(os.path.dirname(__file__))\nwith open(os.path.join(here, \"requests\", \"__version__.py\"), \"r\", \"utf-8\") as f:\n    exec(f.read(), about)\n\nwith open(\"README.md\", \"r\", \"utf-8\") as f:\n    readme = f.read()\n\nsetup(\n    name=about[\"__title__\"],\n    version=about[\"__version__\"],\n    description=about[\"__description__\"],\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=about[\"__author__\"],\n    author_email=about[\"__author_email__\"],\n    url=about[\"__url__\"],\n    packages=[\"requests\"],\n    package_data={\"\": [\"LICENSE\", \"NOTICE\"]},\n    package_dir={\"requests\": \"requests\"},\n    include_package_data=True,\n    python_requires=\">=3.7, <4\",\n    install_requires=requires,\n    license=about[\"__license__\"],\n    zip_safe=False,\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Environment :: Web Environment\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Topic :: Internet :: WWW/HTTP\",\n        \"Topic :: Software Development :: Libraries\",\n    ],\n    cmdclass={\"test\": PyTest},\n    tests_require=test_requirements,\n    extras_require={\n        \"security\": [],\n        \"socks\": [\"PySocks>=1.5.6, !=1.5.7\"],\n        \"use_chardet_on_py3\": [\"chardet>=3.0.2,<6\"],\n    },\n    project_urls={\n        \"Documentation\": \"https://requests.readthedocs.io\",\n        \"Source\": \"https://github.com/psf/requests\",\n    },\n)\n",
      "code_after": "#!/usr/bin/env python\nimport os\nimport sys\nfrom codecs import open\n\nfrom setuptools import setup\nfrom setuptools.command.test import test as TestCommand\n\nCURRENT_PYTHON = sys.version_info[:2]\nREQUIRED_PYTHON = (3, 7)\n\nif CURRENT_PYTHON < REQUIRED_PYTHON:\n    sys.stderr.write(\n        \"\"\"\n==========================\nUnsupported Python version\n==========================\nThis version of Requests requires at least Python {}.{}, but\nyou're trying to install it on Python {}.{}. To resolve this,\nconsider upgrading to a supported Python version.\n\nIf you can't upgrade your Python version, you'll need to\npin to an older version of Requests (<2.28).\n\"\"\".format(\n            *(REQUIRED_PYTHON + CURRENT_PYTHON)\n        )\n    )\n    sys.exit(1)\n\n\nclass PyTest(TestCommand):\n    user_options = [(\"pytest-args=\", \"a\", \"Arguments to pass into py.test\")]\n\n    def initialize_options(self):\n        TestCommand.initialize_options(self)\n        try:\n            from multiprocessing import cpu_count\n\n            self.pytest_args = [\"-n\", str(cpu_count()), \"--boxed\"]\n        except (ImportError, NotImplementedError):\n            self.pytest_args = [\"-n\", \"1\", \"--boxed\"]\n\n    def finalize_options(self):\n        TestCommand.finalize_options(self)\n        self.test_args = []\n        self.test_suite = True\n\n    def run_tests(self):\n        import pytest\n\n        errno = pytest.main(self.pytest_args)\n        sys.exit(errno)\n\n\n# 'setup.py publish' shortcut.\nif sys.argv[-1] == \"publish\":\n    os.system(\"python setup.py sdist bdist_wheel\")\n    os.system(\"twine upload dist/*\")\n    sys.exit()\n\nrequires = [\n    \"charset_normalizer>=2,<4\",\n    \"idna>=2.5,<4\",\n    \"urllib3>=1.21.1,<1.27\",\n    \"certifi>=2017.4.17\",\n]\ntest_requirements = [\n    \"pytest-httpbin==0.0.7\",\n    \"pytest-cov\",\n    \"pytest-mock\",\n    \"pytest-xdist\",\n    \"PySocks>=1.5.6, !=1.5.7\",\n    \"pytest>=3\",\n]\n\nabout = {}\nhere = os.path.abspath(os.path.dirname(__file__))\nwith open(os.path.join(here, \"requests\", \"__version__.py\"), \"r\", \"utf-8\") as f:\n    exec(f.read(), about)\n\nwith open(\"README.md\", \"r\", \"utf-8\") as f:\n    readme = f.read()\n\nsetup(\n    name=about[\"__title__\"],\n    version=about[\"__version__\"],\n    description=about[\"__description__\"],\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=about[\"__author__\"],\n    author_email=about[\"__author_email__\"],\n    url=about[\"__url__\"],\n    packages=[\"requests\"],\n    package_data={\"\": [\"LICENSE\", \"NOTICE\"]},\n    package_dir={\"requests\": \"requests\"},\n    include_package_data=True,\n    python_requires=\">=3.7\",\n    install_requires=requires,\n    license=about[\"__license__\"],\n    zip_safe=False,\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Environment :: Web Environment\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.7\",\n        \"Programming Language :: Python :: 3.8\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Topic :: Internet :: WWW/HTTP\",\n        \"Topic :: Software Development :: Libraries\",\n    ],\n    cmdclass={\"test\": PyTest},\n    tests_require=test_requirements,\n    extras_require={\n        \"security\": [],\n        \"socks\": [\"PySocks>=1.5.6, !=1.5.7\"],\n        \"use_chardet_on_py3\": [\"chardet>=3.0.2,<6\"],\n    },\n    project_urls={\n        \"Documentation\": \"https://requests.readthedocs.io\",\n        \"Source\": \"https://github.com/psf/requests\",\n    },\n)\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "07a6fba0ee06",
      "repo": "requests",
      "commit_hash": "79f2ec3",
      "commit_message": "Grammar fix (#6133)",
      "file_path": "requests/utils.py",
      "language": "python",
      "code_before": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import to_native_string  # noqa: F401\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except OSError:\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {}\n\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes a iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such a NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\n# Moved outside of function to avoid recompile every call\n_CLEAN_HEADER_REGEX_BYTE = re.compile(b\"^\\\\S[^\\\\r\\\\n]*$|^$\")\n_CLEAN_HEADER_REGEX_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header value is a string which doesn't contain\n    leading whitespace or return characters. This prevents unintended\n    header injection.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n\n    if isinstance(value, bytes):\n        pat = _CLEAN_HEADER_REGEX_BYTE\n    else:\n        pat = _CLEAN_HEADER_REGEX_STR\n    try:\n        if not pat.match(value):\n            raise InvalidHeader(\n                f\"Invalid return character or leading space in header: {name}\"\n            )\n    except TypeError:\n        raise InvalidHeader(\n            f\"Value for header {{{name}: {value}}} must be of type \"\n            f\"str or bytes, not {type(value)}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "code_after": "\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom urllib3.util import make_headers, parse_url\n\nfrom . import certs\nfrom .__version__ import __version__\n\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import to_native_string  # noqa: F401\nfrom .compat import (\n    Mapping,\n    basestring,\n    bytes,\n    getproxies,\n    getproxies_environment,\n    integer_types,\n)\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    proxy_bypass,\n    proxy_bypass_environment,\n    quote,\n    str,\n    unquote,\n    urlparse,\n    urlunparse,\n)\nfrom .cookies import cookiejar_from_dict\nfrom .exceptions import (\n    FileModeWarning,\n    InvalidHeader,\n    InvalidURL,\n    UnrewindableBodyError,\n)\nfrom .structures import CaseInsensitiveDict\n\nNETRC_FILES = (\".netrc\", \"_netrc\")\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == \"win32\":\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(\n                winreg.HKEY_CURRENT_USER,\n                r\"Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings\",\n            )\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\n        except OSError:\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(\";\")\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == \"<local>\":\n                if \".\" not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")  # mask dots\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\n            test = test.replace(\"?\", r\".\")  # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, \"items\"):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, \"__len__\"):\n        total_length = len(o)\n\n    elif hasattr(o, \"len\"):\n        total_length = o.len\n\n    elif hasattr(o, \"fileno\"):\n        try:\n            fileno = o.fileno()\n        except (io.UnsupportedOperation, AttributeError):\n            # AttributeError is a surprising exception, seeing as how we've just checked\n            # that `hasattr(o, 'fileno')`.  It happens for objects obtained via\n            # `Tarfile.extractfile()`, per issue 5229.\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if \"b\" not in o.mode:\n                warnings.warn(\n                    (\n                        \"Requests has determined the content-length for this \"\n                        \"request using the binary size of the file: however, the \"\n                        \"file has been opened in text mode (i.e. without the 'b' \"\n                        \"flag in the mode). This may lead to an incorrect \"\n                        \"content-length. In Requests 3.0, support will be removed \"\n                        \"for files in text mode.\"\n                    ),\n                    FileModeWarning,\n                )\n\n    if hasattr(o, \"tell\"):\n        try:\n            current_position = o.tell()\n        except OSError:\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, \"seek\") and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except OSError:\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get(\"NETRC\")\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\n\n    try:\n        from netrc import NetrcParseError, netrc\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b\":\"\n        if isinstance(url, str):\n            splitstr = splitstr.decode(\"ascii\")\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = 0 if _netrc[0] else 1\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, OSError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, \"name\", None)\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = \"/\".join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\n            yield tmp_handler\n        os.replace(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if \"=\" not in item:\n            result[item] = None\n            continue\n        name, value = item.split(\"=\", 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != \"\\\\\\\\\":\n            return value.replace(\"\\\\\\\\\", \"\\\\\").replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {}\n\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (\n        charset_re.findall(content)\n        + pragma_re.findall(content)\n        + xml_re.findall(content)\n    )\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(\";\")\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get(\"content-type\")\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if \"charset\" in params:\n        return params[\"charset\"].strip(\"'\\\"\")\n\n    if \"text\" in content_type:\n        return \"ISO-8859-1\"\n\n    if \"application/json\" in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return \"utf-8\"\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes an iterator.\"\"\"\n\n    if r.encoding is None:\n        yield from iterator\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b\"\", final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos : pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn(\n        (\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\n            \"more information, please see the discussion on issue #2266. (This\"\n            \" warning should only appear once.)\"\n        ),\n        DeprecationWarning,\n    )\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors=\"replace\")\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\n)\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split(\"%\")\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(f\"Invalid percent-escape sequence: '{h}'\")\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = f\"%{parts[i]}\"\n        else:\n            parts[i] = f\"%{parts[i]}\"\n    return \"\".join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\n    netaddr, bits = net.split(\"/\")\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except OSError:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count(\"/\") == 1:\n        try:\n            mask = int(string_network.split(\"/\")[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split(\"/\")[0])\n        except OSError:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    def get_proxy(key):\n        return os.environ.get(key) or os.environ.get(key.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy(\"no_proxy\")\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += f\":{parsed.port}\"\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ(\"no_proxy\", no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\n\n    proxy_keys = [\n        urlparts.scheme + \"://\" + urlparts.hostname,\n        urlparts.scheme,\n        \"all://\" + urlparts.hostname,\n        \"all\",\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef resolve_proxies(request, proxies, trust_env=True):\n    \"\"\"This method takes proxy information from a request and configuration\n    input to resolve a mapping of target proxies. This will consider settings\n    such a NO_PROXY to strip proxy configurations.\n\n    :param request: Request or PreparedRequest\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    :param trust_env: Boolean declaring whether to trust environment configs\n\n    :rtype: dict\n    \"\"\"\n    proxies = proxies if proxies is not None else {}\n    url = request.url\n    scheme = urlparse(url).scheme\n    no_proxy = proxies.get(\"no_proxy\")\n    new_proxies = proxies.copy()\n\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\n\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\n\n        if proxy:\n            new_proxies.setdefault(scheme, proxy)\n    return new_proxies\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return f\"{name}/{__version__}\"\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict(\n        {\n            \"User-Agent\": default_user_agent(),\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\n            \"Accept\": \"*/*\",\n            \"Connection\": \"keep-alive\",\n        }\n    )\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = \" '\\\"\"\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(\", *<\", value):\n        try:\n            url, params = val.split(\";\", 1)\n        except ValueError:\n            url, params = val, \"\"\n\n        link = {\"url\": url.strip(\"<> '\\\"\")}\n\n        for param in params.split(\";\"):\n            try:\n                key, value = param.split(\"=\")\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = \"\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return \"utf-32\"  # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return \"utf-16\"  # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return \"utf-8\"\n    if nullcount == 2:\n        if sample[::2] == _null2:  # 1st and 3rd are null\n            return \"utf-16-be\"\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return \"utf-16-le\"\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return \"utf-32-be\"\n        if sample[1:] == _null3:\n            return \"utf-32-le\"\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    parsed = parse_url(url)\n    scheme, auth, host, port, path, query, fragment = parsed\n\n    # A defect in urlparse determines that there isn't a netloc present in some\n    # urls. We previously assumed parsing was overly cautious, and swapped the\n    # netloc and path. Due to a lack of tests on the original defect, this is\n    # maintained with parse_url for backwards compatibility.\n    netloc = parsed.netloc\n    if not netloc:\n        netloc, path = path, netloc\n\n    if auth:\n        # parse_url doesn't provide the netloc with auth\n        # so we'll add it ourselves.\n        netloc = \"@\".join([auth, netloc])\n    if scheme is None:\n        scheme = new_scheme\n    if path is None:\n        path = \"\"\n\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = (\"\", \"\")\n\n    return auth\n\n\n# Moved outside of function to avoid recompile every call\n_CLEAN_HEADER_REGEX_BYTE = re.compile(b\"^\\\\S[^\\\\r\\\\n]*$|^$\")\n_CLEAN_HEADER_REGEX_STR = re.compile(r\"^\\S[^\\r\\n]*$|^$\")\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header value is a string which doesn't contain\n    leading whitespace or return characters. This prevents unintended\n    header injection.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n\n    if isinstance(value, bytes):\n        pat = _CLEAN_HEADER_REGEX_BYTE\n    else:\n        pat = _CLEAN_HEADER_REGEX_STR\n    try:\n        if not pat.match(value):\n            raise InvalidHeader(\n                f\"Invalid return character or leading space in header: {name}\"\n            )\n    except TypeError:\n        raise InvalidHeader(\n            f\"Value for header {{{name}: {value}}} must be of type \"\n            f\"str or bytes, not {type(value)}\"\n        )\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit(\"@\", 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, \"seek\", None)\n    if body_seek is not None and isinstance(\n        prepared_request._body_position, integer_types\n    ):\n        try:\n            body_seek(prepared_request._body_position)\n        except OSError:\n            raise UnrewindableBodyError(\n                \"An error occurred when rewinding request body for redirect.\"\n            )\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "55afe5aae95c",
      "repo": "requests",
      "commit_hash": "55da533",
      "commit_message": "Defer the trustme import until inside the fixture",
      "file_path": "tests/conftest.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n\ntry:\n    from http.server import HTTPServer\n    from http.server import SimpleHTTPRequestHandler\nexcept ImportError:\n    from BaseHTTPServer import HTTPServer\n    from SimpleHTTPServer import SimpleHTTPRequestHandler \n\nimport ssl\nimport tempfile\nimport threading\n\nimport pytest\nfrom requests.compat import urljoin\nimport trustme\n\n\ndef prepare_url(value):\n    # Issue #1483: Make sure the URL always has a trailing slash\n    httpbin_url = value.url.rstrip('/') + '/'\n\n    def inner(*suffix):\n        return urljoin(httpbin_url, '/'.join(suffix))\n\n    return inner\n\n\n@pytest.fixture\ndef httpbin(httpbin):\n    return prepare_url(httpbin)\n\n\n@pytest.fixture\ndef httpbin_secure(httpbin_secure):\n    return prepare_url(httpbin_secure)\n\n\n@pytest.fixture\ndef nosan_server(tmp_path_factory):\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # only commonName, no subjectAltName\n    server_cert = ca.issue_cert(common_name=u\"localhost\")\n    ca_bundle = str(tmpdir / \"ca.pem\")\n    ca.cert_pem.write_to_path(ca_bundle)\n\n    context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n    server_cert.configure_cert(context)\n    server = HTTPServer((\"localhost\", 0), SimpleHTTPRequestHandler)\n    server.socket = context.wrap_socket(server.socket, server_side=True)\n    server_thread = threading.Thread(target=server.serve_forever)\n    server_thread.start()\n\n    yield \"localhost\", server.server_address[1], ca_bundle\n\n    server.shutdown()\n    server_thread.join()\n",
      "code_after": "# -*- coding: utf-8 -*-\n\ntry:\n    from http.server import HTTPServer\n    from http.server import SimpleHTTPRequestHandler\nexcept ImportError:\n    from BaseHTTPServer import HTTPServer\n    from SimpleHTTPServer import SimpleHTTPRequestHandler \n\nimport ssl\nimport tempfile\nimport threading\n\nimport pytest\nfrom requests.compat import urljoin\n\n\ndef prepare_url(value):\n    # Issue #1483: Make sure the URL always has a trailing slash\n    httpbin_url = value.url.rstrip('/') + '/'\n\n    def inner(*suffix):\n        return urljoin(httpbin_url, '/'.join(suffix))\n\n    return inner\n\n\n@pytest.fixture\ndef httpbin(httpbin):\n    return prepare_url(httpbin)\n\n\n@pytest.fixture\ndef httpbin_secure(httpbin_secure):\n    return prepare_url(httpbin_secure)\n\n\n@pytest.fixture\ndef nosan_server(tmp_path_factory):\n    # delay importing until the fixture in order to make it possible\n    # to deselect the test via command-line when trustme is not available\n    import trustme\n\n    tmpdir = tmp_path_factory.mktemp(\"certs\")\n    ca = trustme.CA()\n    # only commonName, no subjectAltName\n    server_cert = ca.issue_cert(common_name=u\"localhost\")\n    ca_bundle = str(tmpdir / \"ca.pem\")\n    ca.cert_pem.write_to_path(ca_bundle)\n\n    context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n    server_cert.configure_cert(context)\n    server = HTTPServer((\"localhost\", 0), SimpleHTTPRequestHandler)\n    server.socket = context.wrap_socket(server.socket, server_side=True)\n    server_thread = threading.Thread(target=server.serve_forever)\n    server_thread.start()\n\n    yield \"localhost\", server.server_address[1], ca_bundle\n\n    server.shutdown()\n    server_thread.join()\n",
      "bug_category": "design",
      "error_type": "design_pattern",
      "confidence": 0.4
    },
    {
      "bug_id": "e922a0cd2510",
      "repo": "requests",
      "commit_hash": "fc106ab",
      "commit_message": "fix minor typos (#5934)",
      "file_path": "requests/utils.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\nfrom urllib3.util import make_headers\n\nfrom .__version__ import __version__\nfrom . import certs\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import to_native_string\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    quote, urlparse, bytes, str, unquote, getproxies,\n    proxy_bypass, urlunparse, basestring, integer_types, is_py3,\n    proxy_bypass_environment, getproxies_environment, Mapping)\nfrom .cookies import cookiejar_from_dict\nfrom .structures import CaseInsensitiveDict\nfrom .exceptions import (\n    InvalidURL, InvalidHeader, FileModeWarning, UnrewindableBodyError)\n\nNETRC_FILES = ('.netrc', '_netrc')\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {'http': 80, 'https': 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == 'win32':\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            if is_py3:\n                import winreg\n            else:\n                import _winreg as winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings,\n                                              'ProxyEnable')[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings,\n                                                'ProxyOverride')[0]\n        except OSError:\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(';')\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == '<local>':\n                if '.' not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")     # mask dots\n            test = test.replace(\"*\", r\".*\")     # change glob sequence\n            test = test.replace(\"?\", r\".\")      # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, 'items'):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, '__len__'):\n        total_length = len(o)\n\n    elif hasattr(o, 'len'):\n        total_length = o.len\n\n    elif hasattr(o, 'fileno'):\n        try:\n            fileno = o.fileno()\n        except io.UnsupportedOperation:\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if 'b' not in o.mode:\n                warnings.warn((\n                    \"Requests has determined the content-length for this \"\n                    \"request using the binary size of the file: however, the \"\n                    \"file has been opened in text mode (i.e. without the 'b' \"\n                    \"flag in the mode). This may lead to an incorrect \"\n                    \"content-length. In Requests 3.0, support will be removed \"\n                    \"for files in text mode.\"),\n                    FileModeWarning\n                )\n\n    if hasattr(o, 'tell'):\n        try:\n            current_position = o.tell()\n        except (OSError, IOError):\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, 'seek') and total_length is None:\n                # StringIO and BytesIO have seek but no useable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except (OSError, IOError):\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get('NETRC')\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = ('~/{}'.format(f) for f in NETRC_FILES)\n\n    try:\n        from netrc import netrc, NetrcParseError\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b':'\n        if isinstance(url, str):\n            splitstr = splitstr.decode('ascii')\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = (0 if _netrc[0] else 1)\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, IOError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, 'name', None)\n    if (name and isinstance(name, basestring) and name[0] != '<' and\n            name[-1] != '>'):\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = '/'.join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split('/')[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    replacer = os.rename if sys.version_info[0] == 2 else os.replace\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, 'wb') as tmp_handler:\n            yield tmp_handler\n        replacer(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if '=' not in item:\n            result[item] = None\n            continue\n        name, value = item.split('=', 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != '\\\\\\\\':\n            return value.replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {}\n\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_encodings_from_content will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (charset_re.findall(content) +\n            pragma_re.findall(content) +\n            xml_re.findall(content))\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(';')\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1:].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get('content-type')\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if 'charset' in params:\n        return params['charset'].strip(\"'\\\"\")\n\n    if 'text' in content_type:\n        return 'ISO-8859-1'\n\n    if 'application/json' in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return 'utf-8'\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes a iterator.\"\"\"\n\n    if r.encoding is None:\n        for item in iterator:\n            yield item\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b'', final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos:pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_unicode_from_response will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors='replace')\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\")\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split('%')\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(\"Invalid percent-escape sequence: '%s'\" % h)\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = '%' + parts[i]\n        else:\n            parts[i] = '%' + parts[i]\n    return ''.join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack('=L', socket.inet_aton(ip))[0]\n    netaddr, bits = net.split('/')\n    netmask = struct.unpack('=L', socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack('=L', socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xffffffff ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack('>I', bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except socket.error:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count('/') == 1:\n        try:\n            mask = int(string_network.split('/')[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split('/')[0])\n        except socket.error:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy('no_proxy')\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (\n            host for host in no_proxy.replace(' ', '').split(',') if host\n        )\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += ':{}'.format(parsed.port)\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ('no_proxy', no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get('all'))\n\n    proxy_keys = [\n        urlparts.scheme + '://' + urlparts.hostname,\n        urlparts.scheme,\n        'all://' + urlparts.hostname,\n        'all',\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return '%s/%s' % (name, __version__)\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict({\n        'User-Agent': default_user_agent(),\n        'Accept-Encoding': DEFAULT_ACCEPT_ENCODING,\n        'Accept': '*/*',\n        'Connection': 'keep-alive',\n    })\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = ' \\'\"'\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(', *<', value):\n        try:\n            url, params = val.split(';', 1)\n        except ValueError:\n            url, params = val, ''\n\n        link = {'url': url.strip('<> \\'\"')}\n\n        for param in params.split(';'):\n            try:\n                key, value = param.split('=')\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = '\\x00'.encode('ascii')  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return 'utf-32'     # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return 'utf-8-sig'  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return 'utf-16'     # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return 'utf-8'\n    if nullcount == 2:\n        if sample[::2] == _null2:   # 1st and 3rd are null\n            return 'utf-16-be'\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return 'utf-16-le'\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return 'utf-32-be'\n        if sample[1:] == _null3:\n            return 'utf-32-le'\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n\n    # urlparse is a finicky beast, and sometimes decides that there isn't a\n    # netloc present. Assume that it's being over-cautious, and switch netloc\n    # and path if urlparse decided there was no netloc.\n    if not netloc:\n        netloc, path = path, netloc\n\n    return urlunparse((scheme, netloc, path, params, query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = ('', '')\n\n    return auth\n\n\n# Moved outside of function to avoid recompile every call\n_CLEAN_HEADER_REGEX_BYTE = re.compile(b'^\\\\S[^\\\\r\\\\n]*$|^$')\n_CLEAN_HEADER_REGEX_STR = re.compile(r'^\\S[^\\r\\n]*$|^$')\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header value is a string which doesn't contain\n    leading whitespace or return characters. This prevents unintended\n    header injection.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n\n    if isinstance(value, bytes):\n        pat = _CLEAN_HEADER_REGEX_BYTE\n    else:\n        pat = _CLEAN_HEADER_REGEX_STR\n    try:\n        if not pat.match(value):\n            raise InvalidHeader(\"Invalid return character or leading space in header: %s\" % name)\n    except TypeError:\n        raise InvalidHeader(\"Value for header {%s: %s} must be of type str or \"\n                            \"bytes, not %s\" % (name, value, type(value)))\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit('@', 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, ''))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, 'seek', None)\n    if body_seek is not None and isinstance(prepared_request._body_position, integer_types):\n        try:\n            body_seek(prepared_request._body_position)\n        except (IOError, OSError):\n            raise UnrewindableBodyError(\"An error occurred when rewinding request \"\n                                        \"body for redirect.\")\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "code_after": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\nfrom urllib3.util import make_headers\n\nfrom .__version__ import __version__\nfrom . import certs\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import to_native_string\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    quote, urlparse, bytes, str, unquote, getproxies,\n    proxy_bypass, urlunparse, basestring, integer_types, is_py3,\n    proxy_bypass_environment, getproxies_environment, Mapping)\nfrom .cookies import cookiejar_from_dict\nfrom .structures import CaseInsensitiveDict\nfrom .exceptions import (\n    InvalidURL, InvalidHeader, FileModeWarning, UnrewindableBodyError)\n\nNETRC_FILES = ('.netrc', '_netrc')\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {'http': 80, 'https': 443}\n\n# Ensure that ', ' is used to preserve previous delimiter behavior.\nDEFAULT_ACCEPT_ENCODING = \", \".join(\n    re.split(r\",\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\n)\n\n\nif sys.platform == 'win32':\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            if is_py3:\n                import winreg\n            else:\n                import _winreg as winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings,\n                                              'ProxyEnable')[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings,\n                                                'ProxyOverride')[0]\n        except OSError:\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(';')\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == '<local>':\n                if '.' not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")     # mask dots\n            test = test.replace(\"*\", r\".*\")     # change glob sequence\n            test = test.replace(\"?\", r\".\")      # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, 'items'):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, '__len__'):\n        total_length = len(o)\n\n    elif hasattr(o, 'len'):\n        total_length = o.len\n\n    elif hasattr(o, 'fileno'):\n        try:\n            fileno = o.fileno()\n        except io.UnsupportedOperation:\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if 'b' not in o.mode:\n                warnings.warn((\n                    \"Requests has determined the content-length for this \"\n                    \"request using the binary size of the file: however, the \"\n                    \"file has been opened in text mode (i.e. without the 'b' \"\n                    \"flag in the mode). This may lead to an incorrect \"\n                    \"content-length. In Requests 3.0, support will be removed \"\n                    \"for files in text mode.\"),\n                    FileModeWarning\n                )\n\n    if hasattr(o, 'tell'):\n        try:\n            current_position = o.tell()\n        except (OSError, IOError):\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, 'seek') and total_length is None:\n                # StringIO and BytesIO have seek but no usable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except (OSError, IOError):\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get('NETRC')\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = ('~/{}'.format(f) for f in NETRC_FILES)\n\n    try:\n        from netrc import netrc, NetrcParseError\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b':'\n        if isinstance(url, str):\n            splitstr = splitstr.decode('ascii')\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = (0 if _netrc[0] else 1)\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, IOError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, 'name', None)\n    if (name and isinstance(name, basestring) and name[0] != '<' and\n            name[-1] != '>'):\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        if not prefix:\n            # If we don't check for an empty prefix after the split (in other words, archive remains unchanged after the split),\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\n            break\n        member = '/'.join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, member.split('/')[-1])\n    if not os.path.exists(extracted_path):\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n        with atomic_open(extracted_path) as file_handler:\n            file_handler.write(zip_file.read(member))\n    return extracted_path\n\n\n@contextlib.contextmanager\ndef atomic_open(filename):\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\n    replacer = os.rename if sys.version_info[0] == 2 else os.replace\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\n    try:\n        with os.fdopen(tmp_descriptor, 'wb') as tmp_handler:\n            yield tmp_handler\n        replacer(tmp_name, filename)\n    except BaseException:\n        os.remove(tmp_name)\n        raise\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if '=' not in item:\n            result[item] = None\n            continue\n        name, value = item.split('=', 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != '\\\\\\\\':\n            return value.replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {}\n\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_encodings_from_content will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (charset_re.findall(content) +\n            pragma_re.findall(content) +\n            xml_re.findall(content))\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(';')\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1:].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get('content-type')\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if 'charset' in params:\n        return params['charset'].strip(\"'\\\"\")\n\n    if 'text' in content_type:\n        return 'ISO-8859-1'\n\n    if 'application/json' in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return 'utf-8'\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes a iterator.\"\"\"\n\n    if r.encoding is None:\n        for item in iterator:\n            yield item\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b'', final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos:pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_unicode_from_response will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors='replace')\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\")\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split('%')\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(\"Invalid percent-escape sequence: '%s'\" % h)\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = '%' + parts[i]\n        else:\n            parts[i] = '%' + parts[i]\n    return ''.join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack('=L', socket.inet_aton(ip))[0]\n    netaddr, bits = net.split('/')\n    netmask = struct.unpack('=L', socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack('=L', socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xffffffff ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack('>I', bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except socket.error:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count('/') == 1:\n        try:\n            mask = int(string_network.split('/')[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split('/')[0])\n        except socket.error:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy('no_proxy')\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (\n            host for host in no_proxy.replace(' ', '').split(',') if host\n        )\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += ':{}'.format(parsed.port)\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ('no_proxy', no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get('all'))\n\n    proxy_keys = [\n        urlparts.scheme + '://' + urlparts.hostname,\n        urlparts.scheme,\n        'all://' + urlparts.hostname,\n        'all',\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return '%s/%s' % (name, __version__)\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict({\n        'User-Agent': default_user_agent(),\n        'Accept-Encoding': DEFAULT_ACCEPT_ENCODING,\n        'Accept': '*/*',\n        'Connection': 'keep-alive',\n    })\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = ' \\'\"'\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(', *<', value):\n        try:\n            url, params = val.split(';', 1)\n        except ValueError:\n            url, params = val, ''\n\n        link = {'url': url.strip('<> \\'\"')}\n\n        for param in params.split(';'):\n            try:\n                key, value = param.split('=')\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = '\\x00'.encode('ascii')  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return 'utf-32'     # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return 'utf-8-sig'  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return 'utf-16'     # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return 'utf-8'\n    if nullcount == 2:\n        if sample[::2] == _null2:   # 1st and 3rd are null\n            return 'utf-16-be'\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return 'utf-16-le'\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return 'utf-32-be'\n        if sample[1:] == _null3:\n            return 'utf-32-le'\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n\n    # urlparse is a finicky beast, and sometimes decides that there isn't a\n    # netloc present. Assume that it's being over-cautious, and switch netloc\n    # and path if urlparse decided there was no netloc.\n    if not netloc:\n        netloc, path = path, netloc\n\n    return urlunparse((scheme, netloc, path, params, query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = ('', '')\n\n    return auth\n\n\n# Moved outside of function to avoid recompile every call\n_CLEAN_HEADER_REGEX_BYTE = re.compile(b'^\\\\S[^\\\\r\\\\n]*$|^$')\n_CLEAN_HEADER_REGEX_STR = re.compile(r'^\\S[^\\r\\n]*$|^$')\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header value is a string which doesn't contain\n    leading whitespace or return characters. This prevents unintended\n    header injection.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n\n    if isinstance(value, bytes):\n        pat = _CLEAN_HEADER_REGEX_BYTE\n    else:\n        pat = _CLEAN_HEADER_REGEX_STR\n    try:\n        if not pat.match(value):\n            raise InvalidHeader(\"Invalid return character or leading space in header: %s\" % name)\n    except TypeError:\n        raise InvalidHeader(\"Value for header {%s: %s} must be of type str or \"\n                            \"bytes, not %s\" % (name, value, type(value)))\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit('@', 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, ''))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, 'seek', None)\n    if body_seek is not None and isinstance(prepared_request._body_position, integer_types):\n        try:\n            body_seek(prepared_request._body_position)\n        except (IOError, OSError):\n            raise UnrewindableBodyError(\"An error occurred when rewinding request \"\n                                        \"body for redirect.\")\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "e6eca492f0c1",
      "repo": "requests",
      "commit_hash": "5855dd7",
      "commit_message": "updated `get_encoding_from_headers` to return utf-8 if the content type is set to application/json, following RFC 4627.",
      "file_path": "requests/utils.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom .__version__ import __version__\nfrom . import certs\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import to_native_string\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    quote, urlparse, bytes, str, unquote, getproxies,\n    proxy_bypass, urlunparse, basestring, integer_types, is_py3,\n    proxy_bypass_environment, getproxies_environment, Mapping)\nfrom .cookies import cookiejar_from_dict\nfrom .structures import CaseInsensitiveDict\nfrom .exceptions import (\n    InvalidURL, InvalidHeader, FileModeWarning, UnrewindableBodyError)\n\nNETRC_FILES = ('.netrc', '_netrc')\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {'http': 80, 'https': 443}\n\n\nif sys.platform == 'win32':\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            if is_py3:\n                import winreg\n            else:\n                import _winreg as winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings,\n                                              'ProxyEnable')[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings,\n                                                'ProxyOverride')[0]\n        except OSError:\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(';')\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == '<local>':\n                if '.' not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")     # mask dots\n            test = test.replace(\"*\", r\".*\")     # change glob sequence\n            test = test.replace(\"?\", r\".\")      # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, 'items'):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, '__len__'):\n        total_length = len(o)\n\n    elif hasattr(o, 'len'):\n        total_length = o.len\n\n    elif hasattr(o, 'fileno'):\n        try:\n            fileno = o.fileno()\n        except io.UnsupportedOperation:\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if 'b' not in o.mode:\n                warnings.warn((\n                    \"Requests has determined the content-length for this \"\n                    \"request using the binary size of the file: however, the \"\n                    \"file has been opened in text mode (i.e. without the 'b' \"\n                    \"flag in the mode). This may lead to an incorrect \"\n                    \"content-length. In Requests 3.0, support will be removed \"\n                    \"for files in text mode.\"),\n                    FileModeWarning\n                )\n\n    if hasattr(o, 'tell'):\n        try:\n            current_position = o.tell()\n        except (OSError, IOError):\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, 'seek') and total_length is None:\n                # StringIO and BytesIO have seek but no useable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except (OSError, IOError):\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get('NETRC')\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = ('~/{}'.format(f) for f in NETRC_FILES)\n\n    try:\n        from netrc import netrc, NetrcParseError\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b':'\n        if isinstance(url, str):\n            splitstr = splitstr.decode('ascii')\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = (0 if _netrc[0] else 1)\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, IOError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, 'name', None)\n    if (name and isinstance(name, basestring) and name[0] != '<' and\n            name[-1] != '>'):\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        member = '/'.join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, *member.split('/'))\n    if not os.path.exists(extracted_path):\n        extracted_path = zip_file.extract(member, path=tmp)\n\n    return extracted_path\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if '=' not in item:\n            result[item] = None\n            continue\n        name, value = item.split('=', 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != '\\\\\\\\':\n            return value.replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {}\n\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_encodings_from_content will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (charset_re.findall(content) +\n            pragma_re.findall(content) +\n            xml_re.findall(content))\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(';')\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1:].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get('content-type')\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if 'charset' in params:\n        return params['charset'].strip(\"'\\\"\")\n\n    if 'text' in content_type:\n        return 'ISO-8859-1'\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes a iterator.\"\"\"\n\n    if r.encoding is None:\n        for item in iterator:\n            yield item\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b'', final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos:pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_unicode_from_response will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors='replace')\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\")\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split('%')\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(\"Invalid percent-escape sequence: '%s'\" % h)\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = '%' + parts[i]\n        else:\n            parts[i] = '%' + parts[i]\n    return ''.join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack('=L', socket.inet_aton(ip))[0]\n    netaddr, bits = net.split('/')\n    netmask = struct.unpack('=L', socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack('=L', socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xffffffff ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack('>I', bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except socket.error:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count('/') == 1:\n        try:\n            mask = int(string_network.split('/')[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split('/')[0])\n        except socket.error:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy('no_proxy')\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (\n            host for host in no_proxy.replace(' ', '').split(',') if host\n        )\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += ':{}'.format(parsed.port)\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ('no_proxy', no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get('all'))\n\n    proxy_keys = [\n        urlparts.scheme + '://' + urlparts.hostname,\n        urlparts.scheme,\n        'all://' + urlparts.hostname,\n        'all',\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return '%s/%s' % (name, __version__)\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict({\n        'User-Agent': default_user_agent(),\n        'Accept-Encoding': ', '.join(('gzip', 'deflate')),\n        'Accept': '*/*',\n        'Connection': 'keep-alive',\n    })\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = ' \\'\"'\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(', *<', value):\n        try:\n            url, params = val.split(';', 1)\n        except ValueError:\n            url, params = val, ''\n\n        link = {'url': url.strip('<> \\'\"')}\n\n        for param in params.split(';'):\n            try:\n                key, value = param.split('=')\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = '\\x00'.encode('ascii')  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return 'utf-32'     # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return 'utf-8-sig'  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return 'utf-16'     # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return 'utf-8'\n    if nullcount == 2:\n        if sample[::2] == _null2:   # 1st and 3rd are null\n            return 'utf-16-be'\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return 'utf-16-le'\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return 'utf-32-be'\n        if sample[1:] == _null3:\n            return 'utf-32-le'\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n\n    # urlparse is a finicky beast, and sometimes decides that there isn't a\n    # netloc present. Assume that it's being over-cautious, and switch netloc\n    # and path if urlparse decided there was no netloc.\n    if not netloc:\n        netloc, path = path, netloc\n\n    return urlunparse((scheme, netloc, path, params, query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = ('', '')\n\n    return auth\n\n\n# Moved outside of function to avoid recompile every call\n_CLEAN_HEADER_REGEX_BYTE = re.compile(b'^\\\\S[^\\\\r\\\\n]*$|^$')\n_CLEAN_HEADER_REGEX_STR = re.compile(r'^\\S[^\\r\\n]*$|^$')\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header value is a string which doesn't contain\n    leading whitespace or return characters. This prevents unintended\n    header injection.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n\n    if isinstance(value, bytes):\n        pat = _CLEAN_HEADER_REGEX_BYTE\n    else:\n        pat = _CLEAN_HEADER_REGEX_STR\n    try:\n        if not pat.match(value):\n            raise InvalidHeader(\"Invalid return character or leading space in header: %s\" % name)\n    except TypeError:\n        raise InvalidHeader(\"Value for header {%s: %s} must be of type str or \"\n                            \"bytes, not %s\" % (name, value, type(value)))\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit('@', 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, ''))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, 'seek', None)\n    if body_seek is not None and isinstance(prepared_request._body_position, integer_types):\n        try:\n            body_seek(prepared_request._body_position)\n        except (IOError, OSError):\n            raise UnrewindableBodyError(\"An error occurred when rewinding request \"\n                                        \"body for redirect.\")\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "code_after": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.utils\n~~~~~~~~~~~~~~\n\nThis module provides utility functions that are used within Requests\nthat are also useful for external consumption.\n\"\"\"\n\nimport codecs\nimport contextlib\nimport io\nimport os\nimport re\nimport socket\nimport struct\nimport sys\nimport tempfile\nimport warnings\nimport zipfile\nfrom collections import OrderedDict\n\nfrom .__version__ import __version__\nfrom . import certs\n# to_native_string is unused here, but imported here for backwards compatibility\nfrom ._internal_utils import to_native_string\nfrom .compat import parse_http_list as _parse_list_header\nfrom .compat import (\n    quote, urlparse, bytes, str, unquote, getproxies,\n    proxy_bypass, urlunparse, basestring, integer_types, is_py3,\n    proxy_bypass_environment, getproxies_environment, Mapping)\nfrom .cookies import cookiejar_from_dict\nfrom .structures import CaseInsensitiveDict\nfrom .exceptions import (\n    InvalidURL, InvalidHeader, FileModeWarning, UnrewindableBodyError)\n\nNETRC_FILES = ('.netrc', '_netrc')\n\nDEFAULT_CA_BUNDLE_PATH = certs.where()\n\nDEFAULT_PORTS = {'http': 80, 'https': 443}\n\n\nif sys.platform == 'win32':\n    # provide a proxy_bypass version on Windows without DNS lookups\n\n    def proxy_bypass_registry(host):\n        try:\n            if is_py3:\n                import winreg\n            else:\n                import _winreg as winreg\n        except ImportError:\n            return False\n\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\n            proxyEnable = int(winreg.QueryValueEx(internetSettings,\n                                              'ProxyEnable')[0])\n            # ProxyOverride is almost always a string\n            proxyOverride = winreg.QueryValueEx(internetSettings,\n                                                'ProxyOverride')[0]\n        except OSError:\n            return False\n        if not proxyEnable or not proxyOverride:\n            return False\n\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(';')\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == '<local>':\n                if '.' not in host:\n                    return True\n            test = test.replace(\".\", r\"\\.\")     # mask dots\n            test = test.replace(\"*\", r\".*\")     # change glob sequence\n            test = test.replace(\"?\", r\".\")      # change glob char\n            if re.match(test, host, re.I):\n                return True\n        return False\n\n    def proxy_bypass(host):  # noqa\n        \"\"\"Return True, if the host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n        \"\"\"\n        if getproxies_environment():\n            return proxy_bypass_environment(host)\n        else:\n            return proxy_bypass_registry(host)\n\n\ndef dict_to_sequence(d):\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\n\n    if hasattr(d, 'items'):\n        d = d.items()\n\n    return d\n\n\ndef super_len(o):\n    total_length = None\n    current_position = 0\n\n    if hasattr(o, '__len__'):\n        total_length = len(o)\n\n    elif hasattr(o, 'len'):\n        total_length = o.len\n\n    elif hasattr(o, 'fileno'):\n        try:\n            fileno = o.fileno()\n        except io.UnsupportedOperation:\n            pass\n        else:\n            total_length = os.fstat(fileno).st_size\n\n            # Having used fstat to determine the file length, we need to\n            # confirm that this file was opened up in binary mode.\n            if 'b' not in o.mode:\n                warnings.warn((\n                    \"Requests has determined the content-length for this \"\n                    \"request using the binary size of the file: however, the \"\n                    \"file has been opened in text mode (i.e. without the 'b' \"\n                    \"flag in the mode). This may lead to an incorrect \"\n                    \"content-length. In Requests 3.0, support will be removed \"\n                    \"for files in text mode.\"),\n                    FileModeWarning\n                )\n\n    if hasattr(o, 'tell'):\n        try:\n            current_position = o.tell()\n        except (OSError, IOError):\n            # This can happen in some weird situations, such as when the file\n            # is actually a special file descriptor like stdin. In this\n            # instance, we don't know what the length is, so set it to zero and\n            # let requests chunk it instead.\n            if total_length is not None:\n                current_position = total_length\n        else:\n            if hasattr(o, 'seek') and total_length is None:\n                # StringIO and BytesIO have seek but no useable fileno\n                try:\n                    # seek to end of file\n                    o.seek(0, 2)\n                    total_length = o.tell()\n\n                    # seek back to current position to support\n                    # partially read file-like objects\n                    o.seek(current_position or 0)\n                except (OSError, IOError):\n                    total_length = 0\n\n    if total_length is None:\n        total_length = 0\n\n    return max(0, total_length - current_position)\n\n\ndef get_netrc_auth(url, raise_errors=False):\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\n\n    netrc_file = os.environ.get('NETRC')\n    if netrc_file is not None:\n        netrc_locations = (netrc_file,)\n    else:\n        netrc_locations = ('~/{}'.format(f) for f in NETRC_FILES)\n\n    try:\n        from netrc import netrc, NetrcParseError\n\n        netrc_path = None\n\n        for f in netrc_locations:\n            try:\n                loc = os.path.expanduser(f)\n            except KeyError:\n                # os.path.expanduser can fail when $HOME is undefined and\n                # getpwuid fails. See https://bugs.python.org/issue20164 &\n                # https://github.com/psf/requests/issues/1846\n                return\n\n            if os.path.exists(loc):\n                netrc_path = loc\n                break\n\n        # Abort early if there isn't one.\n        if netrc_path is None:\n            return\n\n        ri = urlparse(url)\n\n        # Strip port numbers from netloc. This weird `if...encode`` dance is\n        # used for Python 3.2, which doesn't support unicode literals.\n        splitstr = b':'\n        if isinstance(url, str):\n            splitstr = splitstr.decode('ascii')\n        host = ri.netloc.split(splitstr)[0]\n\n        try:\n            _netrc = netrc(netrc_path).authenticators(host)\n            if _netrc:\n                # Return with login / password\n                login_i = (0 if _netrc[0] else 1)\n                return (_netrc[login_i], _netrc[2])\n        except (NetrcParseError, IOError):\n            # If there was a parsing error or a permissions issue reading the file,\n            # we'll just skip netrc auth unless explicitly asked to raise errors.\n            if raise_errors:\n                raise\n\n    # App Engine hackiness.\n    except (ImportError, AttributeError):\n        pass\n\n\ndef guess_filename(obj):\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\n    name = getattr(obj, 'name', None)\n    if (name and isinstance(name, basestring) and name[0] != '<' and\n            name[-1] != '>'):\n        return os.path.basename(name)\n\n\ndef extract_zipped_paths(path):\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\n    archive with the location of an extracted copy of the target, or else\n    just return the provided path unchanged.\n    \"\"\"\n    if os.path.exists(path):\n        # this is already a valid path, no need to do anything further\n        return path\n\n    # find the first valid part of the provided path and treat that as a zip archive\n    # assume the rest of the path is the name of a member in the archive\n    archive, member = os.path.split(path)\n    while archive and not os.path.exists(archive):\n        archive, prefix = os.path.split(archive)\n        member = '/'.join([prefix, member])\n\n    if not zipfile.is_zipfile(archive):\n        return path\n\n    zip_file = zipfile.ZipFile(archive)\n    if member not in zip_file.namelist():\n        return path\n\n    # we have a valid zip archive and a valid member of that archive\n    tmp = tempfile.gettempdir()\n    extracted_path = os.path.join(tmp, *member.split('/'))\n    if not os.path.exists(extracted_path):\n        extracted_path = zip_file.extract(member, path=tmp)\n\n    return extracted_path\n\n\ndef from_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. Unless it can not be represented as such, return an\n    OrderedDict, e.g.,\n\n    ::\n\n        >>> from_key_val_list([('key', 'val')])\n        OrderedDict([('key', 'val')])\n        >>> from_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n        >>> from_key_val_list({'key': 'val'})\n        OrderedDict([('key', 'val')])\n\n    :rtype: OrderedDict\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    return OrderedDict(value)\n\n\ndef to_key_val_list(value):\n    \"\"\"Take an object and test to see if it can be represented as a\n    dictionary. If it can be, return a list of tuples, e.g.,\n\n    ::\n\n        >>> to_key_val_list([('key', 'val')])\n        [('key', 'val')]\n        >>> to_key_val_list({'key': 'val'})\n        [('key', 'val')]\n        >>> to_key_val_list('string')\n        Traceback (most recent call last):\n        ...\n        ValueError: cannot encode objects that are not 2-tuples\n\n    :rtype: list\n    \"\"\"\n    if value is None:\n        return None\n\n    if isinstance(value, (str, bytes, bool, int)):\n        raise ValueError('cannot encode objects that are not 2-tuples')\n\n    if isinstance(value, Mapping):\n        value = value.items()\n\n    return list(value)\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_list_header(value):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Quotes are removed automatically after parsing.\n\n    It basically works like :func:`parse_set_header` just that items\n    may appear multiple times and case sensitivity is preserved.\n\n    The return value is a standard :class:`list`:\n\n    >>> parse_list_header('token, \"quoted value\"')\n    ['token', 'quoted value']\n\n    To create a header from the :class:`list` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a list header.\n    :return: :class:`list`\n    :rtype: list\n    \"\"\"\n    result = []\n    for item in _parse_list_header(value):\n        if item[:1] == item[-1:] == '\"':\n            item = unquote_header_value(item[1:-1])\n        result.append(item)\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef parse_dict_header(value):\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\n    convert them into a python dict:\n\n    >>> d = parse_dict_header('foo=\"is a fish\", bar=\"as well\"')\n    >>> type(d) is dict\n    True\n    >>> sorted(d.items())\n    [('bar', 'as well'), ('foo', 'is a fish')]\n\n    If there is no value for a key it will be `None`:\n\n    >>> parse_dict_header('key_without_value')\n    {'key_without_value': None}\n\n    To create a header from the :class:`dict` again, use the\n    :func:`dump_header` function.\n\n    :param value: a string with a dict header.\n    :return: :class:`dict`\n    :rtype: dict\n    \"\"\"\n    result = {}\n    for item in _parse_list_header(value):\n        if '=' not in item:\n            result[item] = None\n            continue\n        name, value = item.split('=', 1)\n        if value[:1] == value[-1:] == '\"':\n            value = unquote_header_value(value[1:-1])\n        result[name] = value\n    return result\n\n\n# From mitsuhiko/werkzeug (used with permission).\ndef unquote_header_value(value, is_filename=False):\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\n    This does not use the real unquoting but what browsers are actually\n    using for quoting.\n\n    :param value: the header value to unquote.\n    :rtype: str\n    \"\"\"\n    if value and value[0] == value[-1] == '\"':\n        # this is not the real unquoting, but fixing this so that the\n        # RFC is met will result in bugs with internet explorer and\n        # probably some other browsers as well.  IE for example is\n        # uploading files with \"C:\\foo\\bar.txt\" as filename\n        value = value[1:-1]\n\n        # if this is a filename and the starting characters look like\n        # a UNC path, then just return the value without quotes.  Using the\n        # replace sequence below on a UNC path has the effect of turning\n        # the leading double slash into a single slash and then\n        # _fix_ie_filename() doesn't work correctly.  See #458.\n        if not is_filename or value[:2] != '\\\\\\\\':\n            return value.replace('\\\\\\\\', '\\\\').replace('\\\\\"', '\"')\n    return value\n\n\ndef dict_from_cookiejar(cj):\n    \"\"\"Returns a key/value dictionary from a CookieJar.\n\n    :param cj: CookieJar object to extract cookies from.\n    :rtype: dict\n    \"\"\"\n\n    cookie_dict = {}\n\n    for cookie in cj:\n        cookie_dict[cookie.name] = cookie.value\n\n    return cookie_dict\n\n\ndef add_dict_to_cookiejar(cj, cookie_dict):\n    \"\"\"Returns a CookieJar from a key/value dictionary.\n\n    :param cj: CookieJar to insert cookies into.\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\n    :rtype: CookieJar\n    \"\"\"\n\n    return cookiejar_from_dict(cookie_dict, cj)\n\n\ndef get_encodings_from_content(content):\n    \"\"\"Returns encodings from given content string.\n\n    :param content: bytestring to extract encodings from.\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_encodings_from_content will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (charset_re.findall(content) +\n            pragma_re.findall(content) +\n            xml_re.findall(content))\n\n\ndef _parse_content_type_header(header):\n    \"\"\"Returns content type and parameters from given header\n\n    :param header: string\n    :return: tuple containing content type and dictionary of\n         parameters\n    \"\"\"\n\n    tokens = header.split(';')\n    content_type, params = tokens[0].strip(), tokens[1:]\n    params_dict = {}\n    items_to_strip = \"\\\"' \"\n\n    for param in params:\n        param = param.strip()\n        if param:\n            key, value = param, True\n            index_of_equals = param.find(\"=\")\n            if index_of_equals != -1:\n                key = param[:index_of_equals].strip(items_to_strip)\n                value = param[index_of_equals + 1:].strip(items_to_strip)\n            params_dict[key.lower()] = value\n    return content_type, params_dict\n\n\ndef get_encoding_from_headers(headers):\n    \"\"\"Returns encodings from given HTTP Header Dict.\n\n    :param headers: dictionary to extract encoding from.\n    :rtype: str\n    \"\"\"\n\n    content_type = headers.get('content-type')\n\n    if not content_type:\n        return None\n\n    content_type, params = _parse_content_type_header(content_type)\n\n    if 'charset' in params:\n        return params['charset'].strip(\"'\\\"\")\n\n    if 'text' in content_type:\n        return 'ISO-8859-1'\n\n    if 'application/json' in content_type:\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\n        return 'utf-8'\n\n\ndef stream_decode_response_unicode(iterator, r):\n    \"\"\"Stream decodes a iterator.\"\"\"\n\n    if r.encoding is None:\n        for item in iterator:\n            yield item\n        return\n\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')\n    for chunk in iterator:\n        rv = decoder.decode(chunk)\n        if rv:\n            yield rv\n    rv = decoder.decode(b'', final=True)\n    if rv:\n        yield rv\n\n\ndef iter_slices(string, slice_length):\n    \"\"\"Iterate over slices of a string.\"\"\"\n    pos = 0\n    if slice_length is None or slice_length <= 0:\n        slice_length = len(string)\n    while pos < len(string):\n        yield string[pos:pos + slice_length]\n        pos += slice_length\n\n\ndef get_unicode_from_response(r):\n    \"\"\"Returns the requested content back in unicode.\n\n    :param r: Response object to get unicode content from.\n\n    Tried:\n\n    1. charset from content-type\n    2. fall back and replace all unicode characters\n\n    :rtype: str\n    \"\"\"\n    warnings.warn((\n        'In requests 3.0, get_unicode_from_response will be removed. For '\n        'more information, please see the discussion on issue #2266. (This'\n        ' warning should only appear once.)'),\n        DeprecationWarning)\n\n    tried_encodings = []\n\n    # Try charset from content-type\n    encoding = get_encoding_from_headers(r.headers)\n\n    if encoding:\n        try:\n            return str(r.content, encoding)\n        except UnicodeError:\n            tried_encodings.append(encoding)\n\n    # Fall back:\n    try:\n        return str(r.content, encoding, errors='replace')\n    except TypeError:\n        return r.content\n\n\n# The unreserved URI characters (RFC 3986)\nUNRESERVED_SET = frozenset(\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\")\n\n\ndef unquote_unreserved(uri):\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\n\n    :rtype: str\n    \"\"\"\n    parts = uri.split('%')\n    for i in range(1, len(parts)):\n        h = parts[i][0:2]\n        if len(h) == 2 and h.isalnum():\n            try:\n                c = chr(int(h, 16))\n            except ValueError:\n                raise InvalidURL(\"Invalid percent-escape sequence: '%s'\" % h)\n\n            if c in UNRESERVED_SET:\n                parts[i] = c + parts[i][2:]\n            else:\n                parts[i] = '%' + parts[i]\n        else:\n            parts[i] = '%' + parts[i]\n    return ''.join(parts)\n\n\ndef requote_uri(uri):\n    \"\"\"Re-quote the given URI.\n\n    This function passes the given URI through an unquote/quote cycle to\n    ensure that it is fully and consistently quoted.\n\n    :rtype: str\n    \"\"\"\n    safe_with_percent = \"!#$%&'()*+,/:;=?@[]~\"\n    safe_without_percent = \"!#$&'()*+,/:;=?@[]~\"\n    try:\n        # Unquote only the unreserved characters\n        # Then quote only illegal characters (do not quote reserved,\n        # unreserved, or '%')\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\n    except InvalidURL:\n        # We couldn't unquote the given URI, so let's try quoting it, but\n        # there may be unquoted '%'s in the URI. We need to make sure they're\n        # properly quoted so they do not cause issues elsewhere.\n        return quote(uri, safe=safe_without_percent)\n\n\ndef address_in_network(ip, net):\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\n\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\n\n    :rtype: bool\n    \"\"\"\n    ipaddr = struct.unpack('=L', socket.inet_aton(ip))[0]\n    netaddr, bits = net.split('/')\n    netmask = struct.unpack('=L', socket.inet_aton(dotted_netmask(int(bits))))[0]\n    network = struct.unpack('=L', socket.inet_aton(netaddr))[0] & netmask\n    return (ipaddr & netmask) == (network & netmask)\n\n\ndef dotted_netmask(mask):\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\n\n    Example: if mask is 24 function returns 255.255.255.0\n\n    :rtype: str\n    \"\"\"\n    bits = 0xffffffff ^ (1 << 32 - mask) - 1\n    return socket.inet_ntoa(struct.pack('>I', bits))\n\n\ndef is_ipv4_address(string_ip):\n    \"\"\"\n    :rtype: bool\n    \"\"\"\n    try:\n        socket.inet_aton(string_ip)\n    except socket.error:\n        return False\n    return True\n\n\ndef is_valid_cidr(string_network):\n    \"\"\"\n    Very simple check of the cidr format in no_proxy variable.\n\n    :rtype: bool\n    \"\"\"\n    if string_network.count('/') == 1:\n        try:\n            mask = int(string_network.split('/')[1])\n        except ValueError:\n            return False\n\n        if mask < 1 or mask > 32:\n            return False\n\n        try:\n            socket.inet_aton(string_network.split('/')[0])\n        except socket.error:\n            return False\n    else:\n        return False\n    return True\n\n\n@contextlib.contextmanager\ndef set_environ(env_name, value):\n    \"\"\"Set the environment variable 'env_name' to 'value'\n\n    Save previous value, yield, and then restore the previous value stored in\n    the environment variable 'env_name'.\n\n    If 'value' is None, do nothing\"\"\"\n    value_changed = value is not None\n    if value_changed:\n        old_value = os.environ.get(env_name)\n        os.environ[env_name] = value\n    try:\n        yield\n    finally:\n        if value_changed:\n            if old_value is None:\n                del os.environ[env_name]\n            else:\n                os.environ[env_name] = old_value\n\n\ndef should_bypass_proxies(url, no_proxy):\n    \"\"\"\n    Returns whether we should bypass proxies or not.\n\n    :rtype: bool\n    \"\"\"\n    # Prioritize lowercase environment variables over uppercase\n    # to keep a consistent behaviour with other http projects (curl, wget).\n    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())\n\n    # First check whether no_proxy is defined. If it is, check that the URL\n    # we're getting isn't in the no_proxy list.\n    no_proxy_arg = no_proxy\n    if no_proxy is None:\n        no_proxy = get_proxy('no_proxy')\n    parsed = urlparse(url)\n\n    if parsed.hostname is None:\n        # URLs don't always have hostnames, e.g. file:/// urls.\n        return True\n\n    if no_proxy:\n        # We need to check whether we match here. We need to see if we match\n        # the end of the hostname, both with and without the port.\n        no_proxy = (\n            host for host in no_proxy.replace(' ', '').split(',') if host\n        )\n\n        if is_ipv4_address(parsed.hostname):\n            for proxy_ip in no_proxy:\n                if is_valid_cidr(proxy_ip):\n                    if address_in_network(parsed.hostname, proxy_ip):\n                        return True\n                elif parsed.hostname == proxy_ip:\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\n                    # matches the IP of the index\n                    return True\n        else:\n            host_with_port = parsed.hostname\n            if parsed.port:\n                host_with_port += ':{}'.format(parsed.port)\n\n            for host in no_proxy:\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\n                    # The URL does match something in no_proxy, so we don't want\n                    # to apply the proxies on this URL.\n                    return True\n\n    with set_environ('no_proxy', no_proxy_arg):\n        # parsed.hostname can be `None` in cases such as a file URI.\n        try:\n            bypass = proxy_bypass(parsed.hostname)\n        except (TypeError, socket.gaierror):\n            bypass = False\n\n    if bypass:\n        return True\n\n    return False\n\n\ndef get_environ_proxies(url, no_proxy=None):\n    \"\"\"\n    Return a dict of environment proxies.\n\n    :rtype: dict\n    \"\"\"\n    if should_bypass_proxies(url, no_proxy=no_proxy):\n        return {}\n    else:\n        return getproxies()\n\n\ndef select_proxy(url, proxies):\n    \"\"\"Select a proxy for the url, if applicable.\n\n    :param url: The url being for the request\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n    \"\"\"\n    proxies = proxies or {}\n    urlparts = urlparse(url)\n    if urlparts.hostname is None:\n        return proxies.get(urlparts.scheme, proxies.get('all'))\n\n    proxy_keys = [\n        urlparts.scheme + '://' + urlparts.hostname,\n        urlparts.scheme,\n        'all://' + urlparts.hostname,\n        'all',\n    ]\n    proxy = None\n    for proxy_key in proxy_keys:\n        if proxy_key in proxies:\n            proxy = proxies[proxy_key]\n            break\n\n    return proxy\n\n\ndef default_user_agent(name=\"python-requests\"):\n    \"\"\"\n    Return a string representing the default user agent.\n\n    :rtype: str\n    \"\"\"\n    return '%s/%s' % (name, __version__)\n\n\ndef default_headers():\n    \"\"\"\n    :rtype: requests.structures.CaseInsensitiveDict\n    \"\"\"\n    return CaseInsensitiveDict({\n        'User-Agent': default_user_agent(),\n        'Accept-Encoding': ', '.join(('gzip', 'deflate')),\n        'Accept': '*/*',\n        'Connection': 'keep-alive',\n    })\n\n\ndef parse_header_links(value):\n    \"\"\"Return a list of parsed link headers proxies.\n\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\n\n    :rtype: list\n    \"\"\"\n\n    links = []\n\n    replace_chars = ' \\'\"'\n\n    value = value.strip(replace_chars)\n    if not value:\n        return links\n\n    for val in re.split(', *<', value):\n        try:\n            url, params = val.split(';', 1)\n        except ValueError:\n            url, params = val, ''\n\n        link = {'url': url.strip('<> \\'\"')}\n\n        for param in params.split(';'):\n            try:\n                key, value = param.split('=')\n            except ValueError:\n                break\n\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\n\n        links.append(link)\n\n    return links\n\n\n# Null bytes; no need to recreate these on each call to guess_json_utf\n_null = '\\x00'.encode('ascii')  # encoding to ASCII for Python 3\n_null2 = _null * 2\n_null3 = _null * 3\n\n\ndef guess_json_utf(data):\n    \"\"\"\n    :rtype: str\n    \"\"\"\n    # JSON always starts with two ASCII characters, so detection is as\n    # easy as counting the nulls and from their location and count\n    # determine the encoding. Also detect a BOM, if present.\n    sample = data[:4]\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\n        return 'utf-32'     # BOM included\n    if sample[:3] == codecs.BOM_UTF8:\n        return 'utf-8-sig'  # BOM included, MS style (discouraged)\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\n        return 'utf-16'     # BOM included\n    nullcount = sample.count(_null)\n    if nullcount == 0:\n        return 'utf-8'\n    if nullcount == 2:\n        if sample[::2] == _null2:   # 1st and 3rd are null\n            return 'utf-16-be'\n        if sample[1::2] == _null2:  # 2nd and 4th are null\n            return 'utf-16-le'\n        # Did not detect 2 valid UTF-16 ascii-range characters\n    if nullcount == 3:\n        if sample[:3] == _null3:\n            return 'utf-32-be'\n        if sample[1:] == _null3:\n            return 'utf-32-le'\n        # Did not detect a valid UTF-32 ascii-range character\n    return None\n\n\ndef prepend_scheme_if_needed(url, new_scheme):\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\n    Does not replace a present scheme with the one provided as an argument.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n\n    # urlparse is a finicky beast, and sometimes decides that there isn't a\n    # netloc present. Assume that it's being over-cautious, and switch netloc\n    # and path if urlparse decided there was no netloc.\n    if not netloc:\n        netloc, path = path, netloc\n\n    return urlunparse((scheme, netloc, path, params, query, fragment))\n\n\ndef get_auth_from_url(url):\n    \"\"\"Given a url with authentication components, extract them into a tuple of\n    username,password.\n\n    :rtype: (str,str)\n    \"\"\"\n    parsed = urlparse(url)\n\n    try:\n        auth = (unquote(parsed.username), unquote(parsed.password))\n    except (AttributeError, TypeError):\n        auth = ('', '')\n\n    return auth\n\n\n# Moved outside of function to avoid recompile every call\n_CLEAN_HEADER_REGEX_BYTE = re.compile(b'^\\\\S[^\\\\r\\\\n]*$|^$')\n_CLEAN_HEADER_REGEX_STR = re.compile(r'^\\S[^\\r\\n]*$|^$')\n\n\ndef check_header_validity(header):\n    \"\"\"Verifies that header value is a string which doesn't contain\n    leading whitespace or return characters. This prevents unintended\n    header injection.\n\n    :param header: tuple, in the format (name, value).\n    \"\"\"\n    name, value = header\n\n    if isinstance(value, bytes):\n        pat = _CLEAN_HEADER_REGEX_BYTE\n    else:\n        pat = _CLEAN_HEADER_REGEX_STR\n    try:\n        if not pat.match(value):\n            raise InvalidHeader(\"Invalid return character or leading space in header: %s\" % name)\n    except TypeError:\n        raise InvalidHeader(\"Value for header {%s: %s} must be of type str or \"\n                            \"bytes, not %s\" % (name, value, type(value)))\n\n\ndef urldefragauth(url):\n    \"\"\"\n    Given a url remove the fragment and the authentication part.\n\n    :rtype: str\n    \"\"\"\n    scheme, netloc, path, params, query, fragment = urlparse(url)\n\n    # see func:`prepend_scheme_if_needed`\n    if not netloc:\n        netloc, path = path, netloc\n\n    netloc = netloc.rsplit('@', 1)[-1]\n\n    return urlunparse((scheme, netloc, path, params, query, ''))\n\n\ndef rewind_body(prepared_request):\n    \"\"\"Move file pointer back to its recorded starting position\n    so it can be read again on redirect.\n    \"\"\"\n    body_seek = getattr(prepared_request.body, 'seek', None)\n    if body_seek is not None and isinstance(prepared_request._body_position, integer_types):\n        try:\n            body_seek(prepared_request._body_position)\n        except (IOError, OSError):\n            raise UnrewindableBodyError(\"An error occurred when rewinding request \"\n                                        \"body for redirect.\")\n    else:\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "eac7e3853e9f",
      "repo": "requests",
      "commit_hash": "9ed5db8",
      "commit_message": "fix raise_for_status docstring (#5293)",
      "file_path": "requests/models.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\nimport sys\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna\n\nfrom urllib3.fields import RequestField\nfrom urllib3.filepost import encode_multipart_formdata\nfrom urllib3.util import parse_url\nfrom urllib3.exceptions import (\n    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n\nfrom io import UnsupportedOperation\nfrom .hooks import default_hooks\nfrom .structures import CaseInsensitiveDict\n\nfrom .auth import HTTPBasicAuth\nfrom .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\nfrom .exceptions import (\n    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n    ContentDecodingError, ConnectionError, StreamConsumedError)\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .utils import (\n    guess_filename, get_auth_from_url, requote_uri,\n    stream_decode_response_unicode, to_key_val_list, parse_header_links,\n    iter_slices, guess_json_utf, super_len, check_header_validity)\nfrom .compat import (\n    Callable, Mapping,\n    cookielib, urlunparse, urlsplit, urlencode, str, bytes,\n    is_py2, chardet, builtin_str, basestring)\nfrom .compat import json as complexjson\nfrom .status_codes import codes\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,               # 301\n    codes.found,               # 302\n    codes.other,               # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin(object):\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = '/'\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append('?')\n            url.append(query)\n\n        return ''.join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, 'read'):\n            return data\n        elif hasattr(data, '__iter__'):\n            result = []\n            for k, vs in to_key_val_list(data):\n                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n                    vs = [vs]\n                for v in vs:\n                    if v is not None:\n                        result.append(\n                            (k.encode('utf-8') if isinstance(k, str) else k,\n                             v.encode('utf-8') if isinstance(v, str) else v))\n            return urlencode(result, doseq=True)\n        else:\n            return data\n\n    @staticmethod\n    def _encode_files(files, data):\n        \"\"\"Build the body for a multipart/form-data request.\n\n        Will successfully encode files when passed as a dict or a list of\n        tuples. Order is retained if data is a list of tuples but arbitrary\n        if parameters are supplied as a dict.\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\n        \"\"\"\n        if (not files):\n            raise ValueError(\"Files must be provided.\")\n        elif isinstance(data, basestring):\n            raise ValueError(\"Data must not be a string.\")\n\n        new_fields = []\n        fields = to_key_val_list(data or {})\n        files = to_key_val_list(files or {})\n\n        for field, val in fields:\n            if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n                val = [val]\n            for v in val:\n                if v is not None:\n                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n                    if not isinstance(v, bytes):\n                        v = str(v)\n\n                    new_fields.append(\n                        (field.decode('utf-8') if isinstance(field, bytes) else field,\n                         v.encode('utf-8') if isinstance(v, str) else v))\n\n        for (k, v) in files:\n            # support for explicit filename\n            ft = None\n            fh = None\n            if isinstance(v, (tuple, list)):\n                if len(v) == 2:\n                    fn, fp = v\n                elif len(v) == 3:\n                    fn, fp, ft = v\n                else:\n                    fn, fp, ft, fh = v\n            else:\n                fn = guess_filename(v) or k\n                fp = v\n\n            if isinstance(fp, (str, bytes, bytearray)):\n                fdata = fp\n            elif hasattr(fp, 'read'):\n                fdata = fp.read()\n            elif fp is None:\n                continue\n            else:\n                fdata = fp\n\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n            rf.make_multipart(content_type=ft)\n            new_fields.append(rf)\n\n        body, content_type = encode_multipart_formdata(new_fields)\n\n        return body, content_type\n\n\nclass RequestHooksMixin(object):\n    def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, '__iter__'):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n\n    def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False\n\n\nclass Request(RequestHooksMixin):\n    \"\"\"A user-created :class:`Request <Request>` object.\n\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n\n    :param method: HTTP method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for (k, v) in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return '<Request [%s]>' % (self.method)\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Generated from either a :class:`Request <Request>` object or manually.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return '<PreparedRequest [%s]>' % (self.method)\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode('utf-8')\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode('utf8')\n        else:\n            url = unicode(url) if is_py2 else str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if ':' in url and not url.lower().startswith('http'):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        try:\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\n        except LocationParseError as e:\n            raise InvalidURL(*e.args)\n\n        if not scheme:\n            error = (\"Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?\")\n            error = error.format(to_native_string(url, 'utf8'))\n\n            raise MissingSchema(error)\n\n        if not host:\n            raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n\n        # In general, we want to try IDNA encoding the hostname if the string contains\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\n        # behaviour. For strings containing only ASCII characters, we need to also verify\n        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n        if not unicode_is_ascii(host):\n            try:\n                host = self._get_idna_encoded_host(host)\n            except UnicodeError:\n                raise InvalidURL('URL has an invalid label.')\n        elif host.startswith(u'*'):\n            raise InvalidURL('URL has an invalid label.')\n\n        # Carefully reconstruct the network location\n        netloc = auth or ''\n        if netloc:\n            netloc += '@'\n        netloc += host\n        if port:\n            netloc += ':' + str(port)\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = '/'\n\n        if is_py2:\n            if isinstance(scheme, str):\n                scheme = scheme.encode('utf-8')\n            if isinstance(netloc, str):\n                netloc = netloc.encode('utf-8')\n            if isinstance(path, str):\n                path = path.encode('utf-8')\n            if isinstance(query, str):\n                query = query.encode('utf-8')\n            if isinstance(fragment, str):\n                fragment = fragment.encode('utf-8')\n\n        if isinstance(params, (str, bytes)):\n            params = to_native_string(params)\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = '%s&%s' % (query, enc_params)\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url\n\n    def prepare_headers(self, headers):\n        \"\"\"Prepares the given HTTP headers.\"\"\"\n\n        self.headers = CaseInsensitiveDict()\n        if headers:\n            for header in headers.items():\n                # Raise exception on invalid header value.\n                check_header_validity(header)\n                name, value = header\n                self.headers[to_native_string(name)] = value\n\n    def prepare_body(self, data, files, json=None):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n\n        if not data and json is not None:\n            # urllib3 requires a bytes-like body. Python 2's json.dumps\n            # provides this natively, but Python 3 gives a Unicode string.\n            content_type = 'application/json'\n            body = complexjson.dumps(json)\n            if not isinstance(body, bytes):\n                body = body.encode('utf-8')\n\n        is_stream = all([\n            hasattr(data, '__iter__'),\n            not isinstance(data, (basestring, list, tuple, Mapping))\n        ])\n\n        try:\n            length = super_len(data)\n        except (TypeError, AttributeError, UnsupportedOperation):\n            length = None\n\n        if is_stream:\n            body = data\n\n            if getattr(body, 'tell', None) is not None:\n                # Record the current file position before reading.\n                # This will allow us to rewind a file in the event\n                # of a redirect.\n                try:\n                    self._body_position = body.tell()\n                except (IOError, OSError):\n                    # This differentiates from None, allowing us to catch\n                    # a failed `tell()` later when trying to rewind the body\n                    self._body_position = object()\n\n            if files:\n                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n\n            if length:\n                self.headers['Content-Length'] = builtin_str(length)\n            else:\n                self.headers['Transfer-Encoding'] = 'chunked'\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, 'read'):\n                        content_type = None\n                    else:\n                        content_type = 'application/x-www-form-urlencoded'\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if content_type and ('content-type' not in self.headers):\n                self.headers['Content-Type'] = content_type\n\n        self.body = body\n\n    def prepare_content_length(self, body):\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n        if body is not None:\n            length = super_len(body)\n            if length:\n                # If length exists, set it. Otherwise, we fallback\n                # to Transfer-Encoding: chunked.\n                self.headers['Content-Length'] = builtin_str(length)\n        elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:\n            # Set Content-Length to 0 for methods that can have a body\n            # but don't provide one. (i.e. not GET or HEAD)\n            self.headers['Content-Length'] = '0'\n\n    def prepare_auth(self, auth, url=''):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)\n\n    def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers['Cookie'] = cookie_header\n\n    def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n\nclass Response(object):\n    \"\"\"The :class:`Response <Response>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        '_content', 'status_code', 'headers', 'url', 'history',\n        'encoding', 'reason', 'cookies', 'elapsed', 'request'\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, '_content_consumed', True)\n        setattr(self, 'raw', None)\n\n    def __repr__(self):\n        return '<Response [%s]>' % (self.status_code)\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return ('location' in self.headers and self.status_code in REDIRECT_STATI)\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))\n\n    @property\n    def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next\n\n    @property\n    def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the chardet library.\"\"\"\n        return chardet.detect(self.content)['encoding']\n\n    def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_size must be of type int or None. A value of None will\n        function differently depending on the value of `stream`.\n        stream=True will read data as it arrives in whatever size the\n        chunks are received. If stream=False, data is returned as\n        a single chunk.\n\n        If decode_unicode is True, content will be decoded using the best\n        available encoding based on the response.\n        \"\"\"\n\n        def generate():\n            # Special case for urllib3.\n            if hasattr(self.raw, 'stream'):\n                try:\n                    for chunk in self.raw.stream(chunk_size, decode_content=True):\n                        yield chunk\n                except ProtocolError as e:\n                    raise ChunkedEncodingError(e)\n                except DecodeError as e:\n                    raise ContentDecodingError(e)\n                except ReadTimeoutError as e:\n                    raise ConnectionError(e)\n            else:\n                # Standard file-like object.\n                while True:\n                    chunk = self.raw.read(chunk_size)\n                    if not chunk:\n                        break\n                    yield chunk\n\n            self._content_consumed = True\n\n        if self._content_consumed and isinstance(self._content, bool):\n            raise StreamConsumedError()\n        elif chunk_size is not None and not isinstance(chunk_size, int):\n            raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n        # simulate reading small chunks of the content\n        reused_chunks = iter_slices(self._content, chunk_size)\n\n        stream_chunks = generate()\n\n        chunks = reused_chunks if self._content_consumed else stream_chunks\n\n        if decode_unicode:\n            chunks = stream_decode_response_unicode(chunks, self)\n\n        return chunks\n\n    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            for line in lines:\n                yield line\n\n        if pending is not None:\n            yield pending\n\n    @property\n    def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\n                    'The content for this response was already consumed')\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content\n\n    @property\n    def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return str('')\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors='replace')\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors='replace')\n\n        return content\n\n    def json(self, **kwargs):\n        r\"\"\"Returns the json-encoded content of a response, if any.\n\n        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n        :raises ValueError: If the response body does not contain valid json.\n        \"\"\"\n\n        if not self.encoding and self.content and len(self.content) > 3:\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\n            # decoding fails, fall back to `self.text` (using chardet to make\n            # a best guess).\n            encoding = guess_json_utf(self.content)\n            if encoding is not None:\n                try:\n                    return complexjson.loads(\n                        self.content.decode(encoding), **kwargs\n                    )\n                except UnicodeDecodeError:\n                    # Wrong UTF codec detected; usually because it's not UTF-8\n                    # but some other 8-bit codec.  This is an RFC violation,\n                    # and the server didn't bother to tell us what codec *was*\n                    # used.\n                    pass\n        return complexjson.loads(self.text, **kwargs)\n\n    @property\n    def links(self):\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n        header = self.headers.get('link')\n\n        # l = MultiDict()\n        l = {}\n\n        if header:\n            links = parse_header_links(header)\n\n            for link in links:\n                key = link.get('rel') or link.get('url')\n                l[key] = link\n\n        return l\n\n    def raise_for_status(self):\n        \"\"\"Raises stored :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = ''\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode('utf-8')\n            except UnicodeDecodeError:\n                reason = self.reason.decode('iso-8859-1')\n        else:\n            reason = self.reason\n\n        if 400 <= self.status_code < 500:\n            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        elif 500 <= self.status_code < 600:\n            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        if http_error_msg:\n            raise HTTPError(http_error_msg, response=self)\n\n    def close(self):\n        \"\"\"Releases the connection back to the pool. Once this method has been\n        called the underlying ``raw`` object must not be accessed again.\n\n        *Note: Should not normally need to be called explicitly.*\n        \"\"\"\n        if not self._content_consumed:\n            self.raw.close()\n\n        release_conn = getattr(self.raw, 'release_conn', None)\n        if release_conn is not None:\n            release_conn()\n",
      "code_after": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\nimport sys\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna\n\nfrom urllib3.fields import RequestField\nfrom urllib3.filepost import encode_multipart_formdata\nfrom urllib3.util import parse_url\nfrom urllib3.exceptions import (\n    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n\nfrom io import UnsupportedOperation\nfrom .hooks import default_hooks\nfrom .structures import CaseInsensitiveDict\n\nfrom .auth import HTTPBasicAuth\nfrom .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\nfrom .exceptions import (\n    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n    ContentDecodingError, ConnectionError, StreamConsumedError)\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .utils import (\n    guess_filename, get_auth_from_url, requote_uri,\n    stream_decode_response_unicode, to_key_val_list, parse_header_links,\n    iter_slices, guess_json_utf, super_len, check_header_validity)\nfrom .compat import (\n    Callable, Mapping,\n    cookielib, urlunparse, urlsplit, urlencode, str, bytes,\n    is_py2, chardet, builtin_str, basestring)\nfrom .compat import json as complexjson\nfrom .status_codes import codes\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,               # 301\n    codes.found,               # 302\n    codes.other,               # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin(object):\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = '/'\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append('?')\n            url.append(query)\n\n        return ''.join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, 'read'):\n            return data\n        elif hasattr(data, '__iter__'):\n            result = []\n            for k, vs in to_key_val_list(data):\n                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n                    vs = [vs]\n                for v in vs:\n                    if v is not None:\n                        result.append(\n                            (k.encode('utf-8') if isinstance(k, str) else k,\n                             v.encode('utf-8') if isinstance(v, str) else v))\n            return urlencode(result, doseq=True)\n        else:\n            return data\n\n    @staticmethod\n    def _encode_files(files, data):\n        \"\"\"Build the body for a multipart/form-data request.\n\n        Will successfully encode files when passed as a dict or a list of\n        tuples. Order is retained if data is a list of tuples but arbitrary\n        if parameters are supplied as a dict.\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\n        \"\"\"\n        if (not files):\n            raise ValueError(\"Files must be provided.\")\n        elif isinstance(data, basestring):\n            raise ValueError(\"Data must not be a string.\")\n\n        new_fields = []\n        fields = to_key_val_list(data or {})\n        files = to_key_val_list(files or {})\n\n        for field, val in fields:\n            if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n                val = [val]\n            for v in val:\n                if v is not None:\n                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n                    if not isinstance(v, bytes):\n                        v = str(v)\n\n                    new_fields.append(\n                        (field.decode('utf-8') if isinstance(field, bytes) else field,\n                         v.encode('utf-8') if isinstance(v, str) else v))\n\n        for (k, v) in files:\n            # support for explicit filename\n            ft = None\n            fh = None\n            if isinstance(v, (tuple, list)):\n                if len(v) == 2:\n                    fn, fp = v\n                elif len(v) == 3:\n                    fn, fp, ft = v\n                else:\n                    fn, fp, ft, fh = v\n            else:\n                fn = guess_filename(v) or k\n                fp = v\n\n            if isinstance(fp, (str, bytes, bytearray)):\n                fdata = fp\n            elif hasattr(fp, 'read'):\n                fdata = fp.read()\n            elif fp is None:\n                continue\n            else:\n                fdata = fp\n\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n            rf.make_multipart(content_type=ft)\n            new_fields.append(rf)\n\n        body, content_type = encode_multipart_formdata(new_fields)\n\n        return body, content_type\n\n\nclass RequestHooksMixin(object):\n    def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, '__iter__'):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n\n    def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False\n\n\nclass Request(RequestHooksMixin):\n    \"\"\"A user-created :class:`Request <Request>` object.\n\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n\n    :param method: HTTP method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for (k, v) in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return '<Request [%s]>' % (self.method)\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Generated from either a :class:`Request <Request>` object or manually.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return '<PreparedRequest [%s]>' % (self.method)\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode('utf-8')\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode('utf8')\n        else:\n            url = unicode(url) if is_py2 else str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if ':' in url and not url.lower().startswith('http'):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        try:\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\n        except LocationParseError as e:\n            raise InvalidURL(*e.args)\n\n        if not scheme:\n            error = (\"Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?\")\n            error = error.format(to_native_string(url, 'utf8'))\n\n            raise MissingSchema(error)\n\n        if not host:\n            raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n\n        # In general, we want to try IDNA encoding the hostname if the string contains\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\n        # behaviour. For strings containing only ASCII characters, we need to also verify\n        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n        if not unicode_is_ascii(host):\n            try:\n                host = self._get_idna_encoded_host(host)\n            except UnicodeError:\n                raise InvalidURL('URL has an invalid label.')\n        elif host.startswith(u'*'):\n            raise InvalidURL('URL has an invalid label.')\n\n        # Carefully reconstruct the network location\n        netloc = auth or ''\n        if netloc:\n            netloc += '@'\n        netloc += host\n        if port:\n            netloc += ':' + str(port)\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = '/'\n\n        if is_py2:\n            if isinstance(scheme, str):\n                scheme = scheme.encode('utf-8')\n            if isinstance(netloc, str):\n                netloc = netloc.encode('utf-8')\n            if isinstance(path, str):\n                path = path.encode('utf-8')\n            if isinstance(query, str):\n                query = query.encode('utf-8')\n            if isinstance(fragment, str):\n                fragment = fragment.encode('utf-8')\n\n        if isinstance(params, (str, bytes)):\n            params = to_native_string(params)\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = '%s&%s' % (query, enc_params)\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url\n\n    def prepare_headers(self, headers):\n        \"\"\"Prepares the given HTTP headers.\"\"\"\n\n        self.headers = CaseInsensitiveDict()\n        if headers:\n            for header in headers.items():\n                # Raise exception on invalid header value.\n                check_header_validity(header)\n                name, value = header\n                self.headers[to_native_string(name)] = value\n\n    def prepare_body(self, data, files, json=None):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n\n        if not data and json is not None:\n            # urllib3 requires a bytes-like body. Python 2's json.dumps\n            # provides this natively, but Python 3 gives a Unicode string.\n            content_type = 'application/json'\n            body = complexjson.dumps(json)\n            if not isinstance(body, bytes):\n                body = body.encode('utf-8')\n\n        is_stream = all([\n            hasattr(data, '__iter__'),\n            not isinstance(data, (basestring, list, tuple, Mapping))\n        ])\n\n        try:\n            length = super_len(data)\n        except (TypeError, AttributeError, UnsupportedOperation):\n            length = None\n\n        if is_stream:\n            body = data\n\n            if getattr(body, 'tell', None) is not None:\n                # Record the current file position before reading.\n                # This will allow us to rewind a file in the event\n                # of a redirect.\n                try:\n                    self._body_position = body.tell()\n                except (IOError, OSError):\n                    # This differentiates from None, allowing us to catch\n                    # a failed `tell()` later when trying to rewind the body\n                    self._body_position = object()\n\n            if files:\n                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n\n            if length:\n                self.headers['Content-Length'] = builtin_str(length)\n            else:\n                self.headers['Transfer-Encoding'] = 'chunked'\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, 'read'):\n                        content_type = None\n                    else:\n                        content_type = 'application/x-www-form-urlencoded'\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if content_type and ('content-type' not in self.headers):\n                self.headers['Content-Type'] = content_type\n\n        self.body = body\n\n    def prepare_content_length(self, body):\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n        if body is not None:\n            length = super_len(body)\n            if length:\n                # If length exists, set it. Otherwise, we fallback\n                # to Transfer-Encoding: chunked.\n                self.headers['Content-Length'] = builtin_str(length)\n        elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:\n            # Set Content-Length to 0 for methods that can have a body\n            # but don't provide one. (i.e. not GET or HEAD)\n            self.headers['Content-Length'] = '0'\n\n    def prepare_auth(self, auth, url=''):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)\n\n    def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers['Cookie'] = cookie_header\n\n    def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n\nclass Response(object):\n    \"\"\"The :class:`Response <Response>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        '_content', 'status_code', 'headers', 'url', 'history',\n        'encoding', 'reason', 'cookies', 'elapsed', 'request'\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, '_content_consumed', True)\n        setattr(self, 'raw', None)\n\n    def __repr__(self):\n        return '<Response [%s]>' % (self.status_code)\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return ('location' in self.headers and self.status_code in REDIRECT_STATI)\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))\n\n    @property\n    def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next\n\n    @property\n    def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the chardet library.\"\"\"\n        return chardet.detect(self.content)['encoding']\n\n    def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_size must be of type int or None. A value of None will\n        function differently depending on the value of `stream`.\n        stream=True will read data as it arrives in whatever size the\n        chunks are received. If stream=False, data is returned as\n        a single chunk.\n\n        If decode_unicode is True, content will be decoded using the best\n        available encoding based on the response.\n        \"\"\"\n\n        def generate():\n            # Special case for urllib3.\n            if hasattr(self.raw, 'stream'):\n                try:\n                    for chunk in self.raw.stream(chunk_size, decode_content=True):\n                        yield chunk\n                except ProtocolError as e:\n                    raise ChunkedEncodingError(e)\n                except DecodeError as e:\n                    raise ContentDecodingError(e)\n                except ReadTimeoutError as e:\n                    raise ConnectionError(e)\n            else:\n                # Standard file-like object.\n                while True:\n                    chunk = self.raw.read(chunk_size)\n                    if not chunk:\n                        break\n                    yield chunk\n\n            self._content_consumed = True\n\n        if self._content_consumed and isinstance(self._content, bool):\n            raise StreamConsumedError()\n        elif chunk_size is not None and not isinstance(chunk_size, int):\n            raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n        # simulate reading small chunks of the content\n        reused_chunks = iter_slices(self._content, chunk_size)\n\n        stream_chunks = generate()\n\n        chunks = reused_chunks if self._content_consumed else stream_chunks\n\n        if decode_unicode:\n            chunks = stream_decode_response_unicode(chunks, self)\n\n        return chunks\n\n    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            for line in lines:\n                yield line\n\n        if pending is not None:\n            yield pending\n\n    @property\n    def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\n                    'The content for this response was already consumed')\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content\n\n    @property\n    def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return str('')\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors='replace')\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors='replace')\n\n        return content\n\n    def json(self, **kwargs):\n        r\"\"\"Returns the json-encoded content of a response, if any.\n\n        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n        :raises ValueError: If the response body does not contain valid json.\n        \"\"\"\n\n        if not self.encoding and self.content and len(self.content) > 3:\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\n            # decoding fails, fall back to `self.text` (using chardet to make\n            # a best guess).\n            encoding = guess_json_utf(self.content)\n            if encoding is not None:\n                try:\n                    return complexjson.loads(\n                        self.content.decode(encoding), **kwargs\n                    )\n                except UnicodeDecodeError:\n                    # Wrong UTF codec detected; usually because it's not UTF-8\n                    # but some other 8-bit codec.  This is an RFC violation,\n                    # and the server didn't bother to tell us what codec *was*\n                    # used.\n                    pass\n        return complexjson.loads(self.text, **kwargs)\n\n    @property\n    def links(self):\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n        header = self.headers.get('link')\n\n        # l = MultiDict()\n        l = {}\n\n        if header:\n            links = parse_header_links(header)\n\n            for link in links:\n                key = link.get('rel') or link.get('url')\n                l[key] = link\n\n        return l\n\n    def raise_for_status(self):\n        \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = ''\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode('utf-8')\n            except UnicodeDecodeError:\n                reason = self.reason.decode('iso-8859-1')\n        else:\n            reason = self.reason\n\n        if 400 <= self.status_code < 500:\n            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        elif 500 <= self.status_code < 600:\n            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        if http_error_msg:\n            raise HTTPError(http_error_msg, response=self)\n\n    def close(self):\n        \"\"\"Releases the connection back to the pool. Once this method has been\n        called the underlying ``raw`` object must not be accessed again.\n\n        *Note: Should not normally need to be called explicitly.*\n        \"\"\"\n        if not self._content_consumed:\n            self.raw.close()\n\n        release_conn = getattr(self.raw, 'release_conn', None)\n        if release_conn is not None:\n            release_conn()\n",
      "bug_category": "readability",
      "error_type": "readability",
      "confidence": 0.4
    },
    {
      "bug_id": "21cfb9413d26",
      "repo": "requests",
      "commit_hash": "b15056d",
      "commit_message": "Revert \"#4965 fix: Accessing response.content twice removes forgets read error.\"",
      "file_path": "requests/models.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\nimport sys\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna\n\nfrom urllib3.fields import RequestField\nfrom urllib3.filepost import encode_multipart_formdata\nfrom urllib3.util import parse_url\nfrom urllib3.exceptions import (\n    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n\nfrom io import UnsupportedOperation\nfrom .hooks import default_hooks\nfrom .structures import CaseInsensitiveDict\n\nfrom .auth import HTTPBasicAuth\nfrom .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\nfrom .exceptions import (\n    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n    ContentDecodingError, ConnectionError, StreamConsumedError)\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .utils import (\n    guess_filename, get_auth_from_url, requote_uri,\n    stream_decode_response_unicode, to_key_val_list, parse_header_links,\n    iter_slices, guess_json_utf, super_len, check_header_validity)\nfrom .compat import (\n    Callable, Mapping,\n    cookielib, urlunparse, urlsplit, urlencode, str, bytes,\n    is_py2, chardet, builtin_str, basestring)\nfrom .compat import json as complexjson\nfrom .status_codes import codes\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,               # 301\n    codes.found,               # 302\n    codes.other,               # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin(object):\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = '/'\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append('?')\n            url.append(query)\n\n        return ''.join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, 'read'):\n            return data\n        elif hasattr(data, '__iter__'):\n            result = []\n            for k, vs in to_key_val_list(data):\n                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n                    vs = [vs]\n                for v in vs:\n                    if v is not None:\n                        result.append(\n                            (k.encode('utf-8') if isinstance(k, str) else k,\n                             v.encode('utf-8') if isinstance(v, str) else v))\n            return urlencode(result, doseq=True)\n        else:\n            return data\n\n    @staticmethod\n    def _encode_files(files, data):\n        \"\"\"Build the body for a multipart/form-data request.\n\n        Will successfully encode files when passed as a dict or a list of\n        tuples. Order is retained if data is a list of tuples but arbitrary\n        if parameters are supplied as a dict.\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\n        \"\"\"\n        if (not files):\n            raise ValueError(\"Files must be provided.\")\n        elif isinstance(data, basestring):\n            raise ValueError(\"Data must not be a string.\")\n\n        new_fields = []\n        fields = to_key_val_list(data or {})\n        files = to_key_val_list(files or {})\n\n        for field, val in fields:\n            if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n                val = [val]\n            for v in val:\n                if v is not None:\n                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n                    if not isinstance(v, bytes):\n                        v = str(v)\n\n                    new_fields.append(\n                        (field.decode('utf-8') if isinstance(field, bytes) else field,\n                         v.encode('utf-8') if isinstance(v, str) else v))\n\n        for (k, v) in files:\n            # support for explicit filename\n            ft = None\n            fh = None\n            if isinstance(v, (tuple, list)):\n                if len(v) == 2:\n                    fn, fp = v\n                elif len(v) == 3:\n                    fn, fp, ft = v\n                else:\n                    fn, fp, ft, fh = v\n            else:\n                fn = guess_filename(v) or k\n                fp = v\n\n            if isinstance(fp, (str, bytes, bytearray)):\n                fdata = fp\n            elif hasattr(fp, 'read'):\n                fdata = fp.read()\n            elif fp is None:\n                continue\n            else:\n                fdata = fp\n\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n            rf.make_multipart(content_type=ft)\n            new_fields.append(rf)\n\n        body, content_type = encode_multipart_formdata(new_fields)\n\n        return body, content_type\n\n\nclass RequestHooksMixin(object):\n    def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, '__iter__'):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n\n    def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False\n\n\nclass Request(RequestHooksMixin):\n    \"\"\"A user-created :class:`Request <Request>` object.\n\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n\n    :param method: HTTP method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for (k, v) in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return '<Request [%s]>' % (self.method)\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Generated from either a :class:`Request <Request>` object or manually.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return '<PreparedRequest [%s]>' % (self.method)\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode('utf-8')\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode('utf8')\n        else:\n            url = unicode(url) if is_py2 else str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if ':' in url and not url.lower().startswith('http'):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        try:\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\n        except LocationParseError as e:\n            raise InvalidURL(*e.args)\n\n        if not scheme:\n            error = (\"Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?\")\n            error = error.format(to_native_string(url, 'utf8'))\n\n            raise MissingSchema(error)\n\n        if not host:\n            raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n\n        # In general, we want to try IDNA encoding the hostname if the string contains\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\n        # behaviour. For strings containing only ASCII characters, we need to also verify\n        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n        if not unicode_is_ascii(host):\n            try:\n                host = self._get_idna_encoded_host(host)\n            except UnicodeError:\n                raise InvalidURL('URL has an invalid label.')\n        elif host.startswith(u'*'):\n            raise InvalidURL('URL has an invalid label.')\n\n        # Carefully reconstruct the network location\n        netloc = auth or ''\n        if netloc:\n            netloc += '@'\n        netloc += host\n        if port:\n            netloc += ':' + str(port)\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = '/'\n\n        if is_py2:\n            if isinstance(scheme, str):\n                scheme = scheme.encode('utf-8')\n            if isinstance(netloc, str):\n                netloc = netloc.encode('utf-8')\n            if isinstance(path, str):\n                path = path.encode('utf-8')\n            if isinstance(query, str):\n                query = query.encode('utf-8')\n            if isinstance(fragment, str):\n                fragment = fragment.encode('utf-8')\n\n        if isinstance(params, (str, bytes)):\n            params = to_native_string(params)\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = '%s&%s' % (query, enc_params)\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url\n\n    def prepare_headers(self, headers):\n        \"\"\"Prepares the given HTTP headers.\"\"\"\n\n        self.headers = CaseInsensitiveDict()\n        if headers:\n            for header in headers.items():\n                # Raise exception on invalid header value.\n                check_header_validity(header)\n                name, value = header\n                self.headers[to_native_string(name)] = value\n\n    def prepare_body(self, data, files, json=None):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n\n        if not data and json is not None:\n            # urllib3 requires a bytes-like body. Python 2's json.dumps\n            # provides this natively, but Python 3 gives a Unicode string.\n            content_type = 'application/json'\n            body = complexjson.dumps(json)\n            if not isinstance(body, bytes):\n                body = body.encode('utf-8')\n\n        is_stream = all([\n            hasattr(data, '__iter__'),\n            not isinstance(data, (basestring, list, tuple, Mapping))\n        ])\n\n        try:\n            length = super_len(data)\n        except (TypeError, AttributeError, UnsupportedOperation):\n            length = None\n\n        if is_stream:\n            body = data\n\n            if getattr(body, 'tell', None) is not None:\n                # Record the current file position before reading.\n                # This will allow us to rewind a file in the event\n                # of a redirect.\n                try:\n                    self._body_position = body.tell()\n                except (IOError, OSError):\n                    # This differentiates from None, allowing us to catch\n                    # a failed `tell()` later when trying to rewind the body\n                    self._body_position = object()\n\n            if files:\n                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n\n            if length:\n                self.headers['Content-Length'] = builtin_str(length)\n            else:\n                self.headers['Transfer-Encoding'] = 'chunked'\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, 'read'):\n                        content_type = None\n                    else:\n                        content_type = 'application/x-www-form-urlencoded'\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if content_type and ('content-type' not in self.headers):\n                self.headers['Content-Type'] = content_type\n\n        self.body = body\n\n    def prepare_content_length(self, body):\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n        if body is not None:\n            length = super_len(body)\n            if length:\n                # If length exists, set it. Otherwise, we fallback\n                # to Transfer-Encoding: chunked.\n                self.headers['Content-Length'] = builtin_str(length)\n        elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:\n            # Set Content-Length to 0 for methods that can have a body\n            # but don't provide one. (i.e. not GET or HEAD)\n            self.headers['Content-Length'] = '0'\n\n    def prepare_auth(self, auth, url=''):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)\n\n    def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers['Cookie'] = cookie_header\n\n    def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n\nclass Response(object):\n    \"\"\"The :class:`Response <Response>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        '_content', 'status_code', 'headers', 'url', 'history',\n        'encoding', 'reason', 'cookies', 'elapsed', 'request'\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n        #: If there was an error in the processing of content,\n        #: then save the error that would return the same error when you re-appeal.\n        self._error = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, '_content_consumed', True)\n        setattr(self, 'raw', None)\n\n    def __repr__(self):\n        return '<Response [%s]>' % (self.status_code)\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return ('location' in self.headers and self.status_code in REDIRECT_STATI)\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))\n\n    @property\n    def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next\n\n    @property\n    def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the chardet library.\"\"\"\n        return chardet.detect(self.content)['encoding']\n\n    def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_size must be of type int or None. A value of None will\n        function differently depending on the value of `stream`.\n        stream=True will read data as it arrives in whatever size the\n        chunks are received. If stream=False, data is returned as\n        a single chunk.\n\n        If decode_unicode is True, content will be decoded using the best\n        available encoding based on the response.\n        \"\"\"\n\n        def generate():\n            # Special case for urllib3.\n            if hasattr(self.raw, 'stream'):\n                try:\n                    for chunk in self.raw.stream(chunk_size, decode_content=True):\n                        yield chunk\n\n                except ProtocolError as e:\n                    self._error = ChunkedEncodingError(e)\n\n                except DecodeError as e:\n                    self._error = ContentDecodingError(e)\n\n                except ReadTimeoutError as e:\n                    self._error = ConnectionError(e)\n\n                finally:\n                    # if we had an error - throw the saved error\n                    if self._error:\n                        raise self._error\n\n            else:\n                # Standard file-like object.\n                while True:\n                    chunk = self.raw.read(chunk_size)\n                    if not chunk:\n                        break\n                    yield chunk\n\n            self._content_consumed = True\n\n        if self._content_consumed and isinstance(self._content, bool):\n            raise StreamConsumedError()\n        elif chunk_size is not None and not isinstance(chunk_size, int):\n            raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n        # simulate reading small chunks of the content\n        reused_chunks = iter_slices(self._content, chunk_size)\n\n        stream_chunks = generate()\n\n        chunks = reused_chunks if self._content_consumed else stream_chunks\n\n        if decode_unicode:\n            chunks = stream_decode_response_unicode(chunks, self)\n\n        return chunks\n\n    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            for line in lines:\n                yield line\n\n        if pending is not None:\n            yield pending\n\n    @property\n    def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\n                    'The content for this response was already consumed')\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n\n        # if we had an error - throw the saved error\n        if self._error is not None:\n            raise self._error\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content\n\n    @property\n    def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return str('')\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n        # Forcefully remove BOM from UTF-8\n        elif self.encoding.lower() == 'utf-8':\n            encoding = 'utf-8-sig'\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors='replace')\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors='replace')\n\n        return content\n\n    def json(self, **kwargs):\n        r\"\"\"Returns the json-encoded content of a response, if any.\n\n        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n        :raises ValueError: If the response body does not contain valid json.\n        \"\"\"\n\n        if not self.encoding and self.content and len(self.content) > 3:\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\n            # decoding fails, fall back to `self.text` (using chardet to make\n            # a best guess).\n            encoding = guess_json_utf(self.content)\n            if encoding is not None:\n                try:\n                    return complexjson.loads(\n                        self.content.decode(encoding), **kwargs\n                    )\n                except UnicodeDecodeError:\n                    # Wrong UTF codec detected; usually because it's not UTF-8\n                    # but some other 8-bit codec.  This is an RFC violation,\n                    # and the server didn't bother to tell us what codec *was*\n                    # used.\n                    pass\n        return complexjson.loads(self.text, **kwargs)\n\n    @property\n    def links(self):\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n        header = self.headers.get('link')\n\n        # l = MultiDict()\n        l = {}\n\n        if header:\n            links = parse_header_links(header)\n\n            for link in links:\n                key = link.get('rel') or link.get('url')\n                l[key] = link\n\n        return l\n\n    def raise_for_status(self):\n        \"\"\"Raises stored :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = ''\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode('utf-8')\n            except UnicodeDecodeError:\n                reason = self.reason.decode('iso-8859-1')\n        else:\n            reason = self.reason\n\n        if 400 <= self.status_code < 500:\n            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        elif 500 <= self.status_code < 600:\n            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        if http_error_msg:\n            raise HTTPError(http_error_msg, response=self)\n\n    def close(self):\n        \"\"\"Releases the connection back to the pool. Once this method has been\n        called the underlying ``raw`` object must not be accessed again.\n\n        *Note: Should not normally need to be called explicitly.*\n        \"\"\"\n        if not self._content_consumed:\n            self.raw.close()\n\n        release_conn = getattr(self.raw, 'release_conn', None)\n        if release_conn is not None:\n            release_conn()\n",
      "code_after": "# -*- coding: utf-8 -*-\n\n\"\"\"\nrequests.models\n~~~~~~~~~~~~~~~\n\nThis module contains the primary objects that power Requests.\n\"\"\"\n\nimport datetime\nimport sys\n\n# Import encoding now, to avoid implicit import later.\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\nimport encodings.idna\n\nfrom urllib3.fields import RequestField\nfrom urllib3.filepost import encode_multipart_formdata\nfrom urllib3.util import parse_url\nfrom urllib3.exceptions import (\n    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n\nfrom io import UnsupportedOperation\nfrom .hooks import default_hooks\nfrom .structures import CaseInsensitiveDict\n\nfrom .auth import HTTPBasicAuth\nfrom .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\nfrom .exceptions import (\n    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n    ContentDecodingError, ConnectionError, StreamConsumedError)\nfrom ._internal_utils import to_native_string, unicode_is_ascii\nfrom .utils import (\n    guess_filename, get_auth_from_url, requote_uri,\n    stream_decode_response_unicode, to_key_val_list, parse_header_links,\n    iter_slices, guess_json_utf, super_len, check_header_validity)\nfrom .compat import (\n    Callable, Mapping,\n    cookielib, urlunparse, urlsplit, urlencode, str, bytes,\n    is_py2, chardet, builtin_str, basestring)\nfrom .compat import json as complexjson\nfrom .status_codes import codes\n\n#: The set of HTTP status codes that indicate an automatically\n#: processable redirect.\nREDIRECT_STATI = (\n    codes.moved,               # 301\n    codes.found,               # 302\n    codes.other,               # 303\n    codes.temporary_redirect,  # 307\n    codes.permanent_redirect,  # 308\n)\n\nDEFAULT_REDIRECT_LIMIT = 30\nCONTENT_CHUNK_SIZE = 10 * 1024\nITER_CHUNK_SIZE = 512\n\n\nclass RequestEncodingMixin(object):\n    @property\n    def path_url(self):\n        \"\"\"Build the path URL to use.\"\"\"\n\n        url = []\n\n        p = urlsplit(self.url)\n\n        path = p.path\n        if not path:\n            path = '/'\n\n        url.append(path)\n\n        query = p.query\n        if query:\n            url.append('?')\n            url.append(query)\n\n        return ''.join(url)\n\n    @staticmethod\n    def _encode_params(data):\n        \"\"\"Encode parameters in a piece of data.\n\n        Will successfully encode parameters when passed as a dict or a list of\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n        if parameters are supplied as a dict.\n        \"\"\"\n\n        if isinstance(data, (str, bytes)):\n            return data\n        elif hasattr(data, 'read'):\n            return data\n        elif hasattr(data, '__iter__'):\n            result = []\n            for k, vs in to_key_val_list(data):\n                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n                    vs = [vs]\n                for v in vs:\n                    if v is not None:\n                        result.append(\n                            (k.encode('utf-8') if isinstance(k, str) else k,\n                             v.encode('utf-8') if isinstance(v, str) else v))\n            return urlencode(result, doseq=True)\n        else:\n            return data\n\n    @staticmethod\n    def _encode_files(files, data):\n        \"\"\"Build the body for a multipart/form-data request.\n\n        Will successfully encode files when passed as a dict or a list of\n        tuples. Order is retained if data is a list of tuples but arbitrary\n        if parameters are supplied as a dict.\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\n        \"\"\"\n        if (not files):\n            raise ValueError(\"Files must be provided.\")\n        elif isinstance(data, basestring):\n            raise ValueError(\"Data must not be a string.\")\n\n        new_fields = []\n        fields = to_key_val_list(data or {})\n        files = to_key_val_list(files or {})\n\n        for field, val in fields:\n            if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n                val = [val]\n            for v in val:\n                if v is not None:\n                    # Don't call str() on bytestrings: in Py3 it all goes wrong.\n                    if not isinstance(v, bytes):\n                        v = str(v)\n\n                    new_fields.append(\n                        (field.decode('utf-8') if isinstance(field, bytes) else field,\n                         v.encode('utf-8') if isinstance(v, str) else v))\n\n        for (k, v) in files:\n            # support for explicit filename\n            ft = None\n            fh = None\n            if isinstance(v, (tuple, list)):\n                if len(v) == 2:\n                    fn, fp = v\n                elif len(v) == 3:\n                    fn, fp, ft = v\n                else:\n                    fn, fp, ft, fh = v\n            else:\n                fn = guess_filename(v) or k\n                fp = v\n\n            if isinstance(fp, (str, bytes, bytearray)):\n                fdata = fp\n            elif hasattr(fp, 'read'):\n                fdata = fp.read()\n            elif fp is None:\n                continue\n            else:\n                fdata = fp\n\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n            rf.make_multipart(content_type=ft)\n            new_fields.append(rf)\n\n        body, content_type = encode_multipart_formdata(new_fields)\n\n        return body, content_type\n\n\nclass RequestHooksMixin(object):\n    def register_hook(self, event, hook):\n        \"\"\"Properly register a hook.\"\"\"\n\n        if event not in self.hooks:\n            raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n\n        if isinstance(hook, Callable):\n            self.hooks[event].append(hook)\n        elif hasattr(hook, '__iter__'):\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\n\n    def deregister_hook(self, event, hook):\n        \"\"\"Deregister a previously registered hook.\n        Returns True if the hook existed, False if not.\n        \"\"\"\n\n        try:\n            self.hooks[event].remove(hook)\n            return True\n        except ValueError:\n            return False\n\n\nclass Request(RequestHooksMixin):\n    \"\"\"A user-created :class:`Request <Request>` object.\n\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n\n    :param method: HTTP method to use.\n    :param url: URL to send.\n    :param headers: dictionary of headers to send.\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\n    :param data: the body to attach to the request. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param json: json for the body to attach to the request (if files or data is not specified).\n    :param params: URL parameters to append to the URL. If a dictionary or\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\n        take place.\n    :param auth: Auth handler or (user, pass) tuple.\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\n    :param hooks: dictionary of callback hooks, for internal usage.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> req.prepare()\n      <PreparedRequest [GET]>\n    \"\"\"\n\n    def __init__(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n\n        # Default empty dicts for dict params.\n        data = [] if data is None else data\n        files = [] if files is None else files\n        headers = {} if headers is None else headers\n        params = {} if params is None else params\n        hooks = {} if hooks is None else hooks\n\n        self.hooks = default_hooks()\n        for (k, v) in list(hooks.items()):\n            self.register_hook(event=k, hook=v)\n\n        self.method = method\n        self.url = url\n        self.headers = headers\n        self.files = files\n        self.data = data\n        self.json = json\n        self.params = params\n        self.auth = auth\n        self.cookies = cookies\n\n    def __repr__(self):\n        return '<Request [%s]>' % (self.method)\n\n    def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            json=self.json,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p\n\n\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n    containing the exact bytes that will be sent to the server.\n\n    Generated from either a :class:`Request <Request>` object or manually.\n\n    Usage::\n\n      >>> import requests\n      >>> req = requests.Request('GET', 'https://httpbin.org/get')\n      >>> r = req.prepare()\n      >>> r\n      <PreparedRequest [GET]>\n\n      >>> s = requests.Session()\n      >>> s.send(r)\n      <Response [200]>\n    \"\"\"\n\n    def __init__(self):\n        #: HTTP verb to send to the server.\n        self.method = None\n        #: HTTP URL to send the request to.\n        self.url = None\n        #: dictionary of HTTP headers.\n        self.headers = None\n        # The `CookieJar` used to create the Cookie header will be stored here\n        # after prepare_cookies is called\n        self._cookies = None\n        #: request body to send to the server.\n        self.body = None\n        #: dictionary of callback hooks, for internal usage.\n        self.hooks = default_hooks()\n        #: integer denoting starting position of a readable file-like body.\n        self._body_position = None\n\n    def prepare(self,\n            method=None, url=None, headers=None, files=None, data=None,\n            params=None, auth=None, cookies=None, hooks=None, json=None):\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\n\n        self.prepare_method(method)\n        self.prepare_url(url, params)\n        self.prepare_headers(headers)\n        self.prepare_cookies(cookies)\n        self.prepare_body(data, files, json)\n        self.prepare_auth(auth, url)\n\n        # Note that prepare_auth must be last to enable authentication schemes\n        # such as OAuth to work on a fully prepared request.\n\n        # This MUST go after prepare_auth. Authenticators could add a hook\n        self.prepare_hooks(hooks)\n\n    def __repr__(self):\n        return '<PreparedRequest [%s]>' % (self.method)\n\n    def copy(self):\n        p = PreparedRequest()\n        p.method = self.method\n        p.url = self.url\n        p.headers = self.headers.copy() if self.headers is not None else None\n        p._cookies = _copy_cookie_jar(self._cookies)\n        p.body = self.body\n        p.hooks = self.hooks\n        p._body_position = self._body_position\n        return p\n\n    def prepare_method(self, method):\n        \"\"\"Prepares the given HTTP method.\"\"\"\n        self.method = method\n        if self.method is not None:\n            self.method = to_native_string(self.method.upper())\n\n    @staticmethod\n    def _get_idna_encoded_host(host):\n        import idna\n\n        try:\n            host = idna.encode(host, uts46=True).decode('utf-8')\n        except idna.IDNAError:\n            raise UnicodeError\n        return host\n\n    def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        #: Accept objects that have string representations.\n        #: We're unable to blindly call unicode/str functions\n        #: as this will include the bytestring indicator (b'')\n        #: on python 3.x.\n        #: https://github.com/psf/requests/pull/2238\n        if isinstance(url, bytes):\n            url = url.decode('utf8')\n        else:\n            url = unicode(url) if is_py2 else str(url)\n\n        # Remove leading whitespaces from url\n        url = url.lstrip()\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if ':' in url and not url.lower().startswith('http'):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        try:\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\n        except LocationParseError as e:\n            raise InvalidURL(*e.args)\n\n        if not scheme:\n            error = (\"Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?\")\n            error = error.format(to_native_string(url, 'utf8'))\n\n            raise MissingSchema(error)\n\n        if not host:\n            raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n\n        # In general, we want to try IDNA encoding the hostname if the string contains\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\n        # behaviour. For strings containing only ASCII characters, we need to also verify\n        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.\n        if not unicode_is_ascii(host):\n            try:\n                host = self._get_idna_encoded_host(host)\n            except UnicodeError:\n                raise InvalidURL('URL has an invalid label.')\n        elif host.startswith(u'*'):\n            raise InvalidURL('URL has an invalid label.')\n\n        # Carefully reconstruct the network location\n        netloc = auth or ''\n        if netloc:\n            netloc += '@'\n        netloc += host\n        if port:\n            netloc += ':' + str(port)\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = '/'\n\n        if is_py2:\n            if isinstance(scheme, str):\n                scheme = scheme.encode('utf-8')\n            if isinstance(netloc, str):\n                netloc = netloc.encode('utf-8')\n            if isinstance(path, str):\n                path = path.encode('utf-8')\n            if isinstance(query, str):\n                query = query.encode('utf-8')\n            if isinstance(fragment, str):\n                fragment = fragment.encode('utf-8')\n\n        if isinstance(params, (str, bytes)):\n            params = to_native_string(params)\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = '%s&%s' % (query, enc_params)\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url\n\n    def prepare_headers(self, headers):\n        \"\"\"Prepares the given HTTP headers.\"\"\"\n\n        self.headers = CaseInsensitiveDict()\n        if headers:\n            for header in headers.items():\n                # Raise exception on invalid header value.\n                check_header_validity(header)\n                name, value = header\n                self.headers[to_native_string(name)] = value\n\n    def prepare_body(self, data, files, json=None):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n\n        if not data and json is not None:\n            # urllib3 requires a bytes-like body. Python 2's json.dumps\n            # provides this natively, but Python 3 gives a Unicode string.\n            content_type = 'application/json'\n            body = complexjson.dumps(json)\n            if not isinstance(body, bytes):\n                body = body.encode('utf-8')\n\n        is_stream = all([\n            hasattr(data, '__iter__'),\n            not isinstance(data, (basestring, list, tuple, Mapping))\n        ])\n\n        try:\n            length = super_len(data)\n        except (TypeError, AttributeError, UnsupportedOperation):\n            length = None\n\n        if is_stream:\n            body = data\n\n            if getattr(body, 'tell', None) is not None:\n                # Record the current file position before reading.\n                # This will allow us to rewind a file in the event\n                # of a redirect.\n                try:\n                    self._body_position = body.tell()\n                except (IOError, OSError):\n                    # This differentiates from None, allowing us to catch\n                    # a failed `tell()` later when trying to rewind the body\n                    self._body_position = object()\n\n            if files:\n                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n\n            if length:\n                self.headers['Content-Length'] = builtin_str(length)\n            else:\n                self.headers['Transfer-Encoding'] = 'chunked'\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, 'read'):\n                        content_type = None\n                    else:\n                        content_type = 'application/x-www-form-urlencoded'\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if content_type and ('content-type' not in self.headers):\n                self.headers['Content-Type'] = content_type\n\n        self.body = body\n\n    def prepare_content_length(self, body):\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n        if body is not None:\n            length = super_len(body)\n            if length:\n                # If length exists, set it. Otherwise, we fallback\n                # to Transfer-Encoding: chunked.\n                self.headers['Content-Length'] = builtin_str(length)\n        elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:\n            # Set Content-Length to 0 for methods that can have a body\n            # but don't provide one. (i.e. not GET or HEAD)\n            self.headers['Content-Length'] = '0'\n\n    def prepare_auth(self, auth, url=''):\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\n\n        # If no Auth is explicitly provided, extract it from the URL first.\n        if auth is None:\n            url_auth = get_auth_from_url(self.url)\n            auth = url_auth if any(url_auth) else None\n\n        if auth:\n            if isinstance(auth, tuple) and len(auth) == 2:\n                # special-case basic HTTP auth\n                auth = HTTPBasicAuth(*auth)\n\n            # Allow auth to make its changes.\n            r = auth(self)\n\n            # Update self to reflect the auth changes.\n            self.__dict__.update(r.__dict__)\n\n            # Recompute Content-Length\n            self.prepare_content_length(self.body)\n\n    def prepare_cookies(self, cookies):\n        \"\"\"Prepares the given HTTP cookie data.\n\n        This function eventually generates a ``Cookie`` header from the\n        given cookies using cookielib. Due to cookielib's design, the header\n        will not be regenerated if it already exists, meaning this function\n        can only be called once for the life of the\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n        header is removed beforehand.\n        \"\"\"\n        if isinstance(cookies, cookielib.CookieJar):\n            self._cookies = cookies\n        else:\n            self._cookies = cookiejar_from_dict(cookies)\n\n        cookie_header = get_cookie_header(self._cookies, self)\n        if cookie_header is not None:\n            self.headers['Cookie'] = cookie_header\n\n    def prepare_hooks(self, hooks):\n        \"\"\"Prepares the given hooks.\"\"\"\n        # hooks can be passed as None to the prepare method and to this\n        # method. To prevent iterating over None, simply use an empty list\n        # if hooks is False-y\n        hooks = hooks or []\n        for event in hooks:\n            self.register_hook(event, hooks[event])\n\n\nclass Response(object):\n    \"\"\"The :class:`Response <Response>` object, which contains a\n    server's response to an HTTP request.\n    \"\"\"\n\n    __attrs__ = [\n        '_content', 'status_code', 'headers', 'url', 'history',\n        'encoding', 'reason', 'cookies', 'elapsed', 'request'\n    ]\n\n    def __init__(self):\n        self._content = False\n        self._content_consumed = False\n        self._next = None\n\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n        self.status_code = None\n\n        #: Case-insensitive Dictionary of Response Headers.\n        #: For example, ``headers['content-encoding']`` will return the\n        #: value of a ``'Content-Encoding'`` response header.\n        self.headers = CaseInsensitiveDict()\n\n        #: File-like object representation of response (for advanced usage).\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n        #: This requirement does not apply for use internally to Requests.\n        self.raw = None\n\n        #: Final URL location of Response.\n        self.url = None\n\n        #: Encoding to decode with when accessing r.text.\n        self.encoding = None\n\n        #: A list of :class:`Response <Response>` objects from\n        #: the history of the Request. Any redirect responses will end\n        #: up here. The list is sorted from the oldest to the most recent request.\n        self.history = []\n\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n        self.reason = None\n\n        #: A CookieJar of Cookies the server sent back.\n        self.cookies = cookiejar_from_dict({})\n\n        #: The amount of time elapsed between sending the request\n        #: and the arrival of the response (as a timedelta).\n        #: This property specifically measures the time taken between sending\n        #: the first byte of the request and finishing parsing the headers. It\n        #: is therefore unaffected by consuming the response content or the\n        #: value of the ``stream`` keyword argument.\n        self.elapsed = datetime.timedelta(0)\n\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n        #: is a response.\n        self.request = None\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *args):\n        self.close()\n\n    def __getstate__(self):\n        # Consume everything; accessing the content attribute makes\n        # sure the content has been fully read.\n        if not self._content_consumed:\n            self.content\n\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\n\n    def __setstate__(self, state):\n        for name, value in state.items():\n            setattr(self, name, value)\n\n        # pickled objects do not have .raw\n        setattr(self, '_content_consumed', True)\n        setattr(self, 'raw', None)\n\n    def __repr__(self):\n        return '<Response [%s]>' % (self.status_code)\n\n    def __bool__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __nonzero__(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code, is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        return self.ok\n\n    def __iter__(self):\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\n        return self.iter_content(128)\n\n    @property\n    def ok(self):\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\n\n        This attribute checks if the status code of the response is between\n        400 and 600 to see if there was a client error or a server error. If\n        the status code is between 200 and 400, this will return True. This\n        is **not** a check to see if the response code is ``200 OK``.\n        \"\"\"\n        try:\n            self.raise_for_status()\n        except HTTPError:\n            return False\n        return True\n\n    @property\n    def is_redirect(self):\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\n        been processed automatically (by :meth:`Session.resolve_redirects`).\n        \"\"\"\n        return ('location' in self.headers and self.status_code in REDIRECT_STATI)\n\n    @property\n    def is_permanent_redirect(self):\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\n        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))\n\n    @property\n    def next(self):\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\n        return self._next\n\n    @property\n    def apparent_encoding(self):\n        \"\"\"The apparent encoding, provided by the chardet library.\"\"\"\n        return chardet.detect(self.content)['encoding']\n\n    def iter_content(self, chunk_size=1, decode_unicode=False):\n        \"\"\"Iterates over the response data.  When stream=True is set on the\n        request, this avoids reading the content at once into memory for\n        large responses.  The chunk size is the number of bytes it should\n        read into memory.  This is not necessarily the length of each item\n        returned as decoding can take place.\n\n        chunk_size must be of type int or None. A value of None will\n        function differently depending on the value of `stream`.\n        stream=True will read data as it arrives in whatever size the\n        chunks are received. If stream=False, data is returned as\n        a single chunk.\n\n        If decode_unicode is True, content will be decoded using the best\n        available encoding based on the response.\n        \"\"\"\n\n        def generate():\n            # Special case for urllib3.\n            if hasattr(self.raw, 'stream'):\n                try:\n                    for chunk in self.raw.stream(chunk_size, decode_content=True):\n                        yield chunk\n                except ProtocolError as e:\n                    raise ChunkedEncodingError(e)\n                except DecodeError as e:\n                    raise ContentDecodingError(e)\n                except ReadTimeoutError as e:\n                    raise ConnectionError(e)\n            else:\n                # Standard file-like object.\n                while True:\n                    chunk = self.raw.read(chunk_size)\n                    if not chunk:\n                        break\n                    yield chunk\n\n            self._content_consumed = True\n\n        if self._content_consumed and isinstance(self._content, bool):\n            raise StreamConsumedError()\n        elif chunk_size is not None and not isinstance(chunk_size, int):\n            raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n        # simulate reading small chunks of the content\n        reused_chunks = iter_slices(self._content, chunk_size)\n\n        stream_chunks = generate()\n\n        chunks = reused_chunks if self._content_consumed else stream_chunks\n\n        if decode_unicode:\n            chunks = stream_decode_response_unicode(chunks, self)\n\n        return chunks\n\n    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None):\n        \"\"\"Iterates over the response data, one line at a time.  When\n        stream=True is set on the request, this avoids reading the\n        content at once into memory for large responses.\n\n        .. note:: This method is not reentrant safe.\n        \"\"\"\n\n        pending = None\n\n        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n\n            if pending is not None:\n                chunk = pending + chunk\n\n            if delimiter:\n                lines = chunk.split(delimiter)\n            else:\n                lines = chunk.splitlines()\n\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n                pending = lines.pop()\n            else:\n                pending = None\n\n            for line in lines:\n                yield line\n\n        if pending is not None:\n            yield pending\n\n    @property\n    def content(self):\n        \"\"\"Content of the response, in bytes.\"\"\"\n\n        if self._content is False:\n            # Read the contents.\n            if self._content_consumed:\n                raise RuntimeError(\n                    'The content for this response was already consumed')\n\n            if self.status_code == 0 or self.raw is None:\n                self._content = None\n            else:\n                self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''\n\n        self._content_consumed = True\n        # don't need to release the connection; that's been handled by urllib3\n        # since we exhausted the data.\n        return self._content\n\n    @property\n    def text(self):\n        \"\"\"Content of the response, in unicode.\n\n        If Response.encoding is None, encoding will be guessed using\n        ``chardet``.\n\n        The encoding of the response content is determined based solely on HTTP\n        headers, following RFC 2616 to the letter. If you can take advantage of\n        non-HTTP knowledge to make a better guess at the encoding, you should\n        set ``r.encoding`` appropriately before accessing this property.\n        \"\"\"\n\n        # Try charset from content-type\n        content = None\n        encoding = self.encoding\n\n        if not self.content:\n            return str('')\n\n        # Fallback to auto-detected encoding.\n        if self.encoding is None:\n            encoding = self.apparent_encoding\n        # Forcefully remove BOM from UTF-8\n        elif self.encoding.lower() == 'utf-8':\n            encoding = 'utf-8-sig'\n\n        # Decode unicode from given encoding.\n        try:\n            content = str(self.content, encoding, errors='replace')\n        except (LookupError, TypeError):\n            # A LookupError is raised if the encoding was not found which could\n            # indicate a misspelling or similar mistake.\n            #\n            # A TypeError can be raised if encoding is None\n            #\n            # So we try blindly encoding.\n            content = str(self.content, errors='replace')\n\n        return content\n\n    def json(self, **kwargs):\n        r\"\"\"Returns the json-encoded content of a response, if any.\n\n        :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n        :raises ValueError: If the response body does not contain valid json.\n        \"\"\"\n\n        if not self.encoding and self.content and len(self.content) > 3:\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\n            # decoding fails, fall back to `self.text` (using chardet to make\n            # a best guess).\n            encoding = guess_json_utf(self.content)\n            if encoding is not None:\n                try:\n                    return complexjson.loads(\n                        self.content.decode(encoding), **kwargs\n                    )\n                except UnicodeDecodeError:\n                    # Wrong UTF codec detected; usually because it's not UTF-8\n                    # but some other 8-bit codec.  This is an RFC violation,\n                    # and the server didn't bother to tell us what codec *was*\n                    # used.\n                    pass\n        return complexjson.loads(self.text, **kwargs)\n\n    @property\n    def links(self):\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n\n        header = self.headers.get('link')\n\n        # l = MultiDict()\n        l = {}\n\n        if header:\n            links = parse_header_links(header)\n\n            for link in links:\n                key = link.get('rel') or link.get('url')\n                l[key] = link\n\n        return l\n\n    def raise_for_status(self):\n        \"\"\"Raises stored :class:`HTTPError`, if one occurred.\"\"\"\n\n        http_error_msg = ''\n        if isinstance(self.reason, bytes):\n            # We attempt to decode utf-8 first because some servers\n            # choose to localize their reason strings. If the string\n            # isn't utf-8, we fall back to iso-8859-1 for all other\n            # encodings. (See PR #3538)\n            try:\n                reason = self.reason.decode('utf-8')\n            except UnicodeDecodeError:\n                reason = self.reason.decode('iso-8859-1')\n        else:\n            reason = self.reason\n\n        if 400 <= self.status_code < 500:\n            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        elif 500 <= self.status_code < 600:\n            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n\n        if http_error_msg:\n            raise HTTPError(http_error_msg, response=self)\n\n    def close(self):\n        \"\"\"Releases the connection back to the pool. Once this method has been\n        called the underlying ``raw`` object must not be accessed again.\n\n        *Note: Should not normally need to be called explicitly.*\n        \"\"\"\n        if not self._content_consumed:\n            self.raw.close()\n\n        release_conn = getattr(self.raw, 'release_conn', None)\n        if release_conn is not None:\n            release_conn()\n",
      "bug_category": "type",
      "error_type": "type_safety",
      "confidence": 0.2
    },
    {
      "bug_id": "1e33e24cbebe",
      "repo": "requests",
      "commit_hash": "b15056d",
      "commit_message": "Revert \"#4965 fix: Accessing response.content twice removes forgets read error.\"",
      "file_path": "tests/test_lowlevel.py",
      "language": "python",
      "code_before": "# -*- coding: utf-8 -*-\n\nimport pytest\nimport threading\nimport requests\nfrom requests.exceptions import ChunkedEncodingError\n\nfrom tests.testserver.server import Server, consume_socket_content\n\nfrom .utils import override_environ\n\n\ndef test_chunked_upload():\n    \"\"\"can safely send generators\"\"\"\n    close_server = threading.Event()\n    server = Server.basic_response_server(wait_to_close_event=close_server)\n    data = iter([b'a', b'b', b'c'])\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.post(url, data=data, stream=True)\n        close_server.set()  # release server block\n\n    assert r.status_code == 200\n    assert r.request.headers['Transfer-Encoding'] == 'chunked'\n\n\ndef test_digestauth_401_count_reset_on_redirect():\n    \"\"\"Ensure we correctly reset num_401_calls after a successful digest auth,\n    followed by a 302 redirect to another digest auth prompt.\n\n    See https://github.com/psf/requests/issues/1979.\n    \"\"\"\n    text_401 = (b'HTTP/1.1 401 UNAUTHORIZED\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    text_302 = (b'HTTP/1.1 302 FOUND\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'Location: /\\r\\n\\r\\n')\n\n    text_200 = (b'HTTP/1.1 200 OK\\r\\n'\n                b'Content-Length: 0\\r\\n\\r\\n')\n\n    expected_digest = (b'Authorization: Digest username=\"user\", '\n                       b'realm=\"me@kennethreitz.com\", '\n                       b'nonce=\"6bf5d6e4da1ce66918800195d6b9130d\", uri=\"/\"')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to initial GET with a challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_401)\n\n        # Verify we receive an Authorization header in response, then redirect.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert expected_digest in request_content\n        sock.send(text_302)\n\n        # Verify Authorization isn't sent to the redirected host,\n        # then send another challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert b'Authorization:' not in request_content\n        sock.send(text_401)\n\n        # Verify Authorization is sent correctly again, and return 200 OK.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert expected_digest in request_content\n        sock.send(text_200)\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.get(url, auth=auth)\n        # Verify server succeeded in authenticating.\n        assert r.status_code == 200\n        # Verify Authorization was sent in final request.\n        assert 'Authorization' in r.request.headers\n        assert r.request.headers['Authorization'].startswith('Digest ')\n        # Verify redirect happened as we expected.\n        assert r.history[0].status_code == 302\n        close_server.set()\n\n\ndef test_digestauth_401_only_sent_once():\n    \"\"\"Ensure we correctly respond to a 401 challenge once, and then\n    stop responding if challenged again.\n    \"\"\"\n    text_401 = (b'HTTP/1.1 401 UNAUTHORIZED\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    expected_digest = (b'Authorization: Digest username=\"user\", '\n                       b'realm=\"me@kennethreitz.com\", '\n                       b'nonce=\"6bf5d6e4da1ce66918800195d6b9130d\", uri=\"/\"')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_failed_response_handler(sock):\n        # Respond to initial GET with a challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_401)\n\n        # Verify we receive an Authorization header in response, then\n        # challenge again.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert expected_digest in request_content\n        sock.send(text_401)\n\n        # Verify the client didn't respond to second challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.get(url, auth=auth)\n        # Verify server didn't authenticate us.\n        assert r.status_code == 401\n        assert r.history[0].status_code == 401\n        close_server.set()\n\n\ndef test_digestauth_only_on_4xx():\n    \"\"\"Ensure we only send digestauth on 4xx challenges.\n\n    See https://github.com/psf/requests/issues/3772.\n    \"\"\"\n    text_200_chal = (b'HTTP/1.1 200 OK\\r\\n'\n                     b'Content-Length: 0\\r\\n'\n                     b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                     b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                     b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to GET with a 200 containing www-authenticate header.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_200_chal)\n\n        # Verify the client didn't respond with auth.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.get(url, auth=auth)\n        # Verify server didn't receive auth from us.\n        assert r.status_code == 200\n        assert len(r.history) == 0\n        close_server.set()\n\n\n_schemes_by_var_prefix = [\n    ('http', ['http']),\n    ('https', ['https']),\n    ('all', ['http', 'https']),\n]\n\n_proxy_combos = []\nfor prefix, schemes in _schemes_by_var_prefix:\n    for scheme in schemes:\n        _proxy_combos.append((\"{}_proxy\".format(prefix), scheme))\n\n_proxy_combos += [(var.upper(), scheme) for var, scheme in _proxy_combos]\n\n\n@pytest.mark.parametrize(\"var,scheme\", _proxy_combos)\ndef test_use_proxy_from_environment(httpbin, var, scheme):\n    url = \"{}://httpbin.org\".format(scheme)\n    fake_proxy = Server()  # do nothing with the requests; just close the socket\n    with fake_proxy as (host, port):\n        proxy_url = \"socks5://{}:{}\".format(host, port)\n        kwargs = {var: proxy_url}\n        with override_environ(**kwargs):\n            # fake proxy's lack of response will cause a ConnectionError\n            with pytest.raises(requests.exceptions.ConnectionError):\n                requests.get(url)\n\n        # the fake proxy received a request\n        assert len(fake_proxy.handler_results) == 1\n\n        # it had actual content (not checking for SOCKS protocol for now)\n        assert len(fake_proxy.handler_results[0]) > 0\n\n\ndef test_redirect_rfc1808_to_non_ascii_location():\n    path = u'\u0161'\n    expected_path = b'%C5%A1'\n    redirect_request = []  # stores the second request to the server\n\n    def redirect_resp_handler(sock):\n        consume_socket_content(sock, timeout=0.5)\n        location = u'//{}:{}/{}'.format(host, port, path)\n        sock.send(\n            b'HTTP/1.1 301 Moved Permanently\\r\\n'\n            b'Content-Length: 0\\r\\n'\n            b'Location: ' + location.encode('utf8') + b'\\r\\n'\n            b'\\r\\n'\n        )\n        redirect_request.append(consume_socket_content(sock, timeout=0.5))\n        sock.send(b'HTTP/1.1 200 OK\\r\\n\\r\\n')\n\n    close_server = threading.Event()\n    server = Server(redirect_resp_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = u'http://{}:{}'.format(host, port)\n        r = requests.get(url=url, allow_redirects=True)\n        assert r.status_code == 200\n        assert len(r.history) == 1\n        assert r.history[0].status_code == 301\n        assert redirect_request[0].startswith(b'GET /' + expected_path + b' HTTP/1.1')\n        assert r.url == u'{}/{}'.format(url, expected_path.decode('ascii'))\n\n        close_server.set()\n\ndef test_fragment_not_sent_with_request():\n    \"\"\"Verify that the fragment portion of a URI isn't sent to the server.\"\"\"\n    def response_handler(sock):\n        req = consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 200 OK\\r\\n'\n            b'Content-Length: '+bytes(len(req))+b'\\r\\n'\n            b'\\r\\n'+req\n        )\n\n    close_server = threading.Event()\n    server = Server(response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/path/to/thing/#view=edit&token=hunter2'.format(host, port)\n        r = requests.get(url)\n        raw_request = r.content\n\n        assert r.status_code == 200\n        headers, body = raw_request.split(b'\\r\\n\\r\\n', 1)\n        status_line, headers = headers.split(b'\\r\\n', 1)\n\n        assert status_line == b'GET /path/to/thing/ HTTP/1.1'\n        for frag in (b'view', b'edit', b'token', b'hunter2'):\n            assert frag not in headers\n            assert frag not in body\n\n        close_server.set()\n\ndef test_fragment_update_on_redirect():\n    \"\"\"Verify we only append previous fragment if one doesn't exist on new\n    location. If a new fragment is encountered in a Location header, it should\n    be added to all subsequent requests.\n    \"\"\"\n\n    def response_handler(sock):\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 302 FOUND\\r\\n'\n            b'Content-Length: 0\\r\\n'\n            b'Location: /get#relevant-section\\r\\n\\r\\n'\n        )\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 302 FOUND\\r\\n'\n            b'Content-Length: 0\\r\\n'\n            b'Location: /final-url/\\r\\n\\r\\n'\n        )\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 200 OK\\r\\n\\r\\n'\n        )\n\n    close_server = threading.Event()\n    server = Server(response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/path/to/thing/#view=edit&token=hunter2'.format(host, port)\n        r = requests.get(url)\n        raw_request = r.content\n\n        assert r.status_code == 200\n        assert len(r.history) == 2\n        assert r.history[0].request.url == url\n\n        # Verify we haven't overwritten the location with our previous fragment.\n        assert r.history[1].request.url == 'http://{}:{}/get#relevant-section'.format(host, port)\n        # Verify previous fragment is used and not the original.\n        assert r.url == 'http://{}:{}/final-url/#relevant-section'.format(host, port)\n\n        close_server.set()\n\n\ndef test_response_content_retains_error():\n    \"\"\"Verify that accessing response.content retains an error.\n\n    See https://github.com/kennethreitz/requests/issues/4965\n    \"\"\"\n\n    data = \"Some random stuff to read from remove server.\\n\"\n\n    def response_handler(sock):\n        req = consume_socket_content(sock, timeout=0.5)\n\n        # Send invalid chunked data (length mismatch)\n        sock.send(\n            b'HTTP/1.1 200 OK\\r\\n'\n            b'Transfer-Encoding: chunked\\r\\n'\n            b'\\r\\n2\\r\\n42\\r\\n8\\r\\n123\\r\\n'  # 5 bytes missing\n        )\n\n    close_server = threading.Event()\n    server = Server(response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/path'.format(host, port)\n        r = requests.post(url, stream=True)\n        with pytest.raises(ChunkedEncodingError):\n            r.content\n\n    # Access the bad response data again, I would expect the same\n    # error again.\n\n    try:\n        content = r.content\n    except ChunkedEncodingError:\n        pass  # fine, same exception\n    else:\n        assert False, \"error response has content: {0!r}\".format(content)\n    close_server.set()\n\n",
      "code_after": "# -*- coding: utf-8 -*-\n\nimport pytest\nimport threading\nimport requests\n\nfrom tests.testserver.server import Server, consume_socket_content\n\nfrom .utils import override_environ\n\n\ndef test_chunked_upload():\n    \"\"\"can safely send generators\"\"\"\n    close_server = threading.Event()\n    server = Server.basic_response_server(wait_to_close_event=close_server)\n    data = iter([b'a', b'b', b'c'])\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.post(url, data=data, stream=True)\n        close_server.set()  # release server block\n\n    assert r.status_code == 200\n    assert r.request.headers['Transfer-Encoding'] == 'chunked'\n\n\ndef test_digestauth_401_count_reset_on_redirect():\n    \"\"\"Ensure we correctly reset num_401_calls after a successful digest auth,\n    followed by a 302 redirect to another digest auth prompt.\n\n    See https://github.com/psf/requests/issues/1979.\n    \"\"\"\n    text_401 = (b'HTTP/1.1 401 UNAUTHORIZED\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    text_302 = (b'HTTP/1.1 302 FOUND\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'Location: /\\r\\n\\r\\n')\n\n    text_200 = (b'HTTP/1.1 200 OK\\r\\n'\n                b'Content-Length: 0\\r\\n\\r\\n')\n\n    expected_digest = (b'Authorization: Digest username=\"user\", '\n                       b'realm=\"me@kennethreitz.com\", '\n                       b'nonce=\"6bf5d6e4da1ce66918800195d6b9130d\", uri=\"/\"')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to initial GET with a challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_401)\n\n        # Verify we receive an Authorization header in response, then redirect.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert expected_digest in request_content\n        sock.send(text_302)\n\n        # Verify Authorization isn't sent to the redirected host,\n        # then send another challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert b'Authorization:' not in request_content\n        sock.send(text_401)\n\n        # Verify Authorization is sent correctly again, and return 200 OK.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert expected_digest in request_content\n        sock.send(text_200)\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.get(url, auth=auth)\n        # Verify server succeeded in authenticating.\n        assert r.status_code == 200\n        # Verify Authorization was sent in final request.\n        assert 'Authorization' in r.request.headers\n        assert r.request.headers['Authorization'].startswith('Digest ')\n        # Verify redirect happened as we expected.\n        assert r.history[0].status_code == 302\n        close_server.set()\n\n\ndef test_digestauth_401_only_sent_once():\n    \"\"\"Ensure we correctly respond to a 401 challenge once, and then\n    stop responding if challenged again.\n    \"\"\"\n    text_401 = (b'HTTP/1.1 401 UNAUTHORIZED\\r\\n'\n                b'Content-Length: 0\\r\\n'\n                b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    expected_digest = (b'Authorization: Digest username=\"user\", '\n                       b'realm=\"me@kennethreitz.com\", '\n                       b'nonce=\"6bf5d6e4da1ce66918800195d6b9130d\", uri=\"/\"')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_failed_response_handler(sock):\n        # Respond to initial GET with a challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_401)\n\n        # Verify we receive an Authorization header in response, then\n        # challenge again.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert expected_digest in request_content\n        sock.send(text_401)\n\n        # Verify the client didn't respond to second challenge.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_failed_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.get(url, auth=auth)\n        # Verify server didn't authenticate us.\n        assert r.status_code == 401\n        assert r.history[0].status_code == 401\n        close_server.set()\n\n\ndef test_digestauth_only_on_4xx():\n    \"\"\"Ensure we only send digestauth on 4xx challenges.\n\n    See https://github.com/psf/requests/issues/3772.\n    \"\"\"\n    text_200_chal = (b'HTTP/1.1 200 OK\\r\\n'\n                     b'Content-Length: 0\\r\\n'\n                     b'WWW-Authenticate: Digest nonce=\"6bf5d6e4da1ce66918800195d6b9130d\"'\n                     b', opaque=\"372825293d1c26955496c80ed6426e9e\", '\n                     b'realm=\"me@kennethreitz.com\", qop=auth\\r\\n\\r\\n')\n\n    auth = requests.auth.HTTPDigestAuth('user', 'pass')\n\n    def digest_response_handler(sock):\n        # Respond to GET with a 200 containing www-authenticate header.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content.startswith(b\"GET / HTTP/1.1\")\n        sock.send(text_200_chal)\n\n        # Verify the client didn't respond with auth.\n        request_content = consume_socket_content(sock, timeout=0.5)\n        assert request_content == b''\n\n        return request_content\n\n    close_server = threading.Event()\n    server = Server(digest_response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/'.format(host, port)\n        r = requests.get(url, auth=auth)\n        # Verify server didn't receive auth from us.\n        assert r.status_code == 200\n        assert len(r.history) == 0\n        close_server.set()\n\n\n_schemes_by_var_prefix = [\n    ('http', ['http']),\n    ('https', ['https']),\n    ('all', ['http', 'https']),\n]\n\n_proxy_combos = []\nfor prefix, schemes in _schemes_by_var_prefix:\n    for scheme in schemes:\n        _proxy_combos.append((\"{}_proxy\".format(prefix), scheme))\n\n_proxy_combos += [(var.upper(), scheme) for var, scheme in _proxy_combos]\n\n\n@pytest.mark.parametrize(\"var,scheme\", _proxy_combos)\ndef test_use_proxy_from_environment(httpbin, var, scheme):\n    url = \"{}://httpbin.org\".format(scheme)\n    fake_proxy = Server()  # do nothing with the requests; just close the socket\n    with fake_proxy as (host, port):\n        proxy_url = \"socks5://{}:{}\".format(host, port)\n        kwargs = {var: proxy_url}\n        with override_environ(**kwargs):\n            # fake proxy's lack of response will cause a ConnectionError\n            with pytest.raises(requests.exceptions.ConnectionError):\n                requests.get(url)\n\n        # the fake proxy received a request\n        assert len(fake_proxy.handler_results) == 1\n\n        # it had actual content (not checking for SOCKS protocol for now)\n        assert len(fake_proxy.handler_results[0]) > 0\n\n\ndef test_redirect_rfc1808_to_non_ascii_location():\n    path = u'\u0161'\n    expected_path = b'%C5%A1'\n    redirect_request = []  # stores the second request to the server\n\n    def redirect_resp_handler(sock):\n        consume_socket_content(sock, timeout=0.5)\n        location = u'//{}:{}/{}'.format(host, port, path)\n        sock.send(\n            b'HTTP/1.1 301 Moved Permanently\\r\\n'\n            b'Content-Length: 0\\r\\n'\n            b'Location: ' + location.encode('utf8') + b'\\r\\n'\n            b'\\r\\n'\n        )\n        redirect_request.append(consume_socket_content(sock, timeout=0.5))\n        sock.send(b'HTTP/1.1 200 OK\\r\\n\\r\\n')\n\n    close_server = threading.Event()\n    server = Server(redirect_resp_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = u'http://{}:{}'.format(host, port)\n        r = requests.get(url=url, allow_redirects=True)\n        assert r.status_code == 200\n        assert len(r.history) == 1\n        assert r.history[0].status_code == 301\n        assert redirect_request[0].startswith(b'GET /' + expected_path + b' HTTP/1.1')\n        assert r.url == u'{}/{}'.format(url, expected_path.decode('ascii'))\n\n        close_server.set()\n\ndef test_fragment_not_sent_with_request():\n    \"\"\"Verify that the fragment portion of a URI isn't sent to the server.\"\"\"\n    def response_handler(sock):\n        req = consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 200 OK\\r\\n'\n            b'Content-Length: '+bytes(len(req))+b'\\r\\n'\n            b'\\r\\n'+req\n        )\n\n    close_server = threading.Event()\n    server = Server(response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/path/to/thing/#view=edit&token=hunter2'.format(host, port)\n        r = requests.get(url)\n        raw_request = r.content\n\n        assert r.status_code == 200\n        headers, body = raw_request.split(b'\\r\\n\\r\\n', 1)\n        status_line, headers = headers.split(b'\\r\\n', 1)\n\n        assert status_line == b'GET /path/to/thing/ HTTP/1.1'\n        for frag in (b'view', b'edit', b'token', b'hunter2'):\n            assert frag not in headers\n            assert frag not in body\n\n        close_server.set()\n\ndef test_fragment_update_on_redirect():\n    \"\"\"Verify we only append previous fragment if one doesn't exist on new\n    location. If a new fragment is encountered in a Location header, it should\n    be added to all subsequent requests.\n    \"\"\"\n\n    def response_handler(sock):\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 302 FOUND\\r\\n'\n            b'Content-Length: 0\\r\\n'\n            b'Location: /get#relevant-section\\r\\n\\r\\n'\n        )\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 302 FOUND\\r\\n'\n            b'Content-Length: 0\\r\\n'\n            b'Location: /final-url/\\r\\n\\r\\n'\n        )\n        consume_socket_content(sock, timeout=0.5)\n        sock.send(\n            b'HTTP/1.1 200 OK\\r\\n\\r\\n'\n        )\n\n    close_server = threading.Event()\n    server = Server(response_handler, wait_to_close_event=close_server)\n\n    with server as (host, port):\n        url = 'http://{}:{}/path/to/thing/#view=edit&token=hunter2'.format(host, port)\n        r = requests.get(url)\n        raw_request = r.content\n\n        assert r.status_code == 200\n        assert len(r.history) == 2\n        assert r.history[0].request.url == url\n\n        # Verify we haven't overwritten the location with our previous fragment.\n        assert r.history[1].request.url == 'http://{}:{}/get#relevant-section'.format(host, port)\n        # Verify previous fragment is used and not the original.\n        assert r.url == 'http://{}:{}/final-url/#relevant-section'.format(host, port)\n\n        close_server.set()\n",
      "bug_category": "import",
      "error_type": "import_error",
      "confidence": 0.2
    },
    {
      "bug_id": "7c74667f4f56",
      "repo": "express",
      "commit_hash": "b0ed15b",
      "commit_message": "chore: fix typo (#6609)",
      "file_path": "test/res.append.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar assert = require('node:assert')\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('res', function () {\n  describe('.append(field, val)', function () {\n    it('should append multiple headers', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.append('Set-Cookie', 'foo=bar')\n        next()\n      })\n\n      app.use(function (req, res) {\n        res.append('Set-Cookie', 'fizz=buzz')\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar', 'fizz=buzz']))\n        .end(done)\n    })\n\n    it('should accept array of values', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.append('Set-Cookie', ['foo=bar', 'fizz=buzz'])\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar', 'fizz=buzz']))\n        .end(done)\n    })\n\n    it('should get reset by res.set(field, val)', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.append('Set-Cookie', 'foo=bar')\n        res.append('Set-Cookie', 'fizz=buzz')\n        next()\n      })\n\n      app.use(function (req, res) {\n        res.set('Set-Cookie', 'pet=tobi')\n        res.end()\n      });\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['pet=tobi']))\n        .end(done)\n    })\n\n    it('should work with res.set(field, val) first', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.set('Set-Cookie', 'foo=bar')\n        next()\n      })\n\n      app.use(function(req, res){\n        res.append('Set-Cookie', 'fizz=buzz')\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar', 'fizz=buzz']))\n        .end(done)\n    })\n\n    it('should work together with res.cookie', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.cookie('foo', 'bar')\n        next()\n      })\n\n      app.use(function (req, res) {\n        res.append('Set-Cookie', 'fizz=buzz')\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar; Path=/', 'fizz=buzz']))\n        .end(done)\n    })\n  })\n})\n\nfunction shouldHaveHeaderValues (key, values) {\n  return function (res) {\n    var headers = res.headers[key.toLowerCase()]\n    assert.ok(headers, 'should have header \"' + key + '\"')\n    assert.strictEqual(headers.length, values.length, 'should have ' + values.length + ' occurances of \"' + key + '\"')\n    for (var i = 0; i < values.length; i++) {\n      assert.strictEqual(headers[i], values[i])\n    }\n  }\n}\n",
      "code_after": "'use strict'\n\nvar assert = require('node:assert')\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('res', function () {\n  describe('.append(field, val)', function () {\n    it('should append multiple headers', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.append('Set-Cookie', 'foo=bar')\n        next()\n      })\n\n      app.use(function (req, res) {\n        res.append('Set-Cookie', 'fizz=buzz')\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar', 'fizz=buzz']))\n        .end(done)\n    })\n\n    it('should accept array of values', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.append('Set-Cookie', ['foo=bar', 'fizz=buzz'])\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar', 'fizz=buzz']))\n        .end(done)\n    })\n\n    it('should get reset by res.set(field, val)', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.append('Set-Cookie', 'foo=bar')\n        res.append('Set-Cookie', 'fizz=buzz')\n        next()\n      })\n\n      app.use(function (req, res) {\n        res.set('Set-Cookie', 'pet=tobi')\n        res.end()\n      });\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['pet=tobi']))\n        .end(done)\n    })\n\n    it('should work with res.set(field, val) first', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.set('Set-Cookie', 'foo=bar')\n        next()\n      })\n\n      app.use(function(req, res){\n        res.append('Set-Cookie', 'fizz=buzz')\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar', 'fizz=buzz']))\n        .end(done)\n    })\n\n    it('should work together with res.cookie', function (done) {\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.cookie('foo', 'bar')\n        next()\n      })\n\n      app.use(function (req, res) {\n        res.append('Set-Cookie', 'fizz=buzz')\n        res.end()\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect(shouldHaveHeaderValues('Set-Cookie', ['foo=bar; Path=/', 'fizz=buzz']))\n        .end(done)\n    })\n  })\n})\n\nfunction shouldHaveHeaderValues (key, values) {\n  return function (res) {\n    var headers = res.headers[key.toLowerCase()]\n    assert.ok(headers, 'should have header \"' + key + '\"')\n    assert.strictEqual(headers.length, values.length, 'should have ' + values.length + ' occurrences of \"' + key + '\"')\n    for (var i = 0; i < values.length; i++) {\n      assert.strictEqual(headers[i], values[i])\n    }\n  }\n}\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "680e30cae8c9",
      "repo": "express",
      "commit_hash": "b8ab465",
      "commit_message": "test: add coverage for app.listen() variants (#6476)",
      "file_path": "test/app.listen.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar express = require('../')\nvar assert = require('node:assert')\n\ndescribe('app.listen()', function(){\n  it('should wrap with an HTTP server', function(done){\n    var app = express();\n\n    var server = app.listen(0, function () {\n      server.close(done)\n    });\n  })\n  it('should callback on HTTP server errors', function (done) {\n    var app1 = express()\n    var app2 = express()\n\n    var server1 = app1.listen(0, function (err) {\n      assert(!err)\n      app2.listen(server1.address().port, function (err) {\n        assert(err.code === 'EADDRINUSE')\n        server1.close()\n        done()\n      })\n    })\n  })\n})\n",
      "code_after": "'use strict'\n\nvar express = require('../')\nvar assert = require('node:assert')\n\ndescribe('app.listen()', function(){\n  it('should wrap with an HTTP server', function(done){\n    var app = express();\n\n    var server = app.listen(0, function () {\n      server.close(done)\n    });\n  })\n  it('should callback on HTTP server errors', function (done) {\n    var app1 = express()\n    var app2 = express()\n\n    var server1 = app1.listen(0, function (err) {\n      assert(!err)\n      app2.listen(server1.address().port, function (err) {\n        assert(err.code === 'EADDRINUSE')\n        server1.close()\n        done()\n      })\n    })\n  })\n  it('accepts port + hostname + backlog + callback', function (done) {\n    const app = express();\n    const server = app.listen(0, '127.0.0.1', 5, function () {\n      const { address, port } = server.address();\n      assert.strictEqual(address, '127.0.0.1');\n      assert(Number.isInteger(port) && port > 0);\n      // backlog isn\u2019t directly inspectable, but if no error was thrown\n      // we know it was accepted.\n      server.close(done);\n    });\n  });\n  it('accepts just a callback (no args)', function (done) {\n    const app = express();\n    // same as app.listen(0, done)\n    const server = app.listen();\n    server.close(done);\n  });\n  it('server.address() gives a { address, port, family } object', function (done) {\n    const app = express();\n    const server = app.listen(0, () => {\n      const addr = server.address();\n      assert(addr && typeof addr === 'object');\n      assert.strictEqual(typeof addr.address, 'string');\n      assert(Number.isInteger(addr.port) && addr.port > 0);\n      assert(typeof addr.family === 'string');\n      server.close(done);\n    });\n  });\n})\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "838cab46b72e",
      "repo": "express",
      "commit_hash": "dfd1851",
      "commit_message": "test: fix typos in test descriptions (#6535)",
      "file_path": "test/express.json.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.json()', function () {\n  it('should parse JSON', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('{\"user\":\"tobi\"}')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .set('Content-Length', '0')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .set('Transfer-Encoding', 'chunked')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle no message-body', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .unset('Transfer-Encoding')\n      .expect(200, '{}', done)\n  })\n\n  // The old node error message modification in body parser is catching this\n  it('should 400 when only whitespace', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('  \\n')\n      .expect(400, '[entity.parse.failed] ' + parseError(' \\n'), done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.json())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('{\"str\":')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.json())\n    app.use(express.json())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('{\"user\":\"tobi\"}')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  describe('when JSON is invalid', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should 400 for bad token', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{:')\n        .expect(400, '[entity.parse.failed] ' + parseError('{:'), done)\n    })\n\n    it('should 400 for incomplete', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\"')\n        .expect(400, '[entity.parse.failed] ' + parseError('{\"user\"'), done)\n    })\n\n    it('should include original body on error object', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .set('X-Error-Property', 'body')\n        .send(' {\"user\"')\n        .expect(400, ' {\"user\"', done)\n    })\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: '1kb' }))\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .set('Content-Length', '1034')\n        .send(JSON.stringify({ str: buf.toString() }))\n        .expect(413, '[entity.too.large] request entity too large', done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var buf = Buffer.alloc(1024, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write('{\"str\":')\n      test.write('\"' + buf.toString() + '\"}')\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000aab562a2e2952b252d21b05a360148c58a0540b0066f7ce1e0a040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: 1024 }))\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send(JSON.stringify({ str: buf.toString() }))\n        .expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send(JSON.stringify({ str: buf.toString() }))\n        .expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var buf = Buffer.alloc(10240, '.')\n      var app = createApp({ limit: '8kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000aab562a2e2952b252d21b05a360148c58a0540b0066f7ce1e0a0400', 'hex'))\n      test.expect(413, done)\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/json')\n        test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/json')\n        test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n        test.expect(200, '{\"name\":\"\u8bba\"}', done)\n      })\n    })\n  })\n\n  describe('with strict option', function () {\n    describe('when undefined', function () {\n      before(function () {\n        this.app = createApp()\n      })\n\n      it('should 400 on primitives', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('true')\n          .expect(400, '[entity.parse.failed] ' + parseError('#rue').replace(/#/g, 't'), done)\n      })\n    })\n\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ strict: false })\n      })\n\n      it('should parse primitives', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('true')\n          .expect(200, 'true', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ strict: true })\n      })\n\n      it('should not parse primitives', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('true')\n          .expect(400, '[entity.parse.failed] ' + parseError('#rue').replace(/#/g, 't'), done)\n      })\n\n      it('should not parse primitives with leading whitespaces', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('    true')\n          .expect(400, '[entity.parse.failed] ' + parseError('    #rue').replace(/#/g, 't'), done)\n      })\n\n      it('should allow leading whitespaces in JSON', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('   { \"user\": \"tobi\" }')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should include correct message in stack trace', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .set('X-Error-Property', 'stack')\n          .send('true')\n          .expect(400)\n          .expect(shouldContainInBody(parseError('#rue').replace(/#/g, 't')))\n          .end(done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"application/vnd.api+json\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'application/vnd.api+json' })\n      })\n\n      it('should parse JSON for custom type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.api+json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore standard type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when [\"application/json\", \"application/vnd.api+json\"]', function () {\n      before(function () {\n        this.app = createApp({\n          type: ['application/json', 'application/vnd.api+json']\n        })\n      })\n\n      it('should parse JSON for \"application/json\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should parse JSON for \"application/vnd.api+json\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.api+json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore \"application/x-json\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'application/vnd.api+json'\n        }\n\n        request(app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.api+json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write('{\"user\":\"tobi\"}')\n        test.expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value if function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('[\"tobi\"]')\n        .expect(403, '[entity.verify.failed] no arrays', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x5b) return\n          var err = new Error('no arrays')\n          err.status = 400\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('[\"tobi\"]')\n        .expect(400, '[entity.verify.failed] no arrays', done)\n    })\n\n    it('should allow custom type', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x5b) return\n          var err = new Error('no arrays')\n          err.type = 'foo.bar'\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('[\"tobi\"]')\n        .expect(403, '[foo.bar] no arrays', done)\n    })\n\n    it('should include original body on error object', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .set('X-Error-Property', 'body')\n        .send('[\"tobi\"]')\n        .expect(403, '[\"tobi\"]', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":\"tobi\"}')\n        .expect(200, '{\"user\":\"tobi\"}', done)\n    })\n\n    it('should work with different charsets', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-16')\n      test.write(Buffer.from('feff007b0022006e0061006d00650022003a00228bba0022007d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should 415 on unknown charset prior to verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          throw new Error('unexpected verify call')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.json())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        res.json(req.body)\n      })\n\n      this.app = app\n    })\n\n    it('should presist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":\"tobi\"}')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('{\"user\":\"tobi\"}')\n        .end(done)\n    })\n\n    it('should persist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('')\n        .end(done)\n    })\n\n    it('should presist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect('{\"name\":\"\u8bba\"}')\n      test.end(done)\n    })\n\n    it('should presist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56cc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should presist store when parse error', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":')\n        .expect(400)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should presist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":\"' + Buffer.alloc(1024 * 100, '.').toString() + '\"}')\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should parse utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-8')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should parse utf-16', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-16')\n      test.write(Buffer.from('feff007b0022006e0061006d00650022003a00228bba0022007d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should parse when content-length != char length', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-8')\n      test.set('Content-Length', '13')\n      test.write(Buffer.from('7b2274657374223a22c3a5227d', 'hex'))\n      test.expect(200, '{\"test\":\"\u00e5\"}', done)\n    })\n\n    it('should default to utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should fail on unknown charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=koi8-r')\n      test.write(Buffer.from('7b226e616d65223a22cec5d4227d', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"KOI8-R\"', done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '1kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('789cab56ca4bcc4d55b2527ab16e97522d00274505ac', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n\n    it('should 400 on malformed encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56cc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(400, done)\n    })\n\n    it('should 413 when inflated value exceeds limit', function (done) {\n      // gzip'd data exceeds 1kb, but deflated below 1kb\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bedc1010d000000c2a0f74f6d0f071400000000000000', 'hex'))\n      test.write(Buffer.from('0000000000000000000000000000000000000000000000000000000000000000', 'hex'))\n      test.write(Buffer.from('0000000000000000004f0625b3b71650c30000', 'hex'))\n      test.expect(413, done)\n    })\n  })\n})\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.json(options))\n\n  app.use(function (err, req, res, next) {\n    // console.log(err)\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    res.json(req.body)\n  })\n\n  return app\n}\n\nfunction parseError (str) {\n  try {\n    JSON.parse(str); throw new SyntaxError('strict violation')\n  } catch (e) {\n    return e.message\n  }\n}\n\nfunction shouldContainInBody (str) {\n  return function (res) {\n    assert.ok(res.text.indexOf(str) !== -1,\n      'expected \\'' + res.text + '\\' to contain \\'' + str + '\\'')\n  }\n}\n",
      "code_after": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.json()', function () {\n  it('should parse JSON', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('{\"user\":\"tobi\"}')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .set('Content-Length', '0')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .set('Transfer-Encoding', 'chunked')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle no message-body', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .unset('Transfer-Encoding')\n      .expect(200, '{}', done)\n  })\n\n  // The old node error message modification in body parser is catching this\n  it('should 400 when only whitespace', function (done) {\n    request(createApp())\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('  \\n')\n      .expect(400, '[entity.parse.failed] ' + parseError(' \\n'), done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.json())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('{\"str\":')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.json())\n    app.use(express.json())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/json')\n      .send('{\"user\":\"tobi\"}')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  describe('when JSON is invalid', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should 400 for bad token', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{:')\n        .expect(400, '[entity.parse.failed] ' + parseError('{:'), done)\n    })\n\n    it('should 400 for incomplete', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\"')\n        .expect(400, '[entity.parse.failed] ' + parseError('{\"user\"'), done)\n    })\n\n    it('should include original body on error object', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .set('X-Error-Property', 'body')\n        .send(' {\"user\"')\n        .expect(400, ' {\"user\"', done)\n    })\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: '1kb' }))\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .set('Content-Length', '1034')\n        .send(JSON.stringify({ str: buf.toString() }))\n        .expect(413, '[entity.too.large] request entity too large', done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var buf = Buffer.alloc(1024, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write('{\"str\":')\n      test.write('\"' + buf.toString() + '\"}')\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000aab562a2e2952b252d21b05a360148c58a0540b0066f7ce1e0a040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: 1024 }))\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send(JSON.stringify({ str: buf.toString() }))\n        .expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send(JSON.stringify({ str: buf.toString() }))\n        .expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var buf = Buffer.alloc(10240, '.')\n      var app = createApp({ limit: '8kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000aab562a2e2952b252d21b05a360148c58a0540b0066f7ce1e0a0400', 'hex'))\n      test.expect(413, done)\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/json')\n        test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/json')\n        test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n        test.expect(200, '{\"name\":\"\u8bba\"}', done)\n      })\n    })\n  })\n\n  describe('with strict option', function () {\n    describe('when undefined', function () {\n      before(function () {\n        this.app = createApp()\n      })\n\n      it('should 400 on primitives', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('true')\n          .expect(400, '[entity.parse.failed] ' + parseError('#rue').replace(/#/g, 't'), done)\n      })\n    })\n\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ strict: false })\n      })\n\n      it('should parse primitives', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('true')\n          .expect(200, 'true', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ strict: true })\n      })\n\n      it('should not parse primitives', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('true')\n          .expect(400, '[entity.parse.failed] ' + parseError('#rue').replace(/#/g, 't'), done)\n      })\n\n      it('should not parse primitives with leading whitespaces', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('    true')\n          .expect(400, '[entity.parse.failed] ' + parseError('    #rue').replace(/#/g, 't'), done)\n      })\n\n      it('should allow leading whitespaces in JSON', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('   { \"user\": \"tobi\" }')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should include correct message in stack trace', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .set('X-Error-Property', 'stack')\n          .send('true')\n          .expect(400)\n          .expect(shouldContainInBody(parseError('#rue').replace(/#/g, 't')))\n          .end(done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"application/vnd.api+json\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'application/vnd.api+json' })\n      })\n\n      it('should parse JSON for custom type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.api+json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore standard type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when [\"application/json\", \"application/vnd.api+json\"]', function () {\n      before(function () {\n        this.app = createApp({\n          type: ['application/json', 'application/vnd.api+json']\n        })\n      })\n\n      it('should parse JSON for \"application/json\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should parse JSON for \"application/vnd.api+json\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.api+json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore \"application/x-json\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'application/vnd.api+json'\n        }\n\n        request(app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.api+json')\n          .send('{\"user\":\"tobi\"}')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write('{\"user\":\"tobi\"}')\n        test.expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value if function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('[\"tobi\"]')\n        .expect(403, '[entity.verify.failed] no arrays', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x5b) return\n          var err = new Error('no arrays')\n          err.status = 400\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('[\"tobi\"]')\n        .expect(400, '[entity.verify.failed] no arrays', done)\n    })\n\n    it('should allow custom type', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x5b) return\n          var err = new Error('no arrays')\n          err.type = 'foo.bar'\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('[\"tobi\"]')\n        .expect(403, '[foo.bar] no arrays', done)\n    })\n\n    it('should include original body on error object', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .set('X-Error-Property', 'body')\n        .send('[\"tobi\"]')\n        .expect(403, '[\"tobi\"]', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":\"tobi\"}')\n        .expect(200, '{\"user\":\"tobi\"}', done)\n    })\n\n    it('should work with different charsets', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-16')\n      test.write(Buffer.from('feff007b0022006e0061006d00650022003a00228bba0022007d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should 415 on unknown charset prior to verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          throw new Error('unexpected verify call')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/json; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.json())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        res.json(req.body)\n      })\n\n      this.app = app\n    })\n\n    it('should persist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":\"tobi\"}')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('{\"user\":\"tobi\"}')\n        .end(done)\n    })\n\n    it('should persist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('')\n        .end(done)\n    })\n\n    it('should persist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect('{\"name\":\"\u8bba\"}')\n      test.end(done)\n    })\n\n    it('should persist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56cc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should persist store when parse error', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":')\n        .expect(400)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should persist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/json')\n        .send('{\"user\":\"' + Buffer.alloc(1024 * 100, '.').toString() + '\"}')\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should parse utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-8')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should parse utf-16', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-16')\n      test.write(Buffer.from('feff007b0022006e0061006d00650022003a00228bba0022007d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should parse when content-length != char length', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=utf-8')\n      test.set('Content-Length', '13')\n      test.write(Buffer.from('7b2274657374223a22c3a5227d', 'hex'))\n      test.expect(200, '{\"test\":\"\u00e5\"}', done)\n    })\n\n    it('should default to utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should fail on unknown charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json; charset=koi8-r')\n      test.write(Buffer.from('7b226e616d65223a22cec5d4227d', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"KOI8-R\"', done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '1kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('7b226e616d65223a22e8aeba227d', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('789cab56ca4bcc4d55b2527ab16e97522d00274505ac', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56ca4bcc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n\n    it('should 400 on malformed encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bab56cc4d55b2527ab16e97522d00515be1cc0e000000', 'hex'))\n      test.expect(400, done)\n    })\n\n    it('should 413 when inflated value exceeds limit', function (done) {\n      // gzip'd data exceeds 1kb, but deflated below 1kb\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/json')\n      test.write(Buffer.from('1f8b080000000000000bedc1010d000000c2a0f74f6d0f071400000000000000', 'hex'))\n      test.write(Buffer.from('0000000000000000000000000000000000000000000000000000000000000000', 'hex'))\n      test.write(Buffer.from('0000000000000000004f0625b3b71650c30000', 'hex'))\n      test.expect(413, done)\n    })\n  })\n})\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.json(options))\n\n  app.use(function (err, req, res, next) {\n    // console.log(err)\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    res.json(req.body)\n  })\n\n  return app\n}\n\nfunction parseError (str) {\n  try {\n    JSON.parse(str); throw new SyntaxError('strict violation')\n  } catch (e) {\n    return e.message\n  }\n}\n\nfunction shouldContainInBody (str) {\n  return function (res) {\n    assert.ok(res.text.indexOf(str) !== -1,\n      'expected \\'' + res.text + '\\' to contain \\'' + str + '\\'')\n  }\n}\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "184deab37d53",
      "repo": "express",
      "commit_hash": "dfd1851",
      "commit_message": "test: fix typos in test descriptions (#6535)",
      "file_path": "test/express.raw.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.raw()', function () {\n  before(function () {\n    this.app = createApp()\n  })\n\n  it('should parse application/octet-stream', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .send('the user is tobi')\n      .expect(200, { buf: '746865207573657220697320746f6269' }, done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.raw())\n\n    app.post('/', function (req, res) {\n      if (Buffer.isBuffer(req.body)) {\n        res.json({ buf: req.body.toString('hex') })\n      } else {\n        res.json(req.body)\n      }\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .send('stuff')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .set('Content-Length', '0')\n      .expect(200, { buf: '' }, done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .set('Transfer-Encoding', 'chunked')\n      .send('')\n      .expect(200, { buf: '' }, done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.raw())\n    app.use(express.raw())\n\n    app.post('/', function (req, res) {\n      if (Buffer.isBuffer(req.body)) {\n        res.json({ buf: req.body.toString('hex') })\n      } else {\n        res.json(req.body)\n      }\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .send('the user is tobi')\n      .expect(200, { buf: '746865207573657220697320746f6269' }, done)\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.set('Content-Length', '1028')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a14704040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var app = createApp({ limit: 1024 })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var buf = Buffer.alloc(10240, '.')\n      var app = createApp({ limit: '8kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a147040400', 'hex'))\n      test.expect(413, done)\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(200, { buf: '6e616d653de8aeba' }, done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"application/vnd+octets\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'application/vnd+octets' })\n      })\n\n      it('should parse for custom type', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/vnd+octets')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should ignore standard type', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, '', done)\n      })\n    })\n\n    describe('when [\"application/octet-stream\", \"application/vnd+octets\"]', function () {\n      before(function () {\n        this.app = createApp({\n          type: ['application/octet-stream', 'application/vnd+octets']\n        })\n      })\n\n      it('should parse \"application/octet-stream\"', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should parse \"application/vnd+octets\"', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/vnd+octets')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should ignore \"application/x-foo\"', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/x-foo')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'application/vnd.octet'\n        }\n\n        var test = request(app).post('/')\n        test.set('Content-Type', 'application/vnd.octet')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value is function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x00) throw new Error('no leading null')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('000102', 'hex'))\n      test.expect(403, '[entity.verify.failed] no leading null', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x00) return\n          var err = new Error('no leading null')\n          err.status = 400\n          throw err\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('000102', 'hex'))\n      test.expect(400, '[entity.verify.failed] no leading null', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x00) throw new Error('no leading null')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('0102', 'hex'))\n      test.expect(200, { buf: '0102' }, done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.raw())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        if (Buffer.isBuffer(req.body)) {\n          res.json({ buf: req.body.toString('hex') })\n        } else {\n          res.json(req.body)\n        }\n      })\n\n      this.app = app\n    })\n\n    it('should presist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/octet-stream')\n        .send('the user is tobi')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect({ buf: '746865207573657220697320746f6269' })\n        .end(done)\n    })\n\n    it('should presist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should presist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect({ buf: '6e616d653de8aeba' })\n      test.end(done)\n    })\n\n    it('should presist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad6080000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should presist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/octet-stream')\n        .send('the user is ' + Buffer.alloc(1024 * 100, '.').toString())\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should ignore charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/octet-stream; charset=utf-8')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, { buf: '6e616d6520697320e8aeba' }, done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '10kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('789ccb4bcc4db57db16e17001068042f', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n  })\n})\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.raw(options))\n\n  app.use(function (err, req, res, next) {\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    if (Buffer.isBuffer(req.body)) {\n      res.json({ buf: req.body.toString('hex') })\n    } else {\n      res.json(req.body)\n    }\n  })\n\n  return app\n}\n",
      "code_after": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.raw()', function () {\n  before(function () {\n    this.app = createApp()\n  })\n\n  it('should parse application/octet-stream', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .send('the user is tobi')\n      .expect(200, { buf: '746865207573657220697320746f6269' }, done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.raw())\n\n    app.post('/', function (req, res) {\n      if (Buffer.isBuffer(req.body)) {\n        res.json({ buf: req.body.toString('hex') })\n      } else {\n        res.json(req.body)\n      }\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .send('stuff')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .set('Content-Length', '0')\n      .expect(200, { buf: '' }, done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .set('Transfer-Encoding', 'chunked')\n      .send('')\n      .expect(200, { buf: '' }, done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.raw())\n    app.use(express.raw())\n\n    app.post('/', function (req, res) {\n      if (Buffer.isBuffer(req.body)) {\n        res.json({ buf: req.body.toString('hex') })\n      } else {\n        res.json(req.body)\n      }\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/octet-stream')\n      .send('the user is tobi')\n      .expect(200, { buf: '746865207573657220697320746f6269' }, done)\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.set('Content-Length', '1028')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a14704040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var app = createApp({ limit: 1024 })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var buf = Buffer.alloc(10240, '.')\n      var app = createApp({ limit: '8kb' })\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a147040400', 'hex'))\n      test.expect(413, done)\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(200, { buf: '6e616d653de8aeba' }, done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"application/vnd+octets\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'application/vnd+octets' })\n      })\n\n      it('should parse for custom type', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/vnd+octets')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should ignore standard type', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, '', done)\n      })\n    })\n\n    describe('when [\"application/octet-stream\", \"application/vnd+octets\"]', function () {\n      before(function () {\n        this.app = createApp({\n          type: ['application/octet-stream', 'application/vnd+octets']\n        })\n      })\n\n      it('should parse \"application/octet-stream\"', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/octet-stream')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should parse \"application/vnd+octets\"', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/vnd+octets')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should ignore \"application/x-foo\"', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Type', 'application/x-foo')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'application/vnd.octet'\n        }\n\n        var test = request(app).post('/')\n        test.set('Content-Type', 'application/vnd.octet')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write(Buffer.from('000102', 'hex'))\n        test.expect(200, { buf: '000102' }, done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value is function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x00) throw new Error('no leading null')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('000102', 'hex'))\n      test.expect(403, '[entity.verify.failed] no leading null', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x00) return\n          var err = new Error('no leading null')\n          err.status = 400\n          throw err\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('000102', 'hex'))\n      test.expect(400, '[entity.verify.failed] no leading null', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x00) throw new Error('no leading null')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('0102', 'hex'))\n      test.expect(200, { buf: '0102' }, done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.raw())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        if (Buffer.isBuffer(req.body)) {\n          res.json({ buf: req.body.toString('hex') })\n        } else {\n          res.json(req.body)\n        }\n      })\n\n      this.app = app\n    })\n\n    it('should persist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/octet-stream')\n        .send('the user is tobi')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect({ buf: '746865207573657220697320746f6269' })\n        .end(done)\n    })\n\n    it('should persist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should persist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect({ buf: '6e616d653de8aeba' })\n      test.end(done)\n    })\n\n    it('should persist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad6080000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should persist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/octet-stream')\n        .send('the user is ' + Buffer.alloc(1024 * 100, '.').toString())\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should ignore charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/octet-stream; charset=utf-8')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, { buf: '6e616d6520697320e8aeba' }, done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '10kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('789ccb4bcc4db57db16e17001068042f', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, { buf: '6e616d653de8aeba' }, done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'application/octet-stream')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n  })\n})\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.raw(options))\n\n  app.use(function (err, req, res, next) {\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    if (Buffer.isBuffer(req.body)) {\n      res.json({ buf: req.body.toString('hex') })\n    } else {\n      res.json(req.body)\n    }\n  })\n\n  return app\n}\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "cbb23fc17941",
      "repo": "express",
      "commit_hash": "dfd1851",
      "commit_message": "test: fix typos in test descriptions (#6535)",
      "file_path": "test/express.text.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.text()', function () {\n  before(function () {\n    this.app = createApp()\n  })\n\n  it('should parse text/plain', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .send('user is tobi')\n      .expect(200, '\"user is tobi\"', done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.text())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .send('user')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(createApp({ limit: '1kb' }))\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .set('Content-Length', '0')\n      .expect(200, '\"\"', done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(createApp({ limit: '1kb' }))\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .set('Transfer-Encoding', 'chunked')\n      .send('')\n      .expect(200, '\"\"', done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.text())\n    app.use(express.text())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .send('user is tobi')\n      .expect(200, '\"user is tobi\"', done)\n  })\n\n  describe('with defaultCharset option', function () {\n    it('should change default charset', function (done) {\n      var server = createApp({ defaultCharset: 'koi8-r' })\n      var test = request(server).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320cec5d4', 'hex'))\n      test.expect(200, '\"name is \u043d\u0435\u0442\"', done)\n    })\n\n    it('should honor content-type charset', function (done) {\n      var server = createApp({ defaultCharset: 'koi8-r' })\n      var test = request(server).post('/')\n      test.set('Content-Type', 'text/plain; charset=utf-8')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      request(createApp({ limit: '1kb' }))\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .set('Content-Length', '1028')\n        .send(buf.toString())\n        .expect(413, done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var buf = Buffer.alloc(1028, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write(buf.toString())\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a14704040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      request(createApp({ limit: 1024 }))\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var app = createApp({ limit: '8kb' })\n      var buf = Buffer.alloc(10240, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a1470404', 'hex'))\n      setTimeout(function () {\n        test.expect(413, done)\n      }, 100)\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'text/plain')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'text/plain')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n        test.expect(200, '\"name is \u8bba\"', done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"text/html\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'text/html' })\n      })\n\n      it('should parse for custom type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/html')\n          .send('<b>tobi</b>')\n          .expect(200, '\"<b>tobi</b>\"', done)\n      })\n\n      it('should ignore standard type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/plain')\n          .send('user is tobi')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when [\"text/html\", \"text/plain\"]', function () {\n      before(function () {\n        this.app = createApp({ type: ['text/html', 'text/plain'] })\n      })\n\n      it('should parse \"text/html\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/html')\n          .send('<b>tobi</b>')\n          .expect(200, '\"<b>tobi</b>\"', done)\n      })\n\n      it('should parse \"text/plain\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/plain')\n          .send('tobi')\n          .expect(200, '\"tobi\"', done)\n      })\n\n      it('should ignore \"text/xml\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/xml')\n          .send('<user>tobi</user>')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'text/vnd.something'\n        }\n\n        request(app)\n          .post('/')\n          .set('Content-Type', 'text/vnd.something')\n          .send('user is tobi')\n          .expect(200, '\"user is tobi\"', done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write('user is tobi')\n        test.expect(200, '\"user is tobi\"', done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value is function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x20) throw new Error('no leading space')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(' user is tobi')\n        .expect(403, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x20) return\n          var err = new Error('no leading space')\n          err.status = 400\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(' user is tobi')\n        .expect(400, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x20) throw new Error('no leading space')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send('user is tobi')\n        .expect(200, '\"user is tobi\"', done)\n    })\n\n    it('should 415 on unknown charset prior to verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          throw new Error('unexpected verify call')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'text/plain; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.text())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        res.json(req.body)\n      })\n\n      this.app = app\n    })\n\n    it('should presist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send('user is tobi')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('\"user is tobi\"')\n        .end(done)\n    })\n\n    it('should presist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should presist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect('\"name is \u8bba\"')\n      test.end(done)\n    })\n\n    it('should presist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b0000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should presist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send('user is ' + Buffer.alloc(1024 * 100, '.').toString())\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should parse utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=utf-8')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should parse codepage charsets', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=koi8-r')\n      test.write(Buffer.from('6e616d6520697320cec5d4', 'hex'))\n      test.expect(200, '\"name is \u043d\u0435\u0442\"', done)\n    })\n\n    it('should parse when content-length != char length', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=utf-8')\n      test.set('Content-Length', '11')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should default to utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should 415 on unknown charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '10kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('789ccb4bcc4d55c82c5678b16e17001a6f050e', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n  })\n})\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.text(options))\n\n  app.use(function (err, req, res, next) {\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    res.json(req.body)\n  })\n\n  return app\n}\n",
      "code_after": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.text()', function () {\n  before(function () {\n    this.app = createApp()\n  })\n\n  it('should parse text/plain', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .send('user is tobi')\n      .expect(200, '\"user is tobi\"', done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.text())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .send('user')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(createApp({ limit: '1kb' }))\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .set('Content-Length', '0')\n      .expect(200, '\"\"', done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(createApp({ limit: '1kb' }))\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .set('Transfer-Encoding', 'chunked')\n      .send('')\n      .expect(200, '\"\"', done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.text())\n    app.use(express.text())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'text/plain')\n      .send('user is tobi')\n      .expect(200, '\"user is tobi\"', done)\n  })\n\n  describe('with defaultCharset option', function () {\n    it('should change default charset', function (done) {\n      var server = createApp({ defaultCharset: 'koi8-r' })\n      var test = request(server).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320cec5d4', 'hex'))\n      test.expect(200, '\"name is \u043d\u0435\u0442\"', done)\n    })\n\n    it('should honor content-type charset', function (done) {\n      var server = createApp({ defaultCharset: 'koi8-r' })\n      var test = request(server).post('/')\n      test.set('Content-Type', 'text/plain; charset=utf-8')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      request(createApp({ limit: '1kb' }))\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .set('Content-Length', '1028')\n        .send(buf.toString())\n        .expect(413, done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var buf = Buffer.alloc(1028, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write(buf.toString())\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a14704040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      request(createApp({ limit: 1024 }))\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1028, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var app = createApp({ limit: '8kb' })\n      var buf = Buffer.alloc(10240, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000ad3d31b05a360148c64000087e5a1470404', 'hex'))\n      setTimeout(function () {\n        test.expect(413, done)\n      }, 100)\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'text/plain')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'text/plain')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n        test.expect(200, '\"name is \u8bba\"', done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"text/html\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'text/html' })\n      })\n\n      it('should parse for custom type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/html')\n          .send('<b>tobi</b>')\n          .expect(200, '\"<b>tobi</b>\"', done)\n      })\n\n      it('should ignore standard type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/plain')\n          .send('user is tobi')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when [\"text/html\", \"text/plain\"]', function () {\n      before(function () {\n        this.app = createApp({ type: ['text/html', 'text/plain'] })\n      })\n\n      it('should parse \"text/html\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/html')\n          .send('<b>tobi</b>')\n          .expect(200, '\"<b>tobi</b>\"', done)\n      })\n\n      it('should parse \"text/plain\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/plain')\n          .send('tobi')\n          .expect(200, '\"tobi\"', done)\n      })\n\n      it('should ignore \"text/xml\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'text/xml')\n          .send('<user>tobi</user>')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'text/vnd.something'\n        }\n\n        request(app)\n          .post('/')\n          .set('Content-Type', 'text/vnd.something')\n          .send('user is tobi')\n          .expect(200, '\"user is tobi\"', done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write('user is tobi')\n        test.expect(200, '\"user is tobi\"', done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value is function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x20) throw new Error('no leading space')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(' user is tobi')\n        .expect(403, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x20) return\n          var err = new Error('no leading space')\n          err.status = 400\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send(' user is tobi')\n        .expect(400, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x20) throw new Error('no leading space')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send('user is tobi')\n        .expect(200, '\"user is tobi\"', done)\n    })\n\n    it('should 415 on unknown charset prior to verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          throw new Error('unexpected verify call')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'text/plain; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.text())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        res.json(req.body)\n      })\n\n      this.app = app\n    })\n\n    it('should persist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send('user is tobi')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('\"user is tobi\"')\n        .end(done)\n    })\n\n    it('should persist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should persist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect('\"name is \u8bba\"')\n      test.end(done)\n    })\n\n    it('should persist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b0000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should persist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'text/plain')\n        .send('user is ' + Buffer.alloc(1024 * 100, '.').toString())\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should parse utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=utf-8')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should parse codepage charsets', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=koi8-r')\n      test.write(Buffer.from('6e616d6520697320cec5d4', 'hex'))\n      test.expect(200, '\"name is \u043d\u0435\u0442\"', done)\n    })\n\n    it('should parse when content-length != char length', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=utf-8')\n      test.set('Content-Length', '11')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should default to utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should 415 on unknown charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '10kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('6e616d6520697320e8aeba', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('789ccb4bcc4d55c82c5678b16e17001a6f050e', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4d55c82c5678b16e170072b3e0200b000000', 'hex'))\n      test.expect(200, '\"name is \u8bba\"', done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'text/plain')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n  })\n})\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.text(options))\n\n  app.use(function (err, req, res, next) {\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    res.json(req.body)\n  })\n\n  return app\n}\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "9ea5b9e705e4",
      "repo": "express",
      "commit_hash": "dfd1851",
      "commit_message": "test: fix typos in test descriptions (#6535)",
      "file_path": "test/express.urlencoded.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.urlencoded()', function () {\n  before(function () {\n    this.app = createApp()\n  })\n\n  it('should parse x-www-form-urlencoded', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('user=tobi')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.urlencoded())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('str=')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .set('Content-Length', '0')\n      .send('')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(createApp({ limit: '1kb' }))\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .set('Transfer-Encoding', 'chunked')\n      .send('')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.urlencoded())\n    app.use(express.urlencoded())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('user=tobi')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  it('should not parse extended syntax', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('user[name][first]=Tobi')\n      .expect(200, '{\"user[name][first]\":\"Tobi\"}', done)\n  })\n\n  describe('with extended option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ extended: false })\n      })\n\n      it('should not parse extended syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user[name][first]=Tobi')\n          .expect(200, '{\"user[name][first]\":\"Tobi\"}', done)\n      })\n\n      it('should parse multiple key instances', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=Tobi&user=Loki')\n          .expect(200, '{\"user\":[\"Tobi\",\"Loki\"]}', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ extended: true })\n      })\n\n      it('should parse multiple key instances', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=Tobi&user=Loki')\n          .expect(200, '{\"user\":[\"Tobi\",\"Loki\"]}', done)\n      })\n\n      it('should parse extended syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user[name][first]=Tobi')\n          .expect(200, '{\"user\":{\"name\":{\"first\":\"Tobi\"}}}', done)\n      })\n\n      it('should parse parameters with dots', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user.name=Tobi')\n          .expect(200, '{\"user.name\":\"Tobi\"}', done)\n      })\n\n      it('should parse fully-encoded extended syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user%5Bname%5D%5Bfirst%5D=Tobi')\n          .expect(200, '{\"user\":{\"name\":{\"first\":\"Tobi\"}}}', done)\n      })\n\n      it('should parse array index notation', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('foo[0]=bar&foo[1]=baz')\n          .expect(200, '{\"foo\":[\"bar\",\"baz\"]}', done)\n      })\n\n      it('should parse array index notation with large array', function (done) {\n        var str = 'f[0]=0'\n\n        for (var i = 1; i < 500; i++) {\n          str += '&f[' + i + ']=' + i.toString(16)\n        }\n\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(str)\n          .expect(function (res) {\n            var obj = JSON.parse(res.text)\n            assert.strictEqual(Object.keys(obj).length, 1)\n            assert.strictEqual(Array.isArray(obj.f), true)\n            assert.strictEqual(obj.f.length, 500)\n          })\n          .expect(200, done)\n      })\n\n      it('should parse array of objects syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('foo[0][bar]=baz&foo[0][fizz]=buzz&foo[]=done!')\n          .expect(200, '{\"foo\":[{\"bar\":\"baz\",\"fizz\":\"buzz\"},\"done!\"]}', done)\n      })\n\n      it('should parse deep object', function (done) {\n        var str = 'foo'\n\n        for (var i = 0; i < 32; i++) {\n          str += '[p]'\n        }\n\n        str += '=bar'\n\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(str)\n          .expect(function (res) {\n            var obj = JSON.parse(res.text)\n            assert.strictEqual(Object.keys(obj).length, 1)\n            assert.strictEqual(typeof obj.foo, 'object')\n\n            var depth = 0\n            var ref = obj.foo\n            while ((ref = ref.p)) { depth++ }\n            assert.strictEqual(depth, 32)\n          })\n          .expect(200, done)\n      })\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/x-www-form-urlencoded')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/x-www-form-urlencoded')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(200, '{\"name\":\"\u8bba\"}', done)\n      })\n    })\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: '1kb' }))\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .set('Content-Length', '1028')\n        .send('str=' + buf.toString())\n        .expect(413, done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var buf = Buffer.alloc(1024, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write('str=')\n      test.write(buf.toString())\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000a2b2e29b2d51b05a360148c580000a0351f9204040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: 1024 }))\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('str=' + buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('str=' + buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var app = createApp({ limit: '8kb' })\n      var buf = Buffer.alloc(10240, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000a2b2e29b2d51b05a360148c580000a0351f92040400', 'hex'))\n      test.expect(413, done)\n    })\n  })\n\n  describe('with parameterLimit option', function () {\n    describe('with extended: false', function () {\n      it('should reject 0', function () {\n        assert.throws(createApp.bind(null, { extended: false, parameterLimit: 0 }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should reject string', function () {\n        assert.throws(createApp.bind(null, { extended: false, parameterLimit: 'beep' }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should 413 if over limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, '[parameters.too.many] too many parameters', done)\n      })\n\n      it('should work when at the limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10))\n          .expect(expectKeyCount(10))\n          .expect(200, done)\n      })\n\n      it('should work if number is floating point', function (done) {\n        request(createApp({ extended: false, parameterLimit: 10.1 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, /too many parameters/, done)\n      })\n\n      it('should work with large limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: 5000 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(5000))\n          .expect(expectKeyCount(5000))\n          .expect(200, done)\n      })\n\n      it('should work with Infinity limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: Infinity }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10000))\n          .expect(expectKeyCount(10000))\n          .expect(200, done)\n      })\n    })\n\n    describe('with extended: true', function () {\n      it('should reject 0', function () {\n        assert.throws(createApp.bind(null, { extended: true, parameterLimit: 0 }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should reject string', function () {\n        assert.throws(createApp.bind(null, { extended: true, parameterLimit: 'beep' }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should 413 if over limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, '[parameters.too.many] too many parameters', done)\n      })\n\n      it('should work when at the limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10))\n          .expect(expectKeyCount(10))\n          .expect(200, done)\n      })\n\n      it('should work if number is floating point', function (done) {\n        request(createApp({ extended: true, parameterLimit: 10.1 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, /too many parameters/, done)\n      })\n\n      it('should work with large limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: 5000 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(5000))\n          .expect(expectKeyCount(5000))\n          .expect(200, done)\n      })\n\n      it('should work with Infinity limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: Infinity }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10000))\n          .expect(expectKeyCount(10000))\n          .expect(200, done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"application/vnd.x-www-form-urlencoded\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'application/vnd.x-www-form-urlencoded' })\n      })\n\n      it('should parse for custom type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.x-www-form-urlencoded')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore standard type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=tobi')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when [\"urlencoded\", \"application/x-pairs\"]', function () {\n      before(function () {\n        this.app = createApp({\n          type: ['urlencoded', 'application/x-pairs']\n        })\n      })\n\n      it('should parse \"application/x-www-form-urlencoded\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should parse \"application/x-pairs\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-pairs')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore application/x-foo', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-foo')\n          .send('user=tobi')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'application/vnd.something'\n        }\n\n        request(app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.something')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write('user=tobi')\n        test.expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value if function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x20) throw new Error('no leading space')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send(' user=tobi')\n        .expect(403, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x20) return\n          var err = new Error('no leading space')\n          err.status = 400\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send(' user=tobi')\n        .expect(400, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow custom type', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x20) return\n          var err = new Error('no leading space')\n          err.type = 'foo.bar'\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send(' user=tobi')\n        .expect(403, '[foo.bar] no leading space', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('user=tobi')\n        .expect(200, '{\"user\":\"tobi\"}', done)\n    })\n\n    it('should 415 on unknown charset prior to verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          throw new Error('unexpected verify call')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.urlencoded())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        res.json(req.body)\n      })\n\n      this.app = app\n    })\n\n    it('should presist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('user=tobi')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('{\"user\":\"tobi\"}')\n        .end(done)\n    })\n\n    it('should presist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should presist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect('{\"name\":\"\u8bba\"}')\n      test.end(done)\n    })\n\n    it('should presist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad6080000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should presist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('user=' + Buffer.alloc(1024 * 100, '.').toString())\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should parse utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=utf-8')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should parse when content-length != char length', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=utf-8')\n      test.set('Content-Length', '7')\n      test.write(Buffer.from('746573743dc3a5', 'hex'))\n      test.expect(200, '{\"test\":\"\u00e5\"}', done)\n    })\n\n    it('should default to utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should fail on unknown charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=koi8-r')\n      test.write(Buffer.from('6e616d653dcec5d4', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"KOI8-R\"', done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '10kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('789ccb4bcc4db57db16e17001068042f', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n  })\n})\n\nfunction createManyParams (count) {\n  var str = ''\n\n  if (count === 0) {\n    return str\n  }\n\n  str += '0=0'\n\n  for (var i = 1; i < count; i++) {\n    var n = i.toString(36)\n    str += '&' + n + '=' + n\n  }\n\n  return str\n}\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.urlencoded(options))\n\n  app.use(function (err, req, res, next) {\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    res.json(req.body)\n  })\n\n  return app\n}\n\nfunction expectKeyCount (count) {\n  return function (res) {\n    assert.strictEqual(Object.keys(JSON.parse(res.text)).length, count)\n  }\n}\n",
      "code_after": "'use strict'\n\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..')\nvar request = require('supertest')\n\ndescribe('express.urlencoded()', function () {\n  before(function () {\n    this.app = createApp()\n  })\n\n  it('should parse x-www-form-urlencoded', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('user=tobi')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  it('should 400 when invalid content-length', function (done) {\n    var app = express()\n\n    app.use(function (req, res, next) {\n      req.headers['content-length'] = '20' // bad length\n      next()\n    })\n\n    app.use(express.urlencoded())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('str=')\n      .expect(400, /content length/, done)\n  })\n\n  it('should handle Content-Length: 0', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .set('Content-Length', '0')\n      .send('')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle empty message-body', function (done) {\n    request(createApp({ limit: '1kb' }))\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .set('Transfer-Encoding', 'chunked')\n      .send('')\n      .expect(200, '{}', done)\n  })\n\n  it('should handle duplicated middleware', function (done) {\n    var app = express()\n\n    app.use(express.urlencoded())\n    app.use(express.urlencoded())\n\n    app.post('/', function (req, res) {\n      res.json(req.body)\n    })\n\n    request(app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('user=tobi')\n      .expect(200, '{\"user\":\"tobi\"}', done)\n  })\n\n  it('should not parse extended syntax', function (done) {\n    request(this.app)\n      .post('/')\n      .set('Content-Type', 'application/x-www-form-urlencoded')\n      .send('user[name][first]=Tobi')\n      .expect(200, '{\"user[name][first]\":\"Tobi\"}', done)\n  })\n\n  describe('with extended option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ extended: false })\n      })\n\n      it('should not parse extended syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user[name][first]=Tobi')\n          .expect(200, '{\"user[name][first]\":\"Tobi\"}', done)\n      })\n\n      it('should parse multiple key instances', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=Tobi&user=Loki')\n          .expect(200, '{\"user\":[\"Tobi\",\"Loki\"]}', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ extended: true })\n      })\n\n      it('should parse multiple key instances', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=Tobi&user=Loki')\n          .expect(200, '{\"user\":[\"Tobi\",\"Loki\"]}', done)\n      })\n\n      it('should parse extended syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user[name][first]=Tobi')\n          .expect(200, '{\"user\":{\"name\":{\"first\":\"Tobi\"}}}', done)\n      })\n\n      it('should parse parameters with dots', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user.name=Tobi')\n          .expect(200, '{\"user.name\":\"Tobi\"}', done)\n      })\n\n      it('should parse fully-encoded extended syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user%5Bname%5D%5Bfirst%5D=Tobi')\n          .expect(200, '{\"user\":{\"name\":{\"first\":\"Tobi\"}}}', done)\n      })\n\n      it('should parse array index notation', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('foo[0]=bar&foo[1]=baz')\n          .expect(200, '{\"foo\":[\"bar\",\"baz\"]}', done)\n      })\n\n      it('should parse array index notation with large array', function (done) {\n        var str = 'f[0]=0'\n\n        for (var i = 1; i < 500; i++) {\n          str += '&f[' + i + ']=' + i.toString(16)\n        }\n\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(str)\n          .expect(function (res) {\n            var obj = JSON.parse(res.text)\n            assert.strictEqual(Object.keys(obj).length, 1)\n            assert.strictEqual(Array.isArray(obj.f), true)\n            assert.strictEqual(obj.f.length, 500)\n          })\n          .expect(200, done)\n      })\n\n      it('should parse array of objects syntax', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('foo[0][bar]=baz&foo[0][fizz]=buzz&foo[]=done!')\n          .expect(200, '{\"foo\":[{\"bar\":\"baz\",\"fizz\":\"buzz\"},\"done!\"]}', done)\n      })\n\n      it('should parse deep object', function (done) {\n        var str = 'foo'\n\n        for (var i = 0; i < 32; i++) {\n          str += '[p]'\n        }\n\n        str += '=bar'\n\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(str)\n          .expect(function (res) {\n            var obj = JSON.parse(res.text)\n            assert.strictEqual(Object.keys(obj).length, 1)\n            assert.strictEqual(typeof obj.foo, 'object')\n\n            var depth = 0\n            var ref = obj.foo\n            while ((ref = ref.p)) { depth++ }\n            assert.strictEqual(depth, 32)\n          })\n          .expect(200, done)\n      })\n    })\n  })\n\n  describe('with inflate option', function () {\n    describe('when false', function () {\n      before(function () {\n        this.app = createApp({ inflate: false })\n      })\n\n      it('should not accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/x-www-form-urlencoded')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(415, '[encoding.unsupported] content encoding unsupported', done)\n      })\n    })\n\n    describe('when true', function () {\n      before(function () {\n        this.app = createApp({ inflate: true })\n      })\n\n      it('should accept content-encoding', function (done) {\n        var test = request(this.app).post('/')\n        test.set('Content-Encoding', 'gzip')\n        test.set('Content-Type', 'application/x-www-form-urlencoded')\n        test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n        test.expect(200, '{\"name\":\"\u8bba\"}', done)\n      })\n    })\n  })\n\n  describe('with limit option', function () {\n    it('should 413 when over limit with Content-Length', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: '1kb' }))\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .set('Content-Length', '1028')\n        .send('str=' + buf.toString())\n        .expect(413, done)\n    })\n\n    it('should 413 when over limit with chunked encoding', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var buf = Buffer.alloc(1024, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.set('Transfer-Encoding', 'chunked')\n      test.write('str=')\n      test.write(buf.toString())\n      test.expect(413, done)\n    })\n\n    it('should 413 when inflated body over limit', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000a2b2e29b2d51b05a360148c580000a0351f9204040000', 'hex'))\n      test.expect(413, done)\n    })\n\n    it('should accept number of bytes', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      request(createApp({ limit: 1024 }))\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('str=' + buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not change when options altered', function (done) {\n      var buf = Buffer.alloc(1024, '.')\n      var options = { limit: '1kb' }\n      var app = createApp(options)\n\n      options.limit = '100kb'\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('str=' + buf.toString())\n        .expect(413, done)\n    })\n\n    it('should not hang response', function (done) {\n      var app = createApp({ limit: '8kb' })\n      var buf = Buffer.alloc(10240, '.')\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(buf)\n      test.write(buf)\n      test.write(buf)\n      test.expect(413, done)\n    })\n\n    it('should not error when inflating', function (done) {\n      var app = createApp({ limit: '1kb' })\n      var test = request(app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000a2b2e29b2d51b05a360148c580000a0351f92040400', 'hex'))\n      test.expect(413, done)\n    })\n  })\n\n  describe('with parameterLimit option', function () {\n    describe('with extended: false', function () {\n      it('should reject 0', function () {\n        assert.throws(createApp.bind(null, { extended: false, parameterLimit: 0 }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should reject string', function () {\n        assert.throws(createApp.bind(null, { extended: false, parameterLimit: 'beep' }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should 413 if over limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, '[parameters.too.many] too many parameters', done)\n      })\n\n      it('should work when at the limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10))\n          .expect(expectKeyCount(10))\n          .expect(200, done)\n      })\n\n      it('should work if number is floating point', function (done) {\n        request(createApp({ extended: false, parameterLimit: 10.1 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, /too many parameters/, done)\n      })\n\n      it('should work with large limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: 5000 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(5000))\n          .expect(expectKeyCount(5000))\n          .expect(200, done)\n      })\n\n      it('should work with Infinity limit', function (done) {\n        request(createApp({ extended: false, parameterLimit: Infinity }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10000))\n          .expect(expectKeyCount(10000))\n          .expect(200, done)\n      })\n    })\n\n    describe('with extended: true', function () {\n      it('should reject 0', function () {\n        assert.throws(createApp.bind(null, { extended: true, parameterLimit: 0 }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should reject string', function () {\n        assert.throws(createApp.bind(null, { extended: true, parameterLimit: 'beep' }),\n          /TypeError: option parameterLimit must be a positive number/)\n      })\n\n      it('should 413 if over limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, '[parameters.too.many] too many parameters', done)\n      })\n\n      it('should work when at the limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: 10 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10))\n          .expect(expectKeyCount(10))\n          .expect(200, done)\n      })\n\n      it('should work if number is floating point', function (done) {\n        request(createApp({ extended: true, parameterLimit: 10.1 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(11))\n          .expect(413, /too many parameters/, done)\n      })\n\n      it('should work with large limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: 5000 }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(5000))\n          .expect(expectKeyCount(5000))\n          .expect(200, done)\n      })\n\n      it('should work with Infinity limit', function (done) {\n        request(createApp({ extended: true, parameterLimit: Infinity }))\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send(createManyParams(10000))\n          .expect(expectKeyCount(10000))\n          .expect(200, done)\n      })\n    })\n  })\n\n  describe('with type option', function () {\n    describe('when \"application/vnd.x-www-form-urlencoded\"', function () {\n      before(function () {\n        this.app = createApp({ type: 'application/vnd.x-www-form-urlencoded' })\n      })\n\n      it('should parse for custom type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.x-www-form-urlencoded')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore standard type', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=tobi')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when [\"urlencoded\", \"application/x-pairs\"]', function () {\n      before(function () {\n        this.app = createApp({\n          type: ['urlencoded', 'application/x-pairs']\n        })\n      })\n\n      it('should parse \"application/x-www-form-urlencoded\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-www-form-urlencoded')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should parse \"application/x-pairs\"', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-pairs')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should ignore application/x-foo', function (done) {\n        request(this.app)\n          .post('/')\n          .set('Content-Type', 'application/x-foo')\n          .send('user=tobi')\n          .expect(200, '', done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should parse when truthy value returned', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return req.headers['content-type'] === 'application/vnd.something'\n        }\n\n        request(app)\n          .post('/')\n          .set('Content-Type', 'application/vnd.something')\n          .send('user=tobi')\n          .expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should work without content-type', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          return true\n        }\n\n        var test = request(app).post('/')\n        test.write('user=tobi')\n        test.expect(200, '{\"user\":\"tobi\"}', done)\n      })\n\n      it('should not invoke without a body', function (done) {\n        var app = createApp({ type: accept })\n\n        function accept (req) {\n          throw new Error('oops!')\n        }\n\n        request(app)\n          .get('/')\n          .expect(404, done)\n      })\n    })\n  })\n\n  describe('with verify option', function () {\n    it('should assert value if function', function () {\n      assert.throws(createApp.bind(null, { verify: 'lol' }),\n        /TypeError: option verify must be function/)\n    })\n\n    it('should error from verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x20) throw new Error('no leading space')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send(' user=tobi')\n        .expect(403, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow custom codes', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x20) return\n          var err = new Error('no leading space')\n          err.status = 400\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send(' user=tobi')\n        .expect(400, '[entity.verify.failed] no leading space', done)\n    })\n\n    it('should allow custom type', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] !== 0x20) return\n          var err = new Error('no leading space')\n          err.type = 'foo.bar'\n          throw err\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send(' user=tobi')\n        .expect(403, '[foo.bar] no leading space', done)\n    })\n\n    it('should allow pass-through', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          if (buf[0] === 0x5b) throw new Error('no arrays')\n        }\n      })\n\n      request(app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('user=tobi')\n        .expect(200, '{\"user\":\"tobi\"}', done)\n    })\n\n    it('should 415 on unknown charset prior to verify', function (done) {\n      var app = createApp({\n        verify: function (req, res, buf) {\n          throw new Error('unexpected verify call')\n        }\n      })\n\n      var test = request(app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=x-bogus')\n      test.write(Buffer.from('00000000', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"X-BOGUS\"', done)\n    })\n  })\n\n  describe('async local storage', function () {\n    before(function () {\n      var app = express()\n      var store = { foo: 'bar' }\n\n      app.use(function (req, res, next) {\n        req.asyncLocalStorage = new AsyncLocalStorage()\n        req.asyncLocalStorage.run(store, next)\n      })\n\n      app.use(express.urlencoded())\n\n      app.use(function (req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        next()\n      })\n\n      app.use(function (err, req, res, next) {\n        var local = req.asyncLocalStorage.getStore()\n\n        if (local) {\n          res.setHeader('x-store-foo', String(local.foo))\n        }\n\n        res.status(err.status || 500)\n        res.send('[' + err.type + '] ' + err.message)\n      })\n\n      app.post('/', function (req, res) {\n        res.json(req.body)\n      })\n\n      this.app = app\n    })\n\n    it('should persist store', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('user=tobi')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .expect('{\"user\":\"tobi\"}')\n        .end(done)\n    })\n\n    it('should persist store when unmatched content-type', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/fizzbuzz')\n        .send('buzz')\n        .expect(200)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n\n    it('should persist store when inflated', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200)\n      test.expect('x-store-foo', 'bar')\n      test.expect('{\"name\":\"\u8bba\"}')\n      test.end(done)\n    })\n\n    it('should persist store when inflate error', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad6080000', 'hex'))\n      test.expect(400)\n      test.expect('x-store-foo', 'bar')\n      test.end(done)\n    })\n\n    it('should persist store when limit exceeded', function (done) {\n      request(this.app)\n        .post('/')\n        .set('Content-Type', 'application/x-www-form-urlencoded')\n        .send('user=' + Buffer.alloc(1024 * 100, '.').toString())\n        .expect(413)\n        .expect('x-store-foo', 'bar')\n        .end(done)\n    })\n  })\n\n  describe('charset', function () {\n    before(function () {\n      this.app = createApp()\n    })\n\n    it('should parse utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=utf-8')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should parse when content-length != char length', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=utf-8')\n      test.set('Content-Length', '7')\n      test.write(Buffer.from('746573743dc3a5', 'hex'))\n      test.expect(200, '{\"test\":\"\u00e5\"}', done)\n    })\n\n    it('should default to utf-8', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should fail on unknown charset', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded; charset=koi8-r')\n      test.write(Buffer.from('6e616d653dcec5d4', 'hex'))\n      test.expect(415, '[charset.unsupported] unsupported charset \"KOI8-R\"', done)\n    })\n  })\n\n  describe('encoding', function () {\n    before(function () {\n      this.app = createApp({ limit: '10kb' })\n    })\n\n    it('should parse without encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support identity encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'identity')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('6e616d653de8aeba', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support gzip encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'gzip')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should support deflate encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'deflate')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('789ccb4bcc4db57db16e17001068042f', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should be case-insensitive', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'GZIP')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('1f8b080000000000000bcb4bcc4db57db16e170099a4bad608000000', 'hex'))\n      test.expect(200, '{\"name\":\"\u8bba\"}', done)\n    })\n\n    it('should 415 on unknown encoding', function (done) {\n      var test = request(this.app).post('/')\n      test.set('Content-Encoding', 'nulls')\n      test.set('Content-Type', 'application/x-www-form-urlencoded')\n      test.write(Buffer.from('000000000000', 'hex'))\n      test.expect(415, '[encoding.unsupported] unsupported content encoding \"nulls\"', done)\n    })\n  })\n})\n\nfunction createManyParams (count) {\n  var str = ''\n\n  if (count === 0) {\n    return str\n  }\n\n  str += '0=0'\n\n  for (var i = 1; i < count; i++) {\n    var n = i.toString(36)\n    str += '&' + n + '=' + n\n  }\n\n  return str\n}\n\nfunction createApp (options) {\n  var app = express()\n\n  app.use(express.urlencoded(options))\n\n  app.use(function (err, req, res, next) {\n    res.status(err.status || 500)\n    res.send(String(req.headers['x-error-property']\n      ? err[req.headers['x-error-property']]\n      : ('[' + err.type + '] ' + err.message)))\n  })\n\n  app.post('/', function (req, res) {\n    res.json(req.body)\n  })\n\n  return app\n}\n\nfunction expectKeyCount (count) {\n  return function (res) {\n    assert.strictEqual(Object.keys(JSON.parse(res.text)).length, count)\n  }\n}\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "f725468f257c",
      "repo": "express",
      "commit_hash": "dfd1851",
      "commit_message": "test: fix typos in test descriptions (#6535)",
      "file_path": "test/res.download.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar after = require('after');\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..');\nvar path = require('node:path')\nvar request = require('supertest');\nvar utils = require('./support/utils')\n\nvar FIXTURES_PATH = path.join(__dirname, 'fixtures')\n\ndescribe('res', function(){\n  describe('.download(path)', function(){\n    it('should transfer as an attachment', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n      .expect(200, '<p>{{user.name}}</p>', done)\n    })\n\n    it('should accept range requests', function (done) {\n      var app = express()\n\n      app.get('/', function (req, res) {\n        res.download('test/fixtures/user.html')\n      })\n\n      request(app)\n        .get('/')\n        .expect('Accept-Ranges', 'bytes')\n        .expect(200, '<p>{{user.name}}</p>', done)\n    })\n\n    it('should respond with requested byte range', function (done) {\n      var app = express()\n\n      app.get('/', function (req, res) {\n        res.download('test/fixtures/user.html')\n      })\n\n      request(app)\n        .get('/')\n        .set('Range', 'bytes=0-2')\n        .expect('Content-Range', 'bytes 0-2/20')\n        .expect(206, '<p>', done)\n    })\n  })\n\n  describe('.download(path, filename)', function(){\n    it('should provide an alternate filename', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html', 'document');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"document\"')\n      .expect(200, done)\n    })\n  })\n\n  describe('.download(path, fn)', function(){\n    it('should invoke the callback', function(done){\n      var app = express();\n      var cb = after(2, done);\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html', cb);\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n      .expect(200, cb);\n    })\n\n    describe('async local storage', function () {\n      it('should presist store', function (done) {\n        var app = express()\n        var cb = after(2, done)\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/name.txt', function (err) {\n            if (err) return cb(err)\n\n            var local = req.asyncLocalStorage.getStore()\n\n            assert.strictEqual(local.foo, 'bar')\n            cb()\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect('Content-Type', 'text/plain; charset=utf-8')\n          .expect('Content-Disposition', 'attachment; filename=\"name.txt\"')\n          .expect(200, 'tobi', cb)\n      })\n\n      it('should presist store on error', function (done) {\n        var app = express()\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/does-not-exist', function (err) {\n            var local = req.asyncLocalStorage.getStore()\n\n            if (local) {\n              res.setHeader('x-store-foo', String(local.foo))\n            }\n\n            res.send(err ? 'got ' + err.status + ' error' : 'no error')\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('x-store-foo', 'bar')\n          .expect('got 404 error')\n          .end(done)\n      })\n    })\n  })\n\n  describe('.download(path, options)', function () {\n    it('should allow options to res.sendFile()', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.download('test/fixtures/.name', {\n          dotfiles: 'allow',\n          maxAge: '4h'\n        })\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Disposition', 'attachment; filename=\".name\"')\n        .expect('Cache-Control', 'public, max-age=14400')\n        .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n        .end(done)\n    })\n\n    describe('with \"headers\" option', function () {\n      it('should set headers on response', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', {\n            headers: {\n              'X-Foo': 'Bar',\n              'X-Bar': 'Foo'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'Bar')\n          .expect('X-Bar', 'Foo')\n          .end(done)\n      })\n\n      it('should use last header when duplicated', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', {\n            headers: {\n              'X-Foo': 'Bar',\n              'x-foo': 'bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'bar')\n          .end(done)\n      })\n\n      it('should override Content-Type', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', {\n            headers: {\n              'Content-Type': 'text/x-custom'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Type', 'text/x-custom')\n          .end(done)\n      })\n\n      it('should not set headers on 404', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/does-not-exist', {\n            headers: {\n              'X-Foo': 'Bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(404)\n          .expect(utils.shouldNotHaveHeader('X-Foo'))\n          .end(done)\n      })\n\n      describe('when headers contains Content-Disposition', function () {\n        it('should be ignored', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.download('test/fixtures/user.html', {\n              headers: {\n                'Content-Disposition': 'inline'\n              }\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n            .end(done)\n        })\n\n        it('should be ignored case-insensitively', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.download('test/fixtures/user.html', {\n              headers: {\n                'content-disposition': 'inline'\n              }\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"root\" option', function () {\n      it('should allow relative path', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('name.txt', {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Disposition', 'attachment; filename=\"name.txt\"')\n          .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n          .end(done)\n      })\n\n      it('should allow up within root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('fake/../name.txt', {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Disposition', 'attachment; filename=\"name.txt\"')\n          .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n          .end(done)\n      })\n\n      it('should reject up outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          var p = '..' + path.sep +\n            path.relative(path.dirname(FIXTURES_PATH), path.join(FIXTURES_PATH, 'name.txt'))\n\n          res.download(p, {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403)\n          .expect(utils.shouldNotHaveHeader('Content-Disposition'))\n          .end(done)\n      })\n\n      it('should reject reading outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('../name.txt', {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403)\n          .expect(utils.shouldNotHaveHeader('Content-Disposition'))\n          .end(done)\n      })\n    })\n  })\n\n  describe('.download(path, filename, fn)', function(){\n    it('should invoke the callback', function(done){\n      var app = express();\n      var cb = after(2, done);\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html', 'document', cb)\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"document\"')\n      .expect(200, cb);\n    })\n  })\n\n  describe('.download(path, filename, options, fn)', function () {\n    it('should invoke the callback', function (done) {\n      var app = express()\n      var cb = after(2, done)\n      var options = {}\n\n      app.use(function (req, res) {\n        res.download('test/fixtures/user.html', 'document', options, cb)\n      })\n\n      request(app)\n      .get('/')\n      .expect(200)\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"document\"')\n      .end(cb)\n    })\n\n    it('should allow options to res.sendFile()', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.download('test/fixtures/.name', 'document', {\n          dotfiles: 'allow',\n          maxAge: '4h'\n        })\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Disposition', 'attachment; filename=\"document\"')\n        .expect('Cache-Control', 'public, max-age=14400')\n        .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n        .end(done)\n    })\n\n    describe('when options.headers contains Content-Disposition', function () {\n      it('should be ignored', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', 'document', {\n            headers: {\n              'Content-Type': 'text/x-custom',\n              'Content-Disposition': 'inline'\n            }\n          })\n        })\n\n        request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Type', 'text/x-custom')\n        .expect('Content-Disposition', 'attachment; filename=\"document\"')\n        .end(done)\n      })\n\n      it('should be ignored case-insensitively', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', 'document', {\n            headers: {\n              'content-type': 'text/x-custom',\n              'content-disposition': 'inline'\n            }\n          })\n        })\n\n        request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Type', 'text/x-custom')\n        .expect('Content-Disposition', 'attachment; filename=\"document\"')\n        .end(done)\n      })\n    })\n  })\n\n  describe('on failure', function(){\n    it('should invoke the callback', function(done){\n      var app = express();\n\n      app.use(function (req, res, next) {\n        res.download('test/fixtures/foobar.html', function(err){\n          if (!err) return next(new Error('expected error'));\n          res.send('got ' + err.status + ' ' + err.code);\n        });\n      });\n\n      request(app)\n      .get('/')\n      .expect(200, 'got 404 ENOENT', done);\n    })\n\n    it('should remove Content-Disposition', function(done){\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.download('test/fixtures/foobar.html', function(err){\n          if (!err) return next(new Error('expected error'));\n          res.end('failed');\n        });\n      });\n\n      request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('Content-Disposition'))\n        .expect(200, 'failed', done)\n    })\n  })\n})\n",
      "code_after": "'use strict'\n\nvar after = require('after');\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('..');\nvar path = require('node:path')\nvar request = require('supertest');\nvar utils = require('./support/utils')\n\nvar FIXTURES_PATH = path.join(__dirname, 'fixtures')\n\ndescribe('res', function(){\n  describe('.download(path)', function(){\n    it('should transfer as an attachment', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n      .expect(200, '<p>{{user.name}}</p>', done)\n    })\n\n    it('should accept range requests', function (done) {\n      var app = express()\n\n      app.get('/', function (req, res) {\n        res.download('test/fixtures/user.html')\n      })\n\n      request(app)\n        .get('/')\n        .expect('Accept-Ranges', 'bytes')\n        .expect(200, '<p>{{user.name}}</p>', done)\n    })\n\n    it('should respond with requested byte range', function (done) {\n      var app = express()\n\n      app.get('/', function (req, res) {\n        res.download('test/fixtures/user.html')\n      })\n\n      request(app)\n        .get('/')\n        .set('Range', 'bytes=0-2')\n        .expect('Content-Range', 'bytes 0-2/20')\n        .expect(206, '<p>', done)\n    })\n  })\n\n  describe('.download(path, filename)', function(){\n    it('should provide an alternate filename', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html', 'document');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"document\"')\n      .expect(200, done)\n    })\n  })\n\n  describe('.download(path, fn)', function(){\n    it('should invoke the callback', function(done){\n      var app = express();\n      var cb = after(2, done);\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html', cb);\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n      .expect(200, cb);\n    })\n\n    describe('async local storage', function () {\n      it('should persist store', function (done) {\n        var app = express()\n        var cb = after(2, done)\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/name.txt', function (err) {\n            if (err) return cb(err)\n\n            var local = req.asyncLocalStorage.getStore()\n\n            assert.strictEqual(local.foo, 'bar')\n            cb()\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect('Content-Type', 'text/plain; charset=utf-8')\n          .expect('Content-Disposition', 'attachment; filename=\"name.txt\"')\n          .expect(200, 'tobi', cb)\n      })\n\n      it('should persist store on error', function (done) {\n        var app = express()\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/does-not-exist', function (err) {\n            var local = req.asyncLocalStorage.getStore()\n\n            if (local) {\n              res.setHeader('x-store-foo', String(local.foo))\n            }\n\n            res.send(err ? 'got ' + err.status + ' error' : 'no error')\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('x-store-foo', 'bar')\n          .expect('got 404 error')\n          .end(done)\n      })\n    })\n  })\n\n  describe('.download(path, options)', function () {\n    it('should allow options to res.sendFile()', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.download('test/fixtures/.name', {\n          dotfiles: 'allow',\n          maxAge: '4h'\n        })\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Disposition', 'attachment; filename=\".name\"')\n        .expect('Cache-Control', 'public, max-age=14400')\n        .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n        .end(done)\n    })\n\n    describe('with \"headers\" option', function () {\n      it('should set headers on response', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', {\n            headers: {\n              'X-Foo': 'Bar',\n              'X-Bar': 'Foo'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'Bar')\n          .expect('X-Bar', 'Foo')\n          .end(done)\n      })\n\n      it('should use last header when duplicated', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', {\n            headers: {\n              'X-Foo': 'Bar',\n              'x-foo': 'bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'bar')\n          .end(done)\n      })\n\n      it('should override Content-Type', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', {\n            headers: {\n              'Content-Type': 'text/x-custom'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Type', 'text/x-custom')\n          .end(done)\n      })\n\n      it('should not set headers on 404', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/does-not-exist', {\n            headers: {\n              'X-Foo': 'Bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(404)\n          .expect(utils.shouldNotHaveHeader('X-Foo'))\n          .end(done)\n      })\n\n      describe('when headers contains Content-Disposition', function () {\n        it('should be ignored', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.download('test/fixtures/user.html', {\n              headers: {\n                'Content-Disposition': 'inline'\n              }\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n            .end(done)\n        })\n\n        it('should be ignored case-insensitively', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.download('test/fixtures/user.html', {\n              headers: {\n                'content-disposition': 'inline'\n              }\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Content-Disposition', 'attachment; filename=\"user.html\"')\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"root\" option', function () {\n      it('should allow relative path', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('name.txt', {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Disposition', 'attachment; filename=\"name.txt\"')\n          .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n          .end(done)\n      })\n\n      it('should allow up within root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('fake/../name.txt', {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Disposition', 'attachment; filename=\"name.txt\"')\n          .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n          .end(done)\n      })\n\n      it('should reject up outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          var p = '..' + path.sep +\n            path.relative(path.dirname(FIXTURES_PATH), path.join(FIXTURES_PATH, 'name.txt'))\n\n          res.download(p, {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403)\n          .expect(utils.shouldNotHaveHeader('Content-Disposition'))\n          .end(done)\n      })\n\n      it('should reject reading outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('../name.txt', {\n            root: FIXTURES_PATH\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403)\n          .expect(utils.shouldNotHaveHeader('Content-Disposition'))\n          .end(done)\n      })\n    })\n  })\n\n  describe('.download(path, filename, fn)', function(){\n    it('should invoke the callback', function(done){\n      var app = express();\n      var cb = after(2, done);\n\n      app.use(function(req, res){\n        res.download('test/fixtures/user.html', 'document', cb)\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"document\"')\n      .expect(200, cb);\n    })\n  })\n\n  describe('.download(path, filename, options, fn)', function () {\n    it('should invoke the callback', function (done) {\n      var app = express()\n      var cb = after(2, done)\n      var options = {}\n\n      app.use(function (req, res) {\n        res.download('test/fixtures/user.html', 'document', options, cb)\n      })\n\n      request(app)\n      .get('/')\n      .expect(200)\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect('Content-Disposition', 'attachment; filename=\"document\"')\n      .end(cb)\n    })\n\n    it('should allow options to res.sendFile()', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.download('test/fixtures/.name', 'document', {\n          dotfiles: 'allow',\n          maxAge: '4h'\n        })\n      })\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Disposition', 'attachment; filename=\"document\"')\n        .expect('Cache-Control', 'public, max-age=14400')\n        .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n        .end(done)\n    })\n\n    describe('when options.headers contains Content-Disposition', function () {\n      it('should be ignored', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', 'document', {\n            headers: {\n              'Content-Type': 'text/x-custom',\n              'Content-Disposition': 'inline'\n            }\n          })\n        })\n\n        request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Type', 'text/x-custom')\n        .expect('Content-Disposition', 'attachment; filename=\"document\"')\n        .end(done)\n      })\n\n      it('should be ignored case-insensitively', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.download('test/fixtures/user.html', 'document', {\n            headers: {\n              'content-type': 'text/x-custom',\n              'content-disposition': 'inline'\n            }\n          })\n        })\n\n        request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Type', 'text/x-custom')\n        .expect('Content-Disposition', 'attachment; filename=\"document\"')\n        .end(done)\n      })\n    })\n  })\n\n  describe('on failure', function(){\n    it('should invoke the callback', function(done){\n      var app = express();\n\n      app.use(function (req, res, next) {\n        res.download('test/fixtures/foobar.html', function(err){\n          if (!err) return next(new Error('expected error'));\n          res.send('got ' + err.status + ' ' + err.code);\n        });\n      });\n\n      request(app)\n      .get('/')\n      .expect(200, 'got 404 ENOENT', done);\n    })\n\n    it('should remove Content-Disposition', function(done){\n      var app = express()\n\n      app.use(function (req, res, next) {\n        res.download('test/fixtures/foobar.html', function(err){\n          if (!err) return next(new Error('expected error'));\n          res.end('failed');\n        });\n      });\n\n      request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('Content-Disposition'))\n        .expect(200, 'failed', done)\n    })\n  })\n})\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "a1a578b80f5e",
      "repo": "express",
      "commit_hash": "dfd1851",
      "commit_message": "test: fix typos in test descriptions (#6535)",
      "file_path": "test/res.sendFile.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar after = require('after');\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('../')\n  , request = require('supertest')\nvar onFinished = require('on-finished');\nvar path = require('node:path');\nvar fixtures = path.join(__dirname, 'fixtures');\nvar utils = require('./support/utils');\n\ndescribe('res', function(){\n  describe('.sendFile(path)', function () {\n    it('should error missing path', function (done) {\n      var app = createApp();\n\n      request(app)\n      .get('/')\n      .expect(500, /path.*required/, done);\n    });\n\n    it('should error for non-string path', function (done) {\n      var app = createApp(42)\n\n      request(app)\n      .get('/')\n      .expect(500, /TypeError: path must be a string to res.sendFile/, done)\n    })\n\n    it('should error for non-absolute path', function (done) {\n      var app = createApp('name.txt')\n\n      request(app)\n        .get('/')\n        .expect(500, /TypeError: path must be absolute/, done)\n    })\n\n    it('should transfer a file', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt'));\n\n      request(app)\n      .get('/')\n      .expect(200, 'tobi', done);\n    });\n\n    it('should transfer a file with special characters in string', function (done) {\n      var app = createApp(path.resolve(fixtures, '% of dogs.txt'));\n\n      request(app)\n      .get('/')\n      .expect(200, '20%', done);\n    });\n\n    it('should include ETag', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt'));\n\n      request(app)\n      .get('/')\n      .expect('ETag', /^(?:W\\/)?\"[^\"]+\"$/)\n      .expect(200, 'tobi', done);\n    });\n\n    it('should 304 when ETag matches', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt'));\n\n      request(app)\n      .get('/')\n      .expect('ETag', /^(?:W\\/)?\"[^\"]+\"$/)\n      .expect(200, 'tobi', function (err, res) {\n        if (err) return done(err);\n        var etag = res.headers.etag;\n        request(app)\n        .get('/')\n        .set('If-None-Match', etag)\n        .expect(304, done);\n      });\n    });\n\n    it('should disable the ETag function if requested', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt')).disable('etag');\n\n      request(app)\n      .get('/')\n      .expect(handleHeaders)\n      .expect(200, done);\n\n      function handleHeaders (res) {\n        assert(res.headers.etag === undefined);\n      }\n    });\n\n    it('should 404 for directory', function (done) {\n      var app = createApp(path.resolve(fixtures, 'blog'));\n\n      request(app)\n      .get('/')\n      .expect(404, done);\n    });\n\n    it('should 404 when not found', function (done) {\n      var app = createApp(path.resolve(fixtures, 'does-no-exist'));\n\n      app.use(function (req, res) {\n        res.statusCode = 200;\n        res.send('no!');\n      });\n\n      request(app)\n      .get('/')\n      .expect(404, done);\n    });\n\n    it('should send cache-control by default', function (done) {\n      var app = createApp(path.resolve(__dirname, 'fixtures/name.txt'))\n\n      request(app)\n        .get('/')\n        .expect('Cache-Control', 'public, max-age=0')\n        .expect(200, done)\n    })\n\n    it('should not serve dotfiles by default', function (done) {\n      var app = createApp(path.resolve(__dirname, 'fixtures/.name'))\n\n      request(app)\n        .get('/')\n        .expect(404, done)\n    })\n\n    it('should not override manual content-types', function (done) {\n      var app = express();\n\n      app.use(function (req, res) {\n        res.contentType('application/x-bogus');\n        res.sendFile(path.resolve(fixtures, 'name.txt'));\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'application/x-bogus')\n      .end(done);\n    })\n\n    it('should not error if the client aborts', function (done) {\n      var app = express();\n      var cb = after(2, done)\n      var error = null\n\n      app.use(function (req, res) {\n        setImmediate(function () {\n          res.sendFile(path.resolve(fixtures, 'name.txt'));\n          setTimeout(function () {\n            cb(error)\n          }, 10)\n        })\n        test.req.abort()\n      });\n\n      app.use(function (err, req, res, next) {\n        error = err\n        next(err)\n      });\n\n      var server = app.listen()\n      var test = request(server).get('/')\n      test.end(function (err) {\n        assert.ok(err)\n        server.close(cb)\n      })\n    })\n  })\n\n  describe('.sendFile(path, fn)', function () {\n    it('should invoke the callback when complete', function (done) {\n      var cb = after(2, done);\n      var app = createApp(path.resolve(fixtures, 'name.txt'), cb);\n\n      request(app)\n      .get('/')\n      .expect(200, cb);\n    })\n\n    it('should invoke the callback when client aborts', function (done) {\n      var cb = after(2, done)\n      var app = express();\n\n      app.use(function (req, res) {\n        setImmediate(function () {\n          res.sendFile(path.resolve(fixtures, 'name.txt'), function (err) {\n            assert.ok(err)\n            assert.strictEqual(err.code, 'ECONNABORTED')\n            cb()\n          });\n        });\n        test.req.abort()\n      });\n\n      var server = app.listen()\n      var test = request(server).get('/')\n      test.end(function (err) {\n        assert.ok(err)\n        server.close(cb)\n      })\n    })\n\n    it('should invoke the callback when client already aborted', function (done) {\n      var cb = after(2, done)\n      var app = express();\n\n      app.use(function (req, res) {\n        onFinished(res, function () {\n          res.sendFile(path.resolve(fixtures, 'name.txt'), function (err) {\n            assert.ok(err)\n            assert.strictEqual(err.code, 'ECONNABORTED')\n            cb()\n          });\n        });\n        test.req.abort()\n      });\n\n      var server = app.listen()\n      var test = request(server).get('/')\n      test.end(function (err) {\n        assert.ok(err)\n        server.close(cb)\n      })\n    })\n\n    it('should invoke the callback without error when HEAD', function (done) {\n      var app = express();\n      var cb = after(2, done);\n\n      app.use(function (req, res) {\n        res.sendFile(path.resolve(fixtures, 'name.txt'), cb);\n      });\n\n      request(app)\n      .head('/')\n      .expect(200, cb);\n    });\n\n    it('should invoke the callback without error when 304', function (done) {\n      var app = express();\n      var cb = after(3, done);\n\n      app.use(function (req, res) {\n        res.sendFile(path.resolve(fixtures, 'name.txt'), cb);\n      });\n\n      request(app)\n      .get('/')\n      .expect('ETag', /^(?:W\\/)?\"[^\"]+\"$/)\n      .expect(200, 'tobi', function (err, res) {\n        if (err) return cb(err);\n        var etag = res.headers.etag;\n        request(app)\n        .get('/')\n        .set('If-None-Match', etag)\n        .expect(304, cb);\n      });\n    });\n\n    it('should invoke the callback on 404', function(done){\n      var app = express();\n\n      app.use(function (req, res) {\n        res.sendFile(path.resolve(fixtures, 'does-not-exist'), function (err) {\n          res.send(err ? 'got ' + err.status + ' error' : 'no error')\n        });\n      });\n\n      request(app)\n        .get('/')\n        .expect(200, 'got 404 error', done)\n    })\n\n    describe('async local storage', function () {\n      it('should presist store', function (done) {\n        var app = express()\n        var cb = after(2, done)\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'name.txt'), function (err) {\n            if (err) return cb(err)\n\n            var local = req.asyncLocalStorage.getStore()\n\n            assert.strictEqual(local.foo, 'bar')\n            cb()\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect('Content-Type', 'text/plain; charset=utf-8')\n          .expect(200, 'tobi', cb)\n      })\n\n      it('should presist store on error', function (done) {\n        var app = express()\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'does-not-exist'), function (err) {\n            var local = req.asyncLocalStorage.getStore()\n\n            if (local) {\n              res.setHeader('x-store-foo', String(local.foo))\n            }\n\n            res.send(err ? 'got ' + err.status + ' error' : 'no error')\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('x-store-foo', 'bar')\n          .expect('got 404 error')\n          .end(done)\n      })\n    })\n  })\n\n  describe('.sendFile(path, options)', function () {\n    it('should pass options to send module', function (done) {\n      request(createApp(path.resolve(fixtures, 'name.txt'), { start: 0, end: 1 }))\n      .get('/')\n      .expect(200, 'to', done)\n    })\n\n    describe('with \"acceptRanges\" option', function () {\n      describe('when true', function () {\n        it('should advertise byte range accepted', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Accept-Ranges', 'bytes')\n            .expect('123456789')\n            .end(done)\n        })\n\n        it('should respond to range request', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('Range', 'bytes=0-4')\n            .expect(206, '12345', done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not advertise accept-ranges', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Accept-Ranges'))\n            .end(done)\n        })\n\n        it('should not honor range requests', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('Range', 'bytes=0-4')\n            .expect(200, '123456789', done)\n        })\n      })\n    })\n\n    describe('with \"cacheControl\" option', function () {\n      describe('when true', function () {\n        it('should send cache-control header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              cacheControl: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=0')\n            .end(done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not send cache-control header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              cacheControl: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Cache-Control'))\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"dotfiles\" option', function () {\n      describe('when \"allow\"', function () {\n        it('should allow dotfiles', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, '.name'), {\n              dotfiles: 'allow'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n            .end(done)\n        })\n      })\n\n      describe('when \"deny\"', function () {\n        it('should deny dotfiles', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, '.name'), {\n              dotfiles: 'deny'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(403)\n            .expect(/Forbidden/)\n            .end(done)\n        })\n      })\n\n      describe('when \"ignore\"', function () {\n        it('should ignore dotfiles', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, '.name'), {\n              dotfiles: 'ignore'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(404)\n            .expect(/Not Found/)\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"headers\" option', function () {\n      it('should set headers on response', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            headers: {\n              'X-Foo': 'Bar',\n              'X-Bar': 'Foo'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'Bar')\n          .expect('X-Bar', 'Foo')\n          .end(done)\n      })\n\n      it('should use last header when duplicated', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            headers: {\n              'X-Foo': 'Bar',\n              'x-foo': 'bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'bar')\n          .end(done)\n      })\n\n      it('should override Content-Type', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            headers: {\n              'Content-Type': 'text/x-custom'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Type', 'text/x-custom')\n          .end(done)\n      })\n\n      it('should not set headers on 404', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'does-not-exist'), {\n            headers: {\n              'X-Foo': 'Bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(404)\n          .expect(utils.shouldNotHaveHeader('X-Foo'))\n          .end(done)\n      })\n    })\n\n    describe('with \"immutable\" option', function () {\n      describe('when true', function () {\n        it('should send cache-control header with immutable', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              immutable: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=0, immutable')\n            .end(done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not send cache-control header with immutable', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              immutable: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=0')\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"lastModified\" option', function () {\n      describe('when true', function () {\n        it('should send last-modified header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldHaveHeader('Last-Modified'))\n            .end(done)\n        })\n\n        it('should conditionally respond with if-modified-since', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('If-Modified-Since', (new Date(Date.now() + 99999).toUTCString()))\n            .expect(304, done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not have last-modified header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Last-Modified'))\n            .end(done)\n        })\n\n        it('should not honor if-modified-since', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('If-Modified-Since', (new Date(Date.now() + 99999).toUTCString()))\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Last-Modified'))\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"maxAge\" option', function () {\n      it('should set cache-control max-age to milliseconds', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: 20000\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=20')\n          .end(done)\n      })\n\n      it('should cap cache-control max-age to 1 year', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: 99999999999\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=31536000')\n          .end(done)\n      })\n\n      it('should min cache-control max-age to 0', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: -20000\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=0')\n          .end(done)\n      })\n\n      it('should floor cache-control max-age', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: 21911.23\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=21')\n          .end(done)\n      })\n\n      describe('when cacheControl: false', function () {\n        it('should not send cache-control', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              cacheControl: false,\n              maxAge: 20000\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Cache-Control'))\n            .end(done)\n        })\n      })\n\n      describe('when string', function () {\n        it('should accept plain number as milliseconds', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20000'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=20')\n            .end(done)\n        })\n\n        it('should accept suffix \"s\" for seconds', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20s'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=20')\n            .end(done)\n        })\n\n        it('should accept suffix \"m\" for minutes', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20m'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=1200')\n            .end(done)\n        })\n\n        it('should accept suffix \"d\" for days', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20d'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=1728000')\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"root\" option', function () {\n      it('should allow relative path', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('name.txt', {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200, 'tobi', done)\n      })\n\n      it('should allow up within root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('fake/../name.txt', {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200, 'tobi', done)\n      })\n\n      it('should reject up outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('..' + path.sep + path.relative(path.dirname(fixtures), path.join(fixtures, 'name.txt')), {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403, done)\n      })\n\n      it('should reject reading outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('../name.txt', {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403, done)\n      })\n    })\n  })\n})\n\nfunction createApp(path, options, fn) {\n  var app = express();\n\n  app.use(function (req, res) {\n    res.sendFile(path, options, fn);\n  });\n\n  return app;\n}\n",
      "code_after": "'use strict'\n\nvar after = require('after');\nvar assert = require('node:assert')\nvar AsyncLocalStorage = require('node:async_hooks').AsyncLocalStorage\n\nvar express = require('../')\n  , request = require('supertest')\nvar onFinished = require('on-finished');\nvar path = require('node:path');\nvar fixtures = path.join(__dirname, 'fixtures');\nvar utils = require('./support/utils');\n\ndescribe('res', function(){\n  describe('.sendFile(path)', function () {\n    it('should error missing path', function (done) {\n      var app = createApp();\n\n      request(app)\n      .get('/')\n      .expect(500, /path.*required/, done);\n    });\n\n    it('should error for non-string path', function (done) {\n      var app = createApp(42)\n\n      request(app)\n      .get('/')\n      .expect(500, /TypeError: path must be a string to res.sendFile/, done)\n    })\n\n    it('should error for non-absolute path', function (done) {\n      var app = createApp('name.txt')\n\n      request(app)\n        .get('/')\n        .expect(500, /TypeError: path must be absolute/, done)\n    })\n\n    it('should transfer a file', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt'));\n\n      request(app)\n      .get('/')\n      .expect(200, 'tobi', done);\n    });\n\n    it('should transfer a file with special characters in string', function (done) {\n      var app = createApp(path.resolve(fixtures, '% of dogs.txt'));\n\n      request(app)\n      .get('/')\n      .expect(200, '20%', done);\n    });\n\n    it('should include ETag', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt'));\n\n      request(app)\n      .get('/')\n      .expect('ETag', /^(?:W\\/)?\"[^\"]+\"$/)\n      .expect(200, 'tobi', done);\n    });\n\n    it('should 304 when ETag matches', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt'));\n\n      request(app)\n      .get('/')\n      .expect('ETag', /^(?:W\\/)?\"[^\"]+\"$/)\n      .expect(200, 'tobi', function (err, res) {\n        if (err) return done(err);\n        var etag = res.headers.etag;\n        request(app)\n        .get('/')\n        .set('If-None-Match', etag)\n        .expect(304, done);\n      });\n    });\n\n    it('should disable the ETag function if requested', function (done) {\n      var app = createApp(path.resolve(fixtures, 'name.txt')).disable('etag');\n\n      request(app)\n      .get('/')\n      .expect(handleHeaders)\n      .expect(200, done);\n\n      function handleHeaders (res) {\n        assert(res.headers.etag === undefined);\n      }\n    });\n\n    it('should 404 for directory', function (done) {\n      var app = createApp(path.resolve(fixtures, 'blog'));\n\n      request(app)\n      .get('/')\n      .expect(404, done);\n    });\n\n    it('should 404 when not found', function (done) {\n      var app = createApp(path.resolve(fixtures, 'does-no-exist'));\n\n      app.use(function (req, res) {\n        res.statusCode = 200;\n        res.send('no!');\n      });\n\n      request(app)\n      .get('/')\n      .expect(404, done);\n    });\n\n    it('should send cache-control by default', function (done) {\n      var app = createApp(path.resolve(__dirname, 'fixtures/name.txt'))\n\n      request(app)\n        .get('/')\n        .expect('Cache-Control', 'public, max-age=0')\n        .expect(200, done)\n    })\n\n    it('should not serve dotfiles by default', function (done) {\n      var app = createApp(path.resolve(__dirname, 'fixtures/.name'))\n\n      request(app)\n        .get('/')\n        .expect(404, done)\n    })\n\n    it('should not override manual content-types', function (done) {\n      var app = express();\n\n      app.use(function (req, res) {\n        res.contentType('application/x-bogus');\n        res.sendFile(path.resolve(fixtures, 'name.txt'));\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'application/x-bogus')\n      .end(done);\n    })\n\n    it('should not error if the client aborts', function (done) {\n      var app = express();\n      var cb = after(2, done)\n      var error = null\n\n      app.use(function (req, res) {\n        setImmediate(function () {\n          res.sendFile(path.resolve(fixtures, 'name.txt'));\n          setTimeout(function () {\n            cb(error)\n          }, 10)\n        })\n        test.req.abort()\n      });\n\n      app.use(function (err, req, res, next) {\n        error = err\n        next(err)\n      });\n\n      var server = app.listen()\n      var test = request(server).get('/')\n      test.end(function (err) {\n        assert.ok(err)\n        server.close(cb)\n      })\n    })\n  })\n\n  describe('.sendFile(path, fn)', function () {\n    it('should invoke the callback when complete', function (done) {\n      var cb = after(2, done);\n      var app = createApp(path.resolve(fixtures, 'name.txt'), cb);\n\n      request(app)\n      .get('/')\n      .expect(200, cb);\n    })\n\n    it('should invoke the callback when client aborts', function (done) {\n      var cb = after(2, done)\n      var app = express();\n\n      app.use(function (req, res) {\n        setImmediate(function () {\n          res.sendFile(path.resolve(fixtures, 'name.txt'), function (err) {\n            assert.ok(err)\n            assert.strictEqual(err.code, 'ECONNABORTED')\n            cb()\n          });\n        });\n        test.req.abort()\n      });\n\n      var server = app.listen()\n      var test = request(server).get('/')\n      test.end(function (err) {\n        assert.ok(err)\n        server.close(cb)\n      })\n    })\n\n    it('should invoke the callback when client already aborted', function (done) {\n      var cb = after(2, done)\n      var app = express();\n\n      app.use(function (req, res) {\n        onFinished(res, function () {\n          res.sendFile(path.resolve(fixtures, 'name.txt'), function (err) {\n            assert.ok(err)\n            assert.strictEqual(err.code, 'ECONNABORTED')\n            cb()\n          });\n        });\n        test.req.abort()\n      });\n\n      var server = app.listen()\n      var test = request(server).get('/')\n      test.end(function (err) {\n        assert.ok(err)\n        server.close(cb)\n      })\n    })\n\n    it('should invoke the callback without error when HEAD', function (done) {\n      var app = express();\n      var cb = after(2, done);\n\n      app.use(function (req, res) {\n        res.sendFile(path.resolve(fixtures, 'name.txt'), cb);\n      });\n\n      request(app)\n      .head('/')\n      .expect(200, cb);\n    });\n\n    it('should invoke the callback without error when 304', function (done) {\n      var app = express();\n      var cb = after(3, done);\n\n      app.use(function (req, res) {\n        res.sendFile(path.resolve(fixtures, 'name.txt'), cb);\n      });\n\n      request(app)\n      .get('/')\n      .expect('ETag', /^(?:W\\/)?\"[^\"]+\"$/)\n      .expect(200, 'tobi', function (err, res) {\n        if (err) return cb(err);\n        var etag = res.headers.etag;\n        request(app)\n        .get('/')\n        .set('If-None-Match', etag)\n        .expect(304, cb);\n      });\n    });\n\n    it('should invoke the callback on 404', function(done){\n      var app = express();\n\n      app.use(function (req, res) {\n        res.sendFile(path.resolve(fixtures, 'does-not-exist'), function (err) {\n          res.send(err ? 'got ' + err.status + ' error' : 'no error')\n        });\n      });\n\n      request(app)\n        .get('/')\n        .expect(200, 'got 404 error', done)\n    })\n\n    describe('async local storage', function () {\n      it('should persist store', function (done) {\n        var app = express()\n        var cb = after(2, done)\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'name.txt'), function (err) {\n            if (err) return cb(err)\n\n            var local = req.asyncLocalStorage.getStore()\n\n            assert.strictEqual(local.foo, 'bar')\n            cb()\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect('Content-Type', 'text/plain; charset=utf-8')\n          .expect(200, 'tobi', cb)\n      })\n\n      it('should persist store on error', function (done) {\n        var app = express()\n        var store = { foo: 'bar' }\n\n        app.use(function (req, res, next) {\n          req.asyncLocalStorage = new AsyncLocalStorage()\n          req.asyncLocalStorage.run(store, next)\n        })\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'does-not-exist'), function (err) {\n            var local = req.asyncLocalStorage.getStore()\n\n            if (local) {\n              res.setHeader('x-store-foo', String(local.foo))\n            }\n\n            res.send(err ? 'got ' + err.status + ' error' : 'no error')\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('x-store-foo', 'bar')\n          .expect('got 404 error')\n          .end(done)\n      })\n    })\n  })\n\n  describe('.sendFile(path, options)', function () {\n    it('should pass options to send module', function (done) {\n      request(createApp(path.resolve(fixtures, 'name.txt'), { start: 0, end: 1 }))\n      .get('/')\n      .expect(200, 'to', done)\n    })\n\n    describe('with \"acceptRanges\" option', function () {\n      describe('when true', function () {\n        it('should advertise byte range accepted', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Accept-Ranges', 'bytes')\n            .expect('123456789')\n            .end(done)\n        })\n\n        it('should respond to range request', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('Range', 'bytes=0-4')\n            .expect(206, '12345', done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not advertise accept-ranges', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Accept-Ranges'))\n            .end(done)\n        })\n\n        it('should not honor range requests', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'nums.txt'), {\n              acceptRanges: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('Range', 'bytes=0-4')\n            .expect(200, '123456789', done)\n        })\n      })\n    })\n\n    describe('with \"cacheControl\" option', function () {\n      describe('when true', function () {\n        it('should send cache-control header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              cacheControl: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=0')\n            .end(done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not send cache-control header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              cacheControl: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Cache-Control'))\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"dotfiles\" option', function () {\n      describe('when \"allow\"', function () {\n        it('should allow dotfiles', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, '.name'), {\n              dotfiles: 'allow'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldHaveBody(Buffer.from('tobi')))\n            .end(done)\n        })\n      })\n\n      describe('when \"deny\"', function () {\n        it('should deny dotfiles', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, '.name'), {\n              dotfiles: 'deny'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(403)\n            .expect(/Forbidden/)\n            .end(done)\n        })\n      })\n\n      describe('when \"ignore\"', function () {\n        it('should ignore dotfiles', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, '.name'), {\n              dotfiles: 'ignore'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(404)\n            .expect(/Not Found/)\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"headers\" option', function () {\n      it('should set headers on response', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            headers: {\n              'X-Foo': 'Bar',\n              'X-Bar': 'Foo'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'Bar')\n          .expect('X-Bar', 'Foo')\n          .end(done)\n      })\n\n      it('should use last header when duplicated', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            headers: {\n              'X-Foo': 'Bar',\n              'x-foo': 'bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('X-Foo', 'bar')\n          .end(done)\n      })\n\n      it('should override Content-Type', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            headers: {\n              'Content-Type': 'text/x-custom'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Content-Type', 'text/x-custom')\n          .end(done)\n      })\n\n      it('should not set headers on 404', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'does-not-exist'), {\n            headers: {\n              'X-Foo': 'Bar'\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(404)\n          .expect(utils.shouldNotHaveHeader('X-Foo'))\n          .end(done)\n      })\n    })\n\n    describe('with \"immutable\" option', function () {\n      describe('when true', function () {\n        it('should send cache-control header with immutable', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              immutable: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=0, immutable')\n            .end(done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not send cache-control header with immutable', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              immutable: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=0')\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"lastModified\" option', function () {\n      describe('when true', function () {\n        it('should send last-modified header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldHaveHeader('Last-Modified'))\n            .end(done)\n        })\n\n        it('should conditionally respond with if-modified-since', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: true\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('If-Modified-Since', (new Date(Date.now() + 99999).toUTCString()))\n            .expect(304, done)\n        })\n      })\n\n      describe('when false', function () {\n        it('should not have last-modified header', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Last-Modified'))\n            .end(done)\n        })\n\n        it('should not honor if-modified-since', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              lastModified: false\n            })\n          })\n\n          request(app)\n            .get('/')\n            .set('If-Modified-Since', (new Date(Date.now() + 99999).toUTCString()))\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Last-Modified'))\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"maxAge\" option', function () {\n      it('should set cache-control max-age to milliseconds', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: 20000\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=20')\n          .end(done)\n      })\n\n      it('should cap cache-control max-age to 1 year', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: 99999999999\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=31536000')\n          .end(done)\n      })\n\n      it('should min cache-control max-age to 0', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: -20000\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=0')\n          .end(done)\n      })\n\n      it('should floor cache-control max-age', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile(path.resolve(fixtures, 'user.html'), {\n            maxAge: 21911.23\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200)\n          .expect('Cache-Control', 'public, max-age=21')\n          .end(done)\n      })\n\n      describe('when cacheControl: false', function () {\n        it('should not send cache-control', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              cacheControl: false,\n              maxAge: 20000\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect(utils.shouldNotHaveHeader('Cache-Control'))\n            .end(done)\n        })\n      })\n\n      describe('when string', function () {\n        it('should accept plain number as milliseconds', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20000'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=20')\n            .end(done)\n        })\n\n        it('should accept suffix \"s\" for seconds', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20s'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=20')\n            .end(done)\n        })\n\n        it('should accept suffix \"m\" for minutes', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20m'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=1200')\n            .end(done)\n        })\n\n        it('should accept suffix \"d\" for days', function (done) {\n          var app = express()\n\n          app.use(function (req, res) {\n            res.sendFile(path.resolve(fixtures, 'user.html'), {\n              maxAge: '20d'\n            })\n          })\n\n          request(app)\n            .get('/')\n            .expect(200)\n            .expect('Cache-Control', 'public, max-age=1728000')\n            .end(done)\n        })\n      })\n    })\n\n    describe('with \"root\" option', function () {\n      it('should allow relative path', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('name.txt', {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200, 'tobi', done)\n      })\n\n      it('should allow up within root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('fake/../name.txt', {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(200, 'tobi', done)\n      })\n\n      it('should reject up outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('..' + path.sep + path.relative(path.dirname(fixtures), path.join(fixtures, 'name.txt')), {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403, done)\n      })\n\n      it('should reject reading outside root', function (done) {\n        var app = express()\n\n        app.use(function (req, res) {\n          res.sendFile('../name.txt', {\n            root: fixtures\n          })\n        })\n\n        request(app)\n          .get('/')\n          .expect(403, done)\n      })\n    })\n  })\n})\n\nfunction createApp(path, options, fn) {\n  var app = express();\n\n  app.use(function (req, res) {\n    res.sendFile(path, options, fn);\n  });\n\n  return app;\n}\n",
      "bug_category": "naming",
      "error_type": "naming_improvement",
      "confidence": 0.4
    },
    {
      "bug_id": "e8d2682d5c0e",
      "repo": "express",
      "commit_hash": "f9954dd",
      "commit_message": "fix(test): remove duplicate word (#6456)",
      "file_path": "test/app.router.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar after = require('after');\nvar express = require('../')\n  , request = require('supertest')\n  , assert = require('node:assert')\n  , methods = require('../lib/utils').methods;\n\nvar shouldSkipQuery = require('./support/utils').shouldSkipQuery\n\ndescribe('app.router', function () {\n  it('should restore req.params after leaving router', function (done) {\n    var app = express();\n    var router = new express.Router();\n\n    function handler1(req, res, next) {\n      res.setHeader('x-user-id', String(req.params.id));\n      next()\n    }\n\n    function handler2(req, res) {\n      res.send(req.params.id);\n    }\n\n    router.use(function (req, res, next) {\n      res.setHeader('x-router', String(req.params.id));\n      next();\n    });\n\n    app.get('/user/:id', handler1, router, handler2);\n\n    request(app)\n      .get('/user/1')\n      .expect('x-router', 'undefined')\n      .expect('x-user-id', '1')\n      .expect(200, '1', done);\n  })\n\n  describe('methods', function () {\n    methods.forEach(function (method) {\n      if (method === 'connect') return;\n\n      it('should include ' + method.toUpperCase(), function (done) {\n        if (method === 'query' && shouldSkipQuery(process.versions.node)) {\n          this.skip()\n        }\n        var app = express();\n\n        app[method]('/foo', function (req, res) {\n          res.send(method)\n        });\n\n        request(app)\n        [method]('/foo')\n          .expect(200, done)\n      })\n\n      it('should reject numbers for app.' + method, function () {\n        var app = express();\n        assert.throws(app[method].bind(app, '/', 3), /argument handler must be a function/);\n      })\n    });\n\n    it('should re-route when method is altered', function (done) {\n      var app = express();\n      var cb = after(3, done);\n\n      app.use(function (req, res, next) {\n        if (req.method !== 'POST') return next();\n        req.method = 'DELETE';\n        res.setHeader('X-Method-Altered', '1');\n        next();\n      });\n\n      app.delete('/', function (req, res) {\n        res.end('deleted everything');\n      });\n\n      request(app)\n        .get('/')\n        .expect(404, cb)\n\n      request(app)\n        .delete('/')\n        .expect(200, 'deleted everything', cb);\n\n      request(app)\n        .post('/')\n        .expect('X-Method-Altered', '1')\n        .expect(200, 'deleted everything', cb);\n    });\n  })\n\n  describe('decode params', function () {\n    it('should decode correct params', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/foo%2Fbar')\n        .expect('foo/bar', done);\n    })\n\n    it('should not accept params in malformed paths', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/%foobar')\n        .expect(400, done);\n    })\n\n    it('should not decode spaces', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/foo+bar')\n        .expect('foo+bar', done);\n    })\n\n    it('should work with unicode', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/%ce%b1')\n        .expect('\\u03b1', done);\n    })\n  })\n\n  it('should be .use()able', function (done) {\n    var app = express();\n\n    var calls = [];\n\n    app.use(function (req, res, next) {\n      calls.push('before');\n      next();\n    });\n\n    app.get('/', function (req, res, next) {\n      calls.push('GET /')\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      calls.push('after');\n      res.json(calls)\n    });\n\n    request(app)\n      .get('/')\n      .expect(200, ['before', 'GET /', 'after'], done)\n  })\n\n  describe('when given a regexp', function () {\n    it('should match the pathname only', function (done) {\n      var app = express();\n\n      app.get(/^\\/user\\/[0-9]+$/, function (req, res) {\n        res.end('user');\n      });\n\n      request(app)\n        .get('/user/12?foo=bar')\n        .expect('user', done);\n    })\n\n    it('should populate req.params with the captures', function (done) {\n      var app = express();\n\n      app.get(/^\\/user\\/([0-9]+)\\/(view|edit)?$/, function (req, res) {\n        var id = req.params[0]\n          , op = req.params[1];\n        res.end(op + 'ing user ' + id);\n      });\n\n      request(app)\n        .get('/user/10/edit')\n        .expect('editing user 10', done);\n    })\n\n    if (supportsRegexp('(?<foo>.*)')) {\n      it('should populate req.params with named captures', function (done) {\n        var app = express();\n        var re = new RegExp('^/user/(?<userId>[0-9]+)/(view|edit)?$');\n\n        app.get(re, function (req, res) {\n          var id = req.params.userId\n            , op = req.params[0];\n          res.end(op + 'ing user ' + id);\n        });\n\n        request(app)\n          .get('/user/10/edit')\n          .expect('editing user 10', done);\n      })\n    }\n\n    it('should ensure regexp matches path prefix', function (done) {\n      var app = express()\n      var p = []\n\n      app.use(/\\/api.*/, function (req, res, next) {\n        p.push('a')\n        next()\n      })\n      app.use(/api/, function (req, res, next) {\n        p.push('b')\n        next()\n      })\n      app.use(/\\/test/, function (req, res, next) {\n        p.push('c')\n        next()\n      })\n      app.use(function (req, res) {\n        res.end()\n      })\n\n      request(app)\n        .get('/test/api/1234')\n        .expect(200, function (err) {\n          if (err) return done(err)\n          assert.deepEqual(p, ['c'])\n          done()\n        })\n    })\n  })\n\n  describe('case sensitivity', function () {\n    it('should be disabled by default', function (done) {\n      var app = express();\n\n      app.get('/user', function (req, res) {\n        res.end('tj');\n      });\n\n      request(app)\n        .get('/USER')\n        .expect('tj', done);\n    })\n\n    describe('when \"case sensitive routing\" is enabled', function () {\n      it('should match identical casing', function (done) {\n        var app = express();\n\n        app.enable('case sensitive routing');\n\n        app.get('/uSer', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/uSer')\n          .expect('tj', done);\n      })\n\n      it('should not match otherwise', function (done) {\n        var app = express();\n\n        app.enable('case sensitive routing');\n\n        app.get('/uSer', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(404, done);\n      })\n    })\n  })\n\n  describe('params', function () {\n    it('should overwrite existing req.params by default', function (done) {\n      var app = express();\n      var router = new express.Router();\n\n      router.get('/:action', function (req, res) {\n        res.send(req.params);\n      });\n\n      app.use('/user/:user', router);\n\n      request(app)\n        .get('/user/1/get')\n        .expect(200, '{\"action\":\"get\"}', done);\n    })\n\n    it('should allow merging existing req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get('/:action', function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use('/user/:user', router);\n\n      request(app)\n        .get('/user/tj/get')\n        .expect(200, '[[\"action\",\"get\"],[\"user\",\"tj\"]]', done);\n    })\n\n    it('should use params from router', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get('/:thing', function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use('/user/:thing', router);\n\n      request(app)\n        .get('/user/tj/get')\n        .expect(200, '[[\"thing\",\"get\"]]', done);\n    })\n\n    it('should merge numeric indices req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/^\\/(.*)\\.(.*)/, function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use(/^\\/user\\/id:(\\d+)/, router);\n\n      request(app)\n        .get('/user/id:10/profile.json')\n        .expect(200, '[[\"0\",\"10\"],[\"1\",\"profile\"],[\"2\",\"json\"]]', done);\n    })\n\n    it('should merge numeric indices req.params when more in parent', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/\\/(.*)/, function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use(/^\\/user\\/id:(\\d+)\\/name:(\\w+)/, router);\n\n      request(app)\n        .get('/user/id:10/name:tj/profile')\n        .expect(200, '[[\"0\",\"10\"],[\"1\",\"tj\"],[\"2\",\"profile\"]]', done);\n    })\n\n    it('should merge numeric indices req.params when parent has same number', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/\\/name:(\\w+)/, function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use(/\\/user\\/id:(\\d+)/, router);\n\n      request(app)\n        .get('/user/id:10/name:tj')\n        .expect(200, '[[\"0\",\"10\"],[\"1\",\"tj\"]]', done);\n    })\n\n    it('should ignore invalid incoming req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get('/:name', function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use('/user/', function (req, res, next) {\n        req.params = 3; // wat?\n        router(req, res, next);\n      });\n\n      request(app)\n        .get('/user/tj')\n        .expect(200, '[[\"name\",\"tj\"]]', done);\n    })\n\n    it('should restore req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/\\/user:(\\w+)\\//, function (req, res, next) {\n        next();\n      });\n\n      app.use(/\\/user\\/id:(\\d+)/, function (req, res, next) {\n        router(req, res, function (err) {\n          var keys = Object.keys(req.params).sort();\n          res.send(keys.map(function (k) { return [k, req.params[k]] }));\n        });\n      });\n\n      request(app)\n        .get('/user/id:42/user:tj/profile')\n        .expect(200, '[[\"0\",\"42\"]]', done);\n    })\n  })\n\n  describe('trailing slashes', function () {\n    it('should be optional by default', function (done) {\n      var app = express();\n\n      app.get('/user', function (req, res) {\n        res.end('tj');\n      });\n\n      request(app)\n        .get('/user/')\n        .expect('tj', done);\n    })\n\n    describe('when \"strict routing\" is enabled', function () {\n      it('should match trailing slashes', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect('tj', done);\n      })\n\n      it('should pass-though middleware', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use(function (req, res, next) {\n          res.setHeader('x-middleware', 'true');\n          next();\n        });\n\n        app.get('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect('x-middleware', 'true')\n          .expect(200, 'tj', done);\n      })\n\n      it('should pass-though mounted middleware', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user/', function (req, res, next) {\n          res.setHeader('x-middleware', 'true');\n          next();\n        });\n\n        app.get('/user/test/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/test/')\n          .expect('x-middleware', 'true')\n          .expect(200, 'tj', done);\n      })\n\n      it('should match no slashes', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect('tj', done);\n      })\n\n      it('should match middleware when omitting the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(200, 'tj', done);\n      })\n\n      it('should match middleware', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(200, 'tj', done);\n      })\n\n      it('should match middleware when adding the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect(200, 'tj', done);\n      })\n\n      it('should fail when omitting the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(404, done);\n      })\n\n      it('should fail when adding the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect(404, done);\n      })\n    })\n  })\n\n  it('should allow literal \".\"', function (done) {\n    var app = express();\n\n    app.get('/api/users/:from..:to', function (req, res) {\n      var from = req.params.from\n        , to = req.params.to;\n\n      res.end('users from ' + from + ' to ' + to);\n    });\n\n    request(app)\n      .get('/api/users/1..50')\n      .expect('users from 1 to 50', done);\n  })\n\n  describe(':name', function () {\n    it('should denote a capture group', function (done) {\n      var app = express();\n\n      app.get('/user/:user', function (req, res) {\n        res.end(req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj')\n        .expect('tj', done);\n    })\n\n    it('should match a single segment only', function (done) {\n      var app = express();\n\n      app.get('/user/:user', function (req, res) {\n        res.end(req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect(404, done);\n    })\n\n    it('should allow several capture groups', function (done) {\n      var app = express();\n\n      app.get('/user/:user/:op', function (req, res) {\n        res.end(req.params.op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect('editing tj', done);\n    })\n\n    it('should work following a partial capture group', function (done) {\n      var app = express();\n      var cb = after(2, done);\n\n      app.get('/user{s}/:user/:op', function (req, res) {\n        res.end(req.params.op + 'ing ' + req.params.user + (req.url.startsWith('/users') ? ' (old)' : ''));\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect('editing tj', cb);\n\n      request(app)\n        .get('/users/tj/edit')\n        .expect('editing tj (old)', cb);\n    })\n\n    it('should work inside literal parenthesis', function (done) {\n      var app = express();\n\n      app.get('/:user\\\\(:op\\\\)', function (req, res) {\n        res.end(req.params.op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/tj(edit)')\n        .expect('editing tj', done);\n    })\n\n    it('should work in array of paths', function (done) {\n      var app = express();\n      var cb = after(2, done);\n\n      app.get(['/user/:user/poke', '/user/:user/pokes'], function (req, res) {\n        res.end('poking ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/poke')\n        .expect('poking tj', cb);\n\n      request(app)\n        .get('/user/tj/pokes')\n        .expect('poking tj', cb);\n    })\n  })\n\n  describe(':name?', function () {\n    it('should denote an optional capture group', function (done) {\n      var app = express();\n\n      app.get('/user/:user{/:op}', function (req, res) {\n        var op = req.params.op || 'view';\n        res.end(op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj')\n        .expect('viewing tj', done);\n    })\n\n    it('should populate the capture group', function (done) {\n      var app = express();\n\n      app.get('/user/:user{/:op}', function (req, res) {\n        var op = req.params.op || 'view';\n        res.end(op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect('editing tj', done);\n    })\n  })\n\n  describe(':name*', function () {\n    it('should match one segment', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user[0])\n      })\n\n      request(app)\n        .get('/user/122')\n        .expect('122', done)\n    })\n\n    it('should match many segments', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user.join('/'))\n      })\n\n      request(app)\n        .get('/user/1/2/3/4')\n        .expect('1/2/3/4', done)\n    })\n\n    it('should match zero segments', function (done) {\n      var app = express()\n\n      app.get('/user{/*user}', function (req, res) {\n        res.end(req.params.user)\n      })\n\n      request(app)\n        .get('/user')\n        .expect('', done)\n    })\n  })\n\n  describe(':name+', function () {\n    it('should match one segment', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user[0])\n      })\n\n      request(app)\n        .get('/user/122')\n        .expect(200, '122', done)\n    })\n\n    it('should match many segments', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user.join('/'))\n      })\n\n      request(app)\n        .get('/user/1/2/3/4')\n        .expect(200, '1/2/3/4', done)\n    })\n\n    it('should not match zero segments', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user)\n      })\n\n      request(app)\n        .get('/user')\n        .expect(404, done)\n    })\n  })\n\n  describe('.:name', function () {\n    it('should denote a format', function (done) {\n      var app = express();\n      var cb = after(2, done)\n\n      app.get('/:name.:format', function (req, res) {\n        res.end(req.params.name + ' as ' + req.params.format);\n      });\n\n      request(app)\n        .get('/foo.json')\n        .expect(200, 'foo as json', cb)\n\n      request(app)\n        .get('/foo')\n        .expect(404, cb)\n    })\n  })\n\n  describe('.:name?', function () {\n    it('should denote an optional format', function (done) {\n      var app = express();\n      var cb = after(2, done)\n\n      app.get('/:name{.:format}', function (req, res) {\n        res.end(req.params.name + ' as ' + (req.params.format || 'html'));\n      });\n\n      request(app)\n        .get('/foo')\n        .expect(200, 'foo as html', cb)\n\n      request(app)\n        .get('/foo.json')\n        .expect(200, 'foo as json', cb)\n    })\n  })\n\n  describe('when next() is called', function () {\n    it('should continue lookup', function (done) {\n      var app = express()\n        , calls = [];\n\n      app.get('/foo{/:bar}', function (req, res, next) {\n        calls.push('/foo/:bar?');\n        next();\n      });\n\n      app.get('/bar', function () {\n        assert(0);\n      });\n\n      app.get('/foo', function (req, res, next) {\n        calls.push('/foo');\n        next();\n      });\n\n      app.get('/foo', function (req, res) {\n        calls.push('/foo 2');\n        res.json(calls)\n      });\n\n      request(app)\n        .get('/foo')\n        .expect(200, ['/foo/:bar?', '/foo', '/foo 2'], done)\n    })\n  })\n\n  describe('when next(\"route\") is called', function () {\n    it('should jump to next route', function (done) {\n      var app = express()\n\n      function fn(req, res, next) {\n        res.set('X-Hit', '1')\n        next('route')\n      }\n\n      app.get('/foo', fn, function (req, res) {\n        res.end('failure')\n      });\n\n      app.get('/foo', function (req, res) {\n        res.end('success')\n      })\n\n      request(app)\n        .get('/foo')\n        .expect('X-Hit', '1')\n        .expect(200, 'success', done)\n    })\n  })\n\n  describe('when next(\"router\") is called', function () {\n    it('should jump out of router', function (done) {\n      var app = express()\n      var router = express.Router()\n\n      function fn(req, res, next) {\n        res.set('X-Hit', '1')\n        next('router')\n      }\n\n      router.get('/foo', fn, function (req, res) {\n        res.end('failure')\n      })\n\n      router.get('/foo', function (req, res) {\n        res.end('failure')\n      })\n\n      app.use(router)\n\n      app.get('/foo', function (req, res) {\n        res.end('success')\n      })\n\n      request(app)\n        .get('/foo')\n        .expect('X-Hit', '1')\n        .expect(200, 'success', done)\n    })\n  })\n\n  describe('when next(err) is called', function () {\n    it('should break out of app.router', function (done) {\n      var app = express()\n        , calls = [];\n\n      app.get('/foo{/:bar}', function (req, res, next) {\n        calls.push('/foo/:bar?');\n        next();\n      });\n\n      app.get('/bar', function () {\n        assert(0);\n      });\n\n      app.get('/foo', function (req, res, next) {\n        calls.push('/foo');\n        next(new Error('fail'));\n      });\n\n      app.get('/foo', function () {\n        assert(0);\n      });\n\n      app.use(function (err, req, res, next) {\n        res.json({\n          calls: calls,\n          error: err.message\n        })\n      })\n\n      request(app)\n        .get('/foo')\n        .expect(200, { calls: ['/foo/:bar?', '/foo'], error: 'fail' }, done)\n    })\n\n    it('should call handler in same route, if exists', function (done) {\n      var app = express();\n\n      function fn1(req, res, next) {\n        next(new Error('boom!'));\n      }\n\n      function fn2(req, res, next) {\n        res.send('foo here');\n      }\n\n      function fn3(err, req, res, next) {\n        res.send('route go ' + err.message);\n      }\n\n      app.get('/foo', fn1, fn2, fn3);\n\n      app.use(function (err, req, res, next) {\n        res.end('error!');\n      })\n\n      request(app)\n        .get('/foo')\n        .expect('route go boom!', done)\n    })\n  })\n\n  describe('promise support', function () {\n    it('should pass rejected promise value', function (done) {\n      var app = express()\n      var router = new express.Router()\n\n      router.use(function createError(req, res, next) {\n        return Promise.reject(new Error('boom!'))\n      })\n\n      router.use(function sawError(err, req, res, next) {\n        res.send('saw ' + err.name + ': ' + err.message)\n      })\n\n      app.use(router)\n\n      request(app)\n        .get('/')\n        .expect(200, 'saw Error: boom!', done)\n    })\n\n    it('should pass rejected promise without value', function (done) {\n      var app = express()\n      var router = new express.Router()\n\n      router.use(function createError(req, res, next) {\n        return Promise.reject()\n      })\n\n      router.use(function sawError(err, req, res, next) {\n        res.send('saw ' + err.name + ': ' + err.message)\n      })\n\n      app.use(router)\n\n      request(app)\n        .get('/')\n        .expect(200, 'saw Error: Rejected promise', done)\n    })\n\n    it('should ignore resolved promise', function (done) {\n      var app = express()\n      var router = new express.Router()\n\n      router.use(function createError(req, res, next) {\n        res.send('saw GET /foo')\n        return Promise.resolve('foo')\n      })\n\n      router.use(function () {\n        done(new Error('Unexpected middleware invoke'))\n      })\n\n      app.use(router)\n\n      request(app)\n        .get('/foo')\n        .expect(200, 'saw GET /foo', done)\n    })\n\n    describe('error handling', function () {\n      it('should pass rejected promise value', function (done) {\n        var app = express()\n        var router = new express.Router()\n\n        router.use(function createError(req, res, next) {\n          return Promise.reject(new Error('boom!'))\n        })\n\n        router.use(function handleError(err, req, res, next) {\n          return Promise.reject(new Error('caught: ' + err.message))\n        })\n\n        router.use(function sawError(err, req, res, next) {\n          res.send('saw ' + err.name + ': ' + err.message)\n        })\n\n        app.use(router)\n\n        request(app)\n          .get('/')\n          .expect(200, 'saw Error: caught: boom!', done)\n      })\n\n      it('should pass rejected promise without value', function (done) {\n        var app = express()\n        var router = new express.Router()\n\n        router.use(function createError(req, res, next) {\n          return Promise.reject()\n        })\n\n        router.use(function handleError(err, req, res, next) {\n          return Promise.reject(new Error('caught: ' + err.message))\n        })\n\n        router.use(function sawError(err, req, res, next) {\n          res.send('saw ' + err.name + ': ' + err.message)\n        })\n\n        app.use(router)\n\n        request(app)\n          .get('/')\n          .expect(200, 'saw Error: caught: Rejected promise', done)\n      })\n\n      it('should ignore resolved promise', function (done) {\n        var app = express()\n        var router = new express.Router()\n\n        router.use(function createError(req, res, next) {\n          return Promise.reject(new Error('boom!'))\n        })\n\n        router.use(function handleError(err, req, res, next) {\n          res.send('saw ' + err.name + ': ' + err.message)\n          return Promise.resolve('foo')\n        })\n\n        router.use(function () {\n          done(new Error('Unexpected middleware invoke'))\n        })\n\n        app.use(router)\n\n        request(app)\n          .get('/foo')\n          .expect(200, 'saw Error: boom!', done)\n      })\n    })\n  })\n\n  it('should allow rewriting of the url', function (done) {\n    var app = express();\n\n    app.get('/account/edit', function (req, res, next) {\n      req.user = { id: 12 }; // faux authenticated user\n      req.url = '/user/' + req.user.id + '/edit';\n      next();\n    });\n\n    app.get('/user/:id/edit', function (req, res) {\n      res.send('editing user ' + req.params.id);\n    });\n\n    request(app)\n      .get('/account/edit')\n      .expect('editing user 12', done);\n  })\n\n  it('should run in order added', function (done) {\n    var app = express();\n    var path = [];\n\n    app.get('/*path', function (req, res, next) {\n      path.push(0);\n      next();\n    });\n\n    app.get('/user/:id', function (req, res, next) {\n      path.push(1);\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      path.push(2);\n      next();\n    });\n\n    app.all('/user/:id', function (req, res, next) {\n      path.push(3);\n      next();\n    });\n\n    app.get('/*splat', function (req, res, next) {\n      path.push(4);\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      path.push(5);\n      res.end(path.join(','))\n    });\n\n    request(app)\n      .get('/user/1')\n      .expect(200, '0,1,2,3,4,5', done);\n  })\n\n  it('should be chainable', function () {\n    var app = express();\n    assert.strictEqual(app.get('/', function () { }), app)\n  })\n\n  it('should should not use disposed router/middleware', function (done) {\n    // more context: https://github.com/expressjs/express/issues/5743#issuecomment-2277148412\n\n    var app = express();\n    var router = new express.Router();\n\n    router.use(function (req, res, next) {\n      res.setHeader('old', 'foo');\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      return router.handle(req, res, next);\n    });\n\n    app.get('/', function (req, res, next) {\n      res.send('yee');\n      next();\n    });\n\n    request(app)\n      .get('/')\n      .expect('old', 'foo')\n      .expect(function (res) {\n        if (typeof res.headers['new'] !== 'undefined') {\n          throw new Error('`new` header should not be present');\n        }\n      })\n      .expect(200, 'yee', function (err, res) {\n        if (err) return done(err);\n\n        router = new express.Router();\n\n        router.use(function (req, res, next) {\n          res.setHeader('new', 'bar');\n          next();\n        });\n\n        request(app)\n          .get('/')\n          .expect('new', 'bar')\n          .expect(function (res) {\n            if (typeof res.headers['old'] !== 'undefined') {\n              throw new Error('`old` header should not be present');\n            }\n          })\n          .expect(200, 'yee', done);\n      });\n  })\n})\n\nfunction supportsRegexp(source) {\n  try {\n    new RegExp(source)\n    return true\n  } catch (e) {\n    return false\n  }\n}\n",
      "code_after": "'use strict'\n\nvar after = require('after');\nvar express = require('../')\n  , request = require('supertest')\n  , assert = require('node:assert')\n  , methods = require('../lib/utils').methods;\n\nvar shouldSkipQuery = require('./support/utils').shouldSkipQuery\n\ndescribe('app.router', function () {\n  it('should restore req.params after leaving router', function (done) {\n    var app = express();\n    var router = new express.Router();\n\n    function handler1(req, res, next) {\n      res.setHeader('x-user-id', String(req.params.id));\n      next()\n    }\n\n    function handler2(req, res) {\n      res.send(req.params.id);\n    }\n\n    router.use(function (req, res, next) {\n      res.setHeader('x-router', String(req.params.id));\n      next();\n    });\n\n    app.get('/user/:id', handler1, router, handler2);\n\n    request(app)\n      .get('/user/1')\n      .expect('x-router', 'undefined')\n      .expect('x-user-id', '1')\n      .expect(200, '1', done);\n  })\n\n  describe('methods', function () {\n    methods.forEach(function (method) {\n      if (method === 'connect') return;\n\n      it('should include ' + method.toUpperCase(), function (done) {\n        if (method === 'query' && shouldSkipQuery(process.versions.node)) {\n          this.skip()\n        }\n        var app = express();\n\n        app[method]('/foo', function (req, res) {\n          res.send(method)\n        });\n\n        request(app)\n        [method]('/foo')\n          .expect(200, done)\n      })\n\n      it('should reject numbers for app.' + method, function () {\n        var app = express();\n        assert.throws(app[method].bind(app, '/', 3), /argument handler must be a function/);\n      })\n    });\n\n    it('should re-route when method is altered', function (done) {\n      var app = express();\n      var cb = after(3, done);\n\n      app.use(function (req, res, next) {\n        if (req.method !== 'POST') return next();\n        req.method = 'DELETE';\n        res.setHeader('X-Method-Altered', '1');\n        next();\n      });\n\n      app.delete('/', function (req, res) {\n        res.end('deleted everything');\n      });\n\n      request(app)\n        .get('/')\n        .expect(404, cb)\n\n      request(app)\n        .delete('/')\n        .expect(200, 'deleted everything', cb);\n\n      request(app)\n        .post('/')\n        .expect('X-Method-Altered', '1')\n        .expect(200, 'deleted everything', cb);\n    });\n  })\n\n  describe('decode params', function () {\n    it('should decode correct params', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/foo%2Fbar')\n        .expect('foo/bar', done);\n    })\n\n    it('should not accept params in malformed paths', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/%foobar')\n        .expect(400, done);\n    })\n\n    it('should not decode spaces', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/foo+bar')\n        .expect('foo+bar', done);\n    })\n\n    it('should work with unicode', function (done) {\n      var app = express();\n\n      app.get('/:name', function (req, res) {\n        res.send(req.params.name);\n      });\n\n      request(app)\n        .get('/%ce%b1')\n        .expect('\\u03b1', done);\n    })\n  })\n\n  it('should be .use()able', function (done) {\n    var app = express();\n\n    var calls = [];\n\n    app.use(function (req, res, next) {\n      calls.push('before');\n      next();\n    });\n\n    app.get('/', function (req, res, next) {\n      calls.push('GET /')\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      calls.push('after');\n      res.json(calls)\n    });\n\n    request(app)\n      .get('/')\n      .expect(200, ['before', 'GET /', 'after'], done)\n  })\n\n  describe('when given a regexp', function () {\n    it('should match the pathname only', function (done) {\n      var app = express();\n\n      app.get(/^\\/user\\/[0-9]+$/, function (req, res) {\n        res.end('user');\n      });\n\n      request(app)\n        .get('/user/12?foo=bar')\n        .expect('user', done);\n    })\n\n    it('should populate req.params with the captures', function (done) {\n      var app = express();\n\n      app.get(/^\\/user\\/([0-9]+)\\/(view|edit)?$/, function (req, res) {\n        var id = req.params[0]\n          , op = req.params[1];\n        res.end(op + 'ing user ' + id);\n      });\n\n      request(app)\n        .get('/user/10/edit')\n        .expect('editing user 10', done);\n    })\n\n    if (supportsRegexp('(?<foo>.*)')) {\n      it('should populate req.params with named captures', function (done) {\n        var app = express();\n        var re = new RegExp('^/user/(?<userId>[0-9]+)/(view|edit)?$');\n\n        app.get(re, function (req, res) {\n          var id = req.params.userId\n            , op = req.params[0];\n          res.end(op + 'ing user ' + id);\n        });\n\n        request(app)\n          .get('/user/10/edit')\n          .expect('editing user 10', done);\n      })\n    }\n\n    it('should ensure regexp matches path prefix', function (done) {\n      var app = express()\n      var p = []\n\n      app.use(/\\/api.*/, function (req, res, next) {\n        p.push('a')\n        next()\n      })\n      app.use(/api/, function (req, res, next) {\n        p.push('b')\n        next()\n      })\n      app.use(/\\/test/, function (req, res, next) {\n        p.push('c')\n        next()\n      })\n      app.use(function (req, res) {\n        res.end()\n      })\n\n      request(app)\n        .get('/test/api/1234')\n        .expect(200, function (err) {\n          if (err) return done(err)\n          assert.deepEqual(p, ['c'])\n          done()\n        })\n    })\n  })\n\n  describe('case sensitivity', function () {\n    it('should be disabled by default', function (done) {\n      var app = express();\n\n      app.get('/user', function (req, res) {\n        res.end('tj');\n      });\n\n      request(app)\n        .get('/USER')\n        .expect('tj', done);\n    })\n\n    describe('when \"case sensitive routing\" is enabled', function () {\n      it('should match identical casing', function (done) {\n        var app = express();\n\n        app.enable('case sensitive routing');\n\n        app.get('/uSer', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/uSer')\n          .expect('tj', done);\n      })\n\n      it('should not match otherwise', function (done) {\n        var app = express();\n\n        app.enable('case sensitive routing');\n\n        app.get('/uSer', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(404, done);\n      })\n    })\n  })\n\n  describe('params', function () {\n    it('should overwrite existing req.params by default', function (done) {\n      var app = express();\n      var router = new express.Router();\n\n      router.get('/:action', function (req, res) {\n        res.send(req.params);\n      });\n\n      app.use('/user/:user', router);\n\n      request(app)\n        .get('/user/1/get')\n        .expect(200, '{\"action\":\"get\"}', done);\n    })\n\n    it('should allow merging existing req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get('/:action', function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use('/user/:user', router);\n\n      request(app)\n        .get('/user/tj/get')\n        .expect(200, '[[\"action\",\"get\"],[\"user\",\"tj\"]]', done);\n    })\n\n    it('should use params from router', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get('/:thing', function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use('/user/:thing', router);\n\n      request(app)\n        .get('/user/tj/get')\n        .expect(200, '[[\"thing\",\"get\"]]', done);\n    })\n\n    it('should merge numeric indices req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/^\\/(.*)\\.(.*)/, function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use(/^\\/user\\/id:(\\d+)/, router);\n\n      request(app)\n        .get('/user/id:10/profile.json')\n        .expect(200, '[[\"0\",\"10\"],[\"1\",\"profile\"],[\"2\",\"json\"]]', done);\n    })\n\n    it('should merge numeric indices req.params when more in parent', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/\\/(.*)/, function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use(/^\\/user\\/id:(\\d+)\\/name:(\\w+)/, router);\n\n      request(app)\n        .get('/user/id:10/name:tj/profile')\n        .expect(200, '[[\"0\",\"10\"],[\"1\",\"tj\"],[\"2\",\"profile\"]]', done);\n    })\n\n    it('should merge numeric indices req.params when parent has same number', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/\\/name:(\\w+)/, function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use(/\\/user\\/id:(\\d+)/, router);\n\n      request(app)\n        .get('/user/id:10/name:tj')\n        .expect(200, '[[\"0\",\"10\"],[\"1\",\"tj\"]]', done);\n    })\n\n    it('should ignore invalid incoming req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get('/:name', function (req, res) {\n        var keys = Object.keys(req.params).sort();\n        res.send(keys.map(function (k) { return [k, req.params[k]] }));\n      });\n\n      app.use('/user/', function (req, res, next) {\n        req.params = 3; // wat?\n        router(req, res, next);\n      });\n\n      request(app)\n        .get('/user/tj')\n        .expect(200, '[[\"name\",\"tj\"]]', done);\n    })\n\n    it('should restore req.params', function (done) {\n      var app = express();\n      var router = new express.Router({ mergeParams: true });\n\n      router.get(/\\/user:(\\w+)\\//, function (req, res, next) {\n        next();\n      });\n\n      app.use(/\\/user\\/id:(\\d+)/, function (req, res, next) {\n        router(req, res, function (err) {\n          var keys = Object.keys(req.params).sort();\n          res.send(keys.map(function (k) { return [k, req.params[k]] }));\n        });\n      });\n\n      request(app)\n        .get('/user/id:42/user:tj/profile')\n        .expect(200, '[[\"0\",\"42\"]]', done);\n    })\n  })\n\n  describe('trailing slashes', function () {\n    it('should be optional by default', function (done) {\n      var app = express();\n\n      app.get('/user', function (req, res) {\n        res.end('tj');\n      });\n\n      request(app)\n        .get('/user/')\n        .expect('tj', done);\n    })\n\n    describe('when \"strict routing\" is enabled', function () {\n      it('should match trailing slashes', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect('tj', done);\n      })\n\n      it('should pass-though middleware', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use(function (req, res, next) {\n          res.setHeader('x-middleware', 'true');\n          next();\n        });\n\n        app.get('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect('x-middleware', 'true')\n          .expect(200, 'tj', done);\n      })\n\n      it('should pass-though mounted middleware', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user/', function (req, res, next) {\n          res.setHeader('x-middleware', 'true');\n          next();\n        });\n\n        app.get('/user/test/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/test/')\n          .expect('x-middleware', 'true')\n          .expect(200, 'tj', done);\n      })\n\n      it('should match no slashes', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect('tj', done);\n      })\n\n      it('should match middleware when omitting the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(200, 'tj', done);\n      })\n\n      it('should match middleware', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(200, 'tj', done);\n      })\n\n      it('should match middleware when adding the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.use('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect(200, 'tj', done);\n      })\n\n      it('should fail when omitting the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user/', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user')\n          .expect(404, done);\n      })\n\n      it('should fail when adding the trailing slash', function (done) {\n        var app = express();\n\n        app.enable('strict routing');\n\n        app.get('/user', function (req, res) {\n          res.end('tj');\n        });\n\n        request(app)\n          .get('/user/')\n          .expect(404, done);\n      })\n    })\n  })\n\n  it('should allow literal \".\"', function (done) {\n    var app = express();\n\n    app.get('/api/users/:from..:to', function (req, res) {\n      var from = req.params.from\n        , to = req.params.to;\n\n      res.end('users from ' + from + ' to ' + to);\n    });\n\n    request(app)\n      .get('/api/users/1..50')\n      .expect('users from 1 to 50', done);\n  })\n\n  describe(':name', function () {\n    it('should denote a capture group', function (done) {\n      var app = express();\n\n      app.get('/user/:user', function (req, res) {\n        res.end(req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj')\n        .expect('tj', done);\n    })\n\n    it('should match a single segment only', function (done) {\n      var app = express();\n\n      app.get('/user/:user', function (req, res) {\n        res.end(req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect(404, done);\n    })\n\n    it('should allow several capture groups', function (done) {\n      var app = express();\n\n      app.get('/user/:user/:op', function (req, res) {\n        res.end(req.params.op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect('editing tj', done);\n    })\n\n    it('should work following a partial capture group', function (done) {\n      var app = express();\n      var cb = after(2, done);\n\n      app.get('/user{s}/:user/:op', function (req, res) {\n        res.end(req.params.op + 'ing ' + req.params.user + (req.url.startsWith('/users') ? ' (old)' : ''));\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect('editing tj', cb);\n\n      request(app)\n        .get('/users/tj/edit')\n        .expect('editing tj (old)', cb);\n    })\n\n    it('should work inside literal parenthesis', function (done) {\n      var app = express();\n\n      app.get('/:user\\\\(:op\\\\)', function (req, res) {\n        res.end(req.params.op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/tj(edit)')\n        .expect('editing tj', done);\n    })\n\n    it('should work in array of paths', function (done) {\n      var app = express();\n      var cb = after(2, done);\n\n      app.get(['/user/:user/poke', '/user/:user/pokes'], function (req, res) {\n        res.end('poking ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/poke')\n        .expect('poking tj', cb);\n\n      request(app)\n        .get('/user/tj/pokes')\n        .expect('poking tj', cb);\n    })\n  })\n\n  describe(':name?', function () {\n    it('should denote an optional capture group', function (done) {\n      var app = express();\n\n      app.get('/user/:user{/:op}', function (req, res) {\n        var op = req.params.op || 'view';\n        res.end(op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj')\n        .expect('viewing tj', done);\n    })\n\n    it('should populate the capture group', function (done) {\n      var app = express();\n\n      app.get('/user/:user{/:op}', function (req, res) {\n        var op = req.params.op || 'view';\n        res.end(op + 'ing ' + req.params.user);\n      });\n\n      request(app)\n        .get('/user/tj/edit')\n        .expect('editing tj', done);\n    })\n  })\n\n  describe(':name*', function () {\n    it('should match one segment', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user[0])\n      })\n\n      request(app)\n        .get('/user/122')\n        .expect('122', done)\n    })\n\n    it('should match many segments', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user.join('/'))\n      })\n\n      request(app)\n        .get('/user/1/2/3/4')\n        .expect('1/2/3/4', done)\n    })\n\n    it('should match zero segments', function (done) {\n      var app = express()\n\n      app.get('/user{/*user}', function (req, res) {\n        res.end(req.params.user)\n      })\n\n      request(app)\n        .get('/user')\n        .expect('', done)\n    })\n  })\n\n  describe(':name+', function () {\n    it('should match one segment', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user[0])\n      })\n\n      request(app)\n        .get('/user/122')\n        .expect(200, '122', done)\n    })\n\n    it('should match many segments', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user.join('/'))\n      })\n\n      request(app)\n        .get('/user/1/2/3/4')\n        .expect(200, '1/2/3/4', done)\n    })\n\n    it('should not match zero segments', function (done) {\n      var app = express()\n\n      app.get('/user/*user', function (req, res) {\n        res.end(req.params.user)\n      })\n\n      request(app)\n        .get('/user')\n        .expect(404, done)\n    })\n  })\n\n  describe('.:name', function () {\n    it('should denote a format', function (done) {\n      var app = express();\n      var cb = after(2, done)\n\n      app.get('/:name.:format', function (req, res) {\n        res.end(req.params.name + ' as ' + req.params.format);\n      });\n\n      request(app)\n        .get('/foo.json')\n        .expect(200, 'foo as json', cb)\n\n      request(app)\n        .get('/foo')\n        .expect(404, cb)\n    })\n  })\n\n  describe('.:name?', function () {\n    it('should denote an optional format', function (done) {\n      var app = express();\n      var cb = after(2, done)\n\n      app.get('/:name{.:format}', function (req, res) {\n        res.end(req.params.name + ' as ' + (req.params.format || 'html'));\n      });\n\n      request(app)\n        .get('/foo')\n        .expect(200, 'foo as html', cb)\n\n      request(app)\n        .get('/foo.json')\n        .expect(200, 'foo as json', cb)\n    })\n  })\n\n  describe('when next() is called', function () {\n    it('should continue lookup', function (done) {\n      var app = express()\n        , calls = [];\n\n      app.get('/foo{/:bar}', function (req, res, next) {\n        calls.push('/foo/:bar?');\n        next();\n      });\n\n      app.get('/bar', function () {\n        assert(0);\n      });\n\n      app.get('/foo', function (req, res, next) {\n        calls.push('/foo');\n        next();\n      });\n\n      app.get('/foo', function (req, res) {\n        calls.push('/foo 2');\n        res.json(calls)\n      });\n\n      request(app)\n        .get('/foo')\n        .expect(200, ['/foo/:bar?', '/foo', '/foo 2'], done)\n    })\n  })\n\n  describe('when next(\"route\") is called', function () {\n    it('should jump to next route', function (done) {\n      var app = express()\n\n      function fn(req, res, next) {\n        res.set('X-Hit', '1')\n        next('route')\n      }\n\n      app.get('/foo', fn, function (req, res) {\n        res.end('failure')\n      });\n\n      app.get('/foo', function (req, res) {\n        res.end('success')\n      })\n\n      request(app)\n        .get('/foo')\n        .expect('X-Hit', '1')\n        .expect(200, 'success', done)\n    })\n  })\n\n  describe('when next(\"router\") is called', function () {\n    it('should jump out of router', function (done) {\n      var app = express()\n      var router = express.Router()\n\n      function fn(req, res, next) {\n        res.set('X-Hit', '1')\n        next('router')\n      }\n\n      router.get('/foo', fn, function (req, res) {\n        res.end('failure')\n      })\n\n      router.get('/foo', function (req, res) {\n        res.end('failure')\n      })\n\n      app.use(router)\n\n      app.get('/foo', function (req, res) {\n        res.end('success')\n      })\n\n      request(app)\n        .get('/foo')\n        .expect('X-Hit', '1')\n        .expect(200, 'success', done)\n    })\n  })\n\n  describe('when next(err) is called', function () {\n    it('should break out of app.router', function (done) {\n      var app = express()\n        , calls = [];\n\n      app.get('/foo{/:bar}', function (req, res, next) {\n        calls.push('/foo/:bar?');\n        next();\n      });\n\n      app.get('/bar', function () {\n        assert(0);\n      });\n\n      app.get('/foo', function (req, res, next) {\n        calls.push('/foo');\n        next(new Error('fail'));\n      });\n\n      app.get('/foo', function () {\n        assert(0);\n      });\n\n      app.use(function (err, req, res, next) {\n        res.json({\n          calls: calls,\n          error: err.message\n        })\n      })\n\n      request(app)\n        .get('/foo')\n        .expect(200, { calls: ['/foo/:bar?', '/foo'], error: 'fail' }, done)\n    })\n\n    it('should call handler in same route, if exists', function (done) {\n      var app = express();\n\n      function fn1(req, res, next) {\n        next(new Error('boom!'));\n      }\n\n      function fn2(req, res, next) {\n        res.send('foo here');\n      }\n\n      function fn3(err, req, res, next) {\n        res.send('route go ' + err.message);\n      }\n\n      app.get('/foo', fn1, fn2, fn3);\n\n      app.use(function (err, req, res, next) {\n        res.end('error!');\n      })\n\n      request(app)\n        .get('/foo')\n        .expect('route go boom!', done)\n    })\n  })\n\n  describe('promise support', function () {\n    it('should pass rejected promise value', function (done) {\n      var app = express()\n      var router = new express.Router()\n\n      router.use(function createError(req, res, next) {\n        return Promise.reject(new Error('boom!'))\n      })\n\n      router.use(function sawError(err, req, res, next) {\n        res.send('saw ' + err.name + ': ' + err.message)\n      })\n\n      app.use(router)\n\n      request(app)\n        .get('/')\n        .expect(200, 'saw Error: boom!', done)\n    })\n\n    it('should pass rejected promise without value', function (done) {\n      var app = express()\n      var router = new express.Router()\n\n      router.use(function createError(req, res, next) {\n        return Promise.reject()\n      })\n\n      router.use(function sawError(err, req, res, next) {\n        res.send('saw ' + err.name + ': ' + err.message)\n      })\n\n      app.use(router)\n\n      request(app)\n        .get('/')\n        .expect(200, 'saw Error: Rejected promise', done)\n    })\n\n    it('should ignore resolved promise', function (done) {\n      var app = express()\n      var router = new express.Router()\n\n      router.use(function createError(req, res, next) {\n        res.send('saw GET /foo')\n        return Promise.resolve('foo')\n      })\n\n      router.use(function () {\n        done(new Error('Unexpected middleware invoke'))\n      })\n\n      app.use(router)\n\n      request(app)\n        .get('/foo')\n        .expect(200, 'saw GET /foo', done)\n    })\n\n    describe('error handling', function () {\n      it('should pass rejected promise value', function (done) {\n        var app = express()\n        var router = new express.Router()\n\n        router.use(function createError(req, res, next) {\n          return Promise.reject(new Error('boom!'))\n        })\n\n        router.use(function handleError(err, req, res, next) {\n          return Promise.reject(new Error('caught: ' + err.message))\n        })\n\n        router.use(function sawError(err, req, res, next) {\n          res.send('saw ' + err.name + ': ' + err.message)\n        })\n\n        app.use(router)\n\n        request(app)\n          .get('/')\n          .expect(200, 'saw Error: caught: boom!', done)\n      })\n\n      it('should pass rejected promise without value', function (done) {\n        var app = express()\n        var router = new express.Router()\n\n        router.use(function createError(req, res, next) {\n          return Promise.reject()\n        })\n\n        router.use(function handleError(err, req, res, next) {\n          return Promise.reject(new Error('caught: ' + err.message))\n        })\n\n        router.use(function sawError(err, req, res, next) {\n          res.send('saw ' + err.name + ': ' + err.message)\n        })\n\n        app.use(router)\n\n        request(app)\n          .get('/')\n          .expect(200, 'saw Error: caught: Rejected promise', done)\n      })\n\n      it('should ignore resolved promise', function (done) {\n        var app = express()\n        var router = new express.Router()\n\n        router.use(function createError(req, res, next) {\n          return Promise.reject(new Error('boom!'))\n        })\n\n        router.use(function handleError(err, req, res, next) {\n          res.send('saw ' + err.name + ': ' + err.message)\n          return Promise.resolve('foo')\n        })\n\n        router.use(function () {\n          done(new Error('Unexpected middleware invoke'))\n        })\n\n        app.use(router)\n\n        request(app)\n          .get('/foo')\n          .expect(200, 'saw Error: boom!', done)\n      })\n    })\n  })\n\n  it('should allow rewriting of the url', function (done) {\n    var app = express();\n\n    app.get('/account/edit', function (req, res, next) {\n      req.user = { id: 12 }; // faux authenticated user\n      req.url = '/user/' + req.user.id + '/edit';\n      next();\n    });\n\n    app.get('/user/:id/edit', function (req, res) {\n      res.send('editing user ' + req.params.id);\n    });\n\n    request(app)\n      .get('/account/edit')\n      .expect('editing user 12', done);\n  })\n\n  it('should run in order added', function (done) {\n    var app = express();\n    var path = [];\n\n    app.get('/*path', function (req, res, next) {\n      path.push(0);\n      next();\n    });\n\n    app.get('/user/:id', function (req, res, next) {\n      path.push(1);\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      path.push(2);\n      next();\n    });\n\n    app.all('/user/:id', function (req, res, next) {\n      path.push(3);\n      next();\n    });\n\n    app.get('/*splat', function (req, res, next) {\n      path.push(4);\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      path.push(5);\n      res.end(path.join(','))\n    });\n\n    request(app)\n      .get('/user/1')\n      .expect(200, '0,1,2,3,4,5', done);\n  })\n\n  it('should be chainable', function () {\n    var app = express();\n    assert.strictEqual(app.get('/', function () { }), app)\n  })\n\n  it('should not use disposed router/middleware', function (done) {\n    // more context: https://github.com/expressjs/express/issues/5743#issuecomment-2277148412\n\n    var app = express();\n    var router = new express.Router();\n\n    router.use(function (req, res, next) {\n      res.setHeader('old', 'foo');\n      next();\n    });\n\n    app.use(function (req, res, next) {\n      return router.handle(req, res, next);\n    });\n\n    app.get('/', function (req, res, next) {\n      res.send('yee');\n      next();\n    });\n\n    request(app)\n      .get('/')\n      .expect('old', 'foo')\n      .expect(function (res) {\n        if (typeof res.headers['new'] !== 'undefined') {\n          throw new Error('`new` header should not be present');\n        }\n      })\n      .expect(200, 'yee', function (err, res) {\n        if (err) return done(err);\n\n        router = new express.Router();\n\n        router.use(function (req, res, next) {\n          res.setHeader('new', 'bar');\n          next();\n        });\n\n        request(app)\n          .get('/')\n          .expect('new', 'bar')\n          .expect(function (res) {\n            if (typeof res.headers['old'] !== 'undefined') {\n              throw new Error('`old` header should not be present');\n            }\n          })\n          .expect(200, 'yee', done);\n      });\n  })\n})\n\nfunction supportsRegexp(source) {\n  try {\n    new RegExp(source)\n    return true\n  } catch (e) {\n    return false\n  }\n}\n",
      "bug_category": "code",
      "error_type": "code_duplication",
      "confidence": 0.4
    },
    {
      "bug_id": "14d2e544ae47",
      "repo": "express",
      "commit_hash": "f9954dd",
      "commit_message": "fix(test): remove duplicate word (#6456)",
      "file_path": "test/res.format.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar after = require('after')\nvar express = require('../')\n  , request = require('supertest')\n  , assert = require('node:assert');\n\nvar app1 = express();\n\napp1.use(function(req, res, next){\n  res.format({\n    'text/plain': function(){\n      res.send('hey');\n    },\n\n    'text/html': function(){\n      res.send('<p>hey</p>');\n    },\n\n    'application/json': function(a, b, c){\n      assert(req === a)\n      assert(res === b)\n      assert(next === c)\n      res.send({ message: 'hey' });\n    }\n  });\n});\n\napp1.use(function(err, req, res, next){\n  if (!err.types) throw err;\n  res.status(err.status)\n  res.send('Supports: ' + err.types.join(', '))\n})\n\nvar app2 = express();\n\napp2.use(function(req, res, next){\n  res.format({\n    text: function(){ res.send('hey') },\n    html: function(){ res.send('<p>hey</p>') },\n    json: function(){ res.send({ message: 'hey' }) }\n  });\n});\n\napp2.use(function(err, req, res, next){\n  res.status(err.status)\n  res.send('Supports: ' + err.types.join(', '))\n})\n\nvar app3 = express();\n\napp3.use(function(req, res, next){\n  res.format({\n    text: function(){ res.send('hey') },\n    default: function (a, b, c) {\n      assert(req === a)\n      assert(res === b)\n      assert(next === c)\n      res.send('default')\n    }\n  })\n});\n\nvar app4 = express();\n\napp4.get('/', function (req, res) {\n  res.format({\n    text: function(){ res.send('hey') },\n    html: function(){ res.send('<p>hey</p>') },\n    json: function(){ res.send({ message: 'hey' }) }\n  });\n});\n\napp4.use(function(err, req, res, next){\n  res.status(err.status)\n  res.send('Supports: ' + err.types.join(', '))\n})\n\nvar app5 = express();\n\napp5.use(function (req, res, next) {\n  res.format({\n    default: function () { res.send('hey') }\n  });\n});\n\ndescribe('res', function(){\n  describe('.format(obj)', function(){\n    describe('with canonicalized mime types', function(){\n      test(app1);\n    })\n\n    describe('with extnames', function(){\n      test(app2);\n    })\n\n    describe('with parameters', function(){\n      var app = express();\n\n      app.use(function(req, res, next){\n        res.format({\n          'text/plain; charset=utf-8': function(){ res.send('hey') },\n          'text/html; foo=bar; bar=baz': function(){ res.send('<p>hey</p>') },\n          'application/json; q=0.5': function(){ res.send({ message: 'hey' }) }\n        });\n      });\n\n      app.use(function(err, req, res, next){\n        res.status(err.status)\n        res.send('Supports: ' + err.types.join(', '))\n      });\n\n      test(app);\n    })\n\n    describe('given .default', function(){\n      it('should be invoked instead of auto-responding', function(done){\n        request(app3)\n        .get('/')\n        .set('Accept', 'text/html')\n        .expect('default', done);\n      })\n\n      it('should work when only .default is provided', function (done) {\n        request(app5)\n        .get('/')\n        .set('Accept', '*/*')\n        .expect('hey', done);\n      })\n\n      it('should be able to invoke other formatter', function (done) {\n        var app = express()\n\n        app.use(function (req, res, next) {\n          res.format({\n            json: function () { res.send('json') },\n            default: function () {\n              res.header('x-default', '1')\n              this.json()\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .set('Accept', 'text/plain')\n          .expect(200)\n          .expect('x-default', '1')\n          .expect('json')\n          .end(done)\n      })\n    })\n\n    describe('in router', function(){\n      test(app4);\n    })\n\n    describe('in router', function(){\n      var app = express();\n      var router = express.Router();\n\n      router.get('/', function (req, res) {\n        res.format({\n          text: function(){ res.send('hey') },\n          html: function(){ res.send('<p>hey</p>') },\n          json: function(){ res.send({ message: 'hey' }) }\n        });\n      });\n\n      router.use(function(err, req, res, next){\n        res.status(err.status)\n        res.send('Supports: ' + err.types.join(', '))\n      })\n\n      app.use(router)\n\n      test(app)\n    })\n  })\n})\n\nfunction test(app) {\n  it('should utilize qvalues in negotiation', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, application/json, */*; q=.1')\n    .expect({\"message\":\"hey\"}, done);\n  })\n\n  it('should allow wildcard type/subtypes', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, application/*, */*; q=.1')\n    .expect({\"message\":\"hey\"}, done);\n  })\n\n  it('should default the Content-Type', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, text/plain')\n    .expect('Content-Type', 'text/plain; charset=utf-8')\n    .expect('hey', done);\n  })\n\n  it('should set the correct charset for the Content-Type', function (done) {\n    var cb = after(3, done)\n\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html')\n    .expect('Content-Type', 'text/html; charset=utf-8', cb)\n\n    request(app)\n    .get('/')\n    .set('Accept', 'text/plain')\n    .expect('Content-Type', 'text/plain; charset=utf-8', cb)\n\n    request(app)\n    .get('/')\n    .set('Accept', 'application/json')\n    .expect('Content-Type', 'application/json; charset=utf-8', cb)\n  })\n\n  it('should Vary: Accept', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, text/plain')\n    .expect('Vary', 'Accept', done);\n  })\n\n  describe('when Accept is not present', function(){\n    it('should invoke the first callback', function(done){\n      request(app)\n      .get('/')\n      .expect('hey', done);\n    })\n  })\n\n  describe('when no match is made', function(){\n    it('should should respond with 406 not acceptable', function(done){\n      request(app)\n      .get('/')\n      .set('Accept', 'foo/bar')\n      .expect('Supports: text/plain, text/html, application/json')\n      .expect(406, done)\n    })\n  })\n}\n",
      "code_after": "'use strict'\n\nvar after = require('after')\nvar express = require('../')\n  , request = require('supertest')\n  , assert = require('node:assert');\n\nvar app1 = express();\n\napp1.use(function(req, res, next){\n  res.format({\n    'text/plain': function(){\n      res.send('hey');\n    },\n\n    'text/html': function(){\n      res.send('<p>hey</p>');\n    },\n\n    'application/json': function(a, b, c){\n      assert(req === a)\n      assert(res === b)\n      assert(next === c)\n      res.send({ message: 'hey' });\n    }\n  });\n});\n\napp1.use(function(err, req, res, next){\n  if (!err.types) throw err;\n  res.status(err.status)\n  res.send('Supports: ' + err.types.join(', '))\n})\n\nvar app2 = express();\n\napp2.use(function(req, res, next){\n  res.format({\n    text: function(){ res.send('hey') },\n    html: function(){ res.send('<p>hey</p>') },\n    json: function(){ res.send({ message: 'hey' }) }\n  });\n});\n\napp2.use(function(err, req, res, next){\n  res.status(err.status)\n  res.send('Supports: ' + err.types.join(', '))\n})\n\nvar app3 = express();\n\napp3.use(function(req, res, next){\n  res.format({\n    text: function(){ res.send('hey') },\n    default: function (a, b, c) {\n      assert(req === a)\n      assert(res === b)\n      assert(next === c)\n      res.send('default')\n    }\n  })\n});\n\nvar app4 = express();\n\napp4.get('/', function (req, res) {\n  res.format({\n    text: function(){ res.send('hey') },\n    html: function(){ res.send('<p>hey</p>') },\n    json: function(){ res.send({ message: 'hey' }) }\n  });\n});\n\napp4.use(function(err, req, res, next){\n  res.status(err.status)\n  res.send('Supports: ' + err.types.join(', '))\n})\n\nvar app5 = express();\n\napp5.use(function (req, res, next) {\n  res.format({\n    default: function () { res.send('hey') }\n  });\n});\n\ndescribe('res', function(){\n  describe('.format(obj)', function(){\n    describe('with canonicalized mime types', function(){\n      test(app1);\n    })\n\n    describe('with extnames', function(){\n      test(app2);\n    })\n\n    describe('with parameters', function(){\n      var app = express();\n\n      app.use(function(req, res, next){\n        res.format({\n          'text/plain; charset=utf-8': function(){ res.send('hey') },\n          'text/html; foo=bar; bar=baz': function(){ res.send('<p>hey</p>') },\n          'application/json; q=0.5': function(){ res.send({ message: 'hey' }) }\n        });\n      });\n\n      app.use(function(err, req, res, next){\n        res.status(err.status)\n        res.send('Supports: ' + err.types.join(', '))\n      });\n\n      test(app);\n    })\n\n    describe('given .default', function(){\n      it('should be invoked instead of auto-responding', function(done){\n        request(app3)\n        .get('/')\n        .set('Accept', 'text/html')\n        .expect('default', done);\n      })\n\n      it('should work when only .default is provided', function (done) {\n        request(app5)\n        .get('/')\n        .set('Accept', '*/*')\n        .expect('hey', done);\n      })\n\n      it('should be able to invoke other formatter', function (done) {\n        var app = express()\n\n        app.use(function (req, res, next) {\n          res.format({\n            json: function () { res.send('json') },\n            default: function () {\n              res.header('x-default', '1')\n              this.json()\n            }\n          })\n        })\n\n        request(app)\n          .get('/')\n          .set('Accept', 'text/plain')\n          .expect(200)\n          .expect('x-default', '1')\n          .expect('json')\n          .end(done)\n      })\n    })\n\n    describe('in router', function(){\n      test(app4);\n    })\n\n    describe('in router', function(){\n      var app = express();\n      var router = express.Router();\n\n      router.get('/', function (req, res) {\n        res.format({\n          text: function(){ res.send('hey') },\n          html: function(){ res.send('<p>hey</p>') },\n          json: function(){ res.send({ message: 'hey' }) }\n        });\n      });\n\n      router.use(function(err, req, res, next){\n        res.status(err.status)\n        res.send('Supports: ' + err.types.join(', '))\n      })\n\n      app.use(router)\n\n      test(app)\n    })\n  })\n})\n\nfunction test(app) {\n  it('should utilize qvalues in negotiation', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, application/json, */*; q=.1')\n    .expect({\"message\":\"hey\"}, done);\n  })\n\n  it('should allow wildcard type/subtypes', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, application/*, */*; q=.1')\n    .expect({\"message\":\"hey\"}, done);\n  })\n\n  it('should default the Content-Type', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, text/plain')\n    .expect('Content-Type', 'text/plain; charset=utf-8')\n    .expect('hey', done);\n  })\n\n  it('should set the correct charset for the Content-Type', function (done) {\n    var cb = after(3, done)\n\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html')\n    .expect('Content-Type', 'text/html; charset=utf-8', cb)\n\n    request(app)\n    .get('/')\n    .set('Accept', 'text/plain')\n    .expect('Content-Type', 'text/plain; charset=utf-8', cb)\n\n    request(app)\n    .get('/')\n    .set('Accept', 'application/json')\n    .expect('Content-Type', 'application/json; charset=utf-8', cb)\n  })\n\n  it('should Vary: Accept', function(done){\n    request(app)\n    .get('/')\n    .set('Accept', 'text/html; q=.5, text/plain')\n    .expect('Vary', 'Accept', done);\n  })\n\n  describe('when Accept is not present', function(){\n    it('should invoke the first callback', function(done){\n      request(app)\n      .get('/')\n      .expect('hey', done);\n    })\n  })\n\n  describe('when no match is made', function(){\n    it('should respond with 406 not acceptable', function(done){\n      request(app)\n      .get('/')\n      .set('Accept', 'foo/bar')\n      .expect('Supports: text/plain, text/html, application/json')\n      .expect(406, done)\n    })\n  })\n}\n",
      "bug_category": "code",
      "error_type": "code_duplication",
      "confidence": 0.4
    },
    {
      "bug_id": "19a711b34032",
      "repo": "express",
      "commit_hash": "55869f4",
      "commit_message": "feat: Added check to support Uint8Array in response sending (#6285)",
      "file_path": "lib/response.js",
      "language": "javascript",
      "code_before": "/*!\n * express\n * Copyright(c) 2009-2013 TJ Holowaychuk\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict';\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar contentDisposition = require('content-disposition');\nvar createError = require('http-errors')\nvar encodeUrl = require('encodeurl');\nvar escapeHtml = require('escape-html');\nvar http = require('node:http');\nvar onFinished = require('on-finished');\nvar mime = require('mime-types')\nvar path = require('node:path');\nvar pathIsAbsolute = require('node:path').isAbsolute;\nvar statuses = require('statuses')\nvar sign = require('cookie-signature').sign;\nvar normalizeType = require('./utils').normalizeType;\nvar normalizeTypes = require('./utils').normalizeTypes;\nvar setCharset = require('./utils').setCharset;\nvar cookie = require('cookie');\nvar send = require('send');\nvar extname = path.extname;\nvar resolve = path.resolve;\nvar vary = require('vary');\n\n/**\n * Response prototype.\n * @public\n */\n\nvar res = Object.create(http.ServerResponse.prototype)\n\n/**\n * Module exports.\n * @public\n */\n\nmodule.exports = res\n\n/**\n * Set the HTTP status code for the response.\n *\n * Expects an integer value between 100 and 999 inclusive.\n * Throws an error if the provided status code is not an integer or if it's outside the allowable range.\n *\n * @param {number} code - The HTTP status code to set.\n * @return {ServerResponse} - Returns itself for chaining methods.\n * @throws {TypeError} If `code` is not an integer.\n * @throws {RangeError} If `code` is outside the range 100 to 999.\n * @public\n */\n\nres.status = function status(code) {\n  // Check if the status code is not an integer\n  if (!Number.isInteger(code)) {\n    throw new TypeError(`Invalid status code: ${JSON.stringify(code)}. Status code must be an integer.`);\n  }\n  // Check if the status code is outside of Node's valid range\n  if (code < 100 || code > 999) {\n    throw new RangeError(`Invalid status code: ${JSON.stringify(code)}. Status code must be greater than 99 and less than 1000.`);\n  }\n\n  this.statusCode = code;\n  return this;\n};\n\n/**\n * Set Link header field with the given `links`.\n *\n * Examples:\n *\n *    res.links({\n *      next: 'http://api.example.com/users?page=2',\n *      last: 'http://api.example.com/users?page=5'\n *    });\n *\n * @param {Object} links\n * @return {ServerResponse}\n * @public\n */\n\nres.links = function(links){\n  var link = this.get('Link') || '';\n  if (link) link += ', ';\n  return this.set('Link', link + Object.keys(links).map(function(rel){\n    return '<' + links[rel] + '>; rel=\"' + rel + '\"';\n  }).join(', '));\n};\n\n/**\n * Send a response.\n *\n * Examples:\n *\n *     res.send(Buffer.from('wahoo'));\n *     res.send({ some: 'json' });\n *     res.send('<p>some html</p>');\n *\n * @param {string|number|boolean|object|Buffer} body\n * @public\n */\n\nres.send = function send(body) {\n  var chunk = body;\n  var encoding;\n  var req = this.req;\n  var type;\n\n  // settings\n  var app = this.app;\n\n  switch (typeof chunk) {\n    // string defaulting to html\n    case 'string':\n      if (!this.get('Content-Type')) {\n        this.type('html');\n      }\n      break;\n    case 'boolean':\n    case 'number':\n    case 'object':\n      if (chunk === null) {\n        chunk = '';\n      } else if (Buffer.isBuffer(chunk)) {\n        if (!this.get('Content-Type')) {\n          this.type('bin');\n        }\n      } else {\n        return this.json(chunk);\n      }\n      break;\n  }\n\n  // write strings in utf-8\n  if (typeof chunk === 'string') {\n    encoding = 'utf8';\n    type = this.get('Content-Type');\n\n    // reflect this in content-type\n    if (typeof type === 'string') {\n      this.set('Content-Type', setCharset(type, 'utf-8'));\n    }\n  }\n\n  // determine if ETag should be generated\n  var etagFn = app.get('etag fn')\n  var generateETag = !this.get('ETag') && typeof etagFn === 'function'\n\n  // populate Content-Length\n  var len\n  if (chunk !== undefined) {\n    if (Buffer.isBuffer(chunk)) {\n      // get length of Buffer\n      len = chunk.length\n    } else if (!generateETag && chunk.length < 1000) {\n      // just calculate length when no ETag + small chunk\n      len = Buffer.byteLength(chunk, encoding)\n    } else {\n      // convert chunk to Buffer and calculate\n      chunk = Buffer.from(chunk, encoding)\n      encoding = undefined;\n      len = chunk.length\n    }\n\n    this.set('Content-Length', len);\n  }\n\n  // populate ETag\n  var etag;\n  if (generateETag && len !== undefined) {\n    if ((etag = etagFn(chunk, encoding))) {\n      this.set('ETag', etag);\n    }\n  }\n\n  // freshness\n  if (req.fresh) this.status(304);\n\n  // strip irrelevant headers\n  if (204 === this.statusCode || 304 === this.statusCode) {\n    this.removeHeader('Content-Type');\n    this.removeHeader('Content-Length');\n    this.removeHeader('Transfer-Encoding');\n    chunk = '';\n  }\n\n  // alter headers for 205\n  if (this.statusCode === 205) {\n    this.set('Content-Length', '0')\n    this.removeHeader('Transfer-Encoding')\n    chunk = ''\n  }\n\n  if (req.method === 'HEAD') {\n    // skip body for HEAD\n    this.end();\n  } else {\n    // respond\n    this.end(chunk, encoding);\n  }\n\n  return this;\n};\n\n/**\n * Send JSON response.\n *\n * Examples:\n *\n *     res.json(null);\n *     res.json({ user: 'tj' });\n *\n * @param {string|number|boolean|object} obj\n * @public\n */\n\nres.json = function json(obj) {\n  // settings\n  var app = this.app;\n  var escape = app.get('json escape')\n  var replacer = app.get('json replacer');\n  var spaces = app.get('json spaces');\n  var body = stringify(obj, replacer, spaces, escape)\n\n  // content-type\n  if (!this.get('Content-Type')) {\n    this.set('Content-Type', 'application/json');\n  }\n\n  return this.send(body);\n};\n\n/**\n * Send JSON response with JSONP callback support.\n *\n * Examples:\n *\n *     res.jsonp(null);\n *     res.jsonp({ user: 'tj' });\n *\n * @param {string|number|boolean|object} obj\n * @public\n */\n\nres.jsonp = function jsonp(obj) {\n  // settings\n  var app = this.app;\n  var escape = app.get('json escape')\n  var replacer = app.get('json replacer');\n  var spaces = app.get('json spaces');\n  var body = stringify(obj, replacer, spaces, escape)\n  var callback = this.req.query[app.get('jsonp callback name')];\n\n  // content-type\n  if (!this.get('Content-Type')) {\n    this.set('X-Content-Type-Options', 'nosniff');\n    this.set('Content-Type', 'application/json');\n  }\n\n  // fixup callback\n  if (Array.isArray(callback)) {\n    callback = callback[0];\n  }\n\n  // jsonp\n  if (typeof callback === 'string' && callback.length !== 0) {\n    this.set('X-Content-Type-Options', 'nosniff');\n    this.set('Content-Type', 'text/javascript');\n\n    // restrict callback charset\n    callback = callback.replace(/[^\\[\\]\\w$.]/g, '');\n\n    if (body === undefined) {\n      // empty argument\n      body = ''\n    } else if (typeof body === 'string') {\n      // replace chars not allowed in JavaScript that are in JSON\n      body = body\n        .replace(/\\u2028/g, '\\\\u2028')\n        .replace(/\\u2029/g, '\\\\u2029')\n    }\n\n    // the /**/ is a specific security mitigation for \"Rosetta Flash JSONP abuse\"\n    // the typeof check is just to reduce client error noise\n    body = '/**/ typeof ' + callback + ' === \\'function\\' && ' + callback + '(' + body + ');';\n  }\n\n  return this.send(body);\n};\n\n/**\n * Send given HTTP status code.\n *\n * Sets the response status to `statusCode` and the body of the\n * response to the standard description from node's http.STATUS_CODES\n * or the statusCode number if no description.\n *\n * Examples:\n *\n *     res.sendStatus(200);\n *\n * @param {number} statusCode\n * @public\n */\n\nres.sendStatus = function sendStatus(statusCode) {\n  var body = statuses.message[statusCode] || String(statusCode)\n\n  this.status(statusCode);\n  this.type('txt');\n\n  return this.send(body);\n};\n\n/**\n * Transfer the file at the given `path`.\n *\n * Automatically sets the _Content-Type_ response header field.\n * The callback `callback(err)` is invoked when the transfer is complete\n * or when an error occurs. Be sure to check `res.headersSent`\n * if you wish to attempt responding, as the header and some data\n * may have already been transferred.\n *\n * Options:\n *\n *   - `maxAge`   defaulting to 0 (can be string converted by `ms`)\n *   - `root`     root directory for relative filenames\n *   - `headers`  object of headers to serve with file\n *   - `dotfiles` serve dotfiles, defaulting to false; can be `\"allow\"` to send them\n *\n * Other options are passed along to `send`.\n *\n * Examples:\n *\n *  The following example illustrates how `res.sendFile()` may\n *  be used as an alternative for the `static()` middleware for\n *  dynamic situations. The code backing `res.sendFile()` is actually\n *  the same code, so HTTP cache support etc is identical.\n *\n *     app.get('/user/:uid/photos/:file', function(req, res){\n *       var uid = req.params.uid\n *         , file = req.params.file;\n *\n *       req.user.mayViewFilesFrom(uid, function(yes){\n *         if (yes) {\n *           res.sendFile('/uploads/' + uid + '/' + file);\n *         } else {\n *           res.send(403, 'Sorry! you cant see that.');\n *         }\n *       });\n *     });\n *\n * @public\n */\n\nres.sendFile = function sendFile(path, options, callback) {\n  var done = callback;\n  var req = this.req;\n  var res = this;\n  var next = req.next;\n  var opts = options || {};\n\n  if (!path) {\n    throw new TypeError('path argument is required to res.sendFile');\n  }\n\n  if (typeof path !== 'string') {\n    throw new TypeError('path must be a string to res.sendFile')\n  }\n\n  // support function as second arg\n  if (typeof options === 'function') {\n    done = options;\n    opts = {};\n  }\n\n  if (!opts.root && !pathIsAbsolute(path)) {\n    throw new TypeError('path must be absolute or specify root to res.sendFile');\n  }\n\n  // create file stream\n  var pathname = encodeURI(path);\n  var file = send(req, pathname, opts);\n\n  // transfer\n  sendfile(res, file, opts, function (err) {\n    if (done) return done(err);\n    if (err && err.code === 'EISDIR') return next();\n\n    // next() all but write errors\n    if (err && err.code !== 'ECONNABORTED' && err.syscall !== 'write') {\n      next(err);\n    }\n  });\n};\n\n/**\n * Transfer the file at the given `path` as an attachment.\n *\n * Optionally providing an alternate attachment `filename`,\n * and optional callback `callback(err)`. The callback is invoked\n * when the data transfer is complete, or when an error has\n * occurred. Be sure to check `res.headersSent` if you plan to respond.\n *\n * Optionally providing an `options` object to use with `res.sendFile()`.\n * This function will set the `Content-Disposition` header, overriding\n * any `Content-Disposition` header passed as header options in order\n * to set the attachment and filename.\n *\n * This method uses `res.sendFile()`.\n *\n * @public\n */\n\nres.download = function download (path, filename, options, callback) {\n  var done = callback;\n  var name = filename;\n  var opts = options || null\n\n  // support function as second or third arg\n  if (typeof filename === 'function') {\n    done = filename;\n    name = null;\n    opts = null\n  } else if (typeof options === 'function') {\n    done = options\n    opts = null\n  }\n\n  // support optional filename, where options may be in it's place\n  if (typeof filename === 'object' &&\n    (typeof options === 'function' || options === undefined)) {\n    name = null\n    opts = filename\n  }\n\n  // set Content-Disposition when file is sent\n  var headers = {\n    'Content-Disposition': contentDisposition(name || path)\n  };\n\n  // merge user-provided headers\n  if (opts && opts.headers) {\n    var keys = Object.keys(opts.headers)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      if (key.toLowerCase() !== 'content-disposition') {\n        headers[key] = opts.headers[key]\n      }\n    }\n  }\n\n  // merge user-provided options\n  opts = Object.create(opts)\n  opts.headers = headers\n\n  // Resolve the full path for sendFile\n  var fullPath = !opts.root\n    ? resolve(path)\n    : path\n\n  // send file\n  return this.sendFile(fullPath, opts, done)\n};\n\n/**\n * Set _Content-Type_ response header with `type` through `mime.contentType()`\n * when it does not contain \"/\", or set the Content-Type to `type` otherwise.\n * When no mapping is found though `mime.contentType()`, the type is set to\n * \"application/octet-stream\".\n *\n * Examples:\n *\n *     res.type('.html');\n *     res.type('html');\n *     res.type('json');\n *     res.type('application/json');\n *     res.type('png');\n *\n * @param {String} type\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.contentType =\nres.type = function contentType(type) {\n  var ct = type.indexOf('/') === -1\n    ? (mime.contentType(type) || 'application/octet-stream')\n    : type;\n\n  return this.set('Content-Type', ct);\n};\n\n/**\n * Respond to the Acceptable formats using an `obj`\n * of mime-type callbacks.\n *\n * This method uses `req.accepted`, an array of\n * acceptable types ordered by their quality values.\n * When \"Accept\" is not present the _first_ callback\n * is invoked, otherwise the first match is used. When\n * no match is performed the server responds with\n * 406 \"Not Acceptable\".\n *\n * Content-Type is set for you, however if you choose\n * you may alter this within the callback using `res.type()`\n * or `res.set('Content-Type', ...)`.\n *\n *    res.format({\n *      'text/plain': function(){\n *        res.send('hey');\n *      },\n *\n *      'text/html': function(){\n *        res.send('<p>hey</p>');\n *      },\n *\n *      'application/json': function () {\n *        res.send({ message: 'hey' });\n *      }\n *    });\n *\n * In addition to canonicalized MIME types you may\n * also use extnames mapped to these types:\n *\n *    res.format({\n *      text: function(){\n *        res.send('hey');\n *      },\n *\n *      html: function(){\n *        res.send('<p>hey</p>');\n *      },\n *\n *      json: function(){\n *        res.send({ message: 'hey' });\n *      }\n *    });\n *\n * By default Express passes an `Error`\n * with a `.status` of 406 to `next(err)`\n * if a match is not made. If you provide\n * a `.default` callback it will be invoked\n * instead.\n *\n * @param {Object} obj\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.format = function(obj){\n  var req = this.req;\n  var next = req.next;\n\n  var keys = Object.keys(obj)\n    .filter(function (v) { return v !== 'default' })\n\n  var key = keys.length > 0\n    ? req.accepts(keys)\n    : false;\n\n  this.vary(\"Accept\");\n\n  if (key) {\n    this.set('Content-Type', normalizeType(key).value);\n    obj[key](req, this, next);\n  } else if (obj.default) {\n    obj.default(req, this, next)\n  } else {\n    next(createError(406, {\n      types: normalizeTypes(keys).map(function (o) { return o.value })\n    }))\n  }\n\n  return this;\n};\n\n/**\n * Set _Content-Disposition_ header to _attachment_ with optional `filename`.\n *\n * @param {String} filename\n * @return {ServerResponse}\n * @public\n */\n\nres.attachment = function attachment(filename) {\n  if (filename) {\n    this.type(extname(filename));\n  }\n\n  this.set('Content-Disposition', contentDisposition(filename));\n\n  return this;\n};\n\n/**\n * Append additional header `field` with value `val`.\n *\n * Example:\n *\n *    res.append('Link', ['<http://localhost/>', '<http://localhost:3000/>']);\n *    res.append('Set-Cookie', 'foo=bar; Path=/; HttpOnly');\n *    res.append('Warning', '199 Miscellaneous warning');\n *\n * @param {String} field\n * @param {String|Array} val\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.append = function append(field, val) {\n  var prev = this.get(field);\n  var value = val;\n\n  if (prev) {\n    // concat the new and prev vals\n    value = Array.isArray(prev) ? prev.concat(val)\n      : Array.isArray(val) ? [prev].concat(val)\n        : [prev, val]\n  }\n\n  return this.set(field, value);\n};\n\n/**\n * Set header `field` to `val`, or pass\n * an object of header fields.\n *\n * Examples:\n *\n *    res.set('Foo', ['bar', 'baz']);\n *    res.set('Accept', 'application/json');\n *    res.set({ Accept: 'text/plain', 'X-API-Key': 'tobi' });\n *\n * Aliased as `res.header()`.\n *\n * When the set header is \"Content-Type\", the type is expanded to include\n * the charset if not present using `mime.contentType()`.\n *\n * @param {String|Object} field\n * @param {String|Array} val\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.set =\nres.header = function header(field, val) {\n  if (arguments.length === 2) {\n    var value = Array.isArray(val)\n      ? val.map(String)\n      : String(val);\n\n    // add charset to content-type\n    if (field.toLowerCase() === 'content-type') {\n      if (Array.isArray(value)) {\n        throw new TypeError('Content-Type cannot be set to an Array');\n      }\n      value = mime.contentType(value)\n    }\n\n    this.setHeader(field, value);\n  } else {\n    for (var key in field) {\n      this.set(key, field[key]);\n    }\n  }\n  return this;\n};\n\n/**\n * Get value for header `field`.\n *\n * @param {String} field\n * @return {String}\n * @public\n */\n\nres.get = function(field){\n  return this.getHeader(field);\n};\n\n/**\n * Clear cookie `name`.\n *\n * @param {String} name\n * @param {Object} [options]\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.clearCookie = function clearCookie(name, options) {\n  // Force cookie expiration by setting expires to the past\n  const opts = { path: '/', ...options, expires: new Date(1)};\n  // ensure maxAge is not passed\n  delete opts.maxAge\n\n  return this.cookie(name, '', opts);\n};\n\n/**\n * Set cookie `name` to `value`, with the given `options`.\n *\n * Options:\n *\n *    - `maxAge`   max-age in milliseconds, converted to `expires`\n *    - `signed`   sign the cookie\n *    - `path`     defaults to \"/\"\n *\n * Examples:\n *\n *    // \"Remember Me\" for 15 minutes\n *    res.cookie('rememberme', '1', { expires: new Date(Date.now() + 900000), httpOnly: true });\n *\n *    // same as above\n *    res.cookie('rememberme', '1', { maxAge: 900000, httpOnly: true })\n *\n * @param {String} name\n * @param {String|Object} value\n * @param {Object} [options]\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.cookie = function (name, value, options) {\n  var opts = { ...options };\n  var secret = this.req.secret;\n  var signed = opts.signed;\n\n  if (signed && !secret) {\n    throw new Error('cookieParser(\"secret\") required for signed cookies');\n  }\n\n  var val = typeof value === 'object'\n    ? 'j:' + JSON.stringify(value)\n    : String(value);\n\n  if (signed) {\n    val = 's:' + sign(val, secret);\n  }\n\n  if (opts.maxAge != null) {\n    var maxAge = opts.maxAge - 0\n\n    if (!isNaN(maxAge)) {\n      opts.expires = new Date(Date.now() + maxAge)\n      opts.maxAge = Math.floor(maxAge / 1000)\n    }\n  }\n\n  if (opts.path == null) {\n    opts.path = '/';\n  }\n\n  this.append('Set-Cookie', cookie.serialize(name, String(val), opts));\n\n  return this;\n};\n\n/**\n * Set the location header to `url`.\n *\n * The given `url` can also be \"back\", which redirects\n * to the _Referrer_ or _Referer_ headers or \"/\".\n *\n * Examples:\n *\n *    res.location('/foo/bar').;\n *    res.location('http://example.com');\n *    res.location('../login');\n *\n * @param {String} url\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.location = function location(url) {\n  return this.set('Location', encodeUrl(url));\n};\n\n/**\n * Redirect to the given `url` with optional response `status`\n * defaulting to 302.\n *\n * Examples:\n *\n *    res.redirect('/foo/bar');\n *    res.redirect('http://example.com');\n *    res.redirect(301, 'http://example.com');\n *    res.redirect('../login'); // /blog/post/1 -> /blog/login\n *\n * @public\n */\n\nres.redirect = function redirect(url) {\n  var address = url;\n  var body;\n  var status = 302;\n\n  // allow status / url\n  if (arguments.length === 2) {\n    status = arguments[0]\n    address = arguments[1]\n  }\n\n  // Set location header\n  address = this.location(address).get('Location');\n\n  // Support text/{plain,html} by default\n  this.format({\n    text: function(){\n      body = statuses.message[status] + '. Redirecting to ' + address\n    },\n\n    html: function(){\n      var u = escapeHtml(address);\n      body = '<p>' + statuses.message[status] + '. Redirecting to ' + u + '</p>'\n    },\n\n    default: function(){\n      body = '';\n    }\n  });\n\n  // Respond\n  this.status(status);\n  this.set('Content-Length', Buffer.byteLength(body));\n\n  if (this.req.method === 'HEAD') {\n    this.end();\n  } else {\n    this.end(body);\n  }\n};\n\n/**\n * Add `field` to Vary. If already present in the Vary set, then\n * this call is simply ignored.\n *\n * @param {Array|String} field\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.vary = function(field){\n  vary(this, field);\n\n  return this;\n};\n\n/**\n * Render `view` with the given `options` and optional callback `fn`.\n * When a callback function is given a response will _not_ be made\n * automatically, otherwise a response of _200_ and _text/html_ is given.\n *\n * Options:\n *\n *  - `cache`     boolean hinting to the engine it should cache\n *  - `filename`  filename of the view being rendered\n *\n * @public\n */\n\nres.render = function render(view, options, callback) {\n  var app = this.req.app;\n  var done = callback;\n  var opts = options || {};\n  var req = this.req;\n  var self = this;\n\n  // support callback function as second arg\n  if (typeof options === 'function') {\n    done = options;\n    opts = {};\n  }\n\n  // merge res.locals\n  opts._locals = self.locals;\n\n  // default callback to respond\n  done = done || function (err, str) {\n    if (err) return req.next(err);\n    self.send(str);\n  };\n\n  // render\n  app.render(view, opts, done);\n};\n\n// pipe the send file stream\nfunction sendfile(res, file, options, callback) {\n  var done = false;\n  var streaming;\n\n  // request aborted\n  function onaborted() {\n    if (done) return;\n    done = true;\n\n    var err = new Error('Request aborted');\n    err.code = 'ECONNABORTED';\n    callback(err);\n  }\n\n  // directory\n  function ondirectory() {\n    if (done) return;\n    done = true;\n\n    var err = new Error('EISDIR, read');\n    err.code = 'EISDIR';\n    callback(err);\n  }\n\n  // errors\n  function onerror(err) {\n    if (done) return;\n    done = true;\n    callback(err);\n  }\n\n  // ended\n  function onend() {\n    if (done) return;\n    done = true;\n    callback();\n  }\n\n  // file\n  function onfile() {\n    streaming = false;\n  }\n\n  // finished\n  function onfinish(err) {\n    if (err && err.code === 'ECONNRESET') return onaborted();\n    if (err) return onerror(err);\n    if (done) return;\n\n    setImmediate(function () {\n      if (streaming !== false && !done) {\n        onaborted();\n        return;\n      }\n\n      if (done) return;\n      done = true;\n      callback();\n    });\n  }\n\n  // streaming\n  function onstream() {\n    streaming = true;\n  }\n\n  file.on('directory', ondirectory);\n  file.on('end', onend);\n  file.on('error', onerror);\n  file.on('file', onfile);\n  file.on('stream', onstream);\n  onFinished(res, onfinish);\n\n  if (options.headers) {\n    // set headers on successful transfer\n    file.on('headers', function headers(res) {\n      var obj = options.headers;\n      var keys = Object.keys(obj);\n\n      for (var i = 0; i < keys.length; i++) {\n        var k = keys[i];\n        res.setHeader(k, obj[k]);\n      }\n    });\n  }\n\n  // pipe\n  file.pipe(res);\n}\n\n/**\n * Stringify JSON, like JSON.stringify, but v8 optimized, with the\n * ability to escape characters that can trigger HTML sniffing.\n *\n * @param {*} value\n * @param {function} replacer\n * @param {number} spaces\n * @param {boolean} escape\n * @returns {string}\n * @private\n */\n\nfunction stringify (value, replacer, spaces, escape) {\n  // v8 checks arguments.length for optimizing simple call\n  // https://bugs.chromium.org/p/v8/issues/detail?id=4730\n  var json = replacer || spaces\n    ? JSON.stringify(value, replacer, spaces)\n    : JSON.stringify(value);\n\n  if (escape && typeof json === 'string') {\n    json = json.replace(/[<>&]/g, function (c) {\n      switch (c.charCodeAt(0)) {\n        case 0x3c:\n          return '\\\\u003c'\n        case 0x3e:\n          return '\\\\u003e'\n        case 0x26:\n          return '\\\\u0026'\n        /* istanbul ignore next: unreachable default */\n        default:\n          return c\n      }\n    })\n  }\n\n  return json\n}\n",
      "code_after": "/*!\n * express\n * Copyright(c) 2009-2013 TJ Holowaychuk\n * Copyright(c) 2014-2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n'use strict';\n\n/**\n * Module dependencies.\n * @private\n */\n\nvar contentDisposition = require('content-disposition');\nvar createError = require('http-errors')\nvar encodeUrl = require('encodeurl');\nvar escapeHtml = require('escape-html');\nvar http = require('node:http');\nvar onFinished = require('on-finished');\nvar mime = require('mime-types')\nvar path = require('node:path');\nvar pathIsAbsolute = require('node:path').isAbsolute;\nvar statuses = require('statuses')\nvar sign = require('cookie-signature').sign;\nvar normalizeType = require('./utils').normalizeType;\nvar normalizeTypes = require('./utils').normalizeTypes;\nvar setCharset = require('./utils').setCharset;\nvar cookie = require('cookie');\nvar send = require('send');\nvar extname = path.extname;\nvar resolve = path.resolve;\nvar vary = require('vary');\n\n/**\n * Response prototype.\n * @public\n */\n\nvar res = Object.create(http.ServerResponse.prototype)\n\n/**\n * Module exports.\n * @public\n */\n\nmodule.exports = res\n\n/**\n * Set the HTTP status code for the response.\n *\n * Expects an integer value between 100 and 999 inclusive.\n * Throws an error if the provided status code is not an integer or if it's outside the allowable range.\n *\n * @param {number} code - The HTTP status code to set.\n * @return {ServerResponse} - Returns itself for chaining methods.\n * @throws {TypeError} If `code` is not an integer.\n * @throws {RangeError} If `code` is outside the range 100 to 999.\n * @public\n */\n\nres.status = function status(code) {\n  // Check if the status code is not an integer\n  if (!Number.isInteger(code)) {\n    throw new TypeError(`Invalid status code: ${JSON.stringify(code)}. Status code must be an integer.`);\n  }\n  // Check if the status code is outside of Node's valid range\n  if (code < 100 || code > 999) {\n    throw new RangeError(`Invalid status code: ${JSON.stringify(code)}. Status code must be greater than 99 and less than 1000.`);\n  }\n\n  this.statusCode = code;\n  return this;\n};\n\n/**\n * Set Link header field with the given `links`.\n *\n * Examples:\n *\n *    res.links({\n *      next: 'http://api.example.com/users?page=2',\n *      last: 'http://api.example.com/users?page=5'\n *    });\n *\n * @param {Object} links\n * @return {ServerResponse}\n * @public\n */\n\nres.links = function(links){\n  var link = this.get('Link') || '';\n  if (link) link += ', ';\n  return this.set('Link', link + Object.keys(links).map(function(rel){\n    return '<' + links[rel] + '>; rel=\"' + rel + '\"';\n  }).join(', '));\n};\n\n/**\n * Send a response.\n *\n * Examples:\n *\n *     res.send(Buffer.from('wahoo'));\n *     res.send({ some: 'json' });\n *     res.send('<p>some html</p>');\n *\n * @param {string|number|boolean|object|Buffer} body\n * @public\n */\n\nres.send = function send(body) {\n  var chunk = body;\n  var encoding;\n  var req = this.req;\n  var type;\n\n  // settings\n  var app = this.app;\n\n  switch (typeof chunk) {\n    // string defaulting to html\n    case 'string':\n      if (!this.get('Content-Type')) {\n        this.type('html');\n      }\n      break;\n    case 'boolean':\n    case 'number':\n    case 'object':\n      if (chunk === null) {\n        chunk = '';\n      } else if (ArrayBuffer.isView(chunk)) {\n        if (!this.get('Content-Type')) {\n          this.type('bin');\n        }\n      } else {\n        return this.json(chunk);\n      }\n      break;\n  }\n\n  // write strings in utf-8\n  if (typeof chunk === 'string') {\n    encoding = 'utf8';\n    type = this.get('Content-Type');\n\n    // reflect this in content-type\n    if (typeof type === 'string') {\n      this.set('Content-Type', setCharset(type, 'utf-8'));\n    }\n  }\n\n  // determine if ETag should be generated\n  var etagFn = app.get('etag fn')\n  var generateETag = !this.get('ETag') && typeof etagFn === 'function'\n\n  // populate Content-Length\n  var len\n  if (chunk !== undefined) {\n    if (Buffer.isBuffer(chunk)) {\n      // get length of Buffer\n      len = chunk.length\n    } else if (!generateETag && chunk.length < 1000) {\n      // just calculate length when no ETag + small chunk\n      len = Buffer.byteLength(chunk, encoding)\n    } else {\n      // convert chunk to Buffer and calculate\n      chunk = Buffer.from(chunk, encoding)\n      encoding = undefined;\n      len = chunk.length\n    }\n\n    this.set('Content-Length', len);\n  }\n\n  // populate ETag\n  var etag;\n  if (generateETag && len !== undefined) {\n    if ((etag = etagFn(chunk, encoding))) {\n      this.set('ETag', etag);\n    }\n  }\n\n  // freshness\n  if (req.fresh) this.status(304);\n\n  // strip irrelevant headers\n  if (204 === this.statusCode || 304 === this.statusCode) {\n    this.removeHeader('Content-Type');\n    this.removeHeader('Content-Length');\n    this.removeHeader('Transfer-Encoding');\n    chunk = '';\n  }\n\n  // alter headers for 205\n  if (this.statusCode === 205) {\n    this.set('Content-Length', '0')\n    this.removeHeader('Transfer-Encoding')\n    chunk = ''\n  }\n\n  if (req.method === 'HEAD') {\n    // skip body for HEAD\n    this.end();\n  } else {\n    // respond\n    this.end(chunk, encoding);\n  }\n\n  return this;\n};\n\n/**\n * Send JSON response.\n *\n * Examples:\n *\n *     res.json(null);\n *     res.json({ user: 'tj' });\n *\n * @param {string|number|boolean|object} obj\n * @public\n */\n\nres.json = function json(obj) {\n  // settings\n  var app = this.app;\n  var escape = app.get('json escape')\n  var replacer = app.get('json replacer');\n  var spaces = app.get('json spaces');\n  var body = stringify(obj, replacer, spaces, escape)\n\n  // content-type\n  if (!this.get('Content-Type')) {\n    this.set('Content-Type', 'application/json');\n  }\n\n  return this.send(body);\n};\n\n/**\n * Send JSON response with JSONP callback support.\n *\n * Examples:\n *\n *     res.jsonp(null);\n *     res.jsonp({ user: 'tj' });\n *\n * @param {string|number|boolean|object} obj\n * @public\n */\n\nres.jsonp = function jsonp(obj) {\n  // settings\n  var app = this.app;\n  var escape = app.get('json escape')\n  var replacer = app.get('json replacer');\n  var spaces = app.get('json spaces');\n  var body = stringify(obj, replacer, spaces, escape)\n  var callback = this.req.query[app.get('jsonp callback name')];\n\n  // content-type\n  if (!this.get('Content-Type')) {\n    this.set('X-Content-Type-Options', 'nosniff');\n    this.set('Content-Type', 'application/json');\n  }\n\n  // fixup callback\n  if (Array.isArray(callback)) {\n    callback = callback[0];\n  }\n\n  // jsonp\n  if (typeof callback === 'string' && callback.length !== 0) {\n    this.set('X-Content-Type-Options', 'nosniff');\n    this.set('Content-Type', 'text/javascript');\n\n    // restrict callback charset\n    callback = callback.replace(/[^\\[\\]\\w$.]/g, '');\n\n    if (body === undefined) {\n      // empty argument\n      body = ''\n    } else if (typeof body === 'string') {\n      // replace chars not allowed in JavaScript that are in JSON\n      body = body\n        .replace(/\\u2028/g, '\\\\u2028')\n        .replace(/\\u2029/g, '\\\\u2029')\n    }\n\n    // the /**/ is a specific security mitigation for \"Rosetta Flash JSONP abuse\"\n    // the typeof check is just to reduce client error noise\n    body = '/**/ typeof ' + callback + ' === \\'function\\' && ' + callback + '(' + body + ');';\n  }\n\n  return this.send(body);\n};\n\n/**\n * Send given HTTP status code.\n *\n * Sets the response status to `statusCode` and the body of the\n * response to the standard description from node's http.STATUS_CODES\n * or the statusCode number if no description.\n *\n * Examples:\n *\n *     res.sendStatus(200);\n *\n * @param {number} statusCode\n * @public\n */\n\nres.sendStatus = function sendStatus(statusCode) {\n  var body = statuses.message[statusCode] || String(statusCode)\n\n  this.status(statusCode);\n  this.type('txt');\n\n  return this.send(body);\n};\n\n/**\n * Transfer the file at the given `path`.\n *\n * Automatically sets the _Content-Type_ response header field.\n * The callback `callback(err)` is invoked when the transfer is complete\n * or when an error occurs. Be sure to check `res.headersSent`\n * if you wish to attempt responding, as the header and some data\n * may have already been transferred.\n *\n * Options:\n *\n *   - `maxAge`   defaulting to 0 (can be string converted by `ms`)\n *   - `root`     root directory for relative filenames\n *   - `headers`  object of headers to serve with file\n *   - `dotfiles` serve dotfiles, defaulting to false; can be `\"allow\"` to send them\n *\n * Other options are passed along to `send`.\n *\n * Examples:\n *\n *  The following example illustrates how `res.sendFile()` may\n *  be used as an alternative for the `static()` middleware for\n *  dynamic situations. The code backing `res.sendFile()` is actually\n *  the same code, so HTTP cache support etc is identical.\n *\n *     app.get('/user/:uid/photos/:file', function(req, res){\n *       var uid = req.params.uid\n *         , file = req.params.file;\n *\n *       req.user.mayViewFilesFrom(uid, function(yes){\n *         if (yes) {\n *           res.sendFile('/uploads/' + uid + '/' + file);\n *         } else {\n *           res.send(403, 'Sorry! you cant see that.');\n *         }\n *       });\n *     });\n *\n * @public\n */\n\nres.sendFile = function sendFile(path, options, callback) {\n  var done = callback;\n  var req = this.req;\n  var res = this;\n  var next = req.next;\n  var opts = options || {};\n\n  if (!path) {\n    throw new TypeError('path argument is required to res.sendFile');\n  }\n\n  if (typeof path !== 'string') {\n    throw new TypeError('path must be a string to res.sendFile')\n  }\n\n  // support function as second arg\n  if (typeof options === 'function') {\n    done = options;\n    opts = {};\n  }\n\n  if (!opts.root && !pathIsAbsolute(path)) {\n    throw new TypeError('path must be absolute or specify root to res.sendFile');\n  }\n\n  // create file stream\n  var pathname = encodeURI(path);\n  var file = send(req, pathname, opts);\n\n  // transfer\n  sendfile(res, file, opts, function (err) {\n    if (done) return done(err);\n    if (err && err.code === 'EISDIR') return next();\n\n    // next() all but write errors\n    if (err && err.code !== 'ECONNABORTED' && err.syscall !== 'write') {\n      next(err);\n    }\n  });\n};\n\n/**\n * Transfer the file at the given `path` as an attachment.\n *\n * Optionally providing an alternate attachment `filename`,\n * and optional callback `callback(err)`. The callback is invoked\n * when the data transfer is complete, or when an error has\n * occurred. Be sure to check `res.headersSent` if you plan to respond.\n *\n * Optionally providing an `options` object to use with `res.sendFile()`.\n * This function will set the `Content-Disposition` header, overriding\n * any `Content-Disposition` header passed as header options in order\n * to set the attachment and filename.\n *\n * This method uses `res.sendFile()`.\n *\n * @public\n */\n\nres.download = function download (path, filename, options, callback) {\n  var done = callback;\n  var name = filename;\n  var opts = options || null\n\n  // support function as second or third arg\n  if (typeof filename === 'function') {\n    done = filename;\n    name = null;\n    opts = null\n  } else if (typeof options === 'function') {\n    done = options\n    opts = null\n  }\n\n  // support optional filename, where options may be in it's place\n  if (typeof filename === 'object' &&\n    (typeof options === 'function' || options === undefined)) {\n    name = null\n    opts = filename\n  }\n\n  // set Content-Disposition when file is sent\n  var headers = {\n    'Content-Disposition': contentDisposition(name || path)\n  };\n\n  // merge user-provided headers\n  if (opts && opts.headers) {\n    var keys = Object.keys(opts.headers)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      if (key.toLowerCase() !== 'content-disposition') {\n        headers[key] = opts.headers[key]\n      }\n    }\n  }\n\n  // merge user-provided options\n  opts = Object.create(opts)\n  opts.headers = headers\n\n  // Resolve the full path for sendFile\n  var fullPath = !opts.root\n    ? resolve(path)\n    : path\n\n  // send file\n  return this.sendFile(fullPath, opts, done)\n};\n\n/**\n * Set _Content-Type_ response header with `type` through `mime.contentType()`\n * when it does not contain \"/\", or set the Content-Type to `type` otherwise.\n * When no mapping is found though `mime.contentType()`, the type is set to\n * \"application/octet-stream\".\n *\n * Examples:\n *\n *     res.type('.html');\n *     res.type('html');\n *     res.type('json');\n *     res.type('application/json');\n *     res.type('png');\n *\n * @param {String} type\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.contentType =\nres.type = function contentType(type) {\n  var ct = type.indexOf('/') === -1\n    ? (mime.contentType(type) || 'application/octet-stream')\n    : type;\n\n  return this.set('Content-Type', ct);\n};\n\n/**\n * Respond to the Acceptable formats using an `obj`\n * of mime-type callbacks.\n *\n * This method uses `req.accepted`, an array of\n * acceptable types ordered by their quality values.\n * When \"Accept\" is not present the _first_ callback\n * is invoked, otherwise the first match is used. When\n * no match is performed the server responds with\n * 406 \"Not Acceptable\".\n *\n * Content-Type is set for you, however if you choose\n * you may alter this within the callback using `res.type()`\n * or `res.set('Content-Type', ...)`.\n *\n *    res.format({\n *      'text/plain': function(){\n *        res.send('hey');\n *      },\n *\n *      'text/html': function(){\n *        res.send('<p>hey</p>');\n *      },\n *\n *      'application/json': function () {\n *        res.send({ message: 'hey' });\n *      }\n *    });\n *\n * In addition to canonicalized MIME types you may\n * also use extnames mapped to these types:\n *\n *    res.format({\n *      text: function(){\n *        res.send('hey');\n *      },\n *\n *      html: function(){\n *        res.send('<p>hey</p>');\n *      },\n *\n *      json: function(){\n *        res.send({ message: 'hey' });\n *      }\n *    });\n *\n * By default Express passes an `Error`\n * with a `.status` of 406 to `next(err)`\n * if a match is not made. If you provide\n * a `.default` callback it will be invoked\n * instead.\n *\n * @param {Object} obj\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.format = function(obj){\n  var req = this.req;\n  var next = req.next;\n\n  var keys = Object.keys(obj)\n    .filter(function (v) { return v !== 'default' })\n\n  var key = keys.length > 0\n    ? req.accepts(keys)\n    : false;\n\n  this.vary(\"Accept\");\n\n  if (key) {\n    this.set('Content-Type', normalizeType(key).value);\n    obj[key](req, this, next);\n  } else if (obj.default) {\n    obj.default(req, this, next)\n  } else {\n    next(createError(406, {\n      types: normalizeTypes(keys).map(function (o) { return o.value })\n    }))\n  }\n\n  return this;\n};\n\n/**\n * Set _Content-Disposition_ header to _attachment_ with optional `filename`.\n *\n * @param {String} filename\n * @return {ServerResponse}\n * @public\n */\n\nres.attachment = function attachment(filename) {\n  if (filename) {\n    this.type(extname(filename));\n  }\n\n  this.set('Content-Disposition', contentDisposition(filename));\n\n  return this;\n};\n\n/**\n * Append additional header `field` with value `val`.\n *\n * Example:\n *\n *    res.append('Link', ['<http://localhost/>', '<http://localhost:3000/>']);\n *    res.append('Set-Cookie', 'foo=bar; Path=/; HttpOnly');\n *    res.append('Warning', '199 Miscellaneous warning');\n *\n * @param {String} field\n * @param {String|Array} val\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.append = function append(field, val) {\n  var prev = this.get(field);\n  var value = val;\n\n  if (prev) {\n    // concat the new and prev vals\n    value = Array.isArray(prev) ? prev.concat(val)\n      : Array.isArray(val) ? [prev].concat(val)\n        : [prev, val]\n  }\n\n  return this.set(field, value);\n};\n\n/**\n * Set header `field` to `val`, or pass\n * an object of header fields.\n *\n * Examples:\n *\n *    res.set('Foo', ['bar', 'baz']);\n *    res.set('Accept', 'application/json');\n *    res.set({ Accept: 'text/plain', 'X-API-Key': 'tobi' });\n *\n * Aliased as `res.header()`.\n *\n * When the set header is \"Content-Type\", the type is expanded to include\n * the charset if not present using `mime.contentType()`.\n *\n * @param {String|Object} field\n * @param {String|Array} val\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.set =\nres.header = function header(field, val) {\n  if (arguments.length === 2) {\n    var value = Array.isArray(val)\n      ? val.map(String)\n      : String(val);\n\n    // add charset to content-type\n    if (field.toLowerCase() === 'content-type') {\n      if (Array.isArray(value)) {\n        throw new TypeError('Content-Type cannot be set to an Array');\n      }\n      value = mime.contentType(value)\n    }\n\n    this.setHeader(field, value);\n  } else {\n    for (var key in field) {\n      this.set(key, field[key]);\n    }\n  }\n  return this;\n};\n\n/**\n * Get value for header `field`.\n *\n * @param {String} field\n * @return {String}\n * @public\n */\n\nres.get = function(field){\n  return this.getHeader(field);\n};\n\n/**\n * Clear cookie `name`.\n *\n * @param {String} name\n * @param {Object} [options]\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.clearCookie = function clearCookie(name, options) {\n  // Force cookie expiration by setting expires to the past\n  const opts = { path: '/', ...options, expires: new Date(1)};\n  // ensure maxAge is not passed\n  delete opts.maxAge\n\n  return this.cookie(name, '', opts);\n};\n\n/**\n * Set cookie `name` to `value`, with the given `options`.\n *\n * Options:\n *\n *    - `maxAge`   max-age in milliseconds, converted to `expires`\n *    - `signed`   sign the cookie\n *    - `path`     defaults to \"/\"\n *\n * Examples:\n *\n *    // \"Remember Me\" for 15 minutes\n *    res.cookie('rememberme', '1', { expires: new Date(Date.now() + 900000), httpOnly: true });\n *\n *    // same as above\n *    res.cookie('rememberme', '1', { maxAge: 900000, httpOnly: true })\n *\n * @param {String} name\n * @param {String|Object} value\n * @param {Object} [options]\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.cookie = function (name, value, options) {\n  var opts = { ...options };\n  var secret = this.req.secret;\n  var signed = opts.signed;\n\n  if (signed && !secret) {\n    throw new Error('cookieParser(\"secret\") required for signed cookies');\n  }\n\n  var val = typeof value === 'object'\n    ? 'j:' + JSON.stringify(value)\n    : String(value);\n\n  if (signed) {\n    val = 's:' + sign(val, secret);\n  }\n\n  if (opts.maxAge != null) {\n    var maxAge = opts.maxAge - 0\n\n    if (!isNaN(maxAge)) {\n      opts.expires = new Date(Date.now() + maxAge)\n      opts.maxAge = Math.floor(maxAge / 1000)\n    }\n  }\n\n  if (opts.path == null) {\n    opts.path = '/';\n  }\n\n  this.append('Set-Cookie', cookie.serialize(name, String(val), opts));\n\n  return this;\n};\n\n/**\n * Set the location header to `url`.\n *\n * The given `url` can also be \"back\", which redirects\n * to the _Referrer_ or _Referer_ headers or \"/\".\n *\n * Examples:\n *\n *    res.location('/foo/bar').;\n *    res.location('http://example.com');\n *    res.location('../login');\n *\n * @param {String} url\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.location = function location(url) {\n  return this.set('Location', encodeUrl(url));\n};\n\n/**\n * Redirect to the given `url` with optional response `status`\n * defaulting to 302.\n *\n * Examples:\n *\n *    res.redirect('/foo/bar');\n *    res.redirect('http://example.com');\n *    res.redirect(301, 'http://example.com');\n *    res.redirect('../login'); // /blog/post/1 -> /blog/login\n *\n * @public\n */\n\nres.redirect = function redirect(url) {\n  var address = url;\n  var body;\n  var status = 302;\n\n  // allow status / url\n  if (arguments.length === 2) {\n    status = arguments[0]\n    address = arguments[1]\n  }\n\n  // Set location header\n  address = this.location(address).get('Location');\n\n  // Support text/{plain,html} by default\n  this.format({\n    text: function(){\n      body = statuses.message[status] + '. Redirecting to ' + address\n    },\n\n    html: function(){\n      var u = escapeHtml(address);\n      body = '<p>' + statuses.message[status] + '. Redirecting to ' + u + '</p>'\n    },\n\n    default: function(){\n      body = '';\n    }\n  });\n\n  // Respond\n  this.status(status);\n  this.set('Content-Length', Buffer.byteLength(body));\n\n  if (this.req.method === 'HEAD') {\n    this.end();\n  } else {\n    this.end(body);\n  }\n};\n\n/**\n * Add `field` to Vary. If already present in the Vary set, then\n * this call is simply ignored.\n *\n * @param {Array|String} field\n * @return {ServerResponse} for chaining\n * @public\n */\n\nres.vary = function(field){\n  vary(this, field);\n\n  return this;\n};\n\n/**\n * Render `view` with the given `options` and optional callback `fn`.\n * When a callback function is given a response will _not_ be made\n * automatically, otherwise a response of _200_ and _text/html_ is given.\n *\n * Options:\n *\n *  - `cache`     boolean hinting to the engine it should cache\n *  - `filename`  filename of the view being rendered\n *\n * @public\n */\n\nres.render = function render(view, options, callback) {\n  var app = this.req.app;\n  var done = callback;\n  var opts = options || {};\n  var req = this.req;\n  var self = this;\n\n  // support callback function as second arg\n  if (typeof options === 'function') {\n    done = options;\n    opts = {};\n  }\n\n  // merge res.locals\n  opts._locals = self.locals;\n\n  // default callback to respond\n  done = done || function (err, str) {\n    if (err) return req.next(err);\n    self.send(str);\n  };\n\n  // render\n  app.render(view, opts, done);\n};\n\n// pipe the send file stream\nfunction sendfile(res, file, options, callback) {\n  var done = false;\n  var streaming;\n\n  // request aborted\n  function onaborted() {\n    if (done) return;\n    done = true;\n\n    var err = new Error('Request aborted');\n    err.code = 'ECONNABORTED';\n    callback(err);\n  }\n\n  // directory\n  function ondirectory() {\n    if (done) return;\n    done = true;\n\n    var err = new Error('EISDIR, read');\n    err.code = 'EISDIR';\n    callback(err);\n  }\n\n  // errors\n  function onerror(err) {\n    if (done) return;\n    done = true;\n    callback(err);\n  }\n\n  // ended\n  function onend() {\n    if (done) return;\n    done = true;\n    callback();\n  }\n\n  // file\n  function onfile() {\n    streaming = false;\n  }\n\n  // finished\n  function onfinish(err) {\n    if (err && err.code === 'ECONNRESET') return onaborted();\n    if (err) return onerror(err);\n    if (done) return;\n\n    setImmediate(function () {\n      if (streaming !== false && !done) {\n        onaborted();\n        return;\n      }\n\n      if (done) return;\n      done = true;\n      callback();\n    });\n  }\n\n  // streaming\n  function onstream() {\n    streaming = true;\n  }\n\n  file.on('directory', ondirectory);\n  file.on('end', onend);\n  file.on('error', onerror);\n  file.on('file', onfile);\n  file.on('stream', onstream);\n  onFinished(res, onfinish);\n\n  if (options.headers) {\n    // set headers on successful transfer\n    file.on('headers', function headers(res) {\n      var obj = options.headers;\n      var keys = Object.keys(obj);\n\n      for (var i = 0; i < keys.length; i++) {\n        var k = keys[i];\n        res.setHeader(k, obj[k]);\n      }\n    });\n  }\n\n  // pipe\n  file.pipe(res);\n}\n\n/**\n * Stringify JSON, like JSON.stringify, but v8 optimized, with the\n * ability to escape characters that can trigger HTML sniffing.\n *\n * @param {*} value\n * @param {function} replacer\n * @param {number} spaces\n * @param {boolean} escape\n * @returns {string}\n * @private\n */\n\nfunction stringify (value, replacer, spaces, escape) {\n  // v8 checks arguments.length for optimizing simple call\n  // https://bugs.chromium.org/p/v8/issues/detail?id=4730\n  var json = replacer || spaces\n    ? JSON.stringify(value, replacer, spaces)\n    : JSON.stringify(value);\n\n  if (escape && typeof json === 'string') {\n    json = json.replace(/[<>&]/g, function (c) {\n      switch (c.charCodeAt(0)) {\n        case 0x3c:\n          return '\\\\u003c'\n        case 0x3e:\n          return '\\\\u003e'\n        case 0x26:\n          return '\\\\u0026'\n        /* istanbul ignore next: unreachable default */\n        default:\n          return c\n      }\n    })\n  }\n\n  return json\n}\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "5ccbe1ebed61",
      "repo": "express",
      "commit_hash": "55869f4",
      "commit_message": "feat: Added check to support Uint8Array in response sending (#6285)",
      "file_path": "test/res.send.js",
      "language": "javascript",
      "code_before": "'use strict'\n\nvar assert = require('node:assert')\nvar express = require('..');\nvar methods = require('../lib/utils').methods;\nvar request = require('supertest');\nvar utils = require('./support/utils');\n\nvar shouldSkipQuery = require('./support/utils').shouldSkipQuery\n\ndescribe('res', function(){\n  describe('.send()', function(){\n    it('should set body to \"\"', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send();\n      });\n\n      request(app)\n      .get('/')\n      .expect(200, '', done);\n    })\n  })\n\n  describe('.send(null)', function(){\n    it('should set body to \"\"', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(null);\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Length', '0')\n      .expect(200, '', done);\n    })\n  })\n\n  describe('.send(undefined)', function(){\n    it('should set body to \"\"', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(undefined);\n      });\n\n      request(app)\n      .get('/')\n      .expect(200, '', done);\n    })\n  })\n\n  describe('.send(Number)', function(){\n    it('should send as application/json', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(1000);\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'application/json; charset=utf-8')\n      .expect(200, '1000', done)\n    })\n  })\n\n  describe('.send(String)', function(){\n    it('should send as html', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send('<p>hey</p>');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect(200, '<p>hey</p>', done);\n    })\n\n    it('should set ETag', function (done) {\n      var app = express();\n\n      app.use(function (req, res) {\n        var str = Array(1000).join('-');\n        res.send(str);\n      });\n\n      request(app)\n      .get('/')\n      .expect('ETag', 'W/\"3e7-qPnkJ3CVdVhFJQvUBfF10TmVA7g\"')\n      .expect(200, done);\n    })\n\n    it('should not override Content-Type', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain').send('hey');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=utf-8')\n      .expect(200, 'hey', done);\n    })\n\n    it('should override charset in Content-Type', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain; charset=iso-8859-1').send('hey');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=utf-8')\n      .expect(200, 'hey', done);\n    })\n\n    it('should keep charset in Content-Type for Buffers', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain; charset=iso-8859-1').send(Buffer.from('hi'))\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=iso-8859-1')\n      .expect(200, 'hi', done);\n    })\n  })\n\n  describe('.send(Buffer)', function(){\n    it('should send as octet-stream', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(Buffer.from('hello'))\n      });\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Type', 'application/octet-stream')\n        .expect(utils.shouldHaveBody(Buffer.from('hello')))\n        .end(done)\n    })\n\n    it('should set ETag', function (done) {\n      var app = express();\n\n      app.use(function (req, res) {\n        res.send(Buffer.alloc(999, '-'))\n      });\n\n      request(app)\n      .get('/')\n      .expect('ETag', 'W/\"3e7-qPnkJ3CVdVhFJQvUBfF10TmVA7g\"')\n      .expect(200, done);\n    })\n\n    it('should not override Content-Type', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain').send(Buffer.from('hey'))\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=utf-8')\n      .expect(200, 'hey', done);\n    })\n\n    it('should not override ETag', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.type('text/plain').set('ETag', '\"foo\"').send(Buffer.from('hey'))\n      })\n\n      request(app)\n      .get('/')\n      .expect('ETag', '\"foo\"')\n      .expect(200, 'hey', done)\n    })\n  })\n\n  describe('.send(Object)', function(){\n    it('should send as application/json', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send({ name: 'tobi' });\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'application/json; charset=utf-8')\n      .expect(200, '{\"name\":\"tobi\"}', done)\n    })\n  })\n\n  describe('when the request method is HEAD', function(){\n    it('should ignore the body', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send('yay');\n      });\n\n      request(app)\n        .head('/')\n        .expect(200)\n        .expect(utils.shouldNotHaveBody())\n        .end(done)\n    })\n  })\n\n  describe('when .statusCode is 204', function(){\n    it('should strip Content-* fields, Transfer-Encoding field, and body', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.status(204).set('Transfer-Encoding', 'chunked').send('foo');\n      });\n\n      request(app)\n      .get('/')\n      .expect(utils.shouldNotHaveHeader('Content-Type'))\n      .expect(utils.shouldNotHaveHeader('Content-Length'))\n      .expect(utils.shouldNotHaveHeader('Transfer-Encoding'))\n      .expect(204, '', done);\n    })\n  })\n\n  describe('when .statusCode is 205', function () {\n    it('should strip Transfer-Encoding field and body, set Content-Length', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.status(205).set('Transfer-Encoding', 'chunked').send('foo')\n      })\n\n      request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('Transfer-Encoding'))\n        .expect('Content-Length', '0')\n        .expect(205, '', done)\n    })\n  })\n\n  describe('when .statusCode is 304', function(){\n    it('should strip Content-* fields, Transfer-Encoding field, and body', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.status(304).set('Transfer-Encoding', 'chunked').send('foo');\n      });\n\n      request(app)\n      .get('/')\n      .expect(utils.shouldNotHaveHeader('Content-Type'))\n      .expect(utils.shouldNotHaveHeader('Content-Length'))\n      .expect(utils.shouldNotHaveHeader('Transfer-Encoding'))\n      .expect(304, '', done);\n    })\n  })\n\n  it('should always check regardless of length', function(done){\n    var app = express();\n    var etag = '\"asdf\"';\n\n    app.use(function(req, res, next){\n      res.set('ETag', etag);\n      res.send('hey');\n    });\n\n    request(app)\n    .get('/')\n    .set('If-None-Match', etag)\n    .expect(304, done);\n  })\n\n  it('should respond with 304 Not Modified when fresh', function(done){\n    var app = express();\n    var etag = '\"asdf\"';\n\n    app.use(function(req, res){\n      var str = Array(1000).join('-');\n      res.set('ETag', etag);\n      res.send(str);\n    });\n\n    request(app)\n    .get('/')\n    .set('If-None-Match', etag)\n    .expect(304, done);\n  })\n\n  it('should not perform freshness check unless 2xx or 304', function(done){\n    var app = express();\n    var etag = '\"asdf\"';\n\n    app.use(function(req, res, next){\n      res.status(500);\n      res.set('ETag', etag);\n      res.send('hey');\n    });\n\n    request(app)\n    .get('/')\n    .set('If-None-Match', etag)\n    .expect('hey')\n    .expect(500, done);\n  })\n\n  it('should not support jsonp callbacks', function(done){\n    var app = express();\n\n    app.use(function(req, res){\n      res.send({ foo: 'bar' });\n    });\n\n    request(app)\n    .get('/?callback=foo')\n    .expect('{\"foo\":\"bar\"}', done);\n  })\n\n  it('should be chainable', function (done) {\n    var app = express()\n\n    app.use(function (req, res) {\n      assert.equal(res.send('hey'), res)\n    })\n\n    request(app)\n    .get('/')\n    .expect(200, 'hey', done)\n  })\n\n  describe('\"etag\" setting', function () {\n    describe('when enabled', function () {\n      it('should send ETag', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.send('kajdslfkasdf');\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"c-IgR/L5SF7CJQff4wxKGF/vfPuZ0\"')\n        .expect(200, done);\n      });\n\n      methods.forEach(function (method) {\n        if (method === 'connect') return;\n\n        it('should send ETag in response to ' + method.toUpperCase() + ' request', function (done) {\n          if (method === 'query' && shouldSkipQuery(process.versions.node)) {\n            this.skip()\n          }\n          var app = express();\n\n          app[method]('/', function (req, res) {\n            res.send('kajdslfkasdf');\n          });\n\n          request(app)\n          [method]('/')\n          .expect('ETag', 'W/\"c-IgR/L5SF7CJQff4wxKGF/vfPuZ0\"')\n          .expect(200, done);\n        })\n      });\n\n      it('should send ETag for empty string response', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.send('');\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"0-2jmj7l5rSw0yVb/vlWAYkK/YBwk\"')\n        .expect(200, done);\n      })\n\n      it('should send ETag for long response', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          var str = Array(1000).join('-');\n          res.send(str);\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"3e7-qPnkJ3CVdVhFJQvUBfF10TmVA7g\"')\n        .expect(200, done);\n      });\n\n      it('should not override ETag when manually set', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.set('etag', '\"asdf\"');\n          res.send('hello!');\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"asdf\"')\n        .expect(200, done);\n      });\n\n      it('should not send ETag for res.send()', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.send();\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('ETag'))\n        .expect(200, done);\n      })\n    });\n\n    describe('when disabled', function () {\n      it('should send no ETag', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          var str = Array(1000).join('-');\n          res.send(str);\n        });\n\n        app.disable('etag');\n\n        request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('ETag'))\n        .expect(200, done);\n      });\n\n      it('should send ETag when manually set', function (done) {\n        var app = express();\n\n        app.disable('etag');\n\n        app.use(function (req, res) {\n          res.set('etag', '\"asdf\"');\n          res.send('hello!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"asdf\"')\n        .expect(200, done);\n      });\n    });\n\n    describe('when \"strong\"', function () {\n      it('should send strong ETag', function (done) {\n        var app = express();\n\n        app.set('etag', 'strong');\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"d-HwnTDHB9U/PRbFMN1z1wps51lqk\"')\n        .expect(200, done);\n      })\n    })\n\n    describe('when \"weak\"', function () {\n      it('should send weak ETag', function (done) {\n        var app = express();\n\n        app.set('etag', 'weak');\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"d-HwnTDHB9U/PRbFMN1z1wps51lqk\"')\n        .expect(200, done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should send custom ETag', function (done) {\n        var app = express();\n\n        app.set('etag', function (body, encoding) {\n          var chunk = !Buffer.isBuffer(body)\n            ? Buffer.from(body, encoding)\n            : body;\n          assert.strictEqual(chunk.toString(), 'hello, world!')\n          return '\"custom\"';\n        });\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"custom\"')\n        .expect(200, done);\n      })\n\n      it('should not send falsy ETag', function (done) {\n        var app = express();\n\n        app.set('etag', function (body, encoding) {\n          return undefined;\n        });\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('ETag'))\n        .expect(200, done);\n      })\n    })\n  })\n})\n",
      "code_after": "'use strict'\n\nvar assert = require('node:assert')\nvar express = require('..');\nvar methods = require('../lib/utils').methods;\nvar request = require('supertest');\nvar utils = require('./support/utils');\n\nvar shouldSkipQuery = require('./support/utils').shouldSkipQuery\n\ndescribe('res', function(){\n  describe('.send()', function(){\n    it('should set body to \"\"', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send();\n      });\n\n      request(app)\n      .get('/')\n      .expect(200, '', done);\n    })\n  })\n\n  describe('.send(null)', function(){\n    it('should set body to \"\"', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(null);\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Length', '0')\n      .expect(200, '', done);\n    })\n  })\n\n  describe('.send(undefined)', function(){\n    it('should set body to \"\"', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(undefined);\n      });\n\n      request(app)\n      .get('/')\n      .expect(200, '', done);\n    })\n  })\n\n  describe('.send(Number)', function(){\n    it('should send as application/json', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(1000);\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'application/json; charset=utf-8')\n      .expect(200, '1000', done)\n    })\n  })\n\n  describe('.send(String)', function(){\n    it('should send as html', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send('<p>hey</p>');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/html; charset=utf-8')\n      .expect(200, '<p>hey</p>', done);\n    })\n\n    it('should set ETag', function (done) {\n      var app = express();\n\n      app.use(function (req, res) {\n        var str = Array(1000).join('-');\n        res.send(str);\n      });\n\n      request(app)\n      .get('/')\n      .expect('ETag', 'W/\"3e7-qPnkJ3CVdVhFJQvUBfF10TmVA7g\"')\n      .expect(200, done);\n    })\n\n    it('should not override Content-Type', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain').send('hey');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=utf-8')\n      .expect(200, 'hey', done);\n    })\n\n    it('should override charset in Content-Type', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain; charset=iso-8859-1').send('hey');\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=utf-8')\n      .expect(200, 'hey', done);\n    })\n\n    it('should keep charset in Content-Type for Buffers', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain; charset=iso-8859-1').send(Buffer.from('hi'))\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=iso-8859-1')\n      .expect(200, 'hi', done);\n    })\n  })\n\n  describe('.send(Buffer)', function(){\n    it('should send as octet-stream', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send(Buffer.from('hello'))\n      });\n\n      request(app)\n        .get('/')\n        .expect(200)\n        .expect('Content-Type', 'application/octet-stream')\n        .expect(utils.shouldHaveBody(Buffer.from('hello')))\n        .end(done)\n    })\n\n    it('should set ETag', function (done) {\n      var app = express();\n\n      app.use(function (req, res) {\n        res.send(Buffer.alloc(999, '-'))\n      });\n\n      request(app)\n      .get('/')\n      .expect('ETag', 'W/\"3e7-qPnkJ3CVdVhFJQvUBfF10TmVA7g\"')\n      .expect(200, done);\n    })\n\n    it('should not override Content-Type', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.set('Content-Type', 'text/plain').send(Buffer.from('hey'))\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'text/plain; charset=utf-8')\n      .expect(200, 'hey', done);\n    })\n\n    it('should accept Uint8Array', function(done){\n      var app = express();\n      app.use(function(req, res){\n        const encodedHey = new TextEncoder().encode(\"hey\");\n        res.set(\"Content-Type\", \"text/plain\").send(encodedHey);\n      })\n\n      request(app)\n        .get(\"/\")\n        .expect(\"Content-Type\", \"text/plain; charset=utf-8\")\n        .expect(200, \"hey\", done);\n    })\n\n    it('should not override ETag', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.type('text/plain').set('ETag', '\"foo\"').send(Buffer.from('hey'))\n      })\n\n      request(app)\n      .get('/')\n      .expect('ETag', '\"foo\"')\n      .expect(200, 'hey', done)\n    })\n  })\n\n  describe('.send(Object)', function(){\n    it('should send as application/json', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send({ name: 'tobi' });\n      });\n\n      request(app)\n      .get('/')\n      .expect('Content-Type', 'application/json; charset=utf-8')\n      .expect(200, '{\"name\":\"tobi\"}', done)\n    })\n  })\n\n  describe('when the request method is HEAD', function(){\n    it('should ignore the body', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.send('yay');\n      });\n\n      request(app)\n        .head('/')\n        .expect(200)\n        .expect(utils.shouldNotHaveBody())\n        .end(done)\n    })\n  })\n\n  describe('when .statusCode is 204', function(){\n    it('should strip Content-* fields, Transfer-Encoding field, and body', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.status(204).set('Transfer-Encoding', 'chunked').send('foo');\n      });\n\n      request(app)\n      .get('/')\n      .expect(utils.shouldNotHaveHeader('Content-Type'))\n      .expect(utils.shouldNotHaveHeader('Content-Length'))\n      .expect(utils.shouldNotHaveHeader('Transfer-Encoding'))\n      .expect(204, '', done);\n    })\n  })\n\n  describe('when .statusCode is 205', function () {\n    it('should strip Transfer-Encoding field and body, set Content-Length', function (done) {\n      var app = express()\n\n      app.use(function (req, res) {\n        res.status(205).set('Transfer-Encoding', 'chunked').send('foo')\n      })\n\n      request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('Transfer-Encoding'))\n        .expect('Content-Length', '0')\n        .expect(205, '', done)\n    })\n  })\n\n  describe('when .statusCode is 304', function(){\n    it('should strip Content-* fields, Transfer-Encoding field, and body', function(done){\n      var app = express();\n\n      app.use(function(req, res){\n        res.status(304).set('Transfer-Encoding', 'chunked').send('foo');\n      });\n\n      request(app)\n      .get('/')\n      .expect(utils.shouldNotHaveHeader('Content-Type'))\n      .expect(utils.shouldNotHaveHeader('Content-Length'))\n      .expect(utils.shouldNotHaveHeader('Transfer-Encoding'))\n      .expect(304, '', done);\n    })\n  })\n\n  it('should always check regardless of length', function(done){\n    var app = express();\n    var etag = '\"asdf\"';\n\n    app.use(function(req, res, next){\n      res.set('ETag', etag);\n      res.send('hey');\n    });\n\n    request(app)\n    .get('/')\n    .set('If-None-Match', etag)\n    .expect(304, done);\n  })\n\n  it('should respond with 304 Not Modified when fresh', function(done){\n    var app = express();\n    var etag = '\"asdf\"';\n\n    app.use(function(req, res){\n      var str = Array(1000).join('-');\n      res.set('ETag', etag);\n      res.send(str);\n    });\n\n    request(app)\n    .get('/')\n    .set('If-None-Match', etag)\n    .expect(304, done);\n  })\n\n  it('should not perform freshness check unless 2xx or 304', function(done){\n    var app = express();\n    var etag = '\"asdf\"';\n\n    app.use(function(req, res, next){\n      res.status(500);\n      res.set('ETag', etag);\n      res.send('hey');\n    });\n\n    request(app)\n    .get('/')\n    .set('If-None-Match', etag)\n    .expect('hey')\n    .expect(500, done);\n  })\n\n  it('should not support jsonp callbacks', function(done){\n    var app = express();\n\n    app.use(function(req, res){\n      res.send({ foo: 'bar' });\n    });\n\n    request(app)\n    .get('/?callback=foo')\n    .expect('{\"foo\":\"bar\"}', done);\n  })\n\n  it('should be chainable', function (done) {\n    var app = express()\n\n    app.use(function (req, res) {\n      assert.equal(res.send('hey'), res)\n    })\n\n    request(app)\n    .get('/')\n    .expect(200, 'hey', done)\n  })\n\n  describe('\"etag\" setting', function () {\n    describe('when enabled', function () {\n      it('should send ETag', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.send('kajdslfkasdf');\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"c-IgR/L5SF7CJQff4wxKGF/vfPuZ0\"')\n        .expect(200, done);\n      });\n\n      methods.forEach(function (method) {\n        if (method === 'connect') return;\n\n        it('should send ETag in response to ' + method.toUpperCase() + ' request', function (done) {\n          if (method === 'query' && shouldSkipQuery(process.versions.node)) {\n            this.skip()\n          }\n          var app = express();\n\n          app[method]('/', function (req, res) {\n            res.send('kajdslfkasdf');\n          });\n\n          request(app)\n          [method]('/')\n          .expect('ETag', 'W/\"c-IgR/L5SF7CJQff4wxKGF/vfPuZ0\"')\n          .expect(200, done);\n        })\n      });\n\n      it('should send ETag for empty string response', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.send('');\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"0-2jmj7l5rSw0yVb/vlWAYkK/YBwk\"')\n        .expect(200, done);\n      })\n\n      it('should send ETag for long response', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          var str = Array(1000).join('-');\n          res.send(str);\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"3e7-qPnkJ3CVdVhFJQvUBfF10TmVA7g\"')\n        .expect(200, done);\n      });\n\n      it('should not override ETag when manually set', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.set('etag', '\"asdf\"');\n          res.send('hello!');\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"asdf\"')\n        .expect(200, done);\n      });\n\n      it('should not send ETag for res.send()', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          res.send();\n        });\n\n        app.enable('etag');\n\n        request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('ETag'))\n        .expect(200, done);\n      })\n    });\n\n    describe('when disabled', function () {\n      it('should send no ETag', function (done) {\n        var app = express();\n\n        app.use(function (req, res) {\n          var str = Array(1000).join('-');\n          res.send(str);\n        });\n\n        app.disable('etag');\n\n        request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('ETag'))\n        .expect(200, done);\n      });\n\n      it('should send ETag when manually set', function (done) {\n        var app = express();\n\n        app.disable('etag');\n\n        app.use(function (req, res) {\n          res.set('etag', '\"asdf\"');\n          res.send('hello!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"asdf\"')\n        .expect(200, done);\n      });\n    });\n\n    describe('when \"strong\"', function () {\n      it('should send strong ETag', function (done) {\n        var app = express();\n\n        app.set('etag', 'strong');\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"d-HwnTDHB9U/PRbFMN1z1wps51lqk\"')\n        .expect(200, done);\n      })\n    })\n\n    describe('when \"weak\"', function () {\n      it('should send weak ETag', function (done) {\n        var app = express();\n\n        app.set('etag', 'weak');\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', 'W/\"d-HwnTDHB9U/PRbFMN1z1wps51lqk\"')\n        .expect(200, done)\n      })\n    })\n\n    describe('when a function', function () {\n      it('should send custom ETag', function (done) {\n        var app = express();\n\n        app.set('etag', function (body, encoding) {\n          var chunk = !Buffer.isBuffer(body)\n            ? Buffer.from(body, encoding)\n            : body;\n          assert.strictEqual(chunk.toString(), 'hello, world!')\n          return '\"custom\"';\n        });\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect('ETag', '\"custom\"')\n        .expect(200, done);\n      })\n\n      it('should not send falsy ETag', function (done) {\n        var app = express();\n\n        app.set('etag', function (body, encoding) {\n          return undefined;\n        });\n\n        app.use(function (req, res) {\n          res.send('hello, world!');\n        });\n\n        request(app)\n        .get('/')\n        .expect(utils.shouldNotHaveHeader('ETag'))\n        .expect(200, done);\n      })\n    })\n  })\n})\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    },
    {
      "bug_id": "1c4f2e02805b",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/auth/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../..');\nvar hash = require('pbkdf2-password')()\nvar path = require('path');\nvar session = require('express-session');\n\nvar app = module.exports = express();\n\n// config\n\napp.set('view engine', 'ejs');\napp.set('views', path.join(__dirname, 'views'));\n\n// middleware\n\napp.use(express.urlencoded())\napp.use(session({\n  resave: false, // don't save session if unmodified\n  saveUninitialized: false, // don't create session until something stored\n  secret: 'shhhh, very secret'\n}));\n\n// Session-persisted message middleware\n\napp.use(function(req, res, next){\n  var err = req.session.error;\n  var msg = req.session.success;\n  delete req.session.error;\n  delete req.session.success;\n  res.locals.message = '';\n  if (err) res.locals.message = '<p class=\"msg error\">' + err + '</p>';\n  if (msg) res.locals.message = '<p class=\"msg success\">' + msg + '</p>';\n  next();\n});\n\n// dummy database\n\nvar users = {\n  tj: { name: 'tj' }\n};\n\n// when you create a user, generate a salt\n// and hash the password ('foobar' is the pass here)\n\nhash({ password: 'foobar' }, function (err, pass, salt, hash) {\n  if (err) throw err;\n  // store the salt & hash in the \"db\"\n  users.tj.salt = salt;\n  users.tj.hash = hash;\n});\n\n\n// Authenticate using our plain-object database of doom!\n\nfunction authenticate(name, pass, fn) {\n  if (!module.parent) console.log('authenticating %s:%s', name, pass);\n  var user = users[name];\n  // query the db for the given username\n  if (!user) return fn(null, null)\n  // apply the same algorithm to the POSTed password, applying\n  // the hash against the pass / salt, if there is a match we\n  // found the user\n  hash({ password: pass, salt: user.salt }, function (err, pass, salt, hash) {\n    if (err) return fn(err);\n    if (hash === user.hash) return fn(null, user)\n    fn(null, null)\n  });\n}\n\nfunction restrict(req, res, next) {\n  if (req.session.user) {\n    next();\n  } else {\n    req.session.error = 'Access denied!';\n    res.redirect('/login');\n  }\n}\n\napp.get('/', function(req, res){\n  res.redirect('/login');\n});\n\napp.get('/restricted', restrict, function(req, res){\n  res.send('Wahoo! restricted area, click to <a href=\"/logout\">logout</a>');\n});\n\napp.get('/logout', function(req, res){\n  // destroy the user's session to log them out\n  // will be re-created next request\n  req.session.destroy(function(){\n    res.redirect('/');\n  });\n});\n\napp.get('/login', function(req, res){\n  res.render('login');\n});\n\napp.post('/login', function (req, res, next) {\n  if (!req.body) return res.sendStatus(400)\n  authenticate(req.body.username, req.body.password, function(err, user){\n    if (err) return next(err)\n    if (user) {\n      // Regenerate session when signing in\n      // to prevent fixation\n      req.session.regenerate(function(){\n        // Store the user's primary key\n        // in the session store to be retrieved,\n        // or in this case the entire user object\n        req.session.user = user;\n        req.session.success = 'Authenticated as ' + user.name\n          + ' click to <a href=\"/logout\">logout</a>. '\n          + ' You may now access <a href=\"/restricted\">/restricted</a>.';\n        res.redirect(req.get('Referrer') || '/');\n      });\n    } else {\n      req.session.error = 'Authentication failed, please check your '\n        + ' username and password.'\n        + ' (use \"tj\" and \"foobar\")';\n      res.redirect('/login');\n    }\n  });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../..');\nvar hash = require('pbkdf2-password')()\nvar path = require('node:path');\nvar session = require('express-session');\n\nvar app = module.exports = express();\n\n// config\n\napp.set('view engine', 'ejs');\napp.set('views', path.join(__dirname, 'views'));\n\n// middleware\n\napp.use(express.urlencoded())\napp.use(session({\n  resave: false, // don't save session if unmodified\n  saveUninitialized: false, // don't create session until something stored\n  secret: 'shhhh, very secret'\n}));\n\n// Session-persisted message middleware\n\napp.use(function(req, res, next){\n  var err = req.session.error;\n  var msg = req.session.success;\n  delete req.session.error;\n  delete req.session.success;\n  res.locals.message = '';\n  if (err) res.locals.message = '<p class=\"msg error\">' + err + '</p>';\n  if (msg) res.locals.message = '<p class=\"msg success\">' + msg + '</p>';\n  next();\n});\n\n// dummy database\n\nvar users = {\n  tj: { name: 'tj' }\n};\n\n// when you create a user, generate a salt\n// and hash the password ('foobar' is the pass here)\n\nhash({ password: 'foobar' }, function (err, pass, salt, hash) {\n  if (err) throw err;\n  // store the salt & hash in the \"db\"\n  users.tj.salt = salt;\n  users.tj.hash = hash;\n});\n\n\n// Authenticate using our plain-object database of doom!\n\nfunction authenticate(name, pass, fn) {\n  if (!module.parent) console.log('authenticating %s:%s', name, pass);\n  var user = users[name];\n  // query the db for the given username\n  if (!user) return fn(null, null)\n  // apply the same algorithm to the POSTed password, applying\n  // the hash against the pass / salt, if there is a match we\n  // found the user\n  hash({ password: pass, salt: user.salt }, function (err, pass, salt, hash) {\n    if (err) return fn(err);\n    if (hash === user.hash) return fn(null, user)\n    fn(null, null)\n  });\n}\n\nfunction restrict(req, res, next) {\n  if (req.session.user) {\n    next();\n  } else {\n    req.session.error = 'Access denied!';\n    res.redirect('/login');\n  }\n}\n\napp.get('/', function(req, res){\n  res.redirect('/login');\n});\n\napp.get('/restricted', restrict, function(req, res){\n  res.send('Wahoo! restricted area, click to <a href=\"/logout\">logout</a>');\n});\n\napp.get('/logout', function(req, res){\n  // destroy the user's session to log them out\n  // will be re-created next request\n  req.session.destroy(function(){\n    res.redirect('/');\n  });\n});\n\napp.get('/login', function(req, res){\n  res.render('login');\n});\n\napp.post('/login', function (req, res, next) {\n  if (!req.body) return res.sendStatus(400)\n  authenticate(req.body.username, req.body.password, function(err, user){\n    if (err) return next(err)\n    if (user) {\n      // Regenerate session when signing in\n      // to prevent fixation\n      req.session.regenerate(function(){\n        // Store the user's primary key\n        // in the session store to be retrieved,\n        // or in this case the entire user object\n        req.session.user = user;\n        req.session.success = 'Authenticated as ' + user.name\n          + ' click to <a href=\"/logout\">logout</a>. '\n          + ' You may now access <a href=\"/restricted\">/restricted</a>.';\n        res.redirect(req.get('Referrer') || '/');\n      });\n    } else {\n      req.session.error = 'Authentication failed, please check your '\n        + ' username and password.'\n        + ' (use \"tj\" and \"foobar\")';\n      res.redirect('/login');\n    }\n  });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "928d5371fec5",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/downloads/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../');\nvar path = require('path');\n\nvar app = module.exports = express();\n\n// path to where the files are stored on disk\nvar FILES_DIR = path.join(__dirname, 'files')\n\napp.get('/', function(req, res){\n  res.send('<ul>' +\n    '<li>Download <a href=\"/files/notes/groceries.txt\">notes/groceries.txt</a>.</li>' +\n    '<li>Download <a href=\"/files/amazing.txt\">amazing.txt</a>.</li>' +\n    '<li>Download <a href=\"/files/missing.txt\">missing.txt</a>.</li>' +\n    '<li>Download <a href=\"/files/CCTV\u5927\u8d5b\u4e0a\u6d77\u5206\u8d5b\u533a.txt\">CCTV\u5927\u8d5b\u4e0a\u6d77\u5206\u8d5b\u533a.txt</a>.</li>' +\n    '</ul>')\n});\n\n// /files/* is accessed via req.params[0]\n// but here we name it :file\napp.get('/files/*file', function (req, res, next) {\n  res.download(req.params.file.join('/'), { root: FILES_DIR }, function (err) {\n    if (!err) return; // file sent\n    if (err.status !== 404) return next(err); // non-404 error\n    // file for download not found\n    res.statusCode = 404;\n    res.send('Cant find that file, sorry!');\n  });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../');\nvar path = require('node:path');\n\nvar app = module.exports = express();\n\n// path to where the files are stored on disk\nvar FILES_DIR = path.join(__dirname, 'files')\n\napp.get('/', function(req, res){\n  res.send('<ul>' +\n    '<li>Download <a href=\"/files/notes/groceries.txt\">notes/groceries.txt</a>.</li>' +\n    '<li>Download <a href=\"/files/amazing.txt\">amazing.txt</a>.</li>' +\n    '<li>Download <a href=\"/files/missing.txt\">missing.txt</a>.</li>' +\n    '<li>Download <a href=\"/files/CCTV\u5927\u8d5b\u4e0a\u6d77\u5206\u8d5b\u533a.txt\">CCTV\u5927\u8d5b\u4e0a\u6d77\u5206\u8d5b\u533a.txt</a>.</li>' +\n    '</ul>')\n});\n\n// /files/* is accessed via req.params[0]\n// but here we name it :file\napp.get('/files/*file', function (req, res, next) {\n  res.download(req.params.file.join('/'), { root: FILES_DIR }, function (err) {\n    if (!err) return; // file sent\n    if (err.status !== 404) return next(err); // non-404 error\n    // file for download not found\n    res.statusCode = 404;\n    res.send('Cant find that file, sorry!');\n  });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "36693c390d2c",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/ejs/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../');\nvar path = require('path');\n\nvar app = module.exports = express();\n\n// Register ejs as .html. If we did\n// not call this, we would need to\n// name our views foo.ejs instead\n// of foo.html. The __express method\n// is simply a function that engines\n// use to hook into the Express view\n// system by default, so if we want\n// to change \"foo.ejs\" to \"foo.html\"\n// we simply pass _any_ function, in this\n// case `ejs.__express`.\n\napp.engine('.html', require('ejs').__express);\n\n// Optional since express defaults to CWD/views\n\napp.set('views', path.join(__dirname, 'views'));\n\n// Path to our public directory\n\napp.use(express.static(path.join(__dirname, 'public')));\n\n// Without this you would need to\n// supply the extension to res.render()\n// ex: res.render('users.html').\napp.set('view engine', 'html');\n\n// Dummy users\nvar users = [\n  { name: 'tobi', email: 'tobi@learnboost.com' },\n  { name: 'loki', email: 'loki@learnboost.com' },\n  { name: 'jane', email: 'jane@learnboost.com' }\n];\n\napp.get('/', function(req, res){\n  res.render('users', {\n    users: users,\n    title: \"EJS example\",\n    header: \"Some users\"\n  });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../');\nvar path = require('node:path');\n\nvar app = module.exports = express();\n\n// Register ejs as .html. If we did\n// not call this, we would need to\n// name our views foo.ejs instead\n// of foo.html. The __express method\n// is simply a function that engines\n// use to hook into the Express view\n// system by default, so if we want\n// to change \"foo.ejs\" to \"foo.html\"\n// we simply pass _any_ function, in this\n// case `ejs.__express`.\n\napp.engine('.html', require('ejs').__express);\n\n// Optional since express defaults to CWD/views\n\napp.set('views', path.join(__dirname, 'views'));\n\n// Path to our public directory\n\napp.use(express.static(path.join(__dirname, 'public')));\n\n// Without this you would need to\n// supply the extension to res.render()\n// ex: res.render('users.html').\napp.set('view engine', 'html');\n\n// Dummy users\nvar users = [\n  { name: 'tobi', email: 'tobi@learnboost.com' },\n  { name: 'loki', email: 'loki@learnboost.com' },\n  { name: 'jane', email: 'jane@learnboost.com' }\n];\n\napp.get('/', function(req, res){\n  res.render('users', {\n    users: users,\n    title: \"EJS example\",\n    header: \"Some users\"\n  });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "a37268e369be",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/error-pages/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../');\nvar path = require('path');\nvar app = module.exports = express();\nvar logger = require('morgan');\nvar silent = process.env.NODE_ENV === 'test'\n\n// general config\napp.set('views', path.join(__dirname, 'views'));\napp.set('view engine', 'ejs');\n\n// our custom \"verbose errors\" setting\n// which we can use in the templates\n// via settings['verbose errors']\napp.enable('verbose errors');\n\n// disable them in production\n// use $ NODE_ENV=production node examples/error-pages\nif (app.settings.env === 'production') app.disable('verbose errors')\n\nsilent || app.use(logger('dev'));\n\n// Routes\n\napp.get('/', function(req, res){\n  res.render('index.ejs');\n});\n\napp.get('/404', function(req, res, next){\n  // trigger a 404 since no other middleware\n  // will match /404 after this one, and we're not\n  // responding here\n  next();\n});\n\napp.get('/403', function(req, res, next){\n  // trigger a 403 error\n  var err = new Error('not allowed!');\n  err.status = 403;\n  next(err);\n});\n\napp.get('/500', function(req, res, next){\n  // trigger a generic (500) error\n  next(new Error('keyboard cat!'));\n});\n\n// Error handlers\n\n// Since this is the last non-error-handling\n// middleware use()d, we assume 404, as nothing else\n// responded.\n\n// $ curl http://localhost:3000/notfound\n// $ curl http://localhost:3000/notfound -H \"Accept: application/json\"\n// $ curl http://localhost:3000/notfound -H \"Accept: text/plain\"\n\napp.use(function(req, res, next){\n  res.status(404);\n\n  res.format({\n    html: function () {\n      res.render('404', { url: req.url })\n    },\n    json: function () {\n      res.json({ error: 'Not found' })\n    },\n    default: function () {\n      res.type('txt').send('Not found')\n    }\n  })\n});\n\n// error-handling middleware, take the same form\n// as regular middleware, however they require an\n// arity of 4, aka the signature (err, req, res, next).\n// when connect has an error, it will invoke ONLY error-handling\n// middleware.\n\n// If we were to next() here any remaining non-error-handling\n// middleware would then be executed, or if we next(err) to\n// continue passing the error, only error-handling middleware\n// would remain being executed, however here\n// we simply respond with an error page.\n\napp.use(function(err, req, res, next){\n  // we may use properties of the error object\n  // here and next(err) appropriately, or if\n  // we possibly recovered from the error, simply next().\n  res.status(err.status || 500);\n  res.render('500', { error: err });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../');\nvar path = require('node:path');\nvar app = module.exports = express();\nvar logger = require('morgan');\nvar silent = process.env.NODE_ENV === 'test'\n\n// general config\napp.set('views', path.join(__dirname, 'views'));\napp.set('view engine', 'ejs');\n\n// our custom \"verbose errors\" setting\n// which we can use in the templates\n// via settings['verbose errors']\napp.enable('verbose errors');\n\n// disable them in production\n// use $ NODE_ENV=production node examples/error-pages\nif (app.settings.env === 'production') app.disable('verbose errors')\n\nsilent || app.use(logger('dev'));\n\n// Routes\n\napp.get('/', function(req, res){\n  res.render('index.ejs');\n});\n\napp.get('/404', function(req, res, next){\n  // trigger a 404 since no other middleware\n  // will match /404 after this one, and we're not\n  // responding here\n  next();\n});\n\napp.get('/403', function(req, res, next){\n  // trigger a 403 error\n  var err = new Error('not allowed!');\n  err.status = 403;\n  next(err);\n});\n\napp.get('/500', function(req, res, next){\n  // trigger a generic (500) error\n  next(new Error('keyboard cat!'));\n});\n\n// Error handlers\n\n// Since this is the last non-error-handling\n// middleware use()d, we assume 404, as nothing else\n// responded.\n\n// $ curl http://localhost:3000/notfound\n// $ curl http://localhost:3000/notfound -H \"Accept: application/json\"\n// $ curl http://localhost:3000/notfound -H \"Accept: text/plain\"\n\napp.use(function(req, res, next){\n  res.status(404);\n\n  res.format({\n    html: function () {\n      res.render('404', { url: req.url })\n    },\n    json: function () {\n      res.json({ error: 'Not found' })\n    },\n    default: function () {\n      res.type('txt').send('Not found')\n    }\n  })\n});\n\n// error-handling middleware, take the same form\n// as regular middleware, however they require an\n// arity of 4, aka the signature (err, req, res, next).\n// when connect has an error, it will invoke ONLY error-handling\n// middleware.\n\n// If we were to next() here any remaining non-error-handling\n// middleware would then be executed, or if we next(err) to\n// continue passing the error, only error-handling middleware\n// would remain being executed, however here\n// we simply respond with an error page.\n\napp.use(function(err, req, res, next){\n  // we may use properties of the error object\n  // here and next(err) appropriately, or if\n  // we possibly recovered from the error, simply next().\n  res.status(err.status || 500);\n  res.render('500', { error: err });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "d62526fba7a2",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/markdown/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar escapeHtml = require('escape-html');\nvar express = require('../..');\nvar fs = require('fs');\nvar marked = require('marked');\nvar path = require('path');\n\nvar app = module.exports = express();\n\n// register .md as an engine in express view system\n\napp.engine('md', function(path, options, fn){\n  fs.readFile(path, 'utf8', function(err, str){\n    if (err) return fn(err);\n    var html = marked.parse(str).replace(/\\{([^}]+)\\}/g, function(_, name){\n      return escapeHtml(options[name] || '');\n    });\n    fn(null, html);\n  });\n});\n\napp.set('views', path.join(__dirname, 'views'));\n\n// make it the default, so we don't need .md\napp.set('view engine', 'md');\n\napp.get('/', function(req, res){\n  res.render('index', { title: 'Markdown Example' });\n});\n\napp.get('/fail', function(req, res){\n  res.render('missing', { title: 'Markdown Example' });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar escapeHtml = require('escape-html');\nvar express = require('../..');\nvar fs = require('node:fs');\nvar marked = require('marked');\nvar path = require('node:path');\n\nvar app = module.exports = express();\n\n// register .md as an engine in express view system\n\napp.engine('md', function(path, options, fn){\n  fs.readFile(path, 'utf8', function(err, str){\n    if (err) return fn(err);\n    var html = marked.parse(str).replace(/\\{([^}]+)\\}/g, function(_, name){\n      return escapeHtml(options[name] || '');\n    });\n    fn(null, html);\n  });\n});\n\napp.set('views', path.join(__dirname, 'views'));\n\n// make it the default, so we don't need .md\napp.set('view engine', 'md');\n\napp.get('/', function(req, res){\n  res.render('index', { title: 'Markdown Example' });\n});\n\napp.get('/fail', function(req, res){\n  res.render('missing', { title: 'Markdown Example' });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "46bda3b6cc56",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/mvc/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../..');\nvar logger = require('morgan');\nvar path = require('path');\nvar session = require('express-session');\nvar methodOverride = require('method-override');\n\nvar app = module.exports = express();\n\n// set our default template engine to \"ejs\"\n// which prevents the need for using file extensions\napp.set('view engine', 'ejs');\n\n// set views for error and 404 pages\napp.set('views', path.join(__dirname, 'views'));\n\n// define a custom res.message() method\n// which stores messages in the session\napp.response.message = function(msg){\n  // reference `req.session` via the `this.req` reference\n  var sess = this.req.session;\n  // simply add the msg to an array for later\n  sess.messages = sess.messages || [];\n  sess.messages.push(msg);\n  return this;\n};\n\n// log\nif (!module.parent) app.use(logger('dev'));\n\n// serve static files\napp.use(express.static(path.join(__dirname, 'public')));\n\n// session support\napp.use(session({\n  resave: false, // don't save session if unmodified\n  saveUninitialized: false, // don't create session until something stored\n  secret: 'some secret here'\n}));\n\n// parse request bodies (req.body)\napp.use(express.urlencoded({ extended: true }))\n\n// allow overriding methods in query (?_method=put)\napp.use(methodOverride('_method'));\n\n// expose the \"messages\" local variable when views are rendered\napp.use(function(req, res, next){\n  var msgs = req.session.messages || [];\n\n  // expose \"messages\" local variable\n  res.locals.messages = msgs;\n\n  // expose \"hasMessages\"\n  res.locals.hasMessages = !! msgs.length;\n\n  /* This is equivalent:\n   res.locals({\n     messages: msgs,\n     hasMessages: !! msgs.length\n   });\n  */\n\n  next();\n  // empty or \"flush\" the messages so they\n  // don't build up\n  req.session.messages = [];\n});\n\n// load controllers\nrequire('./lib/boot')(app, { verbose: !module.parent });\n\napp.use(function(err, req, res, next){\n  // log it\n  if (!module.parent) console.error(err.stack);\n\n  // error page\n  res.status(500).render('5xx');\n});\n\n// assume 404 since no middleware responded\napp.use(function(req, res, next){\n  res.status(404).render('404', { url: req.originalUrl });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../..');\nvar logger = require('morgan');\nvar path = require('node:path');\nvar session = require('express-session');\nvar methodOverride = require('method-override');\n\nvar app = module.exports = express();\n\n// set our default template engine to \"ejs\"\n// which prevents the need for using file extensions\napp.set('view engine', 'ejs');\n\n// set views for error and 404 pages\napp.set('views', path.join(__dirname, 'views'));\n\n// define a custom res.message() method\n// which stores messages in the session\napp.response.message = function(msg){\n  // reference `req.session` via the `this.req` reference\n  var sess = this.req.session;\n  // simply add the msg to an array for later\n  sess.messages = sess.messages || [];\n  sess.messages.push(msg);\n  return this;\n};\n\n// log\nif (!module.parent) app.use(logger('dev'));\n\n// serve static files\napp.use(express.static(path.join(__dirname, 'public')));\n\n// session support\napp.use(session({\n  resave: false, // don't save session if unmodified\n  saveUninitialized: false, // don't create session until something stored\n  secret: 'some secret here'\n}));\n\n// parse request bodies (req.body)\napp.use(express.urlencoded({ extended: true }))\n\n// allow overriding methods in query (?_method=put)\napp.use(methodOverride('_method'));\n\n// expose the \"messages\" local variable when views are rendered\napp.use(function(req, res, next){\n  var msgs = req.session.messages || [];\n\n  // expose \"messages\" local variable\n  res.locals.messages = msgs;\n\n  // expose \"hasMessages\"\n  res.locals.hasMessages = !! msgs.length;\n\n  /* This is equivalent:\n   res.locals({\n     messages: msgs,\n     hasMessages: !! msgs.length\n   });\n  */\n\n  next();\n  // empty or \"flush\" the messages so they\n  // don't build up\n  req.session.messages = [];\n});\n\n// load controllers\nrequire('./lib/boot')(app, { verbose: !module.parent });\n\napp.use(function(err, req, res, next){\n  // log it\n  if (!module.parent) console.error(err.stack);\n\n  // error page\n  res.status(500).render('5xx');\n});\n\n// assume 404 since no middleware responded\napp.use(function(req, res, next){\n  res.status(404).render('404', { url: req.originalUrl });\n});\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "c328573c317a",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/mvc/lib/boot.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../..');\nvar fs = require('fs');\nvar path = require('path');\n\nmodule.exports = function(parent, options){\n  var dir = path.join(__dirname, '..', 'controllers');\n  var verbose = options.verbose;\n  fs.readdirSync(dir).forEach(function(name){\n    var file = path.join(dir, name)\n    if (!fs.statSync(file).isDirectory()) return;\n    verbose && console.log('\\n   %s:', name);\n    var obj = require(file);\n    var name = obj.name || name;\n    var prefix = obj.prefix || '';\n    var app = express();\n    var handler;\n    var method;\n    var url;\n\n    // allow specifying the view engine\n    if (obj.engine) app.set('view engine', obj.engine);\n    app.set('views', path.join(__dirname, '..', 'controllers', name, 'views'));\n\n    // generate routes based\n    // on the exported methods\n    for (var key in obj) {\n      // \"reserved\" exports\n      if (~['name', 'prefix', 'engine', 'before'].indexOf(key)) continue;\n      // route exports\n      switch (key) {\n        case 'show':\n          method = 'get';\n          url = '/' + name + '/:' + name + '_id';\n          break;\n        case 'list':\n          method = 'get';\n          url = '/' + name + 's';\n          break;\n        case 'edit':\n          method = 'get';\n          url = '/' + name + '/:' + name + '_id/edit';\n          break;\n        case 'update':\n          method = 'put';\n          url = '/' + name + '/:' + name + '_id';\n          break;\n        case 'create':\n          method = 'post';\n          url = '/' + name;\n          break;\n        case 'index':\n          method = 'get';\n          url = '/';\n          break;\n        default:\n          /* istanbul ignore next */\n          throw new Error('unrecognized route: ' + name + '.' + key);\n      }\n\n      // setup\n      handler = obj[key];\n      url = prefix + url;\n\n      // before middleware support\n      if (obj.before) {\n        app[method](url, obj.before, handler);\n        verbose && console.log('     %s %s -> before -> %s', method.toUpperCase(), url, key);\n      } else {\n        app[method](url, handler);\n        verbose && console.log('     %s %s -> %s', method.toUpperCase(), url, key);\n      }\n    }\n\n    // mount the app\n    parent.use(app);\n  });\n};\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../../..');\nvar fs = require('node:fs');\nvar path = require('node:path');\n\nmodule.exports = function(parent, options){\n  var dir = path.join(__dirname, '..', 'controllers');\n  var verbose = options.verbose;\n  fs.readdirSync(dir).forEach(function(name){\n    var file = path.join(dir, name)\n    if (!fs.statSync(file).isDirectory()) return;\n    verbose && console.log('\\n   %s:', name);\n    var obj = require(file);\n    var name = obj.name || name;\n    var prefix = obj.prefix || '';\n    var app = express();\n    var handler;\n    var method;\n    var url;\n\n    // allow specifying the view engine\n    if (obj.engine) app.set('view engine', obj.engine);\n    app.set('views', path.join(__dirname, '..', 'controllers', name, 'views'));\n\n    // generate routes based\n    // on the exported methods\n    for (var key in obj) {\n      // \"reserved\" exports\n      if (~['name', 'prefix', 'engine', 'before'].indexOf(key)) continue;\n      // route exports\n      switch (key) {\n        case 'show':\n          method = 'get';\n          url = '/' + name + '/:' + name + '_id';\n          break;\n        case 'list':\n          method = 'get';\n          url = '/' + name + 's';\n          break;\n        case 'edit':\n          method = 'get';\n          url = '/' + name + '/:' + name + '_id/edit';\n          break;\n        case 'update':\n          method = 'put';\n          url = '/' + name + '/:' + name + '_id';\n          break;\n        case 'create':\n          method = 'post';\n          url = '/' + name;\n          break;\n        case 'index':\n          method = 'get';\n          url = '/';\n          break;\n        default:\n          /* istanbul ignore next */\n          throw new Error('unrecognized route: ' + name + '.' + key);\n      }\n\n      // setup\n      handler = obj[key];\n      url = prefix + url;\n\n      // before middleware support\n      if (obj.before) {\n        app[method](url, obj.before, handler);\n        verbose && console.log('     %s %s -> before -> %s', method.toUpperCase(), url, key);\n      } else {\n        app[method](url, handler);\n        verbose && console.log('     %s %s -> %s', method.toUpperCase(), url, key);\n      }\n    }\n\n    // mount the app\n    parent.use(app);\n  });\n};\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "9dd50393b38c",
      "repo": "express",
      "commit_hash": "4111359",
      "commit_message": "fix(refactor): prefix built-in node module imports",
      "file_path": "examples/route-separation/index.js",
      "language": "javascript",
      "code_before": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../..');\nvar path = require('path');\nvar app = express();\nvar logger = require('morgan');\nvar cookieParser = require('cookie-parser');\nvar methodOverride = require('method-override');\nvar site = require('./site');\nvar post = require('./post');\nvar user = require('./user');\n\nmodule.exports = app;\n\n// Config\n\napp.set('view engine', 'ejs');\napp.set('views', path.join(__dirname, 'views'));\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.use(logger('dev'));\n}\n\napp.use(methodOverride('_method'));\napp.use(cookieParser());\napp.use(express.urlencoded({ extended: true }))\napp.use(express.static(path.join(__dirname, 'public')));\n\n// General\n\napp.get('/', site.index);\n\n// User\n\napp.get('/users', user.list);\napp.all('/user/:id{/:op}', user.load);\napp.get('/user/:id', user.view);\napp.get('/user/:id/view', user.view);\napp.get('/user/:id/edit', user.edit);\napp.put('/user/:id/edit', user.update);\n\n// Posts\n\napp.get('/posts', post.list);\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "code_after": "'use strict'\n\n/**\n * Module dependencies.\n */\n\nvar express = require('../..');\nvar path = require('node:path');\nvar app = express();\nvar logger = require('morgan');\nvar cookieParser = require('cookie-parser');\nvar methodOverride = require('method-override');\nvar site = require('./site');\nvar post = require('./post');\nvar user = require('./user');\n\nmodule.exports = app;\n\n// Config\n\napp.set('view engine', 'ejs');\napp.set('views', path.join(__dirname, 'views'));\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.use(logger('dev'));\n}\n\napp.use(methodOverride('_method'));\napp.use(cookieParser());\napp.use(express.urlencoded({ extended: true }))\napp.use(express.static(path.join(__dirname, 'public')));\n\n// General\n\napp.get('/', site.index);\n\n// User\n\napp.get('/users', user.list);\napp.all('/user/:id{/:op}', user.load);\napp.get('/user/:id', user.view);\napp.get('/user/:id/view', user.view);\napp.get('/user/:id/edit', user.edit);\napp.put('/user/:id/edit', user.update);\n\n// Posts\n\napp.get('/posts', post.list);\n\n/* istanbul ignore next */\nif (!module.parent) {\n  app.listen(3000);\n  console.log('Express started on port 3000');\n}\n",
      "bug_category": "complexity",
      "error_type": "complexity_reduction",
      "confidence": 0.4
    },
    {
      "bug_id": "57b91976a172",
      "repo": "lodash",
      "commit_hash": "2235819",
      "commit_message": "fix: linting issues (#6033)",
      "file_path": "test/playwright-runner.spec.js",
      "language": "javascript",
      "code_before": "const { test, expect } = require('@playwright/test');\n\ntest.describe.configure({ mode: 'parallel' });\n\ntest('index', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/index.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n\ntest('fp', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/fp.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n\ntest('backbone', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/backbone.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n\ntest('underscore', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/underscore.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});",
      "code_after": "const { test, expect } = require('@playwright/test');\n\ntest.describe.configure({ mode: 'parallel' });\n\ntest('index', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/index.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n\ntest('fp', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/fp.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n\ntest('backbone', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/backbone.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n\ntest('underscore', async ({ page }) => {\n  await page.goto('http://localhost:9001/test/underscore.html');\n  await expect(page.locator('text=0 failed')).toBeVisible({ timeout: 60000 });\n});\n",
      "bug_category": "logic",
      "error_type": "logic_error",
      "confidence": 0.3
    }
  ]
}